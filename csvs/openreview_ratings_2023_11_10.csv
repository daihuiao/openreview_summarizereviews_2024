Title,Mean,Median,StDev,Rating,Confidence,Rating,Confidence,Rating,Confidence,Rating,Confidence,Rating,Confidence,Rating,Confidence,Rating,Confidence,Rating,Confidence,
Modelling Microbial Communities with Graph Neural Networks,4.5, 4.5, 1.5, 6, 3, 6, 3, 3, 3, 3, 4
TabR: Tabular Deep Learning Meets Nearest Neighbors in 2023,5.75, 6.0, 1.7853571071357126, 3, 4, 6, 3, 6, 2, 8, 3
Neural Evolutionary Kernel Method: A Knowledge-Based Learning Architechture for Evolutionary PDEs,4.25, 4.0, 1.299038105676658, 3, 3, 3, 4, 5, 4, 6, 2
PINNacle: A Comprehensive Benchmark of Physics-Informed Neural Networks for Solving PDEs,4.5, 5.5, 2.0615528128088303, 6, 3, 1, 5, 6, 3, 5, 3
SaNN: Simple Yet Powerful Simplicial-aware Neural Networks,6.0, 6.5, 2.1213203435596424, 3, 4, 5, 3, 8, 2, 8, 4
FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search,4.0, 4.0, 1.0, 5, 4, 5, 4, 3, 5, 3, 5
Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models,6.4, 6.0, 1.3564659966250536, 8, 3, 5, 4, 6, 3, 8, 3, 5, 3
Farzi Data: Autoregressive Data Distillation,5.2, 6.0, 1.16619037896906, 3, 4, 5, 2, 6, 3, 6, 4, 6, 3
BATTLE: Towards Behavior-oriented Adversarial Attacks against Deep Reinforcement Learning,4.0, 4.0, 1.0, 5, 4, 3, 4, 3, 3, 5, 4
Understanding Large Language Models Through the Lens of Dataset Generation,5.5, 5.5, 1.8027756377319946, 3, 5, 5, 4, 6, 4, 8, 4
Temporal Parallelization for GPU Acceleration of Spiking Neural Networks,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 4, 3, 3
FSN: Feature Shift Network for Load-Domain Domain Generalization,3.625, 3.0, 1.1110243021644486, 6, 4, 3, 5, 3, 3, 3, 4, 3, 4, 3, 4, 5, 3, 3, 3
Ask Again Then Fail: Large Language Models’ Vacillations in Judgement,6.0, 6.0, 0.0, 6, 4, 6, 4
Do Current Large Language Models Master Adequate Clinical Knowledge?,4.333333333333333, 5.0, 0.9428090415820634, 3, 2, 5, 4, 5, 4
SIMULTANEOUS GENERATION AND IMPROVEMENT: A UNIFIED RL PARADIGM FOR FJSP OPTIMIZATION,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 3, 3, 3
Model-Agnostic Shift-Equivariant Downsampling,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 4, 5, 4, 3, 4
Visuo-emotional perception and Human Cognition to engineer content-generation using Generative AI,2.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 1, 5, 3, 2
Amplifying Training Data Exposure through Fine-Tuning with Pseudo-Labeled Memberships,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 4, 6, 3, 6, 2
FairPATE: Exposing the Pareto Frontier of Fairness Privacy Accuracy and Coverage,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 3, 5, 4
Real-time computer vision on low-end boards via clustering motion vectors,3.25, 3.0, 1.7853571071357126, 3, 4, 1, 4, 6, 4, 3, 3
Beyond Memorization: Violating Privacy via Inference with Large Language Models,7.2, 8.0, 0.9797958971132712, 8, 4, 8, 2, 8, 3, 6, 3, 6, 5
AdaLomo: Low-memory Optimization with Adaptive Learning Rate,3.25, 3.0, 1.7853571071357126, 3, 4, 3, 3, 1, 5, 6, 3
Deep Network Partition Density Exhibits Double Descent,4.25, 4.0, 1.299038105676658, 6, 3, 3, 3, 5, 4, 3, 3
Locality Sensitive Sparse Encoding for Learning World Models Online,6.0, 5.0, 1.4142135623730951, 5, 4, 8, 3, 5, 3
Towards Relaxing the Unbiasedness Condition of Doubly Robust Estimators for Debiased Recommendation,5.5, 5.5, 1.8027756377319946, 3, 4, 5, 4, 6, 3, 8, 3
Instruct2Act: Mapping Multi-modality Instructions to Robotic Arm Actions with Large Language Model,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 4, 3, 4, 5, 4
Beyond Disentanglement: On the Orthogonality of Learned Representations,4.75, 5.0, 1.0897247358851685, 6, 5, 5, 3, 3, 4, 5, 3
Directional Rank Reduction for Backdoor Defense,5.25, 5.0, 0.4330127018922193, 5, 3, 6, 4, 5, 4, 5, 4
Regulation Games for Trustworthy Machine Learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 3, 5, 4
3D Molecular Pretraining via Localized Geometric Generation,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 4, 3, 4
CLIP Exhibits Improved Compositional Generalization Through Representation Disentanglement,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 3, 5, 3
Disentanglement Learning via Topology,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 4, 5, 4
Object-Centric Noise Filtering in Neural Radiance Fields via Influence Functions and Segmentation,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 4, 3, 4
Unified Language Model Alignment with Demonstration and Point-wise Human Preference,4.75, 5.0, 1.0897247358851685, 3, 3, 6, 3, 5, 4, 5, 4
DisFormer: Disentangled Object Representations for Learning Visual Dynamics Via Transformers,3.5, 3.0, 0.8660254037844386, 3, 3, 5, 4, 3, 4, 3, 3
Why are hyperbolic neural networks effective? A study on hierarchical representation capability,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 5, 3, 3, 4
Large Language Models as superpositions of cultural perspectives,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 5, 3
InstaTAP: Instance Motion Estimation for Tracking Any Point,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 4, 3, 4
An Enhanced Gromov-Wasserstein Barycenter Method for Graph-based Clustering,4.5, 4.5, 1.5, 3, 5, 6, 3, 3, 3, 6, 3
Physics-informed neural networks for transformed geometries and manifolds,3.25, 3.0, 1.7853571071357126, 3, 4, 6, 4, 3, 3, 1, 4
Enhancing Neural Subset Selection: Integrating Background Information into Set Representations,5.0, 5.0, 0.0, 5, 4
Causal Impact Index: A Causal Formulation of Citations,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 3
Node-CwR: Node Classification with Reject Option,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4, 3, 4
Segment Anything Meets Universal Adversarial Perturbation,3.0, 3.0, 1.632993161855452, 3, 4, 5, 5, 1, 5
Episode Transformer: Model-based Episodic Reinforcement Learning,3.5, 3.0, 0.8660254037844386, 3, 2, 5, 4, 3, 3, 3, 3
Everyone Deserves A Reward: Learning Customized Human Preferences,4.333333333333333, 5.0, 0.9428090415820634, 5, 2, 3, 3, 5, 4
Bridging Vision and Language Spaces with Assignment Prediction,5.8, 5.0, 1.16619037896906, 5, 4, 5, 5, 6, 5, 5, 4, 8, 3
Fair Domain Generalization with Arbitrary Sensitive Attributes,3.25, 3.0, 1.7853571071357126, 3, 4, 3, 4, 6, 4, 1, 5
Metanetwork: A novel approach to interpreting ANNs,2.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 3, 4, 1, 4
Generative Judge for Evaluating Alignment,5.0, 5.0, 0.0, 5, 2, 5, 3, 5, 4
Rethinking and Extending the Probabilistic Inference Capacity of GNNs,6.6, 6.0, 1.2, 6, 3, 5, 3, 8, 3, 6, 2, 8, 2
Bi-GCL: Efficient Search on Networks,nan, nan, nan
Recurrent Distance-Encoding Neural Networks for Graph Representation Learning,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 5, 3, 6, 3
Learning model uncertainty as variance-minimizing instance weights,5.333333333333333, 5.0, 2.0548046676563256, 5, 3, 3, 3, 8, 3
TVTSv2: Learning Out-of-the-box Spatiotemporal Visual Representations at Scale,6.5, 6.5, 1.5, 8, 4, 5, 4, 8, 3, 5, 4
Controlled Text Generation via Language Model Arithmetic,6.25, 6.0, 1.0897247358851685, 6, 3, 6, 3, 5, 3, 8, 3
Tracking Cognitive Development of Large Language Models,2.5, 3.0, 0.8660254037844386, 3, 5, 1, 5, 3, 4, 3, 4
Black-box Targeted Adversarial Attack on Segment Anything (SAM),3.75, 4.0, 1.920286436967152, 3, 4, 5, 4, 1, 5, 6, 4
Forward Learning with Top-Down Feedback: Empirical and Analytical Characterization,6.0, 6.5, 2.1213203435596424, 5, 3, 3, 4, 8, 4, 8, 3
Do not Start with Trembling Hands: Improving Multi-agent Reinforcement Learning with Stable Prefix Policy,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 3
Chain-of-Symbol Prompting for Spatial Relationships in Large Language Models,5.5, 5.5, 0.5, 6, 4, 6, 3, 5, 3, 5, 4
Lightweight Graph Neural Network Search with Graph Sparsification,5.333333333333333, 5.0, 2.0548046676563256, 3, 5, 8, 2, 5, 4
RLP: A reinforcement learning benchmark for neural algorithmic reasoning,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 3, 3, 4, 5, 4
Vision Transformer with Irregular Attention,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 3, 3, 2, 3, 4
Towards Cross Domain Generalization of Hamiltonian Representation via Meta Learning,4.25, 4.0, 1.299038105676658, 5, 3, 6, 2, 3, 3, 3, 4
UBERT: Unsupervised adaptive early exits in BERT,4.0, 4.0, 1.0, 3, 4, 5, 4, 5, 1, 3, 4
PEACH: Pretrained-embedding Explanation Across Contextual and Hierarchical Structure,4.0, 3.0, 1.4142135623730951, 6, 3, 3, 4, 3, 4
ReLiK: Retrieve Read and LinK: Fast and Accurate Entity Linking and Relation Extraction on an Academic Budget,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 3, 5, 4
What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 3, 6, 4
Causality-Inspired Spatial-Temporal Explanations for Dynamic Graph Neural Networks,4.75, 4.0, 2.0463381929681126, 5, 4, 3, 2, 8, 2, 3, 4
Dissecting learning and forgetting in language model finetuning,5.75, 5.0, 1.299038105676658, 8, 4, 5, 3, 5, 4, 5, 4
MetaFormer with Holistic Attention Modelling Improves Few-Shot Classification,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 6, 5, 5, 3
TinyTrain: Deep Neural Network Training at the Extreme Edge,5.25, 5.0, 1.7853571071357126, 8, 4, 5, 5, 5, 4, 3, 4
Test-time Adaption against Multi-modal Reliability Bias,7.0, 7.0, 1.0, 8, 5, 6, 5, 6, 4, 8, 5
Fully Identical Initialization,5.0, 6.0, 1.4142135623730951, 6, 4, 6, 4, 3, 4
LatentCBF: A Control Barrier Function in Latent Space for Safe Control,4.0, 4.0, 1.0, 3, 4, 5, 4, 5, 4, 3, 4
Mirage: Model-agnostic Graph Distillation for Graph Classification,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 4, 6, 4, 5, 3
Stealing the Invisible: Unveiling Pre-Trained CNN Models through Adversarial Examples and Timing Side-Channels,2.5, 3.0, 0.8660254037844386, 3, 4, 1, 4, 3, 4, 3, 4
A Weakly Supervised and Globally Explainable Learning Framework for Brain Tumor Segmentation,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4, 3, 4
Exploring mechanisms of Neural Robustness: probing the bridge between geometry and spectrum,4.25, 4.0, 1.299038105676658, 6, 4, 3, 4, 3, 4, 5, 4
Two-shot learning of continuous interpolation using a conceptor-aided recurrent autoencoder,5.0, 4.5, 2.1213203435596424, 3, 4, 6, 1, 8, 2, 3, 3
On the Learnability of Watermarks for Language Models,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 6, 4, 5, 3
Personalized Language Generation via Bayesian Metric Augmented Retrieval,5.25, 5.0, 1.7853571071357126, 5, 5, 5, 3, 3, 4, 8, 2
Prompt Sketching for Large Language Models,4.25, 4.0, 1.299038105676658, 3, 4, 3, 3, 6, 3, 5, 4
Consistency Training with Learnable Data Augmentation for Graph Anomaly Detection with Limited Supervision,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 4, 6, 4
AN ENTROPY PERSPECTIVE IN KNOWLEDGE DISTILLATION,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 2
OPTIMIZING STABILIZATION IN SINGULARLY PER- TURBED PROBLEMS WITH SUPG SCHEME,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 3, 3, 5
Bellman Optimal Step-size Straightening of Flow-Matching Models,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 5, 6, 3
Distributional Structured Pruning by Lower bounding the Total Variation Distance using Witness functions,5.0, 6.0, 1.4142135623730951, 6, 3, 6, 3, 3, 3
ZGS-Based Event-Driven Algorithms for Bayesian Optimization in Fully Distributed Multi-Agent Systems,3.25, 3.0, 1.7853571071357126, 1, 3, 6, 2, 3, 4, 3, 4
Boosted Long Short-Term Memory with Additional Inner Layers,2.3333333333333335, 3.0, 0.9428090415820634, 1, 5, 3, 2, 3, 4
An Optimization-Based Framework for Adversarial Defence of Graph Neural Networks Via Adaptive Lipschitz Regularization,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 4, 3, 3, 3, 4
Teaching LLMs to Teach Themselves Better Instructions via Reinforcement Learning,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 5, 3, 3, 4
Diffusion with Synthetic Features: Feature Imputation for Graphs with Partially Observed Features,4.75, 5.0, 1.0897247358851685, 6, 2, 5, 4, 5, 3, 3, 5
LST-Bench:A Benchmark for long sequence time-series forecasting Task,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 1, 5
Enhancing Tail Performance in Extreme Classifiers by Label Variance Reduction,5.5, 5.5, 0.5, 5, 2, 6, 5, 6, 4, 5, 3
Time2Image: A Unified Image Representation Framework for Time Series Classification,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 5, 4, 6, 4
FruitBin: A tunable large-scale dataset for advancing 6D Pose estimation in fruit bin picking automation,4.75, 4.0, 2.0463381929681126, 5, 5, 8, 5, 3, 4, 3, 4
Uncovering the Spectrum of Graph Generative Models: From One-Shot to Sequential,4.8, 5.0, 0.9797958971132712, 5, 4, 5, 4, 6, 3, 3, 3, 5, 3
Universal Algorithm for Extreme Bandits with the Minimal Complexities,3.0, 3.0, 1.4142135623730951, 3, 4, 5, 3, 1, 3, 3, 4
Summing Up the Facts: Additive Mechanisms behind Factual Recall in LLMs,5.0, 5.5, 1.224744871391589, 5, 3, 3, 2, 6, 4, 6, 2
Task-Oriented Multi-View Representation Learning,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 5, 6, 4, 5, 4
Understanding the Mechanics and Dynamics of Memorisation in Large Language Models: A Case Study with Random Strings,5.0, 5.0, 1.0954451150103321, 6, 2, 5, 3, 3, 4, 6, 3, 5, 3
NeFL: Nested Federated Learning for Heterogeneous Clients,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 3, 6, 3
Harnessing Text to Image Diffusion for Dense Prediction Tasks,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 5, 5, 4
Is This the Subspace You Are Looking for? An Interpretability Illusion for Subspace Activation Patching,6.333333333333333, 8.0, 2.357022603955158, 8, 2, 3, 3, 8, 3
Fixed-Budget Best Arm Identification with Variance-Dependent Regret Bounds,6.0, 5.5, 1.224744871391589, 5, 4, 6, 3, 8, 3, 5, 3
Symmetric Mean-field Langevin Dynamics for Distributional Minimax Problems,6.6, 6.0, 1.2, 8, 2, 6, 4, 6, 3, 8, 3, 5, 3
Causal Inference Using LLM-Guided Discovery,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 3, 3, 3
Learning Predictive Checklists with Probabilistic Logic Programming,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 3, 4, 5, 4
Parrot: Enhancing Multi-Turn Chat Models by Learning to Ask Questions,5.5, 5.5, 1.8027756377319946, 3, 5, 5, 4, 6, 4, 8, 4
Knowledge Graph Completion by Intermediate Variables Regularization,5.25, 5.0, 1.7853571071357126, 8, 4, 3, 5, 5, 4, 5, 4
Attributed Graph Clustering via Coarsening with Modularity,3.4, 3.0, 0.8, 3, 4, 3, 4, 3, 5, 5, 4, 3, 3
MAGDiff: Covariate Data Set Shift Detection via Activation Graphs of Deep Neural Networks,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 3, 3, 4, 5, 3
Prototypes-Injected Prompt for Federated Class Incremental Learning,4.25, 4.0, 1.299038105676658, 6, 1, 5, 4, 3, 5, 3, 4
Demonstration-Regularized RL,5.25, 5.0, 1.7853571071357126, 3, 2, 5, 3, 8, 2, 5, 2
Explorative Latent Self-Supervised Active Search Algorithm (ELSA),4.0, 5.0, 2.160246899469287, 1, 4, 5, 2, 6, 3
Negative-prompt Inversion: Fast Image Inversion for Editing with Text-guided Diffusion Models,4.75, 5.0, 1.0897247358851685, 6, 4, 3, 4, 5, 4, 5, 4
GatedMTL: Learning to Share Specialize and Prune Representations for Multi-task Learning,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 3, 3, 4
PDE-Diffusion: Physic guided diffusion model for solving partial derivative equations,2.2, 3.0, 0.9797958971132712, 3, 4, 3, 3, 3, 5, 1, 4, 1, 5
BEV-CLIP: Multi-modal BEV Retrieval Methodology for Complex Scene in Autonomous Driving,4.0, 4.0, 1.0, 5, 4, 3, 5, 3, 4, 5, 4
Differentiable Optimization in Plane-Wave Density Functional Theory for Solid States,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 2, 5, 3, 3, 3
Multilingual Jailbreak Challenges in Large Language Models,5.2, 6.0, 1.16619037896906, 3, 4, 6, 3, 6, 4, 5, 4, 6, 4
Instruction-tuned LLMs with World Knowledge are More Aligned to the Human Brain,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 6, 3, 3, 2
Brain-inspired Geometry Constrain on Represention for Compositional Generalization,3.0, 3.0, 1.4142135623730951, 1, 3, 3, 4, 5, 4, 3, 3
Mask Frozen-DETR: High Quality Instance Segmentation with One GPU,4.25, 4.0, 1.299038105676658, 5, 4, 3, 5, 3, 3, 6, 4
Categorical Features of entities in Recommendation Systems Using Graph Neural Networks,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 5, 4
Generalized Policy Iteration using Tensor Approximation for Hybrid Control,6.75, 7.0, 1.299038105676658, 8, 4, 8, 4, 6, 2, 5, 3
$t^3$-Variational Autoencoder: Learning Heavy-tailed Data with Student's t and Power Divergence,7.333333333333333, 8.0, 0.9428090415820634, 8, 4, 6, 4, 8, 3
Neuron to Graph: Interpreting Language Model Neurons at Scale,4.0, 5.0, 1.7888543819998317, 6, 3, 5, 4, 1, 4, 3, 4, 5, 5
Residual Factorized Fourier Neural Operator for simulation of three-dimensional turbulence,3.0, 3.0, 0.0, 3, 3, 3, 5, 3, 4, 3, 4
Adjustable Quantile-Guided Diffusion Policy for Diverse Behavior Generation in Offline RL,4.0, 4.0, 1.0, 5, 4, 3, 3, 3, 4, 5, 3
Cooperative Hardware-Prompt Learning for Snapshot Compressive Imaging,6.5, 6.5, 1.5, 5, 3, 8, 5, 8, 4, 5, 4
Prompt Optimization via Adversarial In-Context Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 3
FEATHER: Lifelong Test-Time Adaptation with Lightweight Adapters,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 4, 5, 4
FLAT-Chat: A Word Recovery Attack on Federated Language Model Training,4.25, 4.0, 1.299038105676658, 3, 5, 3, 4, 5, 4, 6, 4
Chain-of-Thought Predictive Control,5.5, 5.5, 0.5, 5, 4, 5, 3, 6, 4, 6, 4
Adapting ConvNets for New Cameras without Retraining,3.5, 4.0, 1.6583123951777, 5, 5, 3, 5, 5, 4, 1, 4
Rethinking the Power of Graph Canonization in Graph Representation Learning with Stability,4.5, 4.5, 1.5, 6, 3, 3, 4
Relating Implicit Bias and Adversarial Attacks through Intrinsic Dimension,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 5, 3, 4, 5, 4
Rethinking Actor-Critic: Successive Actors for Critic Maximization,4.0, 4.0, 1.0, 5, 4, 5, 3, 3, 5, 3, 3
Gradual Optimization Learning for Conformational Energy Minimization,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 3, 5, 4, 6, 3
AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly Detection,6.166666666666667, 5.5, 1.3437096247164249, 8, 3, 5, 5, 6, 5, 5, 4, 8, 3, 5, 3
Chat Vector: A Simple Approach to Equip LLMs With New Language Chat Capabilities,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 6, 3, 5, 3
Generative Models are Self-Watermarked: Intellectual Property Declaration through Re-Generation,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 3, 5, 3
Nonlinear Inference Learning for Differentially Private Massive Data,2.5, 3.0, 0.8660254037844386, 3, 4, 1, 3, 3, 5, 3, 4
Boosting Selective Rationalization with Shortcuts Discovery,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 3, 6, 3
RL4CO: a Unified Reinforcement Learning for Combinatorial Optimization Library,4.0, 4.0, 1.0, 5, 3, 3, 4, 5, 4, 3, 3
IKL: Boosting Long-Tail Recognition with Implicit Knowledge Learning,4.333333333333333, 5.0, 0.9428090415820634, 3, 5, 5, 5, 5, 4
GPT Can Solve Mathematical Problems Without a Calculator,6.0, 6.5, 2.1213203435596424, 8, 4, 3, 4, 8, 3, 5, 4
S4G: Breaking the Bottleneck on Graphs with Structured State Spaces,4.666666666666667, 3.0, 2.357022603955158, 8, 3, 3, 4, 3, 4
CORN: Contact-based Object Representation for Nonprehensile Manipulation of General Unseen Objects,6.0, 5.5, 2.5495097567963922, 6, 4, 5, 4, 3, 3, 10, 4
An Intuitive Multi-Frequency Feature Representation for SO(3)-Equivariant Networks,5.2, 6.0, 1.16619037896906, 3, 2, 6, 4, 6, 3, 6, 3, 5, 4
Language-Independent Embeddings for Entity Recognition via LLM Data-Level Knowledge Distillation,nan, nan, nan
CodeComplex: A Time-complexity Dataset for Multi-language Source Codes,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 3, 5, 4
Implicit Regularisation in Overparametrized Networks: A Multiscale Analysis of the Fokker-Planck equation,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 3, 3, 3, 5, 4
KoLA: Carefully Benchmarking World Knowledge of Large Language Models,6.75, 7.0, 1.299038105676658, 5, 2, 6, 4, 8, 2, 8, 4
Screening Unlearnable Examples via Iterative Self Regression,3.5, 4.0, 1.6583123951777, 1, 5, 3, 4, 5, 4, 5, 4
Graph Parsing Networks,5.5, 5.5, 1.8027756377319946, 5, 3, 8, 3, 6, 5, 3, 4
Retrieving Texts by Abstract Descriptions,4.6, 5.0, 0.7999999999999999, 5, 3, 3, 4, 5, 4, 5, 5, 5, 3
TESTAM: A Time-Enhanced Spatio-Temporal Attention Model with Mixture of Experts,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 5, 4, 6, 3
Improving SAM Requires Rethinking its Optimization Formulation,6.0, 5.5, 2.5495097567963922, 3, 3, 5, 4, 6, 3, 10, 4
RedMotion: Motion Prediction via Redundancy Reduction,5.333333333333333, 5.0, 2.0548046676563256, 3, 5, 8, 4, 5, 2
TILDE-Q: A Transformation Invariant Loss Function for Time-Series Forecasting,5.5, 5.5, 1.8027756377319946, 5, 4, 6, 4, 3, 4, 8, 4
Learning From Simplicial Data Based on Random Walks and 1D Convolutions,6.0, 6.5, 2.1213203435596424, 8, 5, 3, 4, 8, 4, 5, 2
Adaptive Environmental Modeling for Task-Oriented Language Agents,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 3, 5, 3
LUM-ViT: Learnable Under-sampling Mask Vision Transformer for Bandwidth Limited Optical Signal Acquisition,5.666666666666667, 6.0, 0.4714045207910317, 6, 5, 6, 4, 5, 3
Sensitivity-Aware Differentially Private Decentralized Learning with Adaptive Noise,4.0, 3.0, 1.2649110640673518, 3, 4, 3, 4, 3, 3, 6, 3, 5, 3
EvIL: Evolution Strategies for Generalisable Imitation Learning,3.75, 3.0, 1.299038105676658, 3, 5, 6, 3, 3, 4, 3, 3
RILe: Reinforced Imitation Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 5
Few Heads are Enough,4.0, 3.0, 1.4142135623730951, 3, 3, 3, 4, 6, 3
LMExplainer: A Knowledge-Enhanced Explainer for Language Models,4.75, 5.0, 1.0897247358851685, 3, 3, 6, 3, 5, 3, 5, 4
Optimal spherical codes for locality-sensitive hashing,2.5, 3.0, 0.8660254037844386, 3, 4, 1, 5, 3, 4, 3, 3
ProtChatGPT: Towards Understanding Proteins with Large Language Models,5.0, 5.5, 1.224744871391589, 6, 4, 5, 3, 6, 4, 3, 4
Bayesian Vector Optimization with Gaussian Processes,5.25, 5.0, 0.4330127018922193, 5, 5, 5, 2, 5, 3, 6, 2
Meta- (out-of-context) learning in neural networks,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 2, 5, 4, 6, 2
On the Long Range Abilities of Transformers,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 4, 5, 4, 5, 3
Social-Transmotion: Promptable Human Trajectory Prediction,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 5, 5, 5, 3, 5
Efficient architectural aspects for text-to-video generation pipeline,5.0, 5.0, 0.0, 5, 5, 5, 3, 5, 4
Gandalf: Learning label correlations in Extreme Multi-label Classification via Label Features,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 6, 5, 5, 4
Robust Classification via Regression-Based Loss Reweighting and Label Correction,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 5, 4, 6, 3
Subject-specific Deep Neural Networks for Count Data with High-cardinality Categorical Features,5.0, 6.0, 1.4142135623730951, 3, 3, 6, 2, 6, 3
ProteinAdapter: Adapting Pre-trained Large Protein Models for Efficient Protein Representation Learning,4.0, 4.0, 1.0, 3, 3, 3, 3, 5, 4, 5, 5
Let's reward step by step: Step-Level reward model as the Navigators for  Reasoning,4.6, 5.0, 0.7999999999999999, 3, 4, 5, 5, 5, 3, 5, 3, 5, 2
Generalization error of spectral algorithms,8.0, 8.0, 0.0, 8, 3, 8, 3, 8, 2
Slot Structured World Models,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 5, 3, 4, 5, 3
Observer Uncertainty of Learning in Games from a Covariance Perspective,5.0, 5.5, 1.224744871391589, 6, 3, 5, 3, 6, 3, 3, 3
Contrastive Implicit Representation Learning,2.3333333333333335, 3.0, 0.9428090415820634, 1, 3, 3, 3, 3, 3
LLM+A: Grounding Large Language Models in Physical World with Affordance Prompting,4.25, 4.0, 1.299038105676658, 5, 4, 3, 5, 3, 4, 6, 3
DAS$^2$C: A Distributed Adaptive Minimax Method with Near-Optimal Convergence,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 4, 3, 5, 5, 5
Learning to Reject with a Fixed Predictor: Application to Decontextualization,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 3, 3, 3
Disentangling Covariates to Predict Counterfactuals for single-cell data,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4, 3, 4
All Languages Matter: On the Multilingual Safety of Large Language Models,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 3, 3, 3, 3, 5
Deep Anti-Regularized Ensembles,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 4, 5, 3, 3, 4
CLASS-INCREMENTAL LEARNING USING GENERATIVE EXPERIENCE REPLAY BASED ON TIME-AWARE REGULARIZATION,3.75, 3.0, 1.299038105676658, 6, 4, 3, 2, 3, 4, 3, 3
Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging,4.25, 3.0, 2.165063509461097, 3, 4, 3, 5, 3, 5, 8, 2
Thin-Thick Adapter: Segmenting Thin Scans Using Thick Annotations,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 5, 3, 6, 4
$\gamma$-Orthogonalized Tensor Deflation: Towards Robust \& Interpretable Tensor Decomposition in the Presence of Correlated Components,5.25, 5.0, 1.7853571071357126, 3, 3, 5, 3, 8, 5, 5, 3
Dynamics-Informed Protein Design with Structure Conditioning,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 6, 4, 5, 4
DfPO: Degeneration-free Policy Optimization via Action Masking in Natural Language Action Spaces,5.25, 5.0, 1.7853571071357126, 5, 4, 5, 4, 8, 3, 3, 3
SR-OOD: Out-of-Distribution Detection via Sample Repairing,3.75, 3.0, 1.299038105676658, 3, 5, 3, 5, 6, 3, 3, 4
Syntactic Representations Enable Interpretable Hierarchical Word Vectors,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 4, 5, 3
On Synthetic Data and Iterative Magnitude Pruning: a Linear Mode Connectivity Study,3.75, 4.0, 1.920286436967152, 5, 3, 3, 5, 1, 4, 6, 3
Can General-Purpose Language Models Emulate a General-Purpose Computer In-Context?,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 5, 3, 4
VRAda: A Variance Reduced Adaptive Algorithm for Stochastic Parameter-Agnostic Minimax Optimizations,3.5, 3.0, 0.8660254037844386, 5, 5, 3, 4, 3, 3, 3, 4
Unlocking Anticipatory Text Generation: A Constrained Approach for Faithful Decoding with Large Language Models,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 3, 3, 6, 3
Partitioning Message Passing for Graph Fraud Detection,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 5, 4, 6, 3
Self-contradictory Hallucinations of Large Language Models: Evaluation Detection and Mitigation,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 4
Non-backtracking Graph Neural Networks,4.2, 5.0, 0.9797958971132712, 5, 5, 3, 4, 5, 4, 5, 3, 3, 4
FHA-Kitchens: A Novel Dataset for Fine-Grained Hand Action Recognition in Kitchen Scenes,4.0, 4.0, 1.0, 5, 3, 3, 5, 5, 4, 3, 4
Towards Analyzing Self-attention via Linear Neural Network,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 3, 5, 4
Do LLMs understand Pragmatics? An Extensive Benchmark for Evaluating Pragmatic Understanding of LLMs,nan, nan, nan
Efficient Denoising Diffusion via Probabilistic Masking,6.0, 6.5, 2.1213203435596424, 5, 4, 8, 3, 8, 3, 3, 3
Phase Transitions in Contrastive Learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 3, 3, 4
There is More to Graphs than Meets the Eye: Learning Universal Features with Self-supervision,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 5, 4
Latent Lie Group Representations,3.6666666666666665, 5.0, 1.8856180831641267, 5, 4, 1, 3, 5, 3
CORE: Common Random Reconstruction for Distributed Optimization with Provable Low Communication Complexity,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 3
The KNN Score for Evaluating Probabilistic Multivariate Time Series Forecasting,3.0, 3.0, 1.632993161855452, 3, 4, 1, 5, 5, 4
ProFeAT: Projected Feature Adversarial Training for Self-Supervised Learning of Robust Representations,5.5, 5.5, 0.5, 6, 5, 5, 4, 6, 5, 5, 4
Semi-Anchored Gradient Methods for Nonconvex-Nonconcave Minimax Problems,4.25, 4.0, 1.299038105676658, 3, 3, 3, 4, 6, 4, 5, 4
Tensor-Train Point Cloud Compression and Efficient Approximate Nearest Neighbor Search,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 6, 3, 3, 3
Automating Continual Learning,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 3
When does In-context Learning Fall Short and Why? A Study on Specification-Heavy Tasks,4.0, 4.0, 1.0, 3, 4, 5, 3, 5, 4, 3, 4
Mitigating backdoor attacks with generative modelling and dataset relabelling,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 3, 5, 4, 5, 3
Layer-wise Pre-weight Decay,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 6, 3, 3, 5
Efficient Unsupervised Knowledge Distillation with Space Similarity,4.8, 5.0, 0.9797958971132712, 5, 4, 3, 4, 5, 3, 6, 4, 5, 3
A Convergent Federated Clustering  Algorithm without Initial Condition,4.0, 4.0, 1.0, 3, 4, 5, 3, 5, 2, 3, 5
Antibody DomainBed: Out-of-Distribution Generalization in Therapeutic Protein Design,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 3, 6, 4, 5, 3
Adaptive Causal Balancing for Collaborative Filtering,5.666666666666667, 6.0, 2.0548046676563256, 8, 3, 6, 3, 3, 4
Integrated Model Explanations by Independent and Collaborative Feature Influence via Linear-Nonlinear Perspectives.,3.4, 3.0, 0.8000000000000002, 5, 4, 3, 3, 3, 4, 3, 4, 3, 4
Where is the Invisible: Spatial-Temporal Reasoning with Object Permanence,4.5, 5.0, 0.8660254037844386, 5, 5, 5, 4, 5, 4, 3, 5
Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems,5.5, 5.5, 1.8027756377319946, 3, 5, 8, 3, 5, 3, 6, 4
Symmetric Neural-Collapse Representations with Supervised Contrastive Loss: The Impact of ReLU and Batching,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 4, 5, 3, 6, 4
Manipulating dropout reveals an optimal balance of efficiency and robustness in biological and machine visual systems,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 3
Controllable Text-to-Image Generation with Automatic Sketches,4.333333333333333, 5.0, 0.9428090415820634, 5, 5, 3, 4, 5, 4
Knowledge Distillation with Perturbed Loss: From a Vanilla Teacher to a Proxy Teacher,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 3, 5, 4
Estimation error of gradient descent in deep regressions,4.25, 4.0, 1.299038105676658, 6, 4, 3, 3, 5, 3, 3, 3
Fast Conditional Intervention in Algorithmic Recourse with Reinforcement Learning,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 3, 6, 4, 5, 3
Domain-agnostic Latent Diffusion Models for Synthesizing High-Quality Implicit Neural Representations,6.0, 6.0, 0.0, 6, 3, 6, 4, 6, 3, 6, 4
DreamFuser: Value-guided Diffusion Policy for Offline Reinforcement Learning,4.0, 3.0, 1.4142135623730951, 6, 3, 3, 4, 3, 3
2D-Supervised Monocular 3D Object Detection by Global-to-Local Reconstruction,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 4, 6, 4
TANGO: Time-Reversal Latent GraphODE for Multi-Agent Dynamical Systems,4.75, 4.0, 2.0463381929681126, 8, 4, 3, 3, 5, 3, 3, 4
Post-Training Recovery from Injected Bias with Self-Influence,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 2, 3, 3
Feature Selection in the Presence of Monotone Batch Effects,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4
Misusing Tools in Large Language Models With Visual Adversarial Examples,4.25, 4.0, 1.299038105676658, 6, 5, 3, 4, 5, 4, 3, 3
FedLoRA: When Personalized Federated Learning Meets Low-Rank Adaptation,5.4, 5.0, 1.624807680927192, 6, 3, 3, 5, 8, 3, 5, 5, 5, 3
Exploring Active Learning in Meta-Learning: Enhancing Context Set Labeling,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 3, 6, 4, 5, 3
A Neural Sandbox Framework for Discovering Spurious Concpets in LLM Decisions,2.0, 2.0, 1.0, 1, 4, 3, 3, 1, 3, 3, 4
From Random to Relevant: Harnessing Salient Masks in Non-IID Federated Learning,5.0, 6.0, 1.4142135623730951, 3, 3, 6, 2, 6, 5
MedJourney: Counterfactual Medical Image Generation by Instruction-Learning from Multimodal Patient Journeys,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 6, 4, 5, 4
Bayesian Coreset Optimization for Personalized Federated Learning,5.0, 6.0, 1.4142135623730951, 6, 2, 3, 3, 6, 3
Fooling the Textual Fooler via Randomizing Latent Representations,4.75, 5.0, 1.0897247358851685, 5, 5, 3, 5, 6, 3, 5, 5
In-context Autoencoder for Context Compression in a Large Language Model,6.5, 6.5, 1.5, 5, 4, 5, 4, 8, 5, 8, 4
Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning,6.5, 6.5, 1.5, 8, 3, 8, 4, 5, 3, 5, 4
Implicit Neural Representation Image Codec with Mixed Context for Fast Decoding,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 4, 3, 4
DECOUPLING REASONING FROM OBSERVATIONS FOR EFFICIENT AUGMENTED LANGUAGE MODELS,4.25, 4.0, 1.299038105676658, 5, 4, 6, 3, 3, 3, 3, 5
Multimarginal Generative Modeling with Stochastic Interpolants,6.0, 5.0, 1.4142135623730951, 5, 3, 5, 4, 8, 3
Neural Bounds on Bayes Error: Advancing Classification and Generative Models,2.3333333333333335, 3.0, 0.9428090415820634, 3, 2, 3, 4, 1, 5
Proving Test Set Contamination for Black-Box Language Models,6.75, 7.0, 1.299038105676658, 5, 3, 6, 3, 8, 3, 8, 3
Leveraging Cross-Modal Neighbor Representation for Improved CLIP Classification,4.5, 5.0, 0.8660254037844386, 5, 5, 3, 4, 5, 5, 5, 2
Stochastic interpolants with data-dependent couplings,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 4
FILI: Syntax Repair By Learning From Own Mistakes,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 3, 5, 4, 3, 5
GrowLength: Accelerating LLMs Pretraining by Progressively Growing Training Length,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 3, 4, 6, 3
Meta Compression: Learning to compress Deep Neural Networks,4.0, 4.0, 1.0, 3, 5, 5, 4, 5, 3, 3, 3
Non-Autoregressive Machine Translation as Constrained HMM,5.333333333333333, 5.0, 2.0548046676563256, 8, 4, 5, 4, 3, 4
Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling,5.0, 5.0, 1.0954451150103321, 3, 5, 6, 4, 5, 4, 5, 3, 6, 3
Efficiently Measuring the Cognitive Ability of LLMs: An Adaptive Testing Perspective,4.0, 4.0, 1.0, 5, 4, 5, 3, 3, 4, 3, 2
Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 2, 6, 3, 6, 2
Structured Graph Reduction for Efficient GNN,4.25, 4.0, 1.299038105676658, 3, 2, 3, 4, 5, 4, 6, 3
RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval,6.0, 6.5, 2.1213203435596424, 8, 3, 8, 3, 3, 3, 5, 4
Fair and Efficient Contribution Valuation for Vertical Federated Learning,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 3, 5, 3, 5, 4
Principal Component Analysis for Cross-Sectionally Correlated Pricing Errors,3.5, 3.0, 0.8660254037844386, 3, 5, 5, 3, 3, 3, 3, 3
Self Guided Exploration for Automatic and Diverse AI Supervision,4.5, 4.5, 1.5, 6, 3, 3, 3, 3, 3, 6, 4
Interpretable and Convergent Graph Neural Network Layers at Scale,5.2, 6.0, 1.9390719429665317, 8, 3, 3, 3, 6, 3, 6, 3, 3, 5
Learning Invariances via Neural Network Pruning,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 5, 3, 3
In-Context Learning through the Bayesian Prism,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 3, 5, 2
Fewer is More: Trojan Attacks on Parameter-Efficient Fine-Tuning,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 5, 5, 4
Harnessing Overlap in Blockwise Transformers for Near-Infinite Context,5.5, 5.5, 1.8027756377319946, 5, 4, 8, 3, 3, 5, 6, 4
L-MBOP-E: Latent-Model Based Offline Planning with Extrinsic Policy Guided Exploration,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 5, 4, 3, 3
Chain of Hindsight aligns Language Models with Feedback,7.0, 7.0, 1.0, 6, 4, 6, 3, 8, 3, 8, 4
Bounding the Robustness and Generalization for Individual Treatment Effect,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 4, 3, 3, 5, 3
GraphChef: Decision-Tree Recipes to Explain Graph Neural Networks,6.6, 6.0, 1.2, 5, 4, 8, 2, 6, 3, 8, 4, 6, 4
Safe Collaborative Filtering,7.0, 8.0, 1.4142135623730951, 8, 2, 8, 3, 5, 3
MAP's not dead yet: Uncovering true language model modes by conditioning away degeneracy,4.75, 4.0, 2.0463381929681126, 3, 4, 5, 3, 8, 4, 3, 4
On Representation Complexity of Model-based and Model-free Reinforcement Learning,6.0, 5.0, 1.4142135623730951, 5, 2, 5, 4, 8, 2
TPA-Gen: A Multi-modal Data Generative Method for Text and Physics-based Animation,3.0, 3.0, 1.632993161855452, 1, 3, 5, 3, 3, 3
Addressing Catastrophic Forgetting and Loss of Plasticity in Neural Networks,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 6, 3, 5, 4
Understanding Multimodal Instruction Format for In-context Learning,5.25, 5.0, 0.4330127018922193, 5, 5, 5, 4, 6, 4, 5, 4
Creative Robot Tool Use with Large Language Models,5.25, 5.0, 1.7853571071357126, 5, 4, 3, 4, 8, 3, 5, 3
DFITE: Estimation of Individual Treatment Effect Using Diffusion Model,3.4, 3.0, 0.8, 3, 3, 3, 4, 3, 4, 5, 3, 3, 4
Hessian-Aware Bayesian Optimization for Decision Making Systems,4.4, 5.0, 2.33238075793812, 5, 2, 5, 2, 8, 4, 3, 3, 1, 4
A Good Learner can Teach Better: Teacher-Student Collaborative Knowledge Distillation,6.25, 6.0, 1.0897247358851685, 6, 3, 8, 4, 5, 4, 6, 1
Unsupervised Representation Learning of Brain Activity via Bridging Voxel Activity and Functional Connectivity,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 4, 5, 4
Diagnosing Transformers: Illuminating Feature Spaces for Clinical Decision-Making,6.666666666666667, 6.0, 0.9428090415820634, 6, 4, 8, 4, 6, 3
What happens when you fine-tuning your model? Mechanistic analysis of procedurally generated tasks.,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 4, 5, 4
LLMatic: Neural Architecture Search via Large Language Models and Quality Diversity Optimization,3.4, 3.0, 0.8000000000000002, 3, 4, 5, 3, 3, 4, 3, 4, 3, 5
Combine and Compare: Graph Rationale Learning with Conditional Non-Rationale Sampling,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 4, 3, 4, 3, 4
Harnessing Discrete Representations for Continual Reinforcement Learning,6.0, 5.5, 1.224744871391589, 5, 4, 5, 4, 8, 3, 6, 4
Learning Dynamical Systems with Helmholtz-Hodge Decomposition and Gaussian Processes,5.6, 6.0, 1.624807680927192, 8, 3, 5, 3, 6, 4, 3, 4, 6, 3
MiniFold: Simple Fast and Accurate Protein Structure Prediction,4.25, 4.0, 1.299038105676658, 3, 5, 5, 3, 6, 4, 3, 4
Who’s Harry Potter? Approximate Unlearning for LLMs,5.25, 5.0, 1.7853571071357126, 5, 3, 5, 4, 3, 3, 8, 3
RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems,6.0, 5.0, 1.4142135623730951, 5, 3, 8, 4, 5, 3
Outliers Memorized Last: Trends in Memorization of Diffusion Models Based on Training Distribution and Epoch,1.5, 1.0, 0.8660254037844386, 1, 4, 3, 4, 1, 5, 1, 5
Seeking Neural Nuggets: Knowledge Transfer in Large Language Models from a Parametric Perspective,6.333333333333333, 6.0, 1.247219128924647, 8, 1, 6, 3, 5, 4
Generalization Error Analysis of Deep Physical Models With Latent Variables Trained on Trajectory Data,5.25, 5.0, 1.7853571071357126, 3, 4, 5, 1, 5, 3, 8, 1
Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 3, 5, 6, 5
GNN-based Probabilistic Supply and Inventory Predictions in Supply Chain Networks,3.75, 4.0, 1.920286436967152, 1, 4, 3, 3, 5, 5, 6, 3
Multi-Scale Generative Modeling in Wavelet Domain,4.0, 3.0, 2.943920288775949, 3, 4, 8, 2, 1, 3
A Theoretical Explanation of Deep RL Performance in Stochastic Environments,4.75, 5.0, 1.0897247358851685, 6, 4, 3, 3, 5, 3, 5, 2
SMILE: Audio-Visual Speech Recognition with Siamese Masked Interaction Learning,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 4, 5, 4
Investigating the Fairness of Large Language Models for Predictions on Tabular Data,4.0, 4.0, 1.0, 3, 4, 3, 4, 3, 4, 5, 4, 5, 4, 5, 4
SuRe: Improving Open-domain Question Answering of LLMs via Summarized Retrieval,6.2, 6.0, 0.9797958971132712, 5, 4, 8, 4, 6, 4, 6, 4, 6, 4
Reinforced UI Instruction Grounding: Towards a Generic UI Task Automation API,5.75, 6.0, 0.4330127018922193, 5, 4, 6, 3, 6, 4, 6, 3
An Explainable AI-based Complementary Attention Mechanism for Detecting Identity Swaps,3.0, 3.0, 1.632993161855452, 1, 5, 5, 3, 3, 4
Retrieval meets Long Context Large Language Models,6.833333333333333, 7.0, 1.2133516482134197, 8, 3, 5, 4, 8, 4, 6, 3, 8, 4, 6, 3
From Child's Play to AI: Insights into Automated Causal Curriculum Learning,4.4, 3.0, 1.9595917942265424, 3, 4, 3, 4, 3, 3, 5, 3, 8, 4
Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 4, 5, 3
Certified Robustness on Visual Graph Matching via Searching Optimal Smoothing Range,6.0, 6.0, 0.0, 6, 4, 6, 3, 6, 4
DAME: A Distillation Based Approach For Model-agnostic Local Explainability,5.25, 6.0, 1.299038105676658, 3, 4, 6, 4, 6, 4, 6, 3
Neural Spectral Methods,5.25, 6.0, 1.299038105676658, 6, 4, 6, 4, 6, 4, 3, 4
Heterogeneous Decision Making towards Mixed Autonomy: When Uncertainty-aware Planning Meets Bounded Rationality,4.5, 4.5, 1.5, 3, 2, 6, 2, 3, 3, 6, 2
Plasticity-Driven Sparsity Training for Deep Reinforcement Learning,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 4, 3, 5, 3, 3
ScoreFlow: Bridging Score and Neural ODE for Reversible Generative Modeling,3.4, 3.0, 1.4966629547095767, 3, 4, 3, 4, 5, 4, 5, 4, 1, 4
Moral High Ground: A text-based games benchmark for moral evaluation,3.0, 3.0, 2.0, 1, 4, 5, 4, 5, 3, 1, 4
Achieving Certified Robustness and Maintaining Clean Accuracy via Vanilla Model Guide,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 3, 3, 4
Generating Images in Context with Multimodal Large Language Models,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 4, 6, 4
Learning to Explore for Stochastic Gradient MCMC,4.25, 4.0, 1.299038105676658, 3, 4, 5, 5, 3, 4, 6, 3
Selective Visual Representations Improve Convergence and Generalization for Embodied AI,6.5, 6.0, 0.8660254037844386, 6, 4, 8, 3, 6, 3, 6, 4
Fairness-Aware Attention for Contrastive Learning,3.6666666666666665, 3.0, 0.9428090415820634, 5, 2, 3, 4, 3, 3
High variance score function estimates help diffusion models generalize,4.0, 4.0, 1.0, 5, 4, 5, 4, 3, 4, 3, 3
STARLING: Self-supervised Training of Text-based Reinforcement Learning Agent with Large Language Models,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 5, 3, 4, 3, 4
Assessing Uncertainty in Similarity Scoring: Performance & Fairness in Face Recognition,5.333333333333333, 5.0, 2.0548046676563256, 3, 4, 5, 3, 8, 3
Lightweight Language Model Calibration for Open-ended Question Answering with Varied Answer Lengths,6.0, 5.0, 1.4142135623730951, 8, 3, 5, 3, 5, 3
Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models,5.75, 6.0, 1.7853571071357126, 6, 4, 8, 5, 3, 4, 6, 4
FusionViT: Hierarchical 3D Object Detection via Lidar-Camera Vision Transformer Fusion,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 5, 5, 4
Improving Generalization of Alignment with Human Preferences through Group Invariant Learning,6.5, 5.5, 2.0615528128088303, 5, 4, 10, 4, 6, 3, 5, 3
Learning and Forgetting Unsafe Examples in Large Language Models,4.25, 4.0, 1.299038105676658, 5, 3, 3, 3, 6, 4, 3, 5
Deep-Learning Approaches for Optimized Web Accessibility: Correcting Violations and Enhancing User Experience,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 4
Chain-of-Knowledge: Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 3, 5, 4, 6, 4
Disentangled Heterogeneous Collaborative Filtering,4.666666666666667, 5.0, 1.247219128924647, 5, 2, 3, 2, 6, 4
Policy Rehearsing: Training Generalizable Policies for Reinforcement Learning,6.25, 6.0, 1.0897247358851685, 5, 4, 8, 3, 6, 3, 6, 3
Energy-based Automated Model Evaluation,5.4, 5.0, 2.244994432064365, 8, 3, 8, 4, 3, 5, 3, 3, 5, 3
Explanation-aware Soft Ensemble Empowers Large Language Model In-context Learning,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 4, 5, 4
Deceptive Fairness Attacks on Graphs via Meta Learning,6.75, 7.0, 1.299038105676658, 8, 3, 5, 5, 8, 3, 6, 3
What Matters to You? Towards Visual Representation Alignment for Robot Learning,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 3, 5, 4, 6, 3
Village-Net clustering: A novel unsupervised manifold clustering method,3.8, 3.0, 0.9797958971132712, 3, 5, 5, 4, 3, 4, 5, 4, 3, 4
Zero-shot Clustering of Embeddings with Pretrained and Self-Supervised Learning Encoders,3.5, 4.0, 1.6583123951777, 5, 4, 1, 5, 3, 4, 5, 4
Genetic Algorithm for Curriculum Generation in Multi-Agent Reinforcement Learning,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 4, 5, 3, 3, 3
Correct and speak: accent reduction with minimum supervision,4.75, 5.0, 2.48746859276655, 5, 3, 5, 4, 8, 4, 1, 5
Faster Maximum Inner Product Search in High Dimensions,2.0, 2.0, 1.0, 3, 3, 1, 4, 3, 3, 1, 5
PINNACLE: PINN Adaptive ColLocation and Experimental points selection,6.75, 7.0, 1.299038105676658, 8, 4, 8, 4, 6, 3, 5, 3
FedDA: Faster Adaptive Gradient Methods for Federated Constrained Optimization,6.0, 6.0, 0.0, 6, 4, 6, 3, 6, 3
A Differentiable Physical Simulation Framework for Soft Robots on Multiple-Task Learning,5.0, 5.5, 1.224744871391589, 6, 3, 3, 4, 5, 4, 6, 4
Use Your INSTINCT: INSTruction optimization usIng Neural bandits Coupled with Transformers,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 5, 6, 3, 5, 5
Instructing Large Language Models to Identify and Ignore Irrelevant Conditions,5.0, 5.5, 1.224744871391589, 6, 4, 3, 3, 6, 3, 5, 4
Adaptive Expansion for Hypergraph Learning,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 3, 6, 5, 3, 4
G2PTL: A Pre-trained Model for Delivery Address and its Applications in Logistics System,6.333333333333333, 6.0, 1.247219128924647, 8, 5, 5, 4, 6, 4
BooookScore: A systematic exploration of book-length summarization in the era of LLMs,7.5, 7.0, 1.6583123951777, 6, 3, 10, 5, 6, 4, 8, 4
NP-GL: Extending Power of Nature from Binary Problems to Real-World Graph Learning,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 3, 5, 4
OpenReviewer: Mitigating Challenges in LLM Reviewing,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 3, 3, 3
Transformer-Based Large Language Models Are Not General Learners: A Universal Circuit Perspective,4.0, 5.0, 1.7888543819998317, 5, 4, 5, 4, 3, 2, 6, 3, 1, 5
Posterior Sampling via Langevin Monte Carlo for Offline Reinforcement Learning,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 5, 4, 6, 3
Efficient Point Cloud Matching for 3D Geometric Shape Assembly,5.75, 5.0, 1.299038105676658, 5, 4, 8, 2, 5, 4, 5, 2
From Deterministic to Probabilistic World: Balancing Enhanced Doubly Robust Learning for Debiased Recommendation,5.666666666666667, 6.0, 2.0548046676563256, 8, 4, 3, 4, 6, 2
FLOOD SIMULATION WITH PHYSICS-INFORMED MESSAGE PASSING,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 4, 3, 3
PACIA: Parameter-Efficient Adapter for Few-Shot Molecular Property Prediction,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 3, 6, 2, 5, 4
Provable Repair of Vision Transformers: Last Layer is All You Need,5.0, 5.0, 0.0, 5, 4, 5, 4
LLMZip: Lossless Text Compression using Large Language Models,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 6, 3, 3, 4
VMFTransformer: An Angle-Preserving and Auto-Scaling Machine for Multi-horizon Probabilistic Forecasting,5.0, 5.0, 0.0, 5, 4, 5, 5, 5, 3, 5, 4
AdaO2B: Adaptive Online to Batch Conversion for Out-of-Distribution Generalization,3.5, 3.0, 0.8660254037844386, 3, 2, 3, 3, 3, 4, 5, 4
Leveraging Previous Tasks in Optimizing Risk Measures with Gaussian Processes,6.5, 6.5, 1.5, 8, 4, 5, 3
Canonpipe: Data Debugging with Shapley Importance over Machine Learning Pipelines,6.25, 6.0, 1.0897247358851685, 6, 3, 8, 2, 6, 3, 5, 4
MoAT: Multi-Modal Augmented Time Series Forecasting,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 3, 3, 4
Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances,7.5, 8.0, 0.8660254037844386, 8, 2, 8, 3, 6, 3, 8, 3
Group Robustness via Adaptive Class-Specific Scaling,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 6, 3, 3, 4
CT++: Complementary Co-Training for Semi-Supervised Semantic Segmentation,4.0, 4.0, 1.0, 3, 5, 3, 5, 5, 4, 5, 4
Towards Better Evaluation of GNN Expressiveness with BREC Dataset,5.0, 6.0, 1.4142135623730951, 3, 4, 6, 3, 6, 2
Pessimistic Nonlinear Least-Squares Value Iteration for Offline Reinforcement Learning,6.25, 6.0, 1.0897247358851685, 5, 3, 6, 3, 6, 4, 8, 3
EMP-SSL: Towards Self-Supervised Learning in One Training Epoch,4.0, 4.0, 1.0, 3, 5, 5, 4, 5, 5, 3, 4
Nuisance-Robust Weighting Network for End-to-End Causal Effect Estimation,5.5, 5.5, 2.5, 8, 2, 3, 4
Skill-Mix: a Flexible and Expandable Family of Evaluations for AI Models,6.0, 5.0, 1.4142135623730951, 5, 3, 8, 4, 5, 3
OrthCaps: An Orthogonal CapsNet with Sparse Attention Routing and Pruning,4.2, 5.0, 1.9390719429665317, 5, 4, 6, 5, 6, 5, 1, 2, 3, 5
Data Refinement: Mitigating Reward Over-Optimization in Reinforcement Learning with Human Feedback,nan, nan, nan
A Quadratic Synchronization Rule for Distributed Deep Learning,6.0, 6.5, 2.1213203435596424, 8, 2, 3, 4, 5, 3, 8, 3
ArchLock: Locking DNN Transferability at the Architecture Level with a Zero-Cost Binary Predictor,5.0, 6.0, 1.4142135623730951, 3, 5, 6, 4, 6, 4
Referring Expression Matters: Multi-referring Feature Aggregation for Referring Video Object Segmentation,3.0, 3.0, 1.632993161855452, 5, 4, 1, 3, 3, 2
Local-Forward: Towards Biological Plausibility in Deep Reinforcement Learning,3.3333333333333335, 3.0, 2.0548046676563256, 3, 4, 1, 4, 6, 2
Exploiting Code Symmetries for Learning Program Semantics,5.0, 4.5, 2.1213203435596424, 8, 4, 3, 5, 3, 4, 6, 2
Weight Uncertainty in Individual Treatment Effect,3.4, 3.0, 1.4966629547095767, 3, 4, 5, 3, 3, 3, 1, 4, 5, 3
Latent Shattering: Turning Unconditional Pretrained Generators Into Conditional Models By Imposing Latent Structure,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 4, 3, 4, 3, 4
Efficient Large Language Models Fine-Tuning on Graphs,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 4, 6, 4, 3, 4
On information dropping and oversmoothing in graph neural networks,3.75, 3.0, 1.299038105676658, 3, 3, 3, 4, 6, 4, 3, 3
HuRef: HUman-REadable Fingerprint  for Large Language Models,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 3, 6, 3
Adaptive Memory Module for Sequential Planning and Reasoning,1.5, 1.0, 0.8660254037844386, 1, 4, 1, 4, 3, 3, 1, 4
Projected Subnetworks Scale Adaptation,2.0, 2.0, 1.0, 3, 4, 3, 4, 1, 4, 1, 4
Multiple Modes for Continual Learning,4.0, 4.0, 1.0, 3, 4, 5, 3, 3, 4, 5, 3
Robust Graph Neural Networks via Unbiased Aggregation,4.6, 5.0, 0.7999999999999999, 3, 4, 5, 4, 5, 4, 5, 3, 5, 4
Flashback: Understanding and Mitigating Forgetting in Federated Learning,4.0, 4.0, 1.0, 5, 4, 5, 3, 3, 4, 3, 4
Efficient Backdoor Mitigation in Federated Learning with Contrastive Loss,2.5, 3.0, 0.8660254037844386, 3, 3, 3, 3, 3, 5, 1, 4
Turing Complete Transformers: Two Transformers Are More Powerful Than One,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 4, 3, 4
PolyFormer: Scalable Graph Transformer via Polynomial Attention,5.5, 5.5, 0.5, 6, 3, 5, 5, 6, 3, 5, 5
A Data-Centric Approach for Financial Large Language Models with Abductive Augmentation Reasoning,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 5, 4, 3, 4
Cost Adaptive Recourse Recommendation by Adaptive Preference Elicitation,5.5, 5.5, 0.5, 6, 3, 5, 4, 6, 3, 5, 3
Multi-Method Self-Training: Improving Code Generation With Text And Vice Versa,4.75, 5.0, 1.0897247358851685, 6, 3, 3, 4, 5, 3, 5, 3
Improving Language Models with Advantage-based Offline Policy Gradients,5.75, 6.0, 1.7853571071357126, 3, 4, 6, 4, 8, 4, 6, 3
RECOMP: Improving Retrieval-Augmented LMs with Context Compression and Selective Augmentation,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 5, 3, 8, 4
Federated Generalization via Information-Theoretic Distribution Diversification,3.0, 3.0, 0.0, 3, 3, 3, 4, 3, 4
Defender of privacy and fairness: tiny but reversible generative model via mutually collaborative knowledge distillation,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 4, 3, 4
Gen-Z: Generative Zero-Shot Text Classification with Contextualized Label Descriptions,5.75, 6.0, 0.4330127018922193, 5, 3, 6, 4, 6, 4, 6, 3
A graph transformer for symbolic regression,4.0, 4.0, 1.0, 3, 4, 5, 4, 5, 4, 3, 4
Learning Latent Structural Causal Models,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 4, 3, 4, 3, 3
Flexible Diffusion for Graph Neural Networks,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4, 3, 4
In-Context Learning Dynamics with Random Binary Sequences,4.0, 4.0, 1.0, 3, 4, 3, 2, 5, 3, 5, 3
Dynamic Representation of Optimal Transport via Ensemble Systems,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 2, 5, 3
Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 5, 3, 6, 3
Be Aware of the Neighborhood Effect: Modeling Selection Bias under Interference for Recommendation,6.25, 6.0, 1.0897247358851685, 6, 3, 5, 4, 6, 2, 8, 3
GraphECL: Towards Efficient Contrastive Learning for Graphs,5.0, 5.0, 1.0954451150103321, 5, 5, 6, 4, 3, 4, 6, 5, 5, 3
An Implicit Watermark Framework for Adversary Identification,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 3, 2, 5, 4
PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization,5.75, 6.0, 1.7853571071357126, 6, 4, 3, 4, 8, 4, 6, 2
Understanding Retrieval Augmentation for Long-Form Question Answering,5.25, 5.0, 1.7853571071357126, 5, 4, 8, 4, 3, 3, 5, 3
Repeated Random Sampling for Minimizing the Time-to-Accuracy of Learning,5.0, 4.5, 2.1213203435596424, 6, 3, 3, 3, 3, 4, 8, 5
Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs,5.25, 5.0, 1.7853571071357126, 3, 4, 5, 4, 5, 4, 8, 5
Enhancing Instance-Level Image Classification with Set-Level Labels,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 5, 4, 6, 3
Rotation has two sides: Evaluating Data Augmentation for Deep One-class Classification,5.4, 6.0, 1.2, 6, 5, 3, 4, 6, 4, 6, 3, 6, 2
QuantEase: Optimization-based Quantization for Large Language Models,5.0, 6.0, 1.4142135623730951, 3, 4, 6, 4, 6, 4
On the Power of Multitask Representation Learning with Gradient Descent,5.0, 5.5, 1.224744871391589, 3, 3, 6, 3, 5, 2, 6, 4
Pushing Boundaries: Mixup's Influence on Neural Collapse,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 4, 5, 2
sRGB Real Noise Modeling via Noise-Aware Sampling with Normalizing Flows,5.75, 6.0, 1.7853571071357126, 6, 5, 6, 5, 3, 4, 8, 4
Open-Ended Learning in General-Sum Games: The Role of Diversity in Correlated Equilibrium,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 2, 3, 5
On Local Equilibrium in Non-Concave Games,6.75, 7.0, 2.5860201081971503, 3, 3, 8, 3, 10, 4, 6, 4
A Benchmark on Robust Semi-Supervised Learning in Open Environments,8.0, 8.0, 0.0, 8, 5, 8, 5, 8, 4, 8, 5
Uncertainty-aware Graph-based Hyperspectral Image Classification,5.4, 5.0, 0.4898979485566356, 5, 4, 5, 4, 6, 2, 5, 2, 6, 3
Zero-shot Human-Object Interaction Detection via Conditional Multi-Modal Prompts,5.25, 5.0, 0.4330127018922193, 5, 5, 6, 5, 5, 4, 5, 4
Pick and Adapt: An Iterative Approach for Source-Free Domain Adaptation,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 6, 4, 5, 4
XplainLLM: A QA Explanation Dataset for Understanding LLM Decision-Making,4.25, 4.0, 1.299038105676658, 3, 4, 6, 3, 3, 3, 5, 2
Generative Adversarial Equilibrium Solvers,6.75, 6.0, 1.920286436967152, 6, 4, 6, 4, 5, 4, 10, 5
Rethinking Counterfactual Fairness: On Which Individuals to Enforce and How?,4.25, 4.0, 1.299038105676658, 3, 5, 6, 4, 3, 4, 5, 3
Learning Boolean functions with neural networks,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 3
Emergent Corpus Pretraining Benefits Vision Language Modeling,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4
Rethinking Test-time Likelihood: The Likelihood Path Principle and Its Application to OOD Detection,5.0, 5.5, 1.224744871391589, 6, 2, 3, 4, 5, 3, 6, 2
Generative Adversarial Inverse Multiagent Learning,6.75, 7.0, 2.5860201081971503, 8, 3, 10, 3, 3, 2, 6, 2
Learning to Play Atari in a World of Tokens,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 3, 5, 4
Do Pre-trained Transformers Really Learn In-context by Gradient Descent?,4.5, 5.0, 0.8660254037844386, 3, 3, 5, 4, 5, 2, 5, 4
Fairness-enhancing mixed effects deep learning improves fairness on in- and out-of-distribution clustered (non-iid) data,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 5, 3, 4
FedOD: Federated Outlier Detection via Neural Approximation,3.3333333333333335, 3.0, 2.0548046676563256, 1, 4, 6, 4, 3, 4
Robustness Evaluation of Proxy Models against Adversarial Optimization,4.75, 5.0, 1.0897247358851685, 3, 3, 6, 3, 5, 3, 5, 3
Multi-Objective Multi-Solution Transport,4.0, 5.0, 2.6832815729997477, 1, 5, 5, 4, 5, 3, 1, 5, 8, 4
FORKS: Fast Second-Order Online Kernel Learning using Incremental Sketching,4.0, 5.0, 1.7888543819998317, 5, 2, 6, 4, 1, 4, 5, 4, 3, 4
Graph Transformers on EHRs: Better Representation Improves Downstream Performance,6.0, 5.5, 1.224744871391589, 5, 4, 8, 5, 5, 3, 6, 4
O3D: Offline Data-driven Discovery and Distillation for Sequential Decision-Making with Large Language Models,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 3, 5, 3
Counterfactual Fairness from Partially DAGs: A General Min-Max Optimization Framework,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 3, 4, 5, 1
On the Scalability and Memory Efficiency of Semidefinite Programs  for Lipschitz Constant Estimation of Neural Networks,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 4, 6, 3
Efficient Recomputation of Marginal Likelihood upon Adding Training Data in Gaussian Processes and Simulator Fusion,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 4, 6, 3
Preconditioning for Physics-Informed Neural Networks,4.5, 5.5, 2.0615528128088303, 5, 3, 6, 2, 1, 4, 6, 3
On the Role of Discrete Tokenization in Visual Representation Learning,6.25, 6.0, 1.0897247358851685, 6, 2, 6, 3, 5, 4, 8, 3
Large Language Models as Automated Aligners for  benchmarking  Vision-Language Models,5.333333333333333, 5.0, 2.0548046676563256, 5, 4, 3, 4, 8, 4
CLaM-TTS: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech,6.4, 8.0, 2.0591260281974, 8, 4, 8, 4, 5, 5, 3, 4, 8, 4
AceGPT Localizing Large Language Models in Arabic,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 4, 3, 4
Improving Large Language Model Fine-tuning for Solving Math Problems,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 2
Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels,6.25, 7.0, 2.0463381929681126, 8, 4, 8, 2, 3, 5, 6, 4
UNR-Explainer: Counterfactual Explanations for Unsupervised Node Representation Learning Models,5.75, 6.0, 1.7853571071357126, 8, 3, 6, 3, 6, 3, 3, 4
Reinforcement Learning for Large Group Systems using Hierarchical Kernel Representations,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 5, 4, 6, 2
Optimizing Interpersonal Communication by Simulating Audiences with Large Language Models,5.5, 5.5, 0.5, 5, 4, 6, 3, 6, 3, 5, 4
Enhancing Neural Network Transparency through Representation Analysis,4.0, 3.0, 1.4142135623730951, 3, 3, 6, 2, 3, 2
Are Bert Family Good Instruction Followers?  A Study on Their Potential And Limitations,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 8, 3, 6, 3
SGOOD: Substructure-enhanced Graph-Level Out-of-Distribution Detection,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 4, 5, 4
Jorge: Approximate Preconditioning for GPU-Efficient Second-Order Optimization,4.5, 5.0, 0.8660254037844386, 5, 5, 5, 4, 3, 2, 5, 4
Imitation Bootstrapped Reinforcement Learning,5.0, 5.5, 1.224744871391589, 6, 4, 3, 3, 6, 4, 5, 3
Exploring the Promise and Limits of Real-Time Recurrent Learning,6.0, 5.5, 1.224744871391589, 5, 3, 5, 4, 6, 3, 8, 4
Attribute-Enhanced Similarity Ranking for Sparse Link Prediction,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 4, 3, 4, 3, 4
Measuring Graph Similarity Using Transfer Cost of Forster Distributions,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 4, 3, 4, 3, 3
TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 6, 3, 8, 4
Scaling physics-informed hard constraints with mixture-of-experts,5.8, 6.0, 0.39999999999999997, 6, 3, 6, 3, 5, 4, 6, 4, 6, 3
Uncovering Causal Variables in Transformers Using Circuit Probing,4.2, 5.0, 1.9390719429665317, 6, 4, 3, 5, 6, 4, 1, 5, 5, 5
InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 3, 5, 3
Discrimination-free Pricing with Privatized Sensitive Attributes,4.666666666666667, 5.0, 1.247219128924647, 5, 2, 6, 2, 3, 4
Recursive Score Estimation Accelerates Diffusion-Based Monte Carlo,6.0, 6.0, 1.8973665961010275, 8, 2, 3, 3, 8, 3, 6, 4, 5, 3
Ensemble Systems Representation for Function Learning over Manifolds,3.0, 3.0, 1.4142135623730951, 1, 3, 5, 3, 3, 3, 3, 3
Generalization in diffusion models arises from geometry-adaptive harmonic representation,8.5, 8.0, 0.8660254037844386, 8, 4, 8, 4, 10, 4, 8, 3
Simplicity Bias of SGD via Sharpness Minimization,6.0, 5.5, 1.224744871391589, 5, 3, 8, 3, 5, 4, 6, 3
Structural Fairness-aware Active Learning for Graph Neural Networks,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 4, 5, 3, 6, 4
Neural-Symbolic Recursive Machine for Systematic Generalization,6.25, 7.0, 2.0463381929681126, 8, 4, 3, 3, 8, 2, 6, 4
Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-Image Generation,6.0, 5.0, 1.4142135623730951, 5, 3, 8, 3, 5, 5
Deep Neural Networks Can Learn Generalizable Same-Different Visual Relations,4.0, 4.0, 1.0, 5, 4, 3, 4, 5, 3, 3, 5
In-context Curriculum for Mathematical Reasoning in Small Language Models,4.0, 3.0, 1.2649110640673518, 3, 3, 3, 4, 3, 4, 6, 4, 5, 4
The Consensus Game: Language Model Generation via Equilibrium Search,7.0, 6.0, 1.7320508075688772, 6, 3, 6, 4, 6, 2, 10, 4
Vector Quantized Representations for Efficient Hierarchical Delineation of Behavioral Repertoires,4.75, 5.0, 1.0897247358851685, 5, 2, 3, 3, 5, 3, 6, 4
STRUCTDROP: A STRUCTURED RANDOM ALGORITHM TOWARDS EFFICIENT LARGE-SCALE GRAPH TRAINING,4.5, 4.5, 1.5, 6, 3, 6, 3, 3, 4, 3, 4
Talking Models: Distill Pre-trained Knowledge to Downstream Models via Interactive Communication,5.5, 5.5, 0.5, 5, 4, 6, 4, 5, 2, 6, 3
Chain of Thought Empowers Transformers to Solve Inherently Serial Problems,6.333333333333333, 7.0, 1.8856180831641267, 8, 5, 6, 4, 8, 2, 3, 4, 8, 2, 5, 4
Tractable MCMC for Private Learning with Pure and Gaussian Differential Privacy,6.0, 5.0, 1.4142135623730951, 8, 3, 5, 3, 5, 4
X-InstructBLIP: A Framework for aligning X-Modal instruction-aware representations to LLMs and Emergent Cross-modal Reasoning,4.8, 5.0, 0.9797958971132712, 5, 5, 5, 4, 6, 3, 3, 4, 5, 4
Efficient Multi-task Reinforcement Learning via Selective Behavior Sharing,4.0, 4.0, 1.0, 5, 4, 3, 4, 3, 4, 5, 4
Optimal Sketching for Residual Error Estimation for Matrix and Vector Norms,6.75, 7.0, 1.299038105676658, 5, 4, 8, 4, 8, 3, 6, 3
Reverse Diffusion Monte Carlo,4.5, 5.5, 2.0615528128088303, 1, 4, 6, 5, 5, 2, 6, 4
LLM-based Stock Market Trend Prediction,1.5, 1.0, 0.8660254037844386, 1, 5, 3, 4, 1, 5, 1, 5
On the Dynamics of Learning Time-Aware Behavior with RNNs,3.0, 3.0, 0.0, 3, 3, 3, 2, 3, 3, 3, 4
Can LLMs Effectively Leverage Graph Structural Information: When and Why,4.2, 3.0, 1.469693845669907, 3, 5, 3, 4, 3, 4, 6, 3, 6, 3
Improving Branching in Neural Network Verification with Bound Implication Graph,5.5, 5.5, 1.8027756377319946, 6, 4, 3, 5, 5, 4, 8, 3
Counting Graph Substructures with Graph Neural Networks,5.5, 5.5, 0.5, 5, 3, 6, 3, 6, 3, 5, 3
Optimal algorithms for group distributionally robust optimization and beyond,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 4
Dynamic Mode Decomposition-inspired Autoencoders for Reduced-order Modeling and Control of PDEs : Theory and Design,5.5, 5.5, 0.5, 5, 3, 6, 3, 5, 3, 6, 3
Exploiting Action Distances for Reward Learning from Human Preferences,3.75, 3.0, 1.299038105676658, 3, 5, 3, 4, 3, 4, 6, 3
Is the Glass Half-Empty or Half-Full? A Mixture-Of-Tasks Perspective on Missing Modality,3.0, 3.0, 0.0, 3, 3, 3, 4, 3, 2, 3, 3
Text2Data: Low-Resource Data Generation with Textual Control,4.25, 4.0, 1.299038105676658, 6, 2, 3, 4, 5, 3, 3, 2
On the Effect of Defection in Federated Learning and How to Prevent It,3.75, 3.0, 1.299038105676658, 3, 4, 6, 3, 3, 4, 3, 4
DIG-MILP: a Deep Instance Generator for Mixed-Integer Linear Programming with Feasibility Guarantee,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 4, 3, 4
Lung Nodule Segmentation Network with Self-Supervised Learning and Attention Mechanisms,nan, nan, nan
Analyzing Complex Interdependencies in Financial Markets: A Neural Network-Based Approach for News Impact Assessment,1.0, 1.0, 0.0, 1, 5, 1, 5, 1, 4
What's the Magic Word? A Control Theory of LLM Prompting,4.6, 5.0, 0.7999999999999999, 3, 3, 5, 3, 5, 3, 5, 4, 5, 5
End-to-end Story Plot Generator,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 5, 5, 5
Generalization Guarantees of Gradient Descent for Multi-Layer Neural Networks,5.5, 5.5, 0.5, 6, 3, 5, 3, 6, 3, 5, 3
Are Models Biased on Text without Gender-related Language?,5.25, 5.0, 0.4330127018922193, 5, 3, 6, 4, 5, 4, 5, 4
Decoupled Actor-Critic,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 3, 5, 4, 5, 3
Unleashing the Potential of LLMs for Quantum Computing: A Study in Quantum Architecture Design,1.6666666666666667, 1.0, 0.9428090415820634, 3, 4, 1, 4, 1, 5
How do skip connections affect Graph Convolutional  networks  with graph sampling? A theoretical analysis on generalization,4.75, 5.0, 1.0897247358851685, 5, 5, 5, 4, 3, 2, 6, 3
PlaSma: Procedural Knowledge Models for Language-based Planning and Re-Planning,6.0, 5.5, 1.224744871391589, 5, 4, 8, 4, 5, 4, 6, 4
From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction,5.25, 5.0, 1.7853571071357126, 3, 4, 8, 4, 5, 4, 5, 4
Patch Ranking Map: Explaining Relations among Top-Ranked Patches Top-Ranked Features and Decisions of Convolutional Neural Networks for Image Classification,2.5, 2.0, 1.6583123951777, 5, 4, 3, 3, 1, 3, 1, 4
The Fine-Grained Chip Placement with Hybrid Action Spaces and Feature Fusion,1.0, 1.0, 0.0, 1, 5, 1, 5, 1, 4, 1, 3
AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents,6.5, 6.0, 0.8660254037844386, 6, 4, 8, 3, 6, 3, 6, 4
UniAudio: An  Audio Foundation Model Toward Universal Audio Generation,5.25, 5.0, 3.191786333700926, 10, 3, 5, 4, 1, 5, 5, 3
Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets,6.0, 6.0, 1.8973665961010275, 8, 3, 5, 4, 8, 2, 6, 4, 3, 4
ABKD: Graph Neural Network Compression with Attention-Based Knowledge Distillation,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 3, 3, 4, 3, 3
Llamas Know What GPTs Don't Show: Surrogate Models for Selective Classification,4.0, 4.0, 1.0, 5, 4, 5, 3, 3, 3, 3, 4
Independent-Set Design of Experiments for Estimating Treatment and Spillover Effects under Network Interference,5.5, 5.5, 0.5, 5, 4, 6, 3, 5, 4, 6, 2
FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores,7.0, 8.0, 1.4142135623730951, 5, 5, 8, 3, 8, 4
Towards Understanding The Winner-Take-Most Behavior Of Neural Network Representations,3.25, 3.0, 1.7853571071357126, 3, 3, 3, 3, 1, 3, 6, 4
SHINE: Shielding Backdoors in Deep Reinforcement Learning,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 5, 5, 2, 6, 3
Semi-Supervised Learning of Tree-Based Models Using Uncertain Interpretation of Data,3.5, 3.0, 0.8660254037844386, 3, 3, 5, 4, 3, 5, 3, 3
Parameter-Efficient Tuning Helps Language Model Alignment,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 3, 4, 6, 3
MIMIC: Masked Image Modeling with Image Correspondences,5.0, 4.5, 2.1213203435596424, 3, 4, 3, 4, 8, 4, 6, 4
Transformer-VQ: Linear-Time Transformers via Vector Quantization,6.333333333333333, 6.0, 1.247219128924647, 6, 3, 8, 3, 5, 2
Can adversarial samples benefit few-shot unsupervised implicit neural shape representation learning ?,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 5, 5, 3
Understanding Contrastive Learning Through the Lens of Margins,4.75, 5.0, 1.0897247358851685, 6, 5, 5, 3, 5, 5, 3, 3
Efficient Model-Agnostic Multi-Group Equivariant Networks,3.5, 4.0, 1.6583123951777, 5, 3, 5, 2, 1, 2, 3, 4
Simple Data Sharing for Multi-Tasked Goal-Oriented Problems,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 2, 3, 2, 5, 3
Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions,5.5, 5.5, 1.8027756377319946, 6, 3, 3, 4, 5, 4, 8, 4
Initializing the Layer-wise Learning Rate,3.75, 3.0, 1.299038105676658, 3, 4, 3, 3, 3, 3, 6, 3
Relational Convolutional Networks: A framework for learning representations of hierarchical relations,6.0, 5.5, 1.224744871391589, 6, 2, 5, 3, 8, 4, 5, 4
How does overparametrization affect features?,3.75, 3.0, 1.299038105676658, 3, 3, 3, 4, 3, 4, 6, 4
The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax Mimicry,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 8, 4, 5, 4
Understanding and Robustifying Sub-domain Alignment for Domain Adaptation,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 3, 4, 5, 3
Abstractors and relational cross-attention: An inductive bias for explicit relational reasoning in Transformers,6.25, 6.0, 1.0897247358851685, 5, 3, 6, 3, 6, 3, 8, 4
Doubly Robust Instance-Reweighted Adversarial Training,6.0, 6.0, 0.0, 6, 5, 6, 4, 6, 5
Estimating uncertainty from feed-forward network based sensing using quasilinear approximation,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 4, 5, 3
SOLVING SCHRODINGER BRIDGE PROBLEM VIA STOCHASTIC ACTION MINIMIZATION,3.4, 3.0, 0.8000000000000002, 3, 4, 5, 2, 3, 4, 3, 4, 3, 4
Training Diffusion Models with Reinforcement Learning,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 4, 6, 4, 3, 4
DIRECTIONALITY IN GRAPH TRANSFORMERS,4.25, 4.0, 1.299038105676658, 6, 4, 3, 4, 5, 4, 3, 4
Latent Conservative Objective Models for Offline Data-Driven Crystal Structure Prediction,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 6, 2, 3, 5
Finite-Time Analysis of On-Policy Heterogeneous Federated Reinforcement Learning,6.25, 6.0, 1.0897247358851685, 6, 3, 8, 3, 5, 3, 6, 3
Explaining the Out-of-Distribution Detection Paradox through Likelihood Peaks,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 4, 6, 4
Federated Q-Learning: Linear Regret Speedup with Low Communication Cost,5.5, 5.5, 0.5, 6, 3, 5, 3, 6, 3, 5, 4
The Trickle-down Impact of Reward Inconsistency on RLHF,4.8, 5.0, 0.9797958971132712, 5, 4, 3, 4, 5, 5, 6, 3, 5, 4
Multi-Resolution Learning with DeepONets and Long Short-Term Memory Neural Networks,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 3, 5, 2
Non-stationary Contextual Bandit Learning via Neural Predictive Ensemble Sampling,3.75, 3.0, 1.299038105676658, 6, 2, 3, 4, 3, 3, 3, 4
Depth From Camera Model,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 4, 3, 5
Deep probabilistic 3D angular regression for directional dark matter detectors,4.5, 4.5, 1.5, 3, 3, 6, 3
Unsupervised Sign Language Translation and Generation,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 5, 5, 4, 5, 4
Cross-modality debiasing: using language to mitigate sub-population shifts in imaging,5.0, 5.5, 1.224744871391589, 5, 4, 6, 3, 6, 3, 3, 4
Decompose Time and Frequency Dependencies: Multivariate Time Series Physiological Signal Emotion Recognition,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 5, 3, 5
Understanding Your Agent: Leveraging Large Language Models for Behavior Explanation,4.0, 4.0, 1.0, 3, 4, 5, 4, 5, 4, 3, 2
Continual Graph Learning for Thermal Analysis of Composite Materials under Interface Variations,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 3, 3, 3
Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 3, 5, 3, 6, 3
Stochastic two points method for deep model gradient free optimization,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 3, 5, 2
SafeDiffuser: Safe Planning with Diffusion Probabilistic Models,4.0, 3.0, 2.943920288775949, 8, 3, 3, 2, 1, 3
Logic-Based Adaptive Reward Shaping for Reinforcement Learning,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 4, 3, 3, 3, 4
Revisitng graph neural networks for traffic forecasting,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 5, 5, 3
Neural Collapse meets Differential Privacy:  Curious behaviors of NoisySGD with Near-Perfect Representation Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 3, 3, 3
Efficient Modulation for Vision Networks,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 3, 5, 5, 5, 4
Pre-training LiDAR-based 3D Object Detectors through Colorization,6.75, 7.0, 1.299038105676658, 5, 5, 6, 4, 8, 4, 8, 5
An Emulator for Fine-tuning Large Language Models using Small Language Models,6.25, 6.0, 1.0897247358851685, 8, 5, 5, 2, 6, 3, 6, 2
Toward Student-oriented Teacher Network Training for Knowledge Distillation,5.25, 5.0, 0.4330127018922193, 5, 3, 6, 3, 5, 4, 5, 3
Language Models Represent Space and Time,5.75, 6.0, 1.7853571071357126, 6, 4, 3, 4, 6, 4, 8, 4
Causal Modelling Agents: Causal Graph Discovery through Synergising Metadata- and Data-driven Reasoning,6.25, 7.0, 2.0463381929681126, 8, 3, 3, 2, 6, 2, 8, 3
Fast-ELECTRA for Efficient Pre-training,6.0, 6.0, 0.0, 6, 3, 6, 4, 6, 4
Maximum Entropy Model Correction in Reinforcement Learning,7.333333333333333, 8.0, 0.9428090415820634, 8, 4, 8, 3, 6, 3
Ceci n'est pas une pomme: Adversarial Illusions in Multi-Modal Embeddings,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 5, 5, 3, 3, 5
Identifying Latent State Transition Processes for Individualized Reinforcement Learning,4.0, 3.0, 1.2649110640673518, 6, 3, 3, 3, 3, 3, 5, 3, 3, 3
Learning Multi-Agent Communication using Regularized Attention Messages,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 4, 3, 4, 3, 5
The mechanistic basis of data dependence and abrupt learning in an in-context classification task,8.25, 9.0, 2.0463381929681126, 5, 3, 8, 4, 10, 4, 10, 4
SpaCE: The Spatial Confounding Environment,6.333333333333333, 6.0, 1.247219128924647, 8, 3, 5, 3, 6, 4
Benchmarking Cognitive Biases in Large Language Models as Evaluators,6.25, 6.0, 1.0897247358851685, 6, 3, 8, 3, 6, 4, 5, 3
Ghostbuster: Detecting Text Ghostwritten by Large Language Models,nan, nan, nan
PILOT: An $\mathcal{O}(1/T)$-Convergent Approach for Policy Evaluation with Nonlinear Function Approximation,7.0, 7.0, 1.0, 8, 3, 6, 3, 8, 3, 6, 3
Graph Neural Networks Gone Hogwild,4.25, 4.0, 1.299038105676658, 3, 3, 3, 3, 5, 3, 6, 2
Impact of Molecular Representations on Deep Learning Model Comparisons in Drug Response Predictions,3.0, 3.0, 1.4142135623730951, 3, 4, 3, 4, 1, 2, 5, 3
Positional Description Matters for Transformers Arithmetic,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 4, 3, 4, 3, 2
FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation,6.333333333333333, 6.0, 1.247219128924647, 8, 4, 5, 3, 6, 4
Contrastive Post-training Large Language Models on Data Curriculum,4.0, 4.0, 1.0, 5, 4, 3, 2, 5, 3, 3, 2
STIMULUS: Achieving Fast Convergence and Low Sample Complexity in Stochastic Multi-Objective Learning,4.4, 3.0, 1.9595917942265424, 3, 4, 5, 3, 8, 3, 3, 4, 3, 2
Language Model Detectors Are Easily Optimized Against,6.0, 6.0, 0.0, 6, 4, 6, 3, 6, 4
The Representation Jensen-Shannon Divergence,4.6, 5.0, 1.3564659966250536, 5, 3, 3, 3, 6, 4, 6, 3, 3, 4
Zero-Shot Robotic Manipulation with Pre-Trained Image-Editing Diffusion Models,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 3, 6, 4, 5, 4
Learning to Reach Goals via Diffusion,4.0, 4.0, 1.0, 5, 4, 3, 3, 3, 3, 5, 3
LUMOS: Towards Language Agents that are Unified Modular and Open Source,5.0, 4.5, 2.1213203435596424, 6, 3, 3, 2, 3, 4, 8, 4
Physics Informed Neurally Constructed ODE Networks (PINeCONes),3.6, 3.0, 1.2000000000000002, 3, 4, 6, 4, 3, 2, 3, 4, 3, 3
CrysFormer: Protein Structure Prediction via 3d Patterson Maps and Partial Structure Attention,3.75, 3.0, 1.299038105676658, 3, 3, 6, 4, 3, 3, 3, 3
Latent Space Simulator for Unveiling Molecular Free Energy Landscapes and Predicting Transition Dynamics,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 5, 5, 3, 4
Causal Estimation of Exposure Shifts with Neural Networks: Evaluating the Health Benefits of Stricter Air Quality Standards in the US,5.0, 6.0, 1.4142135623730951, 6, 4, 6, 3, 3, 3
An empirical investigation of generalization dynamics in deep ReLU networks via nonlinear mode decomposition,3.75, 3.0, 1.299038105676658, 3, 3, 3, 5, 6, 3, 3, 2
Efficient Transfer Learning from Arbitrary Pre-Trained Models,4.75, 5.0, 1.0897247358851685, 6, 4, 3, 4, 5, 4, 5, 4
On the Role of Edge Dependency in Graph Generative Models,5.75, 6.0, 1.7853571071357126, 6, 4, 8, 4, 3, 4, 6, 4
DiffDock-Pocket: Diffusion for Pocket-Level Docking with Sidechain Flexibility,5.25, 5.0, 1.7853571071357126, 5, 3, 5, 4, 8, 3, 3, 4
Learning Diverse Quadruped Locomotion Gaits via Reward Machines,5.333333333333333, 5.0, 2.0548046676563256, 8, 4, 5, 4, 3, 5
How Capable Can a Transformer Become? A Study on Synthetic Interpretable Tasks,5.0, 4.5, 2.1213203435596424, 8, 4, 3, 4, 6, 4, 3, 4
Auto DP-SGD: Dual Improvements of Privacy and Accuracy via Automatic Clipping Threshold and Noise Multiplier Estimation,3.0, 3.0, 1.4142135623730951, 3, 3, 3, 4, 1, 4, 5, 5
A New Physics-Based Continuous-Time Reinforcement Learning Algorithm with Performance Guarantees,3.0, 3.0, 1.632993161855452, 1, 4, 5, 2, 3, 3
Graph neural processes and their application to molecular functions,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 3, 5, 4, 5, 4
Simple Hierarchical Planning with Diffusion,5.0, 5.5, 1.224744871391589, 6, 3, 5, 4, 6, 4, 3, 5
Stochastic Gradient Descent for Gaussian Processes Done Right,5.8, 5.0, 1.16619037896906, 8, 4, 5, 4, 6, 3, 5, 3, 5, 3
Confronting Reward Model Overoptimization with Constrained RLHF,6.25, 6.0, 1.0897247358851685, 6, 4, 8, 3, 5, 4, 6, 3
GAFormer: Enhancing Timeseries Transformers Through Group-Aware Embeddings,5.8, 6.0, 0.39999999999999997, 6, 2, 6, 2, 6, 4, 5, 3, 6, 2
Improved order analysis and design of exponential integrator for diffusion models sampling,5.0, 6.0, 1.4142135623730951, 3, 4, 6, 4, 6, 2
Setting the Record Straight on Transformer Oversmoothing,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 4, 6, 4, 5, 4
KBFormer: A Transformer-based Diffusion Model of Structured Entities with Heterogeneous Properties,5.0, 5.0, 1.0954451150103321, 3, 3, 5, 2, 6, 3, 5, 2, 6, 3
Bridging Sequence and Structure: Latent Diffusion for Conditional Protein Generation,5.0, 4.5, 2.1213203435596424, 3, 5, 3, 5, 6, 4, 8, 3
Why is SAM Robust to Label Noise?,5.0, 5.5, 1.224744871391589, 5, 4, 6, 4, 6, 3, 3, 3
Gradient descent for matrix factorization: Understanding large initialization,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 5, 2, 6, 2
How FaR Are Large Language Models From Agents with Theory-of-Mind?,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 5, 6, 3
Predicting the Performance of Foundation Models via Agreement-on-the-line,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 3, 5, 4, 5, 3
Revisiting the Last-Iterative Convergence of Stochastic Gradient Methods,6.333333333333333, 6.0, 1.247219128924647, 8, 4, 6, 2, 5, 4
Learning transferrable and interpretable representation for brain network,5.0, 5.5, 1.224744871391589, 5, 5, 6, 4, 3, 4, 6, 3
CNN Kernels Can Be the Best Shapelets,5.4, 5.0, 1.624807680927192, 5, 4, 5, 5, 8, 5, 6, 3, 3, 3
COTIC: Embracing Non-uniformity in Event Sequence Data via Multilayer Continuous Convolution,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 3, 3, 5
Stochastic Vision Transformers with Wasserstein Distance-Aware Attention,5.333333333333333, 5.0, 0.4714045207910317, 5, 2, 5, 5, 6, 1
Fine-Tuning Language Models with Advantage-Induced Policy Alignment,4.75, 4.0, 2.0463381929681126, 5, 3, 3, 4, 8, 5, 3, 4
Score-Based Multimodal Autoencoders,5.5, 5.5, 1.8027756377319946, 3, 3, 5, 4, 6, 5, 8, 3
Fine-Tuning Language Models for Factuality,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 4, 5, 4, 5, 3
Improving classifier decision boundaries using nearest neighbors,2.3333333333333335, 3.0, 0.9428090415820634, 3, 4, 3, 4, 1, 4
LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL Architectures,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 8, 3, 6, 1
Malcom-PSGD: Inexact Proximal Stochastic Gradient Descent for Communication Efficient Decentralized Machine Learning,4.25, 4.0, 1.299038105676658, 3, 4, 6, 3, 5, 4, 3, 4
Absolute Policy Optimization,4.0, 4.0, 1.0, 5, 3, 5, 4, 3, 4, 3, 4
Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling,5.75, 5.0, 1.299038105676658, 8, 3, 5, 4, 5, 2, 5, 5
Approaching an unknown communication system by latent space exploration and causal inference,4.75, 4.0, 2.0463381929681126, 5, 2, 3, 2, 3, 4, 8, 3
Limited-Memory Greedy Quasi-Newton Method with Non-asymptotic Superlinear Convergence Rate,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 3, 3, 6, 2
Overthinking the Truth: Understanding how Language Models Process False Demonstrations,7.333333333333333, 8.0, 0.9428090415820634, 6, 5, 8, 3, 8, 3
Transforming Smallholder Farmers Support with an AI-Powered FAQbot: A Comparison of Techniques,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 3, 4, 1, 4
Efficient Subgraph Rule Induction via Tree Folding in Differentiable Logic Programming,4.25, 4.0, 1.299038105676658, 3, 4, 5, 3, 3, 4, 6, 3
Estimating Unknown Population Sizes Using Hypergeometric Maximum Likelihood,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 3, 6, 4, 5, 2
Regularized Robust MDPs and Risk-Sensitive MDPs: Equivalence Policy Gradient and Sample Complexity,5.75, 6.0, 0.4330127018922193, 5, 4, 6, 4, 6, 4, 6, 4
Federated Binary Matrix Factorization using Proximal Optimization,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 4, 5, 3
Feature Learning in Infinite Depth Neural Networks,6.0, 6.0, 1.8973665961010275, 6, 4, 8, 4, 5, 3, 3, 4, 8, 4
Two Facets of SDE Under an Information-Theoretic Lens: Generalization of SGD via Training Trajectories and via Terminal States,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 2, 3, 4, 5, 3
VideoDirectorGPT: Consistent Multi-Scene Video Generation via LLM-Guided Planning,4.0, 4.0, 1.0, 5, 4, 5, 5, 3, 4, 3, 4
Out-of-domain Fact Checking,4.666666666666667, 3.0, 2.357022603955158, 3, 4, 8, 4, 3, 4
Language Models Linearly Represent Sentiment,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 3, 3, 5, 3
Improved Techniques for Training Consistency Models,7.0, 7.0, 1.0, 8, 4, 8, 4, 6, 4, 6, 4
A Theoretical Study of the Jacobian Matrix in Deep Neural Networks,4.6, 5.0, 0.7999999999999999, 3, 4, 5, 3, 5, 4, 5, 4, 5, 3
Why Do We Need Weight Decay in Modern Deep Learning?,4.2, 5.0, 0.9797958971132712, 5, 4, 3, 3, 3, 3, 5, 4, 5, 3
Demystifying Poisoning Backdoor Attacks from a Statistical Perspective,5.5, 5.5, 1.8027756377319946, 5, 3, 8, 4, 6, 3, 3, 5
Concept Alignment as a Prerequisite for Value Alignment,4.0, 4.5, 2.1213203435596424, 3, 3, 1, 4, 6, 5, 6, 2
Learning to make adherence-aware advice,5.0, 5.0, 0.0, 5, 3, 5, 3
Provable Compositional Generalization for Object-Centric Learning,7.333333333333333, 8.0, 0.9428090415820634, 8, 4, 8, 3, 6, 3
Battle of the Wordsmiths: Comparing ChatGPT GPT-4 Claude and Bard,4.0, 4.0, 1.0, 5, 3, 5, 4, 3, 3, 3, 3
iHyperTime: Interpretable Time Series Generation with Implicit Neural Representations,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 5, 4, 6, 3
Bridging the Fairness Divide: Achieving Group and Individual Fairness in Graph Neural Networks,3.0, 3.0, 1.4142135623730951, 1, 4, 3, 4, 5, 4, 3, 4
Beyond Spatio-Temporal Representations: Evolving Fourier Transform for Temporal Graphs,6.0, 6.0, 0.0, 6, 3, 6, 2, 6, 4, 6, 3
RoCA: A Robust Method to Discover Causal or Anticausal Relation by Noise Injection,4.0, 3.0, 1.4142135623730951, 6, 2, 3, 4, 3, 3
Cycle Consistency Driven Object Discovery,6.0, 5.5, 1.224744871391589, 5, 4, 8, 4, 6, 2, 5, 4
RF-POLICY: Rectified Flows are Adaptive Decision Makers,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 3, 3, 5, 5, 4
Rectifying Group Irregularities in Explanations for Distribution Shift,4.25, 5.0, 1.920286436967152, 5, 2, 5, 4, 1, 2, 6, 3
Contrastive Decoding Improves Reasoning in Large Language Models,4.333333333333333, 5.0, 0.9428090415820634, 5, 5, 5, 4, 3, 4
Sufficient conditions for offline reactivation in recurrent neural networks,4.75, 5.0, 1.0897247358851685, 5, 5, 6, 4, 5, 3, 3, 4
Centroid-Based Learning for Malware Detection and Novel Family Identification,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 5, 5, 3
On the benefits of pixel-based hierarchical policies for task generalization,2.5, 3.0, 0.8660254037844386, 1, 4, 3, 3, 3, 3, 3, 4
GUARD: A Safe Reinforcement Learning Benchmark,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 5, 3, 4, 5, 5
Forward Learning of Graph Neural Networks,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 4, 6, 2, 6, 4
Size Generalization of Graph Neural Networks on Biological Data: Insights and Practices from the Spectral Perspective,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 4, 3, 5, 5, 4
Self-Supervised Learning with the Matching Gap,4.8, 5.0, 1.8330302779823362, 5, 4, 3, 4, 3, 5, 8, 4, 5, 4
COMPARATOR: Reference-free machine translation evaluation by inter-system comparison,6.0, 6.5, 2.1213203435596424, 5, 3, 8, 4, 8, 4, 3, 4
Multi-timestep models for Model-based Reinforcement Learning,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 1, 4
Multisensory Geospatial Models via Cross-Sensor Pretraining,5.0, 4.5, 2.1213203435596424, 6, 4, 3, 5, 8, 4, 3, 4
Embedding Improves Neural Regularizers for Inverse Problems,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 2, 5, 4, 3, 4
SwapTransformer: Highway Overtaking Tactical Planner Model via Imitation Learning on OSHA Dataset,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 3, 3, 3
GEO: Generative Engine Optimization,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 5
Clarify When Necessary: Resolving Ambiguity with Language Models,4.75, 4.0, 2.0463381929681126, 3, 3, 5, 3, 3, 4, 8, 4
From gradient attacks to data poisoning,3.0, 3.0, 1.4142135623730951, 5, 4, 1, 5, 3, 5, 3, 4
Curriculum reinforcement learning for quantum architecture search under hardware errors,5.2, 6.0, 1.16619037896906, 5, 3, 3, 4, 6, 4, 6, 5, 6, 4
Does CLIP’s generalization performance mainly stem from high train-test similarity?,5.0, 5.5, 1.224744871391589, 5, 5, 6, 4, 3, 4, 6, 4
State-wise Constrained Policy Optimization,4.666666666666667, 3.0, 2.357022603955158, 3, 4, 8, 3, 3, 3
Out of the Ordinary: Spectrally Adapting Regression for Covariate Shift,5.5, 5.5, 0.5, 6, 4, 5, 3, 5, 3, 6, 4
A Unified Approach for Online Continuous DR-Submodular Maximization,7.0, 6.0, 2.160246899469287, 6, 3, 5, 4, 10, 3
Fast Sampling via De-randomization for Discrete Diffusion Models,4.25, 4.0, 1.299038105676658, 3, 4, 3, 4, 6, 3, 5, 5
A Linearly Convergent GAN Inversion-based Algorithm for Reverse Engineering of Deceptions,4.666666666666667, 5.0, 1.247219128924647, 3, 2, 5, 3, 6, 3
Amortized Bayesian Inference with Hybrid Expert-in-the-Loop and Learnable Summary Statistics,4.6, 5.0, 1.3564659966250536, 3, 4, 3, 4, 6, 2, 5, 4, 6, 3
SEArch: A Self-Evolving Framework for Network Architecture Optimization,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 3, 5, 4
When Scaling Meets LLM Finetuning: The Effect of Data Model and Finetuning Method,6.5, 6.5, 1.5, 8, 3, 5, 3, 8, 4, 5, 3
Instance Needs More Care: Rewriting Prompts for Instances Yields Better Zero-Shot Performance,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 5, 3, 6, 2
Learning to design protein-protein interactions with enhanced generalization,6.2, 6.0, 0.9797958971132712, 6, 5, 6, 2, 6, 4, 8, 5, 5, 3
Robustness to Multi-Modal Environment Uncertainty in MARL using Curriculum Learning,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 5, 3, 4, 1, 4
AlphaFold Distillation for Protein Design,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 4
Video2Demo: Grounding Videos in State-Action Demonstrations,4.0, 4.0, 1.0, 5, 4, 5, 3, 3, 4, 3, 3
Causal Representation Learning in Temporal Data via Single-Parent Decoding,3.75, 3.0, 1.299038105676658, 3, 4, 3, 3, 6, 3, 3, 3
Deep Independent Vector Analysis,4.25, 4.0, 1.299038105676658, 6, 2, 5, 3, 3, 4, 3, 4
G-Local Attention Graph Pooling for Graph Classification,3.0, 3.0, 0.0, 3, 5, 3, 5, 3, 4, 3, 4
Relational Constraints On Neural Networks Reproduce Human Biases towards Abstract Geometric Regularity,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 3, 5, 5, 5, 3
Compositional Search of Stable Crystalline Structures in Multi-Component Alloys Using Generative Diffusion Models,3.0, 3.0, 0.0, 3, 2, 3, 3
L2MAC: Large Language Model Automatic Computer for Unbounded Code Generation,6.6, 6.0, 1.2, 8, 3, 6, 4, 6, 3, 5, 4, 8, 4
Learning High-Order Relationships of Brain Regions,4.5, 4.5, 1.5, 6, 1, 6, 3, 3, 4, 3, 5
Stabilized E(n)-Equivariant Graph Neural Networks-assisted Generative Models,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 3, 5, 3
BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 4, 5, 3, 5, 4
Plan-based Prompting Improves Literature Review Generation,3.0, 3.0, 1.2649110640673518, 3, 3, 5, 3, 3, 3, 3, 4, 1, 4
Neural Rankers for Code Generation via Inter-Cluster Modeling,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 3, 6, 4, 3, 4
Linear programming using diagonal linear networks,5.5, 5.5, 0.5, 5, 4, 5, 4, 6, 2, 6, 3
Efficient Value Propagation with the Compositional Optimality Equation,3.0, 3.0, 1.4142135623730951, 3, 4, 5, 3, 3, 3, 1, 4
TROJFAIR: TROJAN FAIRNESS ATTACKS,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 5, 4, 6, 4
An Inexact Conditional Gradient Method for Constrained Bilevel Optimization,6.25, 6.0, 1.0897247358851685, 6, 3, 5, 4, 8, 3, 6, 4
NeuroBack: Improving CDCL SAT Solving using Graph Neural Networks,5.75, 5.0, 1.299038105676658, 5, 4, 8, 3, 5, 4, 5, 4
Group Preference Optimization: Few-Shot Alignment of Large Language Models,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 4, 5, 4
Unsupervised Federated Graph Matching with Graphlet Feature Extraction and Separate Trust Region,6.0, 6.5, 2.1213203435596424, 5, 3, 8, 5, 8, 4, 3, 3
GLASU: A Communication-Efficient Algorithm for Federated Learning with Vertically Distributed Graph Data,4.25, 4.0, 1.299038105676658, 5, 3, 3, 4, 6, 3, 3, 4
Strategic Recommendations for Improved Outcomes in Congestion Games,3.75, 3.0, 1.299038105676658, 6, 3, 3, 3, 3, 2, 3, 3
Complexity of Formal Explainability for Sequential  Models,5.6, 6.0, 1.624807680927192, 5, 4, 8, 4, 3, 3, 6, 4, 6, 4
RPNet: Robust Non-Interactive Private Inference against Malicious Clients with Adversarial Attacks,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 5, 2, 3, 5
Analyzing Neural Network Based Generative Diffusion Models via Convexification,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 4, 3, 4, 5, 2
LayoutDETR: Detection Transformer Is a Good Multimodal Layout Designer,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 5, 4, 6, 4
Constraining Non-Negative Matrix Factorization to Improve Signature Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 4
A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models,4.25, 4.0, 1.299038105676658, 3, 4, 5, 3, 3, 4, 6, 3
Explore Establish Exploit: Red Teaming Language Models from Scratch,4.75, 4.0, 2.0463381929681126, 3, 4, 8, 4, 3, 4, 5, 4
Learning Structured Sparse Neural Networks Using Group Envelope Regularization,3.6666666666666665, 3.0, 0.9428090415820634, 5, 5, 3, 3, 3, 3
Instilling Inductive Biases with Subnetworks,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 6, 3, 8, 3
MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning,6.0, 6.5, 2.1213203435596424, 5, 4, 8, 3, 3, 3, 8, 4
MaskINT: Video Editing via Interpolative Non-autoregressive Masked Transformers,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 4, 6, 4
ENHANCING MULTIVARIATE TIME SERIES FORECAST- ING WITH MUTUAL INFORMATION-DRIVEN CROSS- VARIABLE AND TEMPORAL MODELING,5.0, 6.0, 1.4142135623730951, 3, 4, 6, 3, 6, 3
Regret Rates for $\epsilon$-Greedy Strategies for Nonparametric Bandits with Delayed Rewards,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 3, 5, 3, 5, 4
Training Diffusion Classifiers with Denoising Assistance,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 6, 3, 3, 4
Scalable Normalizing Flows Enable Boltzmann Generators for Macromolecules,5.5, 5.5, 0.5, 5, 4, 6, 3, 5, 4, 6, 3
Sentiment-Enhanced Stock Price Prediction: A Novel Ensemble Model Approach,2.3333333333333335, 3.0, 0.9428090415820634, 3, 4, 1, 5, 3, 4
Large Language Models Can Design Game-Theoretic Objectives for Multi-Agent Planning,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 3, 3, 4, 3, 4
Stability Analysis of Various Symbolic Rule Extraction Methods from Recurrent Neural Network,6.5, 6.5, 1.5, 8, 3, 5, 1
Harnessing Density Ratios for Online Reinforcement Learning,6.666666666666667, 6.0, 0.9428090415820634, 8, 2, 6, 3, 6, 3
MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training,6.5, 6.5, 1.5, 5, 4, 5, 3, 8, 3, 8, 4
Variance-aware Regret Bounds for Stochastic Contextual Dueling Bandits,6.0, 5.5, 1.224744871391589, 5, 3, 6, 4, 5, 3, 8, 2
GOODFIT: A Deep Learning Optimizer Fine Tuned for Fine Tuning,4.0, 4.0, 1.0, 5, 3, 3, 3, 3, 4, 5, 3
A Discretization Framework for Robust Contextual Stochastic Optimization,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 3, 5, 4, 3, 3
Nature-Inspired Local Propagation,4.25, 5.0, 1.920286436967152, 5, 3, 1, 2, 6, 2, 5, 1
Which Examples to Annotate for In-Context Learning? Towards Effective and Efficient Selection,4.25, 4.0, 1.299038105676658, 3, 3, 6, 3, 5, 3, 3, 4
Gradient Descent Provably Solves Nonlinear Tomographic Reconstruction,5.5, 5.5, 1.8027756377319946, 5, 4, 8, 1, 3, 2, 6, 4
Consensus Optimization at Representation: Improving Personalized Federated Learning via Data-Centric Regularization,4.0, 4.0, 1.0, 3, 4, 5, 3, 3, 4, 5, 3
GlycoNMR: A Carbohydrate-Specific NMR Chemical Shift Dataset for Machine Learning Research,5.333333333333333, 5.0, 0.4714045207910317, 5, 2, 6, 3, 5, 4
DynamicsDiffusion: Generating and Rare Event Sampling of Molecular Dynamic Trajectories Using Diffusion Models,3.0, 3.0, 0.0, 3, 5, 3, 5, 3, 4, 3, 5, 3, 4
RePLan: Robotic Replanning with Perception and Language Models,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 5, 4
A Theoretical and Empirical Analysis on Reconstruction Attacks and Defenses,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4
Predictive auxiliary objectives in deep RL mimic learning in the brain,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 8, 4, 6, 3
Machine learning pipelines synthesis with large language models,3.0, 3.0, 1.4142135623730951, 1, 5, 3, 3, 3, 4, 5, 4
GATE: How to Keep Out Intrusive Neighbors,5.2, 5.0, 0.39999999999999997, 5, 3, 5, 3, 5, 4, 5, 3, 6, 4
Risk Bounds of Accelerated SGD for Overparameterized Linear Regression,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 5, 4, 6, 3
A Theory of Non-Linear Feature Learning with One Gradient Step in Two-Layer Neural Networks,5.5, 5.5, 0.5, 5, 3, 6, 2, 6, 3, 5, 4
Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text,4.25, 3.0, 2.165063509461097, 3, 3, 8, 3, 3, 4, 3, 3
Towards Deep Viticultural Representations: Joint Region and Grape Variety Embeddings,2.5, 3.0, 0.8660254037844386, 1, 4, 3, 5, 3, 3, 3, 4
Task structure and nonlinearity jointly determine learned representational geometry,6.0, 5.5, 1.224744871391589, 5, 2, 6, 3, 8, 3, 5, 3
OODRobustBench: benchmarking and analyzing adversarial robustness under distribution shift,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 4, 6, 5, 6, 5
The Distributional Reward Critic Architecture for Reinforcement Learning Under Confusion Matrix Reward Perturbations,5.0, 5.5, 1.224744871391589, 3, 4, 6, 3, 5, 4, 6, 3
Llemma: An Open Language Model for Mathematics,6.666666666666667, 6.0, 0.9428090415820634, 8, 3, 6, 2, 6, 4
Fine-grained Local Sensitivity Analysis of Standard Dot-Product Self-Attention,4.666666666666667, 5.0, 1.247219128924647, 5, 2, 3, 4, 6, 3
Travelling Salesman Problem Goes Sparse With Graph Neural Networks,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4, 3, 4
Imitation Learning Using Generalized Sliced Wasserstein Distances,4.4, 5.0, 1.2, 6, 4, 5, 4, 3, 3, 5, 3, 3, 3
URDFormer: Constructing interactive Realistic Scenes from Real Images via Simulation and Generative Modeling,4.25, 4.0, 1.299038105676658, 3, 3, 6, 3, 5, 4, 3, 4
Directly Fine-Tuning Diffusion Models on Differentiable Rewards,5.5, 5.5, 1.8027756377319946, 5, 4, 6, 4, 8, 4, 3, 5
Predictive scalable and interpretable knowledge tracing on structured domains,5.0, 5.5, 2.5495097567963922, 1, 3, 5, 4, 8, 3, 6, 3
Maximum Likelihood Estimation is All You Need for Well-Specified Covariate Shift,6.75, 7.0, 1.299038105676658, 6, 3, 8, 4, 8, 3, 5, 4
Scaling Safe Learning-based Control to  Long-Horizon Temporal Tasks,4.25, 4.0, 1.299038105676658, 3, 4, 6, 5, 5, 4, 3, 2
Differentiable Learning of Generalized Structured Matrices for Efficient Deep Neural Networks,5.666666666666667, 6.0, 0.4714045207910317, 6, 5, 5, 3, 6, 3
HyperSINDy: Deep Generative Modeling of Nonlinear Stochastic Governing Equations,5.333333333333333, 5.0, 1.4907119849998596, 5, 5, 6, 3, 5, 3, 8, 4, 5, 5, 3, 3
DEXR: A Unified Approach Towards Environment Agnostic Exploration,3.75, 3.0, 1.299038105676658, 3, 5, 3, 3, 3, 3, 6, 4
A Flexible Generative Model for Heterogeneous Tabular EHR with Missing Modality,5.0, 5.0, 1.0954451150103321, 6, 3, 3, 4, 6, 5, 5, 4, 5, 2
UnifiedGT: Exploring the Effective Ingredients of Transformers in Large Graphs,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 3, 5, 4, 3, 4
Robustness Evaluation Using Local Substitute Networks,4.166666666666667, 3.0, 1.8633899812498247, 3, 4, 3, 4, 8, 3, 3, 4, 5, 2, 3, 2
Simplifying GNN Performance with Low Rank Kernel Models,3.0, 3.0, 1.4142135623730951, 3, 4, 3, 3, 5, 3, 1, 4
Designing Skill-Compatible AI: Methodologies and Frameworks in Chess,5.75, 6.0, 1.7853571071357126, 6, 4, 8, 4, 3, 3, 6, 4
CLIN: A Continually Learning Language Agent for Rapid Task Adaptation and Generalization,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 4, 5, 4, 5, 3
Vision-Language Integration in Multimodal Video Transformers (Partially) Aligns with the Brain,3.75, 4.0, 1.920286436967152, 3, 3, 1, 5, 5, 5, 6, 1
Exchangeable Dataset Amortization for Bayesian Posterior Inference,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 3, 5, 4
FroSSL: Frobenius Norm Minimization for Self-Supervised Learning,3.0, 3.0, 1.4142135623730951, 1, 5, 3, 3, 5, 3, 3, 4
Tree Search-Based Policy Optimization under Stochastic Execution Delay,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 3, 5, 3
Context-Aware Meta-Learning,5.25, 5.0, 0.4330127018922193, 5, 3, 6, 3, 5, 3, 5, 5
Efficient Offline Reinforcement Learning: The Critic is Critical,4.333333333333333, 5.0, 0.9428090415820634, 3, 3, 5, 3, 5, 4
A simple and interpretable model of grokking modular arithmetic tasks,5.8, 5.0, 1.16619037896906, 5, 3, 8, 4, 6, 3, 5, 4, 5, 3
SAFHE: Defending Against Backdoor and Gradient Inversion Attacks in Federated Learning,4.333333333333333, 5.0, 0.9428090415820634, 3, 5, 5, 2, 5, 5
LLM Censorship: The Problem and its Limitations,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 2, 3, 3, 5, 3
SurroCBM: Concept Bottleneck Surrogate Models for Joint Unsupervised Concept Discovery and Post-hoc Explanation,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 4, 3, 4
CoarsenConf: Equivariant Coarsening with Aggregated Attention for Molecular Conformer Generation,4.5, 4.5, 1.5, 3, 3, 6, 3, 3, 3, 6, 4
In-Context Learning for Few-Shot Molecular Property Prediction,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 4, 3, 4, 3, 4
Graph Neural Modeling of Network Flows,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4, 3, 5
Constrained Parameter Regularization,5.333333333333333, 5.0, 2.0548046676563256, 5, 2, 3, 5, 8, 3
Robustness of Deep Learning for Accelerated MRI: Benefits of Diverse Training Data,6.0, 5.5, 3.082207001484488, 3, 5, 3, 5, 10, 4, 8, 3
Unifying Model-Based and Model-Free Reinforcement Learning with Equivalent Policy Sets,4.0, 4.0, 1.0, 5, 4, 3, 4, 5, 4, 3, 3
FIITED: Fine-grained embedding dimension optimization during training for recommender systems,4.4, 3.0, 1.9595917942265424, 3, 4, 3, 2, 8, 4, 3, 4, 5, 3
Beyond Accuracy: Evaluating Self-Consistency of Code LLMs,5.5, 5.5, 1.8027756377319946, 6, 4, 3, 3, 8, 3, 5, 4
Improving Generalization for Small Datasets with Data-Aware Dynamic Reinitialization,5.5, 5.5, 0.5, 6, 3, 5, 4, 6, 4, 5, 4
Ito Diffusion Approximation of Universal Ito Chains for Sampling Optimization and Boosting,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 6, 3, 8, 3
From Bricks to Bridges: Product of Invariances to Enhance Latent Space Communication,5.0, 5.5, 1.224744871391589, 3, 3, 6, 4, 5, 3, 6, 3
Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning,6.25, 6.0, 1.0897247358851685, 5, 5, 6, 4, 6, 3, 8, 2
Feasibility with Language Models for Open-World Compositional Zero-Shot Learning,4.25, 4.0, 1.299038105676658, 5, 5, 6, 4, 3, 4, 3, 4
Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning,5.0, 6.0, 1.4142135623730951, 6, 3, 3, 4, 6, 3
Memorization Capacity of Multi-Head Attention in Transformers,6.75, 7.0, 1.299038105676658, 8, 3, 5, 2, 8, 3, 6, 3
A SIMILARITY-AGNOSTIC REINFORCEMENT LEARNING APPROACH FOR LEAD OPTIMIZATION,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 3, 3, 5, 4
Modeling Boundedly Rational Agents with Latent Inference Budgets,6.25, 6.0, 1.0897247358851685, 5, 3, 6, 4, 8, 4, 6, 3
Certifiably Byzantine-Robust Federated Conformal Prediction,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 4, 3, 3
Binder: Hierarchical Concept Representation through Order Embedding of Binary Vectors,3.6, 3.0, 1.7435595774162693, 5, 3, 6, 4, 3, 4, 1, 5, 3, 4
Algorithm Design for Learned Algorithms,3.0, 3.0, 1.4142135623730951, 3, 4, 1, 5, 3, 4, 5, 4
The Effectiveness of Random Forgetting for Robust Generalization,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 5, 6, 3
Diffeomorphic Mesh Deformation via Efficient Optimal Transport for Cortical Surface Reconstruction,6.75, 7.0, 1.299038105676658, 5, 3, 6, 2, 8, 4, 8, 4
Lie Group Decompositions for Equivariant Neural Networks,6.0, 6.0, 1.7320508075688772, 6, 3, 3, 3, 5, 3, 6, 3, 8, 3, 8, 3
RL Algorithms are Information-State Policies in the Bayes-Adaptive MDP,4.25, 3.0, 2.165063509461097, 3, 2, 3, 4, 3, 3, 8, 4
Efficient Heterogeneous Meta-Learning via Channel Shuffling Modulation,5.75, 6.0, 0.4330127018922193, 6, 5, 6, 4, 5, 5, 6, 4
A Mechanism for Solving Relational Tasks in Transformer Language Models,3.75, 4.0, 1.920286436967152, 3, 3, 5, 4, 1, 5, 6, 4
Controllable Data Generation via Iterative Data-Property Mutual Mappings,3.5, 4.0, 1.6583123951777, 3, 4, 5, 4, 5, 4, 1, 4
To Grok or not to Grok: Disentangling Generalization and Memorization on Corrupted Algorithmic Datasets,6.0, 5.0, 1.4142135623730951, 5, 4, 8, 4, 5, 4
Revisiting Non-separable Binary Classification and its Applications in Anomaly Detection,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 5, 2, 6, 2
Basis Function Encoding of Numerical Features in Factorization Machines for Improved Accuracy,5.285714285714286, 5.0, 1.3850513878332367, 6, 4, 5, 2, 8, 3, 5, 3, 5, 3, 5, 2, 3, 3
Task Generalization in Decision-Focused Learning,4.75, 4.0, 2.0463381929681126, 5, 4, 3, 4, 8, 4, 3, 4
Everybody Needs a Little HELP: Explaining Graphs via Hierarchical Concepts,4.0, 4.0, 1.0, 3, 4, 3, 3, 5, 3, 5, 3
Hypernymy Understanding Evaluation of Text-to-Image Models via WordNet Hierarchy,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 4, 5, 3
Generation Reconstruction Representation All-in-One: A Joint Autoencoding Diffusion Model,4.0, 3.0, 1.4142135623730951, 6, 3, 3, 4, 3, 3
Generate to Discriminate: Expert Routing for Continual Learning,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 5, 3, 3, 4
Flatter Faster: Scaling Momentum for Optimal Speedup of SGD,5.0, 6.0, 1.4142135623730951, 6, 3, 3, 3, 6, 3
Recurrent Neural Cellular Automata with Self-Attention for Multi-agent System,4.25, 4.0, 1.299038105676658, 6, 3, 3, 4, 3, 3, 5, 3
VCR-Graphormer: A Mini-batch Graph Transformer via Virtual Connections,5.5, 5.5, 0.5, 5, 5, 6, 5, 6, 4, 5, 4
Mitigating Accumulated Distribution Divergence in Batch Normalization for Unsupervised Domain Adaptation,nan, nan, nan
Composite Backdoor Attacks Against Large Language Models,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 4, 5, 4
Optimistic Bayesian Optimization with Unknown Constraints,6.0, 6.5, 2.1213203435596424, 5, 4, 8, 3, 3, 4, 8, 4
Enhanced Adversarial Domain Generation via Optimized Batch Normalization and Classifier,nan, nan, nan
DRSM: De-Randomized Smoothing on Malware Classifier Providing Certified Robustness,5.0, 5.0, 1.0954451150103321, 6, 4, 6, 4, 3, 4, 5, 4, 5, 4
Calibrated Chaos: Variance Between Runs of Neural Network Training is Harmless and Inevitable,6.0, 5.5, 1.224744871391589, 6, 4, 5, 4, 8, 4, 5, 3
Identifying Drivers of Predictive Uncertainty using Variance Feature Attribution,4.0, 3.5, 3.082207001484488, 1, 5, 6, 4, 1, 4, 8, 3
Lyfe Agents: generative agents for low-cost real-time social interactions,4.2, 5.0, 0.9797958971132712, 3, 2, 5, 2, 3, 4, 5, 3, 5, 4
Circuit Component Reuse Across Tasks in Transformer Language Models,6.0, 5.5, 1.224744871391589, 8, 3, 6, 4, 5, 3, 5, 3
Fourier Ordinary Differential Equations,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 4, 3, 4, 5, 4
PhaseFusion: A Diffusion-based Periodic Parameterized Motion Generation Framework,4.25, 4.0, 1.299038105676658, 6, 2, 3, 4, 3, 3, 5, 4
Identifying Spurious Biases Early in Training through the Lens of Simplicity Bias,nan, nan, nan
NEURAL ADDITIVE TENSOR DECOMPOSITION FOR SPARSE TENSORS,4.75, 4.0, 2.0463381929681126, 3, 4, 5, 4, 3, 4, 8, 4
Large Language Models to Enhance Bayesian Optimization,5.75, 6.0, 1.7853571071357126, 3, 5, 6, 3, 6, 3, 8, 3
Probing Innocuous Overfitting within Robust Linear Analytical Classifications,nan, nan, nan
Likelihood Training of Cascaded Diffusion Models via Hierarchical Volume-preserving Maps,4.25, 4.0, 1.299038105676658, 3, 3, 6, 5, 3, 2, 5, 4
Towards Identifiable Unsupervised Domain Translation: A Diversified Distribution Matching Approach,5.5, 5.5, 1.8027756377319946, 3, 5, 8, 2, 6, 4, 5, 4
Apollo: Zero-shot MultiModal Reasoning with Multiple Experts,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 3
Lie Neurons: A General Adjoint-Equivariant Neural Network for Semisimple Lie Algebras,5.0, 5.5, 1.224744871391589, 6, 3, 3, 3, 5, 3, 6, 4
Learning Dynamics on Manifolds with Neural Ordinary Differential Equations,3.0, 3.0, 1.4142135623730951, 3, 4, 1, 4, 5, 4, 3, 3
Empirical Analysis of Model Selection for Heterogeneous Causal Effect Estimation,6.0, 5.5, 1.224744871391589, 5, 3, 8, 3, 5, 3, 6, 4
Parameter Estimation of Long Memory Stochastic Processes with Deep Neural Networks,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 3, 3, 3, 3, 3
Detecting Deepfakes Without Seeing Any,5.333333333333333, 5.0, 2.0548046676563256, 8, 5, 5, 4, 3, 4
Effective Graph Representation Learning via Smoothed Contrastive Learning,4.75, 4.0, 2.0463381929681126, 3, 4, 8, 2, 3, 4, 5, 3
Graph Neural Tangent Kernel and Graph Neural Network Gaussian Processes for Node Classification/ Regression,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 4, 6, 3
SineNet: Learning Temporal Dynamics in Time-Dependent Partial Differential Equations,4.5, 4.5, 1.5, 6, 4, 3, 3, 3, 3, 6, 5
Emergence of Surprise and Predictive Signals from Local Contrastive Learning,4.75, 4.0, 2.0463381929681126, 5, 4, 8, 4, 3, 4, 3, 4
GNNBoundary: Towards Explaining Graph Neural Networks through the Lens of Decision Boundaries,6.0, 5.5, 1.224744871391589, 6, 3, 5, 3, 8, 3, 5, 3
On the memorisation of image classifiers,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 6, 2, 3, 4
Optimization without retraction on the random generalized Stiefel manifold for canonical correlation analysis,6.5, 5.5, 2.0615528128088303, 10, 4, 5, 3, 5, 3, 6, 4
A Long Way To Go: Investigating Length Correlations in RLHF,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 4, 6, 3, 6, 3
Sparse Spiking Neural Network: Exploiting Heterogeneity in Timescales for Pruning Recurrent SNN,5.0, 5.5, 1.224744871391589, 3, 4, 5, 4, 6, 4, 6, 3
HashOrder: Accelerating Graph Processing Through Hashing-based Reordering,5.333333333333333, 5.0, 1.4907119849998596, 8, 4, 3, 4, 5, 3, 6, 3, 5, 4, 5, 3
Guiding Language Models Reasoning with Planning Tokens,5.0, 5.5, 2.5495097567963922, 5, 4, 8, 3, 1, 4, 6, 3
PrivilegedDreamer: Explicit Imagination of Privileged Information for Adaptation in Uncertain Environments,3.5, 3.0, 0.8660254037844386, 5, 5, 3, 4, 3, 4, 3, 5
Investigating the Benefits of Projection Head for Representation Learning,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 3, 5, 4, 5, 4
A Variational Perspective on Solving Inverse Problems with Diffusion Models,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 6, 3, 5, 5
Can Large Language Models Infer Causation from Correlation?,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 5
A Novel Autoencoder Based Approach for Counterfactual Estimation Using Sparsity Constraints,2.5, 3.0, 0.8660254037844386, 3, 3, 3, 3, 1, 4, 3, 4
MemStranding: Adversarial attacks on temporal graph neural networks,5.0, 6.0, 1.4142135623730951, 6, 4, 6, 2, 3, 4
Anisotropy helps: improved statistical and computational complexity of the mean-field Langevin dynamics under structured data,6.333333333333333, 6.0, 1.247219128924647, 6, 3, 5, 2, 8, 3
ARIES: A Corpus of Scientific Paper Edits Made in Response to Peer Reviews,5.5, 5.5, 2.5, 8, 3, 3, 4, 8, 4, 3, 4
Splicing Up Your Predictions with RNA Contrastive Learning,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 4
Unnormalized Density Estimation with Root Sobolev Norm Regularization,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 5, 3, 3, 3
Network Alignment with Transferable Graph Autoencoders,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 4, 6, 4, 5, 4
Class-Conditional Conformal Prediction for Imbalanced Data via Top-$k$ Classes,4.0, 3.0, 1.2649110640673518, 3, 2, 3, 3, 6, 4, 5, 3, 3, 4
Competitive-Collaborative GAN with Performance Guarantee,3.5, 3.0, 0.8660254037844386, 5, 5, 3, 4, 3, 4, 3, 5
Certified Copy: A Resistant Backdoor Attack,3.0, 3.0, 1.0690449676496976, 1, 4, 3, 4, 3, 4, 3, 4, 3, 5, 5, 4, 3, 3
SPADE: Sparsity-Guided Debugging for Deep Neural Networks,5.0, 4.5, 2.1213203435596424, 3, 4, 8, 3, 3, 4, 6, 3
TimewarpVAE: Simultaneous Time-Warping and Representation Learning of Trajectories,5.0, 5.5, 1.224744871391589, 6, 3, 3, 4, 6, 4, 5, 3
AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation,6.0, 6.5, 2.1213203435596424, 5, 4, 3, 3, 8, 3, 8, 2
CycleAlign: Iterative Distillation from Black-box LLM to White-box Models for Better Human Alignment,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 4, 5, 5
Jointly-Learned Exit and Inference for a Dynamic Neural Network,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 5, 6, 4, 5, 4
Confidential-DPproof: Confidential Proof of Differentially Private Training,6.666666666666667, 5.0, 2.357022603955158, 10, 4, 5, 3, 5, 2
Understanding of  Server-Assisted Federated Learning with Incomplete Client Participation,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 4, 3, 4
Randomized Benchmarking of Local Zeroth-Order Optimizers for Variational Quantum Systems,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4, 3, 5
Enhancing Group Fairness in Federated Learning through Personalization,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 4, 5, 4
Understanding the Robustness of Multi-modal Contrastive Learning to Distribution Shift,5.5, 5.5, 0.5, 5, 4, 6, 4, 6, 2, 5, 4
Fusion Token: Enhancing Compression and Efficiency in Language Model Tokenization,3.5, 3.0, 0.8660254037844386, 3, 3, 5, 2, 3, 4, 3, 3
SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 3, 6, 2, 5, 2
Layer-wise linear mode connectivity,5.5, 5.5, 0.5, 6, 3, 5, 4, 5, 3, 6, 4
Understanding Certified Training with Interval Bound Propagation,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 5, 6, 3, 5, 4
Offline RL with Observation Histories: Analyzing and Improving Sample Complexity,5.0, 5.0, 0.0, 5, 2, 5, 3, 5, 3
Zero-Shot Goal-Directed Dialogue via RL on Imagined Conversations,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 3, 3, 3
Double Equivariance for Inductive Link Prediction for Both New Nodes and New Relation Types,5.5, 5.5, 1.8027756377319946, 6, 4, 8, 4, 3, 4, 5, 4
Exploring the Edge of Stability: Insights from a Fine-Grained Analysis of Gradient Descent in Shallow ReLU Networks,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 5, 3, 4, 1, 3
Topoformer: brain-like topographic organization in Transformer language models through spatial querying and reweighting,5.2, 5.0, 1.6, 5, 4, 8, 4, 5, 4, 3, 3, 5, 4
Graph-based Virtual Sensing from Sparse and Partial Multivariate Observations,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 4, 6, 2
NEFTune: Noisy Embeddings Improve Instruction Finetuning,5.75, 6.0, 1.7853571071357126, 6, 4, 3, 3, 6, 3, 8, 4
DS-Prover: A Dynamic Sampling Based Approach for Neural Theorem Proving,3.75, 3.0, 1.299038105676658, 3, 5, 3, 3, 6, 4, 3, 4
An operator preconditioning perspective on training in physics-informed machine learning,5.666666666666667, 5.0, 1.1055415967851332, 5, 5, 5, 4, 5, 3, 5, 3, 8, 4, 6, 3
M-BioBERTa: Modular RoBERTa-based Model for Biobank-scale Unified Representations,4.666666666666667, 5.0, 1.247219128924647, 3, 5, 6, 4, 5, 4
A neuro-symbolic framework for answering conjunctive queries,3.6, 3.0, 1.2000000000000002, 3, 5, 3, 2, 6, 3, 3, 4, 3, 4
Two-stage LLM Fine-tuning with Less Specialization and More Generalization,6.25, 6.0, 1.0897247358851685, 6, 4, 6, 4, 8, 4, 5, 3
Closing the gap on tabular data with Fourier and Implicit Categorical Features,4.4, 5.0, 1.2, 6, 5, 3, 5, 5, 4, 3, 4, 5, 4
Explaining Contrastive Models using Exemplars: Explanation Confidence and Knowledge Limits,4.75, 4.0, 2.0463381929681126, 3, 4, 8, 3, 5, 4, 3, 4
(Dynamic) Prompting might be all you need to repair Compressed LLMs,5.0, 4.5, 2.1213203435596424, 3, 4, 8, 3, 6, 3, 3, 3
Instance Segmentation with Supervoxel Based Topological Loss Function,5.0, 5.0, 0.0, 5, 4, 5, 5, 5, 4
Using Approximate Models for Efficient Exploration in Reinforcement Learning,2.5, 3.0, 0.8660254037844386, 1, 4, 3, 3, 3, 3, 3, 4
$\nu$-ensembles: Improving deep ensemble calibration in the small data regime,4.4, 5.0, 1.2, 3, 4, 3, 3, 6, 4, 5, 4, 5, 4
Sparse Refinement for Efficient High-Resolution Semantic Segmentation,5.5, 5.5, 0.5, 5, 5, 6, 4, 5, 4, 6, 4
Sorting Out Quantum Monte Carlo,4.25, 4.0, 1.299038105676658, 6, 4, 3, 4, 5, 3, 3, 5
Proximal Preference Optimization for Diffusion Models,4.75, 4.0, 2.0463381929681126, 5, 5, 3, 3, 8, 5, 3, 5
Understanding the Theoretical Generalization Performance of Federated Learning,4.25, 4.0, 1.299038105676658, 3, 4, 5, 3, 6, 3, 3, 4
Expressive Losses for Verified Robustness via Convex Combinations,5.25, 5.0, 1.7853571071357126, 3, 4, 8, 4, 5, 2, 5, 2
Baseline Defenses for Adversarial Attacks Against Aligned Language Models,5.25, 5.0, 1.7853571071357126, 5, 4, 8, 3, 5, 4, 3, 4
On Sampling Information Sets to Learn from Imperfect Information,1.6666666666666667, 1.0, 0.9428090415820634, 3, 3, 1, 5, 1, 4
Deep Unlearning: Fast and Efficient Training-free Approach to Controlled Forgetting,5.25, 5.0, 1.7853571071357126, 5, 3, 5, 4, 3, 5, 8, 4
Modular Learning of Deep Causal Generative Models for High-dimensional Causal Inference,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 4, 5, 3, 3, 3
In-Context Pretraining: Language Modeling Beyond Document Boundaries,7.0, 7.0, 1.0, 6, 4, 6, 3, 8, 4, 8, 3
Detecting Shortcuts using Mutual Information,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 3, 3, 4
Neural functional a posteriori error estimates,5.5, 5.5, 1.8027756377319946, 6, 1, 5, 3, 8, 3, 3, 3
FedLPA: Personalized One-shot Federated Learning with Layer-Wise Posterior Aggregation,5.0, 5.0, 1.0954451150103321, 5, 3, 6, 3, 3, 5, 6, 3, 5, 3
What's In My Big Data?,7.0, 6.5, 2.1213203435596424, 10, 5, 5, 4, 8, 4, 5, 4
A Topology-aware Graph Coarsening Framework for Continual Graph Learning,5.0, 4.5, 2.1213203435596424, 6, 3, 8, 3, 3, 4, 3, 5
Learning Adaptive Multiresolution Transforms via Meta-Framelet-based Graph Convolutional Network,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 3, 6, 4, 5, 4
Conditional Generative Models are Sufficient to Sample from Any Causal Effect Estimand,4.0, 5.0, 1.7320508075688772, 5, 2, 1, 4, 5, 3, 5, 3
Reservoir Transformer at Infinite Horizon: the Lyapunov Time and the Butterfly Effect,4.25, 4.0, 1.299038105676658, 6, 2, 3, 3, 3, 2, 5, 4
REFACTOR: Learning to Extract Theorems from Proofs,5.5, 5.5, 2.5, 3, 4, 3, 4, 8, 4, 8, 4
PaperQA: Retrieval-Augmented Generative Agent for Scientific Research,4.0, 4.0, 1.0, 5, 4, 5, 3, 3, 5, 3, 4
On Feature Diversity in Energy-based Models,5.6, 6.0, 0.48989794855663565, 6, 2, 5, 3, 5, 4, 6, 2, 6, 3
Let's do the time-warp-attend: Learning topological invariants of dynamical systems,4.5, 4.5, 1.5, 6, 4, 3, 4, 6, 5, 3, 3
Kick Bad Guys Out! Zero-Knowledge-Proof-Based Anomaly Detection in Federated Learning,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 3, 6, 2
FStega: Fourier Neural Operators for printer-proof steganography,2.8, 3.0, 1.8330302779823362, 1, 5, 3, 4, 6, 3, 3, 2, 1, 5
Sparse MoE with Language Guided Routing for Multilingual Machine Translation,6.5, 6.5, 1.5, 8, 4, 5, 5, 5, 4, 8, 5
Class-Wise Generalization Error: An Information-Theoretic Analysis,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 6, 4, 5, 4
Detecting Pretraining Data from Large Language Models,6.0, 5.5, 1.224744871391589, 5, 3, 5, 4, 8, 3, 6, 3
Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with Autoformalization,5.75, 6.0, 1.7853571071357126, 3, 4, 8, 4, 6, 3, 6, 4
Bring Your Own Data!  Self-Supervised Evaluation for Large Language Models,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 4
On Diffusion Modeling for Anomaly Detection,6.25, 6.0, 1.0897247358851685, 5, 5, 8, 4, 6, 3, 6, 4
Defending Against Transfer Attacks From Public Models,4.5, 4.5, 2.692582403567252, 8, 3, 3, 5, 6, 3, 1, 5
Balancing the Picture: Debiasing Vision-Language Datasets with Synthetic Contrast Sets,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 4, 6, 3
Social Reward: Evaluating and Enhancing Generative AI through Million-User Feedback from an Online Creative Community,6.25, 6.0, 1.0897247358851685, 5, 4, 8, 3, 6, 4, 6, 2
Optimization for Neural Operator Learning: Wider Networks are Better,4.25, 4.0, 1.299038105676658, 3, 5, 3, 3, 6, 3, 5, 5
PRO: Pseudo-label Regularized Optimization on Unlabeled Test Data,3.75, 3.0, 1.299038105676658, 3, 3, 3, 4, 3, 4, 6, 3
Recent Link Classification on Temporal Graphs Using Profile Builder,4.2, 5.0, 1.6000000000000003, 1, 2, 5, 3, 5, 3, 5, 4, 5, 3
AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with TikZ,6.25, 6.0, 1.0897247358851685, 5, 4, 6, 3, 8, 3, 6, 4
Sharpness-Aware Minimization Enhances Feature Quality via Balanced Learning,5.5, 6.0, 1.118033988749895, 6, 3, 3, 4, 6, 3, 6, 3, 6, 4, 6, 4
Improving Generalization and Safety of Deep Neural Networks with Masked Anchoring,5.8, 6.0, 1.6, 6, 3, 8, 3, 6, 4, 3, 4, 6, 3
Can LLM-Generated Misinformation Be Detected?,4.75, 4.0, 2.0463381929681126, 5, 4, 8, 5, 3, 5, 3, 3
Sharp results for NIEP and NMF,5.8, 5.0, 1.9390719429665317, 8, 1, 5, 3, 8, 4, 5, 3, 3, 3
A Simple and Efficient Baseline for Data Attribution on Images,4.0, 4.0, 1.0, 5, 4, 3, 5, 3, 4, 5, 2
A Simple Interpretable Transformer for Fine-Grained Image Classification and Analysis,5.5, 5.5, 0.5, 5, 5, 6, 4, 6, 4, 5, 4
Molecule Relaxation by Reverse Diffusion with Time Step Prediction,4.5, 5.0, 0.8660254037844386, 5, 5, 5, 4, 3, 3, 5, 3
PLPP: PROMPT LEARNING WITH PERPLEXITY FOR VISION-LANGUAGE MODELS,2.5, 3.0, 0.8660254037844386, 3, 5, 3, 5, 1, 4, 3, 5
Interactive Semantic Map Representation for Skill-based Visual Object Navigation,2.5, 2.0, 1.6583123951777, 3, 3, 1, 4, 1, 4, 5, 3
Fine-tuning Aligned Language Models Compromises Safety Even When Users Do Not Intend To!,6.5, 5.5, 2.0615528128088303, 5, 5, 6, 4, 10, 5, 5, 2
High-Order Tensor Recovery with A Tensor $U_1$ Norm,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 4
One-shot Active Learning Based on Lewis Weight Sampling for Multiple Deep Models,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 3, 6, 3, 5, 3
Disentangling Time Series Representations via Contrastive based $l$-Variational Inference,5.666666666666667, 8.0, 3.299831645537222, 8, 5, 8, 4, 1, 3
Minimalist and High-Performance Semantic Segmentation with Plain Vision Transformers,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 5, 4, 3, 5
D5RL: Diverse Datasets for Data-Driven Deep Reinforcement Learning,4.0, 5.0, 2.160246899469287, 1, 4, 6, 3, 5, 3
Endowing Protein Language Models with Structural Knowledge,4.8, 5.0, 0.9797958971132712, 5, 5, 5, 4, 6, 3, 5, 5, 3, 5
Improved algorithm and bounds for successive projection,5.25, 6.0, 1.299038105676658, 3, 3, 6, 2, 6, 2, 6, 3
Role of Locality and Weight Sharing in Image-Based Tasks: A Sample Complexity Separation between CNNs LCNs and FCNs,5.5, 5.5, 1.8027756377319946, 3, 5, 5, 3, 6, 3, 8, 3
In-Depth Comparison of Regularization Methods For Long-Tailed Learning in Trajectory Prediction,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 5, 5, 4
A Distributional Analogue to the Successor Representation,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 3, 6, 2, 5, 2
H-Rockmate: Hierarchical Approach for Efficient Re-materialization of Large Neural Networks,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 3, 3, 4
Hyperbolic Embeddings in Sequential Self-Attention for Improved Next-Item Recommendations,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 5, 3, 4, 3, 5
Understanding Hidden Context in Preference Learning: Consequences for RLHF,5.5, 5.5, 1.8027756377319946, 5, 2, 8, 2, 6, 3, 3, 3
On Memorization and Privacy Risks of Sharpness Aware Minimization,4.6, 5.0, 1.3564659966250536, 5, 3, 3, 4, 6, 2, 3, 4, 6, 3
Estimating Shape Distances on Neural Representations with Limited Samples,6.75, 7.0, 2.5860201081971503, 8, 4, 10, 4, 3, 3, 6, 3
AgentTuning: Enabling Generalized Agent Abilities for LLMs,5.0, 6.0, 1.4142135623730951, 3, 4, 6, 4, 6, 4
Explicitly Disentangled Representations in Object-Centric Learning,5.0, 5.0, 0.0, 5, 5, 5, 2, 5, 4, 5, 3
Reduced-Rank Online Gaussian Process Modeling With Uncertain Inputs,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 4, 5, 3, 5, 3
Learning semilinear neural operators: A unified recursive framework for prediction and data assimilation.,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 3, 5, 4
Resource Efficient Self-Supervised Learning for Speech Embeddings,5.0, 5.5, 1.224744871391589, 3, 4, 6, 4, 6, 3, 5, 4
Balancing Stability and Plasticity in Continual Learning: the readout-decomposition of activation change (RDAC) framework,4.75, 5.0, 1.0897247358851685, 6, 1, 3, 5, 5, 5, 5, 2
ADJUSTING THE INDUCTIVE BIAS OF DIFFUSION MODELS,nan, nan, nan
Beyond Differentiability: Neurosymbolic Learning with Black-Box Programs,4.75, 5.0, 1.0897247358851685, 6, 2, 3, 5, 5, 2, 5, 2
Leveraging image representations for bounded adversarial attacks and robustness,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 3, 3, 5, 3
SEER: Towards Efficient Preference-based Reinforcement Learning via Aligned Experience Estimation,4.0, 4.0, 1.0, 3, 3, 5, 2, 3, 3, 5, 2
Rethinking the Buyer’s Inspection Paradox in Information Markets with Language Agents,5.5, 5.5, 0.5, 6, 4, 6, 4, 5, 3, 5, 2
Not Just Pretty Pictures: Toward Interventional Data Augmentation Using Text-to-Image Generators,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 5, 5, 4, 5, 4
Fair Adversarial Training: on the Adversarial Attack and Defense of Fairness,5.0, 5.5, 1.224744871391589, 6, 4, 6, 3, 5, 2, 3, 4
Deep Generalized Green's Function,nan, nan, nan
Multimodal Procedural Planning via Dual Text-Image Prompting,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 4, 6, 3
SPFormer: Enhancing Vision Transformer with Superpixel Representation,4.0, 4.0, 1.0, 3, 4, 3, 5, 5, 4, 5, 4
Head Information Bottleneck: An Evaluation Method for Transformer Head Contributions in Speech Task,4.25, 3.0, 2.165063509461097, 3, 3, 3, 4, 8, 4, 3, 3
Eureka: Human-Level Reward Design via Coding Large Language Models,5.5, 5.5, 0.5, 6, 4, 5, 4, 6, 4, 5, 4
f-FERM: A  Scalable Framework for  Robust Fair Empirical Risk Minimization,5.5, 5.5, 1.8027756377319946, 5, 3, 6, 4, 8, 3, 3, 4
Plausibly Deniable Encryption with Large Language Models,6.5, 6.5, 1.5, 8, 4, 5, 3
The crossover strategy based on the cellular automata for genetic Algorithms with binary chromosomes population,2.0, 2.0, 1.0, 3, 4, 1, 4
Two-Stage Diffusion Models: Better Image Synthesis by Explicitly Modeling Semantics,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 6, 3, 5, 3
Source-Free and Image-Only Unsupervised Domain Adaptation for Category Level Object Pose Estimation,5.0, 5.5, 1.224744871391589, 6, 3, 6, 4, 5, 4, 3, 3
Tensor Time-Series Forecasting and Anomaly Detection with Augmented Causality,3.75, 3.0, 2.5860201081971503, 3, 4, 3, 3, 1, 3, 8, 3
Towards Adversarially Robust Condensed Dataset by Curvature Regularization,3.0, 3.0, 1.4142135623730951, 5, 2, 3, 3, 1, 4, 3, 4
Closing the Curious Case of Neural Text Degeneration,7.0, 7.0, 1.0, 8, 4, 8, 2, 6, 4, 6, 4
Mediator Interpretation and Faster Learning Algorithms for Linear Correlated Equilibria in General Sequential Games,6.0, 6.0, 0.0, 6, 3, 6, 3, 6, 3, 6, 2
xVal: A Continuous Number Encoding for Large Language Models,4.0, 4.5, 2.1213203435596424, 1, 4, 6, 3, 3, 3, 6, 3
3D Feature Prediction for Masked-AutoEncoder-Based Point Cloud Pretraining,5.75, 5.0, 1.299038105676658, 5, 4, 8, 4, 5, 4, 5, 4
Robust Policy Optimization with Evolutionary Techniques,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 5, 3, 3
Temporal graph models fail to capture global temporal dynamics,3.25, 3.0, 1.7853571071357126, 3, 4, 1, 2, 6, 3, 3, 4
Understanding Catastrophic Forgetting in Language Models via Implicit Inference,5.75, 6.0, 1.7853571071357126, 3, 5, 8, 3, 6, 4, 6, 3
Robot Learning from Demonstration: Enhancing Plan Execution with Failure Detection Model,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 4, 3, 4
Lion Secretly Solves a Constrained Optimization: As Lyapunov Predicts,7.25, 8.0, 1.299038105676658, 8, 2, 5, 3, 8, 3, 8, 2
Controllable Pareto Trade-off between Fairness and Accuracy,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 4
Distributionally Robust Optimization with Bias & Variance Reduced Gradients,7.0, 7.0, 1.0, 6, 3, 8, 4, 8, 4, 6, 3
Competition Priors for Object-Centric Learning,3.75, 4.0, 1.920286436967152, 3, 4, 5, 4, 1, 4, 6, 4
Greedy PIG: Adaptive Integrated Gradients,4.25, 4.0, 1.299038105676658, 6, 3, 3, 4, 5, 3, 3, 3
Synthesizing Programmatic Policy for Domain Generalization,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 4
Multi-Scale Window based Transformer Network for High Quality Image Inpainting,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 5, 5, 5, 3, 5
Tweedie Moment Projected Diffusions for Inverse Problems,4.0, 4.0, 1.0, 5, 4, 3, 5, 5, 4, 3, 4
Spectral Highways: Injecting Homophily into Heterophilic Graphs,4.5, 5.0, 0.8660254037844386, 3, 5, 5, 4, 5, 4, 5, 5
Biological Sequence Editing with Generative Flow Networks,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 3, 3, 2
QualEval: Qualitative Evaluation for Model Improvement,2.3333333333333335, 3.0, 0.9428090415820634, 3, 2, 1, 4, 3, 4
Steering No-Regret Learners to Optimal Equilibria,5.75, 5.0, 1.299038105676658, 8, 3, 5, 3, 5, 4, 5, 3
AgentMixer: Multi-Agent Correlated Policy Factorization,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 5, 3, 3, 3
Dynamic Assortment Selection and Pricing with Learning,3.0, 3.0, 0.0, 3, 3
Implicit regularization of multi-task learning and finetuning in overparameterized neural networks,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 8, 4, 6, 2
Quack: Automatic Jailbreaking Large Language Models via Role-playing,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 3
ACES: Generating Diverse Programming Puzzles with Autotelic Language Models and Semantic Descriptors,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 3, 4, 5, 4
Enhancement-Driven Pretraining for Robust Fingerprint Representation Learning,2.3333333333333335, 3.0, 0.9428090415820634, 3, 3, 1, 4, 3, 4
Learning from A Single Graph is All You Need for Near-Shortest Path Routing,3.1666666666666665, 3.0, 1.462494064565354, 3, 4, 1, 4, 3, 3, 6, 3, 3, 3, 3, 3
Generative Entropic Neural Optimal Transport To Map Within and Across Space,6.25, 6.0, 1.0897247358851685, 6, 3, 6, 3, 5, 4, 8, 4
Bridging Debiasing Tasks with Sufficient Projection: A General Theoretical Framework for Vector Representations,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 3, 3, 5, 4
Human-in-the-loop Detection of AI-generated Text via Grammatical Patterns,3.5, 3.0, 0.8660254037844386, 3, 3, 5, 3, 3, 3, 3, 3
Towards Meta-Models for Automated Interpretability,3.0, 3.0, 1.632993161855452, 1, 5, 3, 3, 5, 3
Efficient Subgraph GNNs by Learning Effective Selection Policies,5.75, 6.0, 0.4330127018922193, 5, 4, 6, 4, 6, 4, 6, 3
Inverse Decision Making via Inverse Generative Modeling,3.75, 3.0, 1.299038105676658, 3, 3, 3, 3, 6, 4, 3, 2
Parsing neural dynamics with infinite recurrent switching linear dynamical systems,6.0, 6.0, 1.0954451150103321, 6, 5, 5, 3, 8, 3, 6, 2, 5, 3
Can We Generate Realistic Hands Using Only Convolution?,3.75, 3.0, 1.299038105676658, 3, 5, 3, 4, 3, 3, 6, 3
Active Retrosynthetic Planning Aware of Route Quality,6.0, 5.0, 1.4142135623730951, 5, 4, 8, 4, 5, 3
ArtWhisperer: A Dataset for Characterizing Human-AI Interactions in Artistic Creations,5.75, 5.0, 1.299038105676658, 8, 4, 5, 4, 5, 3, 5, 4
How do Language Models Bind Entities in Context?,5.25, 5.0, 0.4330127018922193, 5, 2, 5, 2, 5, 3, 6, 3
LayerAct: Advancing CNNs with BatchNorm through Layer-direction Normalization,5.333333333333333, 5.0, 0.4714045207910317, 5, 2, 5, 4, 6, 3
A Benchmark for Learning to Translate a New Language from One Grammar Book,7.0, 8.0, 1.4142135623730951, 5, 5, 8, 4, 8, 4
Novel Quadratic Constraints for Extending LipSDP beyond Slope-Restricted Activations,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 2, 6, 3
Fairness-aware Message Passing for Graph Neural Networks,4.6, 5.0, 0.7999999999999999, 5, 4, 5, 4, 3, 4, 5, 4, 5, 3
SARI: SIMPLISTIC AVERAGE AND ROBUST IDENTIFICATION BASED NOISY PARTIAL LABEL LEARNING,3.75, 4.0, 1.920286436967152, 6, 5, 1, 4, 3, 4, 5, 3
From Local Explainability to Global Robustness: Improving the Robustness of Machine Learning Models Using Counterfactual Explanations,4.0, 4.0, 1.0, 3, 4, 5, 4, 5, 4, 3, 3
Backdoor Attack for Federated Learning with Fake Clients,4.0, 4.0, 1.0, 5, 4, 3, 3, 3, 4, 5, 4
Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation,5.75, 6.0, 0.4330127018922193, 5, 3, 6, 3, 6, 3, 6, 4
Corrupting Unbounded Unlearnable Datasets with Pixel-based Image Transformations,4.0, 3.0, 1.4142135623730951, 3, 5, 3, 3, 6, 4
Navigating Scaling Laws: Accelerating Vision Transformer's Training via Adaptive Strategies,3.75, 3.0, 1.299038105676658, 3, 3, 6, 4, 3, 3, 3, 3
Towards Reliable Evaluation and Fast Training of Robust Semantic Segmentation Models,5.0, 5.5, 1.224744871391589, 6, 3, 6, 3, 3, 4, 5, 4
Two-sided Competing Matching Markets With Complementary Preferences,4.25, 4.0, 1.299038105676658, 3, 3, 5, 3, 6, 2, 3, 4
Pushing Gradient towards Zero: A Novel Pruning Method for Large Language Models,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 5, 4, 3, 3
Tab2Gan: Utilizing image conversion and Gan inversion for tabular model robustness,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 4, 3, 3, 3, 5
Is Inverse Reinforcement Learning Harder than Standard Reinforcement Learning?,6.0, 5.5, 1.224744871391589, 6, 3, 8, 2, 5, 3, 5, 5
FedDRO: Federated Compositional Optimization for Distributionally Robust Learning,4.25, 4.0, 1.299038105676658, 5, 4, 6, 3, 3, 5, 3, 4
Neural Diffusion Models,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 6, 3, 5, 4
Calibration-then-Calculation: A Variance Reduced Metric Framework,4.6, 5.0, 1.3564659966250536, 6, 4, 3, 4, 5, 4, 6, 3, 3, 3
Robust Reinforcement Learning for Portfolio Management via Competition and Cooperation Strategies,3.25, 3.0, 0.6614378277661477, 5, 2, 3, 3, 3, 4, 3, 3, 3, 2, 3, 4, 3, 3, 3, 4
Poisoning-based Backdoor Attacks for Arbitrary Target Label with Positive Triggers,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 5, 5, 3, 4
Implicit Neural Representations and the Algebra of Complex Wavelets,5.2, 6.0, 1.9390719429665317, 8, 4, 3, 4, 6, 3, 3, 3, 6, 3
Fiber Monte Carlo,5.666666666666667, 6.0, 2.0548046676563256, 6, 3, 8, 4, 3, 4
ICA model estimation using an optimized version of genetic algorithms,4.5, 4.5, 1.5, 6, 2, 3, 3
Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation,5.8, 5.0, 1.16619037896906, 5, 4, 6, 3, 5, 3, 8, 3, 5, 4
High-dimensional Bayesian Optimization with Group Testing,4.5, 4.5, 1.5, 6, 3, 3, 3, 3, 3, 6, 3
Modeling state-dependent communication between brain regions with switching nonlinear dynamical systems,4.6, 5.0, 1.3564659966250536, 3, 4, 3, 4, 6, 4, 5, 4, 6, 4
Predicting the Encoding Error of Implicit Neural Representations,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 4, 3, 3, 3, 4
Robustness via learned Bregman divergence,4.75, 4.0, 2.0463381929681126, 3, 4, 3, 4, 5, 3, 8, 4
Reason to Behave: Achieving Human-Like Task Execution for Physics-Based Characters,3.0, 3.0, 1.4142135623730951, 3, 5, 3, 4, 1, 4, 5, 4
Reducing the Need for Backpropagation and Discovering Better Optima With Explicit Optimizations of Neural Networks,2.5, 3.0, 0.8660254037844386, 3, 3, 3, 3, 3, 4, 1, 4
SOI: Scaling down computational complexity by estimating partial states of the model,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 3, 6, 3, 3, 3
Elephants Never Forget: Testing Language Models for Memorization of Tabular Data,4.75, 4.0, 2.0463381929681126, 3, 4, 3, 4, 8, 4, 5, 3
IMPROVING ADVERSARIAL TRAINING WITH MARGIN- WEIGHTED PERTURBATION BUDGET,4.25, 4.0, 1.299038105676658, 3, 4, 3, 4, 6, 4, 5, 4
Object-Centric Semantic Vector Quantization,5.5, 5.5, 0.5, 5, 3, 5, 4, 6, 3, 6, 2
In-Context Unlearning: Language Models as Few Shot Unlearners,5.0, 6.0, 1.4142135623730951, 6, 4, 3, 3, 6, 2
Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization,5.6, 6.0, 1.624807680927192, 8, 4, 6, 5, 5, 4, 3, 4, 6, 3
ChunkAttention: Efficient Attention on KV Cache with Chunking Sharing and Batching,4.5, 5.0, 0.8660254037844386, 3, 5, 5, 3, 5, 5, 5, 3
Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 5, 4, 6, 4
EPIC: Compressing Deep GNNs via Expressive Power Gap-Induced Knowledge Distillation,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 4
The common Stability Mechanism behind most Self-Supervised Learning Approaches,4.0, 4.0, 1.0, 5, 3, 3, 3, 3, 5, 5, 3
Orthogonal Sequential Fusion in Multimodal Learning,3.0, 3.0, 1.4142135623730951, 3, 4, 1, 5, 3, 3, 5, 2
Unsupervised graph neural networks with recurrent features for solving combinatorial optimization problems,3.75, 3.0, 1.299038105676658, 3, 2, 6, 2, 3, 4, 3, 4
Towards Dynamic EHR Phenotyping: A Generative Clustering Model,4.0, 4.0, 1.0, 3, 4, 5, 3, 3, 5, 5, 3
ADELT: Transpilation Between Deep Learning Frameworks,5.0, 4.5, 2.1213203435596424, 8, 4, 3, 4, 6, 4, 3, 5
Training-Free Generalization on Heterogeneous Tabular Data via Meta-Representation,3.25, 3.0, 1.7853571071357126, 3, 4, 1, 4, 3, 4, 6, 4
MIRAGE: Modelling Interpretable Multivariate Time Series Forecasts with Actionable Ground Explanations,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 2
Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting,5.5, 5.5, 0.5, 6, 3, 6, 4, 5, 3, 5, 3
Learning the Latent Noisy Data Generative Process for Label-Noise Learning,4.25, 4.0, 1.299038105676658, 3, 5, 6, 4, 3, 4, 5, 3
Jailbreaking Black Box Large Language Models in Twenty Queries,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 4, 5, 3, 5, 4
Data Imputation by Pursuing Better Classification: A Supervised Learning Approach,5.5, 5.5, 0.5, 6, 4, 6, 4, 5, 3, 5, 3
IG-Net: Image-Goal Network for Offline Visual Navigation on A Large-Scale Game Map,3.6, 3.0, 1.2000000000000002, 3, 5, 6, 4, 3, 4, 3, 4, 3, 4
Learning the Hidden Set Locally,5.666666666666667, 6.0, 2.0548046676563256, 6, 3, 8, 3, 3, 2
What Makes a Good Prune? Optimal Unstructured Pruning for Maximal Cosine Similarity,5.5, 5.5, 1.8027756377319946, 6, 4, 3, 5, 8, 3, 5, 4
Boosting Multi-Agent Reinforcement Learning via Transition-Informed Representations,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 5, 3
Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 2, 5, 4
EXPLEME: A Study in Meme Interpretability Diving Beyond Input Attribution,5.5, 5.5, 2.5, 3, 4, 3, 4, 8, 4, 8, 2
Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis,6.0, 5.5, 1.224744871391589, 6, 3, 5, 5, 8, 5, 5, 3
Adversarial Latent Feature Augmentation for Fairness,5.166666666666667, 5.5, 1.0671873729054746, 6, 3, 3, 1, 6, 3, 5, 3, 5, 4, 6, 2
A Generative Model for Game Theory with Flow Equilibrium,4.0, 3.0, 1.4142135623730951, 3, 3, 3, 3, 6, 3
An Agnostic View on the Cost of Overfitting in (Kernel) Ridge Regression,7.0, 7.0, 1.0, 8, 5, 6, 2
Discouraging Posterior Collapse in Hierarchical Variational Autoencoders Using Context,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 4, 5, 2, 5, 2
Towards Complete Expressiveness Capacity of Mixed Multi-Agent Q Value Function,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 3, 6, 5
Differentiable Tree Search in Latent State Space,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 4, 6, 3, 5, 4
Model-based Reinforcement Learning for Parameterized Action Spaces,5.6, 5.0, 2.33238075793812, 5, 3, 3, 4, 5, 4, 10, 4, 5, 4
Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors,6.5, 6.0, 0.8660254037844386, 6, 4, 6, 4, 6, 4, 8, 3
Explaining Kernel Clustering via Decision Trees,6.75, 7.0, 1.299038105676658, 8, 5, 6, 3, 8, 4, 5, 4
Prompt-aware Adapter: Towards Learning Effective Visual Tokens for GPT4-Style Multimodal Models,4.0, 4.0, 1.0, 3, 4, 5, 3, 5, 4, 3, 4
Improving Offline RL by Blending Heuristics,5.5, 5.5, 1.8027756377319946, 6, 4, 8, 4, 3, 4, 5, 3
Understanding Heterophily for Graph Neural Networks,5.8, 6.0, 1.6, 6, 4, 6, 5, 3, 5, 6, 5, 8, 3
Assessing Robustness via Score-based Adversarial Image Generation,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 5, 3, 4, 5, 4
AST-T5: Structure-Aware Pretraining for Code Generation and Understanding,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 5, 5, 4
CAMMARL: Conformal Action Modeling in Multi Agent Reinforcement Learning,4.5, 5.0, 0.8660254037844386, 3, 3, 5, 4, 5, 3, 5, 5
Online Fractional Knapsack With Predictions,4.5, 4.5, 1.5, 3, 4, 6, 4, 6, 4, 3, 2
STUPD: A Synthetic Dataset for Spatial and Temporal Relation Reasoning,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 5, 5, 5
Cooperative Graph Neural Networks,4.75, 4.0, 2.0463381929681126, 5, 3, 3, 5, 8, 3, 3, 4
High Dimensional Causal Inference with Variational Backdoor Adjustment,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 3, 3, 5, 3
How Hard is Trojan Detection in DNNs? Fooling Detectors With Evasive Trojans,4.0, 4.0, 1.0, 3, 4, 5, 5, 5, 4, 3, 4
Exploring the Limitations of Graph-based Logical Reasoning in Large Language Models,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 1, 4, 3, 4
Evaluating Robustness to Unforeseen Adversarial Attacks,4.5, 4.5, 1.5, 6, 4, 3, 4, 6, 4, 3, 4
Provable Benefits of Multi-task RL under Non-Markovian Decision Making Processes,6.2, 6.0, 0.9797958971132712, 5, 1, 6, 4, 6, 3, 6, 3, 8, 2
RetroTune: Mitigating spurious features via retrospective fine-tuning,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 4, 5, 3
Learning Delays in Spiking Neural Networks using Dilated Convolutions with Learnable Spacings,5.0, 4.5, 2.1213203435596424, 6, 3, 8, 5, 3, 4, 3, 4
Can Copyright be Reduced to Privacy?,3.75, 3.0, 1.299038105676658, 3, 5, 6, 4, 3, 2, 3, 2
The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”,6.0, 6.0, 0.0, 6, 4, 6, 3, 6, 3, 6, 3
Fake News Detection via an Adaptive Feature Matching Optimization Framework,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 5, 5, 4
Metric Learning for Detection of Large Language Model Generated Texts,3.75, 3.0, 1.299038105676658, 6, 4, 3, 5, 3, 4, 3, 3
Outlier Weighed Layerwise Sparsity (OWL): A Missing Secret Sauce for Pruning LLMs to High Sparsity,5.75, 7.0, 2.8613807855648994, 8, 5, 6, 4, 8, 4, 1, 4
IMEX-Reg: Implicit-Explicit Regularization in the Function Space for Continual Learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 1, 5, 3
Generalist Equivariant Transformer Towards 3D Molecular Interaction Learning,5.75, 5.0, 1.299038105676658, 5, 5, 5, 4, 8, 3, 5, 3
Improving Robustness in Vision Transformers with Nullspace Noise Augmented Finetuning,4.666666666666667, 5.0, 2.8674417556808756, 1, 3, 8, 2, 5, 4
DeepROCK: Error-controlled interaction detection in deep neural networks,4.5, 4.5, 1.5, 6, 3, 3, 2
Subspace Grid-sweep: ML Defense Evaluation via Constrained Brute-force Search,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 4, 5, 4, 6, 3
Embedding File Structure for Tabular File Preparation,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 3, 3, 5, 3
Conditional Guided Diffusion Probabilistic Models for Image Super-Resolution,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 4, 3, 5
Generating Stealthy Jailbreak Prompts on Aligned Large Language Models,5.5, 5.5, 1.8027756377319946, 3, 4, 8, 4, 6, 4, 5, 3
Playing repeated games with Large Language Models,3.4, 3.0, 0.8000000000000002, 3, 4, 5, 4, 3, 3, 3, 3, 3, 4
Decision ConvFormer: Local Filtering in MetaFormer is Sufficient for Decision Making,7.0, 8.0, 1.4142135623730951, 8, 4, 8, 4, 5, 3
To guide or not to guide: Improving diffusion sampling with progressive guidance,4.5, 4.5, 1.5, 3, 4, 6, 4, 3, 5, 6, 5
From Matching to Mixing: A Graph Interpolation Approach for SAT Instance Generation,6.0, 5.0, 1.4142135623730951, 5, 3, 5, 3, 8, 3
Are LLMs Aware that Some Questions are not Open-ended?,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 4
Generative Marginalization Models,5.6, 6.0, 1.624807680927192, 6, 4, 6, 3, 3, 4, 5, 3, 8, 3
MeRino: Entropy-driven Design for Mobile-friendly Generative Language Models,4.25, 4.0, 1.299038105676658, 3, 4, 3, 4, 5, 4, 6, 3
Where Does In-context Machine Translation Happen in Large Language Models?,5.0, 5.5, 1.224744871391589, 6, 4, 3, 3, 6, 4, 5, 4
Mo' Data Mo' Problems: How Data Composition Compromises Scaling Properties,4.5, 4.5, 1.5, 3, 4, 3, 4, 6, 4, 6, 4
How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?,6.25, 6.0, 1.0897247358851685, 6, 3, 6, 3, 8, 3, 5, 4
A Stable Fast and Fully Automatic Learning Algorithm for Predictive Coding Networks,4.0, 4.5, 2.1213203435596424, 3, 4, 6, 4, 6, 3, 1, 4
Gaussian Process-Based Corruption-resilience Forecasting Models,4.25, 5.0, 1.920286436967152, 1, 4, 5, 3, 5, 4, 6, 4
Scalable Monotonic Neural Networks,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 5, 6, 3, 5, 3
Accurate Retraining-free Pruning for Pretrained Encoder-based Language Models,6.25, 6.0, 1.0897247358851685, 6, 5, 6, 4, 8, 4, 5, 4
Exploiting Negative Samples: A Catalyst for Cohort Discovery in Healthcare Analytics,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 4, 6, 3
Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game,4.4, 3.0, 1.9595917942265424, 3, 4, 3, 4, 3, 4, 5, 3, 8, 4
Private Overparameterized Linear Regression without Suffering in High Dimensions,4.5, 4.5, 1.5, 6, 3, 3, 3, 6, 3, 3, 5
Prospector: Improving LLM Agents with Self-Asking and Trajectory Ranking,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 5, 2, 6, 3
Investigating the chaotic dynamics produced by deep reinforcement learning controllers,3.25, 3.0, 1.7853571071357126, 1, 4, 3, 4, 6, 3, 3, 3
PROGRAM: PROtotype GRAph Model based Pseudo-Label Learning for Test-Time Adaptation,5.8, 5.0, 1.16619037896906, 5, 5, 5, 4, 6, 3, 5, 2, 8, 3
Navigating Dataset Documentations in AI: A Large-Scale Analysis of Dataset Cards on HuggingFace,5.333333333333333, 5.0, 2.0548046676563256, 5, 3, 8, 4, 3, 4
A Language-Agent Approach to Formal Theorem-Proving,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 3, 5, 4
An Extensive Analysis on the Underlying Premises Behind Deep Reinforcement Learning Algorithm Design,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 3, 5, 4, 3, 3
A Differentially Private Clustering Algorithm for Well-Clustered Graphs,6.5, 6.0, 0.8660254037844386, 8, 3, 6, 3, 6, 2, 6, 3
Follow-the-Perturbed-Leader for Adversarial Bandits: Heavy Tails Robustness and Privacy,6.75, 7.0, 1.299038105676658, 8, 3, 8, 3, 5, 4, 6, 4
Better Safe than Sorry: Pre-training CLIP against Targeted Data Poisoning and Backdoor Attacks,4.666666666666667, 3.0, 2.357022603955158, 3, 4, 8, 4, 3, 5
Tool-Augmented Reward Modeling,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 3, 6, 4
Refined Tensorial Radiance Field: Harnessing coordinate based networks for novel view synthesis from sparse inputs,4.25, 4.0, 1.299038105676658, 6, 5, 5, 3, 3, 4, 3, 4
Minimax optimality of convolutional neural networks for infinite dimensional input-output problems and separation from kernel methods,7.333333333333333, 8.0, 0.9428090415820634, 8, 2, 6, 2, 8, 3
Reweighted Solutions for Weighted Low Rank Approximation,5.75, 5.0, 1.299038105676658, 5, 3, 8, 2, 5, 4, 5, 4
Consistent algorithms for multi-label classification with macro-at-$k$ metrics,6.5, 6.0, 0.8660254037844386, 6, 4, 8, 3, 6, 3, 6, 3
Iteratively Refined Behavior Regularization for Offline Reinforcement Learning,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 5
A Theory of Unimodal Bias in Multimodal Learning,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 5, 4, 6, 3
How well does Persistent Homology generalize on graphs?,4.25, 4.0, 1.299038105676658, 3, 3, 6, 3, 3, 2, 5, 3
Dynamic Layer Tying for Parameter-Efficient Transformers,6.25, 6.0, 2.48746859276655, 3, 4, 10, 4, 6, 3, 6, 3
Unlearning via Sparse Representations,5.0, 5.0, 0.0, 5, 3, 5, 2, 5, 2, 5, 4
Reward-Consistent Dynamics Models are Strongly Generalizable for Offline Reinforcement Learning,6.0, 5.5, 1.224744871391589, 5, 4, 8, 4, 5, 3, 6, 3
Long Horizon Episodic Decision Making for Cognitively Inspired Robots,1.5, 1.0, 0.8660254037844386, 3, 5, 1, 4, 1, 5, 1, 4
Vlearn: Off-Policy Learning with Efficient State-Value Function Estimation,4.25, 4.0, 1.299038105676658, 5, 2, 3, 5, 6, 3, 3, 3
CL-Calib: Enhancing Post-training Quantization Calibration through Contrastive Learning,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 4, 6, 5, 5, 1
UNITE:Universally Trustworthy GNN Via Subgraph Identification,4.4, 3.0, 1.9595917942265424, 3, 4, 3, 4, 5, 3, 3, 4, 8, 5
Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion,6.25, 6.0, 1.0897247358851685, 5, 3, 8, 4, 6, 4, 6, 4
Resonator-Gated RNNs,5.0, 5.5, 1.224744871391589, 3, 4, 6, 3, 5, 4, 6, 3
Learning with Language Inference and Tips for Continual Reinforcement Learning,2.3333333333333335, 3.0, 0.9428090415820634, 1, 5, 3, 3, 3, 4
Federated Zeroth-Order Optimization using Trajectory-Informed Surrogate Gradients,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 3, 2, 5, 4
Quantum Speedups in Linear Programming via Sublinear Multi-Gibbs Sampling,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 4, 6, 4
Dissecting sample hardness: Fine-grained analysis of Hardness Characterization Methods,5.4, 5.0, 2.5768197453450252, 8, 2, 5, 3, 8, 4, 1, 5, 5, 3
Curiosity Driven Protein Sequence Generation via Reinforcement Learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 2
MorphOcc: An Implicit Generative Model of Neuronal Morphologies,4.0, 3.0, 1.4142135623730951, 3, 3, 6, 4, 3, 4
Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 6, 4, 3, 5
Offline Imitation Learning without Auxiliary High-quality Behavior Data,5.75, 6.0, 1.7853571071357126, 6, 3, 3, 4, 8, 4, 6, 4
HIWE: Scene Importance Weighted Encoding For Fast Neural Radiance Field Training,3.0, 3.0, 1.4142135623730951, 3, 5, 1, 4, 3, 4, 5, 5
Simplifying Referred Visual Search with Conditional Contrastive Learning,5.333333333333333, 5.0, 0.4714045207910317, 5, 5, 5, 4, 6, 3
Towards Foundation Models for Learning on Tabular Data,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 4, 3, 5, 3, 4
Schrodinger Bridge to Bridge Generative Diffusion Method to Off-Policy Evaluation,3.5, 3.0, 0.8660254037844386, 5, 2, 3, 4, 3, 3, 3, 3
Pruning via Ranking (PvR): A unified structured pruning approach,4.0, 3.0, 1.4142135623730951, 6, 3, 3, 4, 3, 5
Exposing the Silent Hidden Impact of Certified Training in Reinforcement Learning,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 3, 5, 3
S-TLLR: STDP-inspired Temporal Local Learning Rule for Spiking Neural Networks,4.25, 4.0, 1.299038105676658, 3, 3, 5, 4, 6, 4, 3, 3
Rethinking the Solution to Curse of Dimensionality on Randomized Smoothing,4.75, 5.0, 2.48746859276655, 1, 4, 8, 3, 5, 4, 5, 4
Relevance-based embeddings for efficient relevance retrieval,6.25, 6.0, 1.0897247358851685, 8, 3, 6, 4, 5, 3, 6, 3
Error Feedback Reloaded: From Quadratic to Arithmetic Mean of Smoothness Constants,5.75, 6.0, 1.7853571071357126, 6, 2, 8, 3, 3, 3, 6, 4
Wigner kernels: body-ordered equivariant machine learning without a basis,5.0, 5.5, 1.224744871391589, 6, 3, 5, 2, 6, 2, 3, 4
Predictive Coding beyond Correlations,4.75, 5.0, 1.0897247358851685, 5, 3, 6, 3, 5, 4, 3, 3
Deep SE(3)-Equivariant Geometric Reasoning for Precise Placement Tasks,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 4, 6, 3
Learning Differentially Private Rewards from Human Feedback,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 4, 5, 4, 5, 3
Lemur: Integrating Large Language Models in Automated Program Verification,5.75, 5.0, 1.299038105676658, 8, 5, 5, 3, 5, 3, 5, 5
CUS3D: A New Comprehensive Urban-Scale Semantic Segmentation 3D Benchmark Dataset,5.25, 5.0, 0.4330127018922193, 5, 5, 5, 4, 5, 5, 6, 4
ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models,5.5, 5.5, 0.5, 5, 2, 5, 4, 6, 3, 6, 4
Error Feedback Shines when Features are Rare,6.25, 7.0, 2.0463381929681126, 8, 3, 3, 4, 8, 4, 6, 3
Towards Optimal Regret in Adversarial Linear MDPs with Bandit Feedback,7.0, 7.0, 1.0, 8, 3, 8, 3, 6, 3, 6, 4
A Precise Characterization of SGD Stability Using Loss Surface Geometry,5.5, 5.5, 1.8027756377319946, 6, 4, 8, 4, 3, 4, 5, 3
Compositional Interfaces for Compositional Generalization,4.25, 4.0, 1.299038105676658, 3, 3, 6, 3, 3, 5, 5, 3
Prodigy: An Expeditiously Adaptive Parameter-Free Learner,4.25, 5.0, 1.920286436967152, 1, 5, 6, 4, 5, 3, 5, 2
Dual RL: Unification and New Methods for Reinforcement and Imitation Learning,6.666666666666667, 6.0, 0.9428090415820634, 8, 4, 6, 4, 6, 4
CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models,4.75, 4.0, 2.0463381929681126, 5, 4, 3, 4, 8, 4, 3, 4
HiLoRL: A Hierarchical Logical Model for Learning Composite Tasks,4.25, 4.0, 1.299038105676658, 6, 3, 3, 4, 3, 3, 5, 4
Scaling Laws for Imitation Learning in Single-Agent Games,6.0, 6.0, 1.8973665961010275, 8, 3, 5, 4, 6, 3, 8, 3, 3, 4
Can Language Agents Approach the Performance of RL? An Empirical Study On OpenAI Gym,4.4, 3.0, 1.9595917942265424, 8, 3, 3, 3, 3, 4, 5, 3, 3, 3
Contrastive Representations Make Planning Easy,4.333333333333333, 5.0, 0.9428090415820634, 3, 3, 5, 3, 5, 2
SpecAR-Net: Spectrogram Analysis and Representation Network for Time Series,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 3, 4, 5, 3
Learning Successor Representations with Distributed Hebbian Temporal Memory,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 3, 3, 3
DNCs require more planning steps,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 4, 3, 3, 3, 3
Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs,5.5, 5.5, 2.5, 8, 4, 3, 3, 3, 4, 8, 3
BaDLoss: Backdoor Detection via Loss Dynamics,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4, 3, 3
Diffusion in Diffusion: Cyclic One-Way Diffusion for Text-Vision-Conditioned Generation,6.25, 6.0, 1.0897247358851685, 5, 4, 6, 2, 6, 4, 8, 4
Improved Invariant Learning for Node-level Out-of-distribution Generalization on Graphs,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 4, 5, 4, 5, 4
Parameter-Free Molecular Classification and Regression with Gzip,4.75, 4.0, 2.0463381929681126, 5, 3, 3, 4, 8, 4, 3, 5
GIFF: Generalized Inference Friendly Forward-Forward Algorithm,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 3, 4, 5, 2
Bounding the Expected Robustness of Graph Neural Networks Subject to Node Feature Attacks,6.333333333333333, 6.0, 1.247219128924647, 5, 3, 8, 2, 6, 4
Boosting Reinforcement Learning with Extremum Experiences,4.0, 4.0, 1.0, 5, 4, 5, 3, 3, 4, 3, 4
Modify Training Direction in Function Space to Reduce Generalization Error,3.5, 3.0, 0.8660254037844386, 5, 2, 3, 3, 3, 4, 3, 3
MoMA: Model-based Mirror Ascent for Offline Reinforcement Learning,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 4, 5, 4, 5, 3
Score Models for Offline Goal-Conditioned Reinforcement Learning,5.0, 5.5, 1.224744871391589, 5, 4, 3, 4, 6, 3, 6, 3
LaDe: The First Comprehensive Last-mile Express Dataset from Industry,5.25, 5.0, 1.7853571071357126, 8, 4, 5, 4, 3, 5, 5, 4
Hiding in Plain Sight: Disguising Data Stealing Attacks in Federated Learning,5.8, 6.0, 1.6, 3, 4, 8, 4, 6, 2, 6, 3, 6, 3
Progressive Pseudo Bag Augmentation with Instance Importance Estimation for Whole Slide Image Classification,4.666666666666667, 3.0, 2.357022603955158, 3, 4, 3, 3, 8, 4
USB-NeRF: Unrolling Shutter Bundle Adjusted Neural Radiance Fields,5.5, 5.5, 2.5, 3, 3, 8, 5, 3, 4, 8, 4
Analyzing the Effects of Emulating on the Reinforcement Learning Manifold,5.333333333333333, 5.0, 2.0548046676563256, 3, 4, 8, 2, 5, 3
A Latent Space Theory for Emergent Abilities in Large Language Models,3.3333333333333335, 3.0, 2.0548046676563256, 6, 3, 3, 4, 1, 4
A trainable manifold for accurate approximation with ReLU Networks,4.25, 3.0, 2.165063509461097, 3, 3, 3, 4, 8, 4, 3, 2
Federated Learning Under Second-Order Data Heterogeneity,3.75, 3.0, 1.299038105676658, 3, 4, 3, 3, 6, 3, 3, 4
Rigid Motion Compensated Compressed Sensing MRI with Untrained Neural Networks,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 5, 4, 3, 4
Supervised Knowledge Makes Large Language Models Better In-context Learners,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 4
COLEP: Certifiably Robust Learning-Reasoning Conformal Prediction via Probabilistic Circuits,5.6, 6.0, 0.48989794855663565, 6, 5, 6, 1, 6, 3, 5, 3, 5, 3
Learning Node Selection via Tripartite Graph Representation in Mixed Integer Linear Programming,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 6, 3, 3, 3
Contrastive Difference Predictive Coding,6.25, 7.0, 2.0463381929681126, 6, 4, 8, 3, 3, 4, 8, 3
Extrapolating Large Language Models to Non-English by Aligning Languages,4.25, 4.0, 1.299038105676658, 6, 4, 5, 4, 3, 4, 3, 5
PARAMETER OPTIMIZATION FOR EPIDEMIOLOGICAL MODEL WITH GENETIC ALGORITHM,1.6666666666666667, 1.0, 0.9428090415820634, 1, 3, 1, 4, 3, 3
From Fourier to Neural ODEs: Flow matching for modeling complex systems,4.75, 4.0, 2.0463381929681126, 5, 3, 3, 4, 3, 3, 8, 3
INRet: A General Framework for Accurate Retrieval of INRs for Shapes,5.5, 5.5, 0.5, 5, 3, 6, 4, 5, 4, 6, 4
BAFFLE: A Baseline of Backpropagation-Free Federated Learning,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 3, 3, 4, 3, 4
Bayesian Exploration Networks,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 6, 2, 8, 3
MAST: A Sparse Training Framework for Multi-agent Reinforcement Learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 4
TinyStories: How Small Can Language Models Be and Still Speak Coherent English,3.0, 3.0, 1.4142135623730951, 1, 4, 3, 3, 3, 4, 5, 3
GraphDeepONet: Learning to simulate time-dependent partial differential equations using graph neural network and deep operator network,4.75, 5.0, 1.0897247358851685, 5, 3, 6, 3, 3, 5, 5, 2
Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment,5.5, 5.5, 1.8027756377319946, 5, 3, 8, 3, 3, 5, 6, 3
Effective Data Augmentation With Diffusion Models,6.5, 6.5, 1.5, 5, 4, 8, 4, 5, 4, 8, 4
Theoretical Analysis on the Generalization Power of Overfitted Transfer Learning,4.75, 4.0, 2.0463381929681126, 5, 3, 8, 3, 3, 4, 3, 4
Out-Of-Domain Unlabeled Data Improves Generalization,5.75, 6.0, 1.7853571071357126, 3, 3, 8, 3, 6, 3, 6, 4
Towards Transparent Time Series Forecasting,5.25, 6.0, 1.299038105676658, 6, 3, 6, 3, 6, 3, 3, 2
Consistent123: One Image to Highly Consistent 3D Asset Using Case-Aware Diffusion Priors,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 5, 5, 3, 5, 4
Denoising Diffusion Variational Inference,4.0, 4.0, 1.0, 3, 3, 3, 4, 5, 3, 5, 4
Explaining black box text modules in natural language with language models,6.0, 5.0, 1.4142135623730951, 5, 3, 8, 4, 5, 4
Convexifying Transformers: Improving optimization and understanding of transformer networks,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 3, 5, 4
Causal-based Analysis on Credibility of Feedforward Neural Network,4.0, 4.0, 1.0, 5, 4, 3, 2, 3, 4, 5, 2
MPformer: Advancing Graph Modeling Through Heterophily Relationship-Based Position Encoding,3.75, 3.0, 1.299038105676658, 3, 5, 3, 4, 3, 5, 6, 4
A Fast and Provable Algorithm for Sparse Phase Retrieval,6.5, 6.0, 0.8660254037844386, 6, 4, 6, 4, 6, 4, 8, 3
WaveFluid: A New Adversarial Approach for Efficient High-Fidelity Speech Synthesis,4.166666666666667, 4.0, 1.2133516482134197, 3, 5, 5, 4, 6, 3, 3, 3, 5, 5, 3, 4
MCM: Masked Cell Modeling for Anomaly Detection in Tabular Data,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 8, 4, 6, 4
Bit Cipher — A Simple yet Powerful Word Representation System that Integrates Efficiently with Language-Models,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4
Representation Disentanglement via Regularization by Causal Identification,4.75, 5.0, 1.0897247358851685, 6, 4, 3, 4, 5, 4, 5, 3
HiGen: Hierarchical Graph Generative Networks,6.2, 6.0, 0.9797958971132712, 5, 3, 6, 3, 6, 3, 6, 3, 8, 3
HART: Efficient Adaptation via Regularized Autoregressive Parameter Generation,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 3, 5, 4
A Policy Gradient Method for Confounded POMDPs,6.5, 6.0, 0.8660254037844386, 6, 2, 6, 3, 6, 3, 8, 1
A Multi-Agent Reinforcement Learning Framework for Evaluating the U.S. ‘Ending the HIV Epidemic’ initiative,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 2, 3, 4, 5, 2
Achieving Fairness in Multi-Agent MDP Using Reinforcement Learning,5.75, 6.0, 1.7853571071357126, 6, 3, 6, 3, 8, 3, 3, 4
Self-supervision Meets Bootstrap Estimation: New Paradigm for Unsupervised Reconstruction with Uncertainty Quantification,3.25, 3.0, 1.7853571071357126, 6, 2, 3, 5, 3, 4, 1, 5
Learning to ignore: Single Source Domain Generalization via Oracle Regularization,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 3, 5, 3, 3, 3
Preventing Model Collapse in Deep Canonical Correlation Analysis by Noise Regularization,6.333333333333333, 6.0, 2.8674417556808756, 10, 4, 6, 2, 3, 4
Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning,5.25, 5.0, 1.7853571071357126, 8, 4, 5, 4, 3, 3, 5, 5
Toward a Mechanistic Understanding of Stepwise Inference in Transformers: A Synthetic Graph Navigation Model,5.25, 6.0, 1.299038105676658, 6, 2, 6, 3, 3, 3, 6, 2
Information-Theoretic World Model learning for Denoised Predictions,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 4, 5, 3
GeoMFormer: A General Architecture for Geometric Molecular Representation Learning,5.75, 6.0, 1.7853571071357126, 6, 4, 8, 4, 6, 3, 3, 4
Quantifying Classification Performance through Combinatorial Geometry and Localized Data Analysis,4.8, 5.0, 0.9797958971132712, 5, 3, 5, 4, 3, 4, 6, 3, 5, 5
Retrieval-Based Reconstruction For Time-series Contrastive Learning,5.25, 5.0, 1.7853571071357126, 8, 4, 5, 3, 3, 3, 5, 4
FedQV: Leveraging Quadratic Voting in Federated Learning,3.0, 3.0, 0.0, 3, 3, 3, 3
Quantile-Free Regression: A Flexible Alternative to Quantile Regression,4.2, 5.0, 0.9797958971132712, 5, 3, 3, 4, 3, 4, 5, 4, 5, 5
What Makes for Robust Multi-Modal Models in the Face of Missing Modalities?,3.5, 4.0, 1.6583123951777, 3, 4, 5, 3, 5, 4, 1, 4
MAGNet: Motif-Agnostic Generation of Molecules from Shapes,3.75, 4.0, 1.920286436967152, 3, 3, 5, 3, 6, 4, 1, 4
Casting Light on Large Generative Networks: Taming Epistemic Uncertainty in Diffusion Models,4.5, 4.5, 1.5, 3, 3, 6, 4, 6, 2, 3, 4
WHICH RESTRAINS FEW-SHOT CLASS-INCREMENTAL LEARNING FORGETTING OR FEW-SHOT LEARNING?,4.0, 3.0, 1.4142135623730951, 3, 5, 3, 5, 6, 3
BackBench: Are Vision Language Models Resilient to Object-to-Background Context?,6.0, 5.5, 1.224744871391589, 5, 4, 8, 4, 6, 3, 5, 3
REAL: Rectified Adversarial Sample via Max-Min Entropy for Test-Time Defense,4.666666666666667, 3.0, 2.357022603955158, 8, 4, 3, 4, 3, 3
Escaping the Sample Trap: Fast and Accurate Epistemic Uncertainty Estimation with Pairwise-Distance Estimators,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 5, 5, 5, 3, 4
CoLiDE: Concomitant Linear DAG Estimation,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 6, 5, 5, 4
PromptNER : Prompting For FewShot Named Entity Recognition,3.5, 3.0, 0.8660254037844386, 3, 5, 5, 4, 3, 4, 3, 3
Video Caching at Data-drifting Network Edge: A KD-based Cross-domain Collaborative Solution,5.0, 5.5, 1.224744871391589, 5, 3, 6, 2, 6, 3, 3, 4
LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models,8.0, 8.0, 0.0, 8, 4, 8, 4
Scaling Convex Neural Networks with Burer-Monteiro Factorization,6.0, 6.0, 1.8973665961010275, 8, 2, 5, 3, 3, 4, 6, 3, 8, 3
Simple mechanisms for representing indexing and manipulating concepts,5.75, 6.0, 1.7853571071357126, 8, 2, 3, 3, 6, 2, 6, 2
Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation,6.5, 6.0, 0.8660254037844386, 6, 4, 8, 4, 6, 4, 6, 3
Large Multimodal Model for Real-World Radiology Report Generation,5.25, 5.0, 1.7853571071357126, 8, 2, 3, 5, 5, 4, 5, 4
PolyGCL: GRAPH CONTRASTIVE LEARNING via Learnable Spectral Polynomial Filters,6.5, 6.5, 1.5, 5, 4, 8, 3, 8, 3, 5, 4
Reward Translation via Reward Machine in Semi-Alignable MDPs,3.75, 3.0, 1.299038105676658, 3, 4, 3, 3, 6, 3, 3, 2
UniTabE: A Universal Pretraining Protocol for Tabular Foundation  Model in Data Science,6.333333333333333, 6.0, 1.247219128924647, 6, 5, 8, 3, 5, 3
Large-Scale Spectral Graph Neural Networks via Laplacian Sparsification,4.5, 5.0, 0.8660254037844386, 5, 2, 5, 3, 3, 5, 5, 4
SASS: Self-Alignment with Semi-Supervised Instruction Data Generation,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 5, 5, 3, 3, 4
WavJourney: Compositional Audio Creation with Large Language Models,5.0, 5.0, 1.0954451150103321, 6, 3, 5, 3, 5, 4, 3, 3, 6, 3
Linguistic Image Understanding,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 4, 5, 5
PolyVoice: Language Models for Speech to Speech Translation,6.0, 6.5, 2.1213203435596424, 8, 5, 5, 3, 3, 4, 8, 4
Adversarial Feature Map Pruning for Backdoor,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 3, 5, 4
Tube Loss: A Novel Approach for High Quality Prediction Interval Estimation,2.5, 3.0, 0.8660254037844386, 3, 3, 3, 2, 1, 5, 3, 3
Expressivity of ReLU-Networks under Convex Relaxations,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 4, 5, 2
WASA: WAtermark-based Source Attribution for Large Language Model-Generated Data,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 3, 5, 2
Learning to Select In-context Examples from Reward,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 3, 4, 5, 3
Graph Neural Networks for Learning Equivariant Representations of Neural Networks,7.333333333333333, 8.0, 0.9428090415820634, 8, 4, 8, 4, 6, 4
Learning Latent Causal Semantics from Text: An Empirical Study of Next-Token Predictors Trained on Programs,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 2, 5, 4, 3, 4
Emerging Pixel-level Semantic Knowledge in Diffusion Models,5.25, 6.0, 1.299038105676658, 3, 3, 6, 5, 6, 4, 6, 4
CLEX: Continuous  Length Extrapolation for Large Language Models,6.25, 6.0, 1.0897247358851685, 5, 3, 6, 2, 8, 2, 6, 5
Towards Plastic and Stable Exemplar-Free Incremental Learning: A Dual-Learner Framework with Cumulative Parameter Averaging,4.0, 4.0, 1.0, 5, 3, 3, 3, 5, 4, 3, 2
A Geometric Perspective on Diffusion Models,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 5, 3, 2, 5, 3
Duality of Information Flow: Insights in Graphical Models and Neural Networks,4.666666666666667, 5.0, 1.247219128924647, 6, 2, 3, 3, 5, 3
GDL-DS: A Benchmark for Geometric Deep Learning under Distribution Shifts,5.666666666666667, 6.0, 2.0548046676563256, 8, 4, 3, 5, 6, 2
Object-level Data Augmentation for Visual 3D Object Detection in Autonomous Driving,5.666666666666667, 6.0, 0.4714045207910317, 6, 5, 5, 5, 6, 3
SEEKING THE SEARCH SPACE FOR SIZE-AWARE VISION TRANSFORMER ARCHITECTURE,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 2, 3, 5
Leveraging Print Debugging to Improve Code Generation in Large Language Models,4.25, 4.0, 1.299038105676658, 5, 5, 3, 3, 3, 5, 6, 4
Implicit Gaussian process representation of vector fields over arbitrary latent manifolds,6.666666666666667, 6.0, 0.9428090415820634, 6, 5, 8, 4, 6, 2
Quality Control at Your Fingertips: Quality-Aware Translation Models,4.666666666666667, 3.0, 2.357022603955158, 3, 5, 3, 4, 8, 4
GraphGuard: Provably Robust Graph Classification against Adversarial Attacks,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 8, 4, 6, 3
Learning HJB Viscosity Solutions with PINNs for Continuous-Time Reinforcement Learning,5.25, 5.0, 1.7853571071357126, 5, 4, 3, 4, 5, 3, 8, 4
ProbTS: A Unified Toolkit to Probe Deep Time-series Forecasting,5.6, 6.0, 1.624807680927192, 3, 5, 6, 3, 8, 4, 5, 4, 6, 5
Imagine Within Practice: Conservative Rollout Length Adaptation for Model-Based Reinforcement Learning,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 4, 5, 4, 5, 3
S4++: Elevating Long Sequence Modeling with State Memory Reply,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 5, 4, 3, 4
Fill with Anything: High-Resolution and Prompt-Faithful Image Completion,4.25, 4.0, 1.299038105676658, 5, 4, 3, 5, 6, 4, 3, 5
Two Heads Are Better Than One: Exploiting Both Sequence and Graph Models in AMR-To-Text Generation,5.0, 5.0, 0.0, 5, 2, 5, 4, 5, 5
Provably Efficient Policy Optimization with Rare Policy Switches,5.5, 5.5, 1.8027756377319946, 5, 3, 6, 2, 3, 5, 8, 4
Multimodal Question Answering for Unified Information Extraction,4.666666666666667, 3.0, 2.357022603955158, 3, 4, 3, 5, 8, 4
Enhancing Tropical Cyclone Formation Prediction Using Graph Neural Networks,2.3333333333333335, 1.0, 1.8856180831641267, 1, 4, 1, 4, 5, 4
Logical Languages Accepted by Transformer Encoders with Hard Attention,5.6, 6.0, 2.244994432064365, 8, 3, 8, 3, 3, 3, 3, 3, 6, 2
Balancing Information Preservation and Computational Efficiency: L2 Normalization and Geodesic Distance in Manifold Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 5
Iterative Graph Neural Network Enhancement Using Explanations,3.75, 3.0, 1.299038105676658, 3, 4, 3, 5, 3, 4, 6, 4
Lightweight uncertainty modelling using function space particle optimization,3.8, 3.0, 0.9797958971132712, 3, 4, 5, 5, 3, 5, 5, 4, 3, 4
FairSeg: A Large-scale Medical Image Segmentation Dataset for Fairness Learning with Fair Error-Bound Scaling,7.0, 7.0, 1.0, 6, 5, 8, 4, 6, 3, 8, 3
Customizable Combination of Parameter-Efficient Modules for Multi-Task Learning,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 3, 6, 4, 5, 4
Rethinking The Dependence Between Gradients and The Initial Point in Deep Learning,2.5, 3.0, 0.8660254037844386, 1, 4, 3, 4, 3, 4, 3, 5
Gaitor: Learning a Unified Representation for Continuous Gait Transition and Terrain Traversal for Quadruped Robots,4.0, 4.0, 1.0, 5, 2, 3, 3, 3, 5, 5, 4
Efficient and scalable reinforcement learning via hypermodel,5.0, 3.0, 2.756809750418044, 10, 4, 3, 5, 6, 3, 3, 5, 3, 3
INCYDE: A large scale cyclone detection and intensity estimation dataset using satellite infrared imagery,3.0, 3.0, 1.632993161855452, 3, 4, 1, 5, 5, 4
Streamlining Generative Models for Structure-Based Drug Design,4.0, 4.0, 1.0, 3, 3, 3, 4, 5, 4, 5, 4
InstructCV: Instruction-Tuned Text-to-Image Diffusion Models as Vision Generalists,5.0, 4.5, 2.1213203435596424, 3, 5, 8, 3, 6, 3, 3, 5
MoteS: Memory Optimization via Fine-grained Scheduling for DNNs on Tiny Devices,4.5, 4.5, 1.5, 6, 4, 3, 3, 3, 5, 6, 3
StyleDreamer: Make Your 3D Style Avatar from a Single View with Consistency Score Distillation,4.0, 4.0, 1.0, 3, 4, 5, 2, 5, 4, 3, 5
Generative Modeling of Individual Behavior at Scale,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 3, 6, 2
Acoustic Prompt Tuning: Empowering Large Language Models with Audition Capabilities,4.6, 5.0, 2.4166091947189146, 5, 4, 3, 3, 8, 3, 6, 3, 1, 2
Mitigating Severe Robustness Degradation on Graphs,6.25, 6.0, 1.0897247358851685, 6, 4, 6, 4, 5, 3, 8, 4
Traveling Waves Encode The Recent Past and Enhance Sequence Learning,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 4, 6, 4, 5, 4
A Critical Study of What Pre-trained Code Models (do not) Learn,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 3, 5, 4, 5, 3
Active Domain Adaptation Of Medical Images Using Feature Disentanglement,5.0, 5.5, 1.224744871391589, 3, 4, 5, 4, 6, 4, 6, 4
Perturbed examples reveal invariances shared by language models,4.5, 4.5, 2.692582403567252, 6, 4, 3, 4, 1, 3, 8, 3
How Sparse Can We Prune A Deep Network: A Geometric Viewpoint,6.0, 5.5, 1.224744871391589, 6, 4, 5, 4, 8, 2, 5, 2
Conserve-Update-Revise to Cure Generalization and Robustness Trade-off in Adversarial Training,5.5, 5.5, 0.5, 5, 3, 6, 4, 6, 3, 5, 1
Red Pill or Blue Pill? Thresholding Strategies for Neural Network Monitoring,3.0, 3.0, 1.632993161855452, 1, 3, 3, 3, 5, 2
Unbalanced Diffusion Schrödinger Bridge,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 1, 5, 3, 3, 3
Matrix-wise Class Imbalance Matters: On the Generalization of Micro-AUC in Multi-label Learning,6.4, 6.0, 1.3564659966250536, 8, 3, 5, 4, 5, 4, 8, 2, 6, 3
Autonomous Tree-search Ability of Large Language Models,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 4, 5, 4, 6, 3
A Novel Approach for Micro-Expression Recognition Incorporating Vertical Attention and Position Localization,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 5, 6, 3
Perturb and Learn: Energy-Based Modelling in Discrete Spaces without MCMC,5.4, 5.0, 1.624807680927192, 8, 4, 5, 4, 3, 5, 6, 3, 5, 4
Greedy Sequential Execution: Solving Homogeneous and Heterogeneous Cooperative Tasks with a Unified Framework,6.25, 7.0, 2.0463381929681126, 6, 3, 8, 3, 8, 4, 3, 5
ZOOPFL: EXPLORING BLACK-BOX FOUNDATION MODELS FOR PERSONALIZED FEDERATED LEARNING,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 4, 5, 3, 5, 4
Hindsight PRIORs for Reward Learning from Human Preferences,6.333333333333333, 6.0, 1.247219128924647, 8, 3, 5, 3, 6, 4
Communication-Efficient Algorithm for Asynchronous Multi-Agent Bandits,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 2, 3, 4, 6, 3
Meta-Guided Diffusion Models for Zero-Shot Medical Imaging Inverse Problems,5.25, 6.0, 1.299038105676658, 6, 5, 3, 3, 6, 3, 6, 4
Are Spiking Neural Networks more expressive than Artificial Neural Networks?,4.25, 4.0, 1.299038105676658, 6, 4, 3, 5, 5, 4, 3, 4
Navigating the Design Space of Equivariant Diffusion-Based Generative Models for De Novo 3D Molecule Generation,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 4, 5, 4, 5, 3
Mildly Overparameterized ReLU Networks Have a Favorable Loss Landscape,5.0, 5.5, 1.224744871391589, 6, 3, 3, 4, 5, 3, 6, 4
Informing Reinforcement Learning Agents by Grounding Natural Language to Markov Decision Processes,3.0, 3.0, 0.0, 3, 3, 3, 4, 3, 4, 3, 4
VQ-CAD: Computer-Aided Design Model Generation with Vector Quantized Diffusion,4.0, 3.0, 1.4142135623730951, 6, 5, 3, 3, 3, 5
DriveGPT4: Interpretable End-to-end Autonomous Driving via Large Language Model,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 5, 5, 4, 6, 2
Effortless Cross-Platform Video Codec: A Codebook-Based Method,5.75, 5.0, 1.299038105676658, 5, 4, 5, 5, 8, 4, 5, 4
Heterogeneous Value Alignment Evaluation for Large Language Models,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 4, 3, 4
Unveiling Linear Mode Connectivity of Re-basin from Neuron Distribution Perspective,3.5, 3.0, 0.8660254037844386, 3, 5, 5, 3, 3, 4, 3, 3
Stabilizing Contrastive RL: Techniques for Robotic Goal Reaching from Offline Data,6.25, 7.0, 2.0463381929681126, 3, 4, 8, 3, 6, 4, 8, 4
Don't be so negative! Score-based Generative Modeling with Oracle-assisted Guidance,3.75, 3.0, 1.299038105676658, 3, 3, 3, 3, 6, 3, 3, 3
M-IDAS: MULTI-MODAL INTRUSION DETECTION AND ANALYTIC SYSTEM,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 3
LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and Generation,5.4, 5.0, 1.624807680927192, 3, 4, 8, 2, 5, 4, 5, 4, 6, 3
Can We Evaluate Domain Adaptation Models Without Target-Domain Labels?,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 5, 4, 6, 5
Transformers Perform In-Context Learning through Neural Networks,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 3
Violence Detection and Localization in Video Through Subgroup Analysis,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 3, 5, 4
Causal Influence-Aware Counterfactual Data Augmentation,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 3
Sinkhorn Output Perturbations: Structured Pseudo-Label Noise in Semi-Supervised Segmentation,5.5, 5.5, 0.5, 5, 5, 6, 3, 6, 3, 5, 3
SkipDecode: Autoregressive Skip Decoding with Batching and Caching for Efficient LLM Inference,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 4, 5, 4, 5, 4
Motor Imagery Decoding Using Ensemble Curriculum Learning and Collaborative Training,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 4, 3, 5, 3, 3
Scalabale AI Safety via Doubly-Efficient Debate,6.5, 6.0, 0.8660254037844386, 6, 2, 8, 2, 6, 3, 6, 2
Architectural Insights for efficient Physics-Informed Neural Network optimization,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 3, 3, 4, 3, 3
Global Optimality for Non-linear Constrained Restoration Problems via Invexity,4.0, 3.0, 1.4142135623730951, 6, 3, 3, 4, 3, 3
CARENET : A NOVEL ARCHITECTURE FOR LOW DATA REGIME MIXING CONVOLUTIONS AND ATTENTION,2.5, 3.0, 0.8660254037844386, 1, 5, 3, 4, 3, 4, 3, 5
Exploring the State and Action Space in Reinforcement Learning with Infinite-Dimensional Confidence Balls,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 3, 5, 4
Seeing Video Through Optical Scattering Media using Spatio-Temporal Diffusion Models,5.333333333333333, 5.0, 2.0548046676563256, 5, 3, 8, 3, 3, 5
Value function estimation using conditional diffusion models for control,5.5, 5.5, 1.8027756377319946, 8, 4, 3, 4, 5, 3, 6, 3
CDGraph: Dual Conditional Social Graph Synthesizing via Diffusion Model,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 2, 5, 4
Multi-View Causal Representation Learning with Partial Observability,7.0, 7.0, 1.0, 6, 3, 6, 3, 8, 4, 8, 3
On the Recoverability of Causal Relations from Temporally Aggregated I.I.D Data,5.0, 5.0, 1.0954451150103321, 6, 3, 5, 4, 3, 3, 6, 4, 5, 4
Exploring the Combined Power of Covariance and Hessian Matrices Eigenanalysis for Binary Classification,4.25, 4.0, 1.299038105676658, 5, 2, 6, 3, 3, 4, 3, 3
Unsupervised Detection of Recurrent Patterns in Neural Recordings with Constrained Filters,6.333333333333333, 6.0, 1.247219128924647, 6, 3, 8, 3, 5, 3
Double Rounding Quantization for Flexible Deep Neural Network Compression,5.0, 5.0, 0.0, 5, 5, 5, 4, 5, 5, 5, 4
DOS: Diverse Outlier Sampling for Out-of-Distribution Detection,5.666666666666667, 6.0, 0.4714045207910317, 5, 3, 6, 4, 6, 4
Towards Dynamic Trend Filtering through Trend Points Detection with Reinforcement Learning,5.5, 5.5, 1.8027756377319946, 3, 3, 5, 3, 8, 3, 6, 3
HiFi-123: Towards High-fidelity One Image to 3D Content Generation,5.25, 5.0, 1.7853571071357126, 3, 5, 5, 4, 8, 4, 5, 5
AdapTable: Test-Time Adaptation for Tabular Data via Shift-Aware Uncertainty Calibrator and Label Distribution Handler,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 3, 5, 5, 4
Ghost in the Minecraft: Hierarchical Agents for Minecraft via Large Language Models with Text-based Knowledge and Memory,4.0, 3.0, 1.4142135623730951, 3, 5, 6, 5, 3, 5
PlatoLM: Teaching LLMs  via a Socratic  Questioning User Simulator,6.0, 5.5, 1.224744871391589, 5, 5, 6, 3, 5, 4, 8, 3
How To Train Your Covariance,4.5, 5.5, 2.0615528128088303, 1, 5, 6, 4, 5, 4, 6, 3
Denoising Task Routing for Diffusion Models,6.0, 6.0, 0.0, 6, 3, 6, 4, 6, 5
Revealing Unintentional Information Leakage in Low-Dimensional Facial Portrait Representations,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 4, 5, 3
CABINET: Content Relevance-based Noise Reduction for Table Question Answering,6.25, 6.0, 1.0897247358851685, 5, 4, 6, 4, 8, 4, 6, 5
Neural Networks and Solomonoff Induction,4.333333333333333, 5.0, 0.9428090415820634, 3, 3, 5, 5, 5, 2
Reward Model Ensembles Help Mitigate Overoptimization,6.0, 6.0, 0.0, 6, 3, 6, 4, 6, 4, 6, 3
Safe RLHF: Safe Reinforcement Learning from Human Feedback,5.75, 6.0, 1.7853571071357126, 6, 3, 3, 5, 8, 3, 6, 4
BENCHMARKING SEQUENTIAL VISUAL INPUT REASONING AND PREDICTION IN MULTIMODAL LARGE LANGUAGE MODELS,4.0, 4.0, 1.0, 5, 5, 3, 4, 3, 4, 5, 4
DiffMaSIF: Score-Based Diffusion Models for Protein Surfaces,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 4, 5, 5
Programmable Synthetic Data Generation,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 3, 6, 5
Frequency-Aware Transformer for Learned  Image Compression,5.5, 5.5, 0.5, 6, 5, 5, 4
CircuitNet 2.0: An Advanced Dataset for Promoting Machine Learning Innovations in Realistic Chip Design Environment,5.0, 5.5, 1.224744871391589, 6, 5, 5, 4, 6, 4, 3, 4
BDQL: Offline RL via Behavior Diffusion Q-learning without Policy Constraint,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 3
Weight-Based Performance Estimation for Diverse Domains,5.0, 6.0, 1.4142135623730951, 6, 3, 3, 5, 6, 4
Humans vs ChatGPT: Uncovering the Non-trivial Distinctions by Evaluating Parallel Responses,3.0, 3.0, 1.4142135623730951, 3, 5, 3, 4, 5, 2, 1, 5
Geometry-Guided Conditional Adaption for Surrogate Models of Large-Scale 3D PDEs on Arbitrary Geometries,4.75, 5.0, 1.0897247358851685, 5, 2, 3, 2, 6, 3, 5, 3
Benchmarking Algorithms for Federated Domain Generalization,7.0, 7.0, 1.0, 8, 3, 6, 3
Forget-Me-Not: Making Backdoor Hard to be Forgotten in Fine-tuning,5.0, 5.5, 1.224744871391589, 3, 5, 6, 4, 6, 5, 5, 4
Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design,6.0, 5.5, 1.224744871391589, 5, 4, 8, 4, 6, 3, 5, 3
PEPNet: A Lightweight Point-based Event Camera 6-DOFs Pose Relocalization Network,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 4, 3, 4
Analyzing Local Representations of Self-supervised Vision Transformers,4.25, 4.0, 1.299038105676658, 6, 4, 3, 4, 3, 4, 5, 5
Deep concept removal,4.0, 4.0, 1.0, 5, 3, 5, 4, 3, 4, 3, 4
Graph Neural Networks on Symmetric Positive Definite Manifold,4.75, 4.0, 2.0463381929681126, 5, 4, 3, 3, 8, 4, 3, 3
Causal analysis of social bias in CLIP,5.75, 6.0, 1.7853571071357126, 3, 3, 8, 4, 6, 4, 6, 2
Deep Models modelled after human brain boost performance in action classification,1.6666666666666667, 1.0, 0.9428090415820634, 1, 5, 1, 4, 3, 4
HFDream: Improving 3D Generation via Human-Assisted Multi-view Text-to-Image Models,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 5, 5, 5
BiXT: Perceiving Longer Sequences With Bi-Directional Cross-Attention Transformers,4.0, 5.0, 2.160246899469287, 1, 5, 6, 4, 5, 4
Towards Robust 3D Pose Transfer with Adversarial Learning,4.2, 5.0, 0.9797958971132712, 5, 4, 3, 4, 5, 3, 3, 3, 5, 4
Variable resolution: improving scene visual question answering with a limited pixel budget,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 5, 6, 5
GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction,5.75, 6.0, 1.7853571071357126, 8, 5, 3, 4, 6, 3, 6, 4
ROBUST DIFFUSION GAN USING SEMI-UNBALANCED OPTIMAL TRANSPORT,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 3, 3, 5, 4
Cross$Q$: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 5, 5, 3, 6, 5
A Soft Labeling Approach for Fairness-aware Learning Under Partially Annotated Sensitive Attributes,3.6666666666666665, 3.0, 0.9428090415820634, 5, 5, 3, 2, 3, 4
Learnable Invisible Backdoor for Diffusion Models,4.25, 3.0, 2.165063509461097, 8, 3, 3, 4, 3, 2, 3, 4
Pruning Attention Heads with Almost-sure Sparsity Targets,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 6, 4, 5, 3
EWoK: Tackling Robust Markov Decision Processes via Estimating Worst Kernel,5.25, 6.0, 1.299038105676658, 3, 4, 6, 2, 6, 4, 6, 3
A New Type of Associative Memory Network with Exponential Storage Capacity,6.5, 6.5, 1.5, 5, 4, 8, 4, 8, 4, 5, 3
Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning,5.0, 5.5, 1.224744871391589, 6, 3, 6, 5, 3, 4, 5, 3
Understanding the Robustness of Randomized Feature Defense Against Query-Based Adversarial Attacks,5.25, 5.0, 1.7853571071357126, 3, 4, 5, 4, 5, 4, 8, 3
Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing,4.666666666666667, 5.0, 1.247219128924647, 6, 2, 5, 2, 3, 4
One is More: Diverse Perspectives within a Single Network for Efficient DRL,4.25, 4.0, 1.299038105676658, 6, 3, 3, 5, 3, 4, 5, 4
Identifying Representations for Intervention Extrapolation,7.5, 8.0, 0.8660254037844386, 8, 4, 8, 4, 6, 4, 8, 4
DockGame: Cooperative Games for Multimeric Rigid Protein Docking,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 5
Time- and Label-efficient Active Learning by Diversity and Uncertainty of Probabilities,4.5, 5.0, 0.8660254037844386, 3, 3, 5, 3, 5, 5, 5, 3
CMMLU: Measuring massive multitask language understanding in Chinese,5.0, 5.0, 0.0, 5, 4, 5, 4
Improving Prompt-based Continual Learning with Key-Query Orthogonal Projection and Prototype-based One-Versus-All,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 4, 5, 4, 5, 4
Feasibility-Guided Safe Offline Reinforcement Learning,6.25, 6.0, 1.0897247358851685, 6, 3, 6, 3, 5, 3, 8, 2
Continual Knowledge Graph Link Prediction: Beyond Experience Replay,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 5, 3, 4, 3, 5
DeepEMD: A Transformer-based Fast Estimation of the Earth Mover’s Distance,4.0, 4.0, 1.0, 3, 3, 5, 3, 3, 4, 5, 4
Unlocking the Transferability of Tokens in Deep Models for Tabular Data,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 6, 3, 5, 3
Do Generated Data Always Help Contrastive Learning?,5.2, 6.0, 1.9390719429665317, 6, 4, 6, 4, 3, 3, 3, 3, 8, 3
Going Deeper with General and Specific Inductive Bias for Real-Time Stereo Matching,4.0, 3.0, 1.2649110640673518, 3, 4, 3, 4, 3, 3, 6, 4, 5, 5
Machine Learning for PROTAC Engineering,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 4, 3, 4
Balance Beam: adaptive computation for affordable training and inference with high-throughput offloading for LLMs,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 4
Self-Supervised Pseudodata Filtering for Improved Replay with Sub-Optimal Generators,2.0, 2.0, 1.0, 1, 5, 3, 5
Towards Global Interaction Efficiency of Graph Networks,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 3, 6, 2
ASMR: Activation-Sharing Multi-Resolution Coordinate Networks for Efficient Inference,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 3, 5, 5
Blending Imitation and Reinforcement Learning for Robust Policy Improvement,5.5, 5.5, 1.8027756377319946, 5, 3, 8, 2, 6, 3, 3, 3
Mitigating Interference in the Knowledge Continuum through Attention-Guided Incremental Learning,4.6, 5.0, 0.7999999999999999, 5, 5, 5, 4, 5, 3, 5, 4, 3, 5
Graphical Object-Centric Actor-Critic,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 6, 3, 3, 4
Exploring Weight Balancing on Long-Tailed Recognition Problem,6.25, 6.0, 1.0897247358851685, 6, 3, 6, 4, 8, 3, 5, 4
Zero Bubble Pipeline Parallelism,5.75, 6.0, 1.7853571071357126, 6, 5, 3, 4, 6, 3, 8, 4
Curated LLM: Synergy of LLMs and Data Curation for tabular augmentation in ultra low-data regimes,3.3333333333333335, 3.0, 2.0548046676563256, 3, 4, 1, 4, 6, 5
Effective Offline Environment Reconstruction when the Dataset is Collected from Diversified Behavior Policies,4.25, 4.0, 1.299038105676658, 3, 3, 5, 3, 6, 4, 3, 4
You Only Submit One Image to Find the Most Suitable Generative Model,5.0, 4.5, 2.1213203435596424, 8, 4, 3, 4, 3, 3, 6, 2
Learn to Achieve Out-of-the-Box Imitation Ability from Only One Demonstration,5.25, 5.0, 1.7853571071357126, 8, 4, 5, 3, 5, 4, 3, 3
Revisiting Ternary Neural Networks towards Asymmetric Thresholds and Uniform Distribution,4.0, 4.0, 1.0, 5, 4, 3, 5, 5, 4, 3, 4
Learning Object-Centric Representation via Reverse Hierarchy Guidance,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 6, 3, 5, 3
LASER: Linear Compression in Wireless Distributed Optimization,6.0, 6.0, 1.0954451150103321, 5, 4, 6, 3, 6, 4, 5, 4, 8, 3
Why Clean Generalization and Robust Overfitting Both Happen in Adversarial Training,4.8, 5.0, 0.9797958971132712, 3, 3, 6, 3, 5, 2, 5, 3, 5, 4
Dynamics of Instruction Tuning: Each Ability of Large Language Models Has Its Own Growth Pace,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 6, 3, 3, 4
MapSelect: Sparse & Interpretable Graph Attention Networks,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 5, 3, 4
Semantic-Enhanced Prototypical Network for Universal Novel Category Discovery,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 4
Attend to Context for Refining Embeddings in Deep Metric Learning,3.75, 4.0, 1.920286436967152, 1, 5, 5, 4, 3, 5, 6, 3
Imbalanced data robust online continual learning based on evolving class aware memory selection and built-in contrastive representation learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 3, 3, 4
Prototype Generation: Robust Feature Visualisation for Data Independent Interpretability,4.666666666666667, 5.0, 2.8674417556808756, 8, 4, 1, 4, 5, 4
CoRe-GD: A Hierarchical Framework for Scalable Graph Visualization with GNNs,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 2, 6, 3, 5, 3
I Know You Did Not Write That! A Sampling Based Watermarking Method for Identifying Machine Generated Text,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 2
OFASys: A Multi-Modal Multi-Task Learning System for Building Generalist Models,3.0, 3.0, 1.632993161855452, 1, 5, 5, 4, 3, 3
H-GAP: Humanoid Control with a Generalist Planner,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 5, 4, 6, 3
Compositional Conservatism: A Transductive Approach in Offline Reinforcement Learning,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 8, 3, 6, 2
Flood and Echo: Algorithmic Alignment of GNNs with Distributed Computing,4.75, 4.0, 2.0463381929681126, 5, 4, 3, 4, 3, 4, 8, 3
MetroGNN: Metro Network Expansion with Deep Reinforcement Learning,4.5, 4.5, 1.5, 6, 4, 3, 4, 6, 4, 3, 3
Meta-Learning Nonlinear Dynamical Systems with Deep Kernels,4.0, 4.0, 1.0, 5, 3, 5, 4, 3, 3, 3, 4
Unlocking the Power of Representations in Long-term Novelty-based Exploration,6.333333333333333, 6.0, 1.247219128924647, 8, 4, 6, 4, 5, 4
MAAD Private: Multi-Attribute Adversarial Debiasing with Differential Privacy,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 5, 3, 3, 3, 4
Exploring High-Order Message-Passing in Graph Transformers,4.0, 4.0, 1.0, 3, 5, 5, 4, 3, 4, 5, 5
Emergence of Equivariance in Deep Ensembles,6.0, 5.5, 1.224744871391589, 5, 4, 8, 3, 6, 2, 5, 4
Time Series Continuous Modeling for Imputation and Forecasting with Implicit Neural Representations,6.0, 5.0, 1.4142135623730951, 8, 3, 5, 4, 5, 4
Beyond Graphs: Learning with Relational DBs,nan, nan, nan
XIMAGENET-12: An Explainable AI Benchmark Dataset for Model Robustness Evaluation,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 3, 3, 5
L(M)V-IQL: Multiple Intention Inverse Reinforcement Learning for Animal Behavior Characterization,4.0, 4.0, 1.0, 5, 4, 5, 4, 3, 5, 3, 3
Synergistic Information Retrieval: Interplay between Search and Large Language Models,5.0, 5.5, 1.224744871391589, 3, 5, 6, 4, 5, 5, 6, 2
Differentiable Sensor Layouts for End-to-End Learning of Task-Specific Camera Parameters,6.5, 6.5, 1.5, 8, 3, 5, 4, 8, 5, 5, 4
Full Elastic Weight Consolidation via the Surrogate Hessian-Vector Product,3.6666666666666665, 3.0, 0.9428090415820634, 3, 2, 5, 3, 3, 5
Flow to Better: Offline Preference-based Reinforcement Learning via Preferred Trajectory Generation,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 3, 5, 5, 4
Latent Noise Segmentation: How Neural Noise Leads to the Emergence of Segmentation and Grouping,5.2, 6.0, 1.9390719429665317, 3, 4, 6, 4, 3, 3, 6, 5, 8, 3
Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling,6.25, 6.0, 1.0897247358851685, 5, 3, 6, 3, 6, 2, 8, 4
Discovering Knowledge-Critical Subnetworks in Neural Language Models,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 3, 4, 5, 4
Kernelised Normalising Flows,6.0, 5.5, 1.224744871391589, 6, 4, 5, 4, 5, 3, 8, 3
Topic modeling as multi-objective optimization with Setwise Contrastive Learning,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 5, 3, 6, 3
ED-NeRF: Efficient Text-Guided Editing of 3D Scene With Latent Space NeRF,5.25, 5.0, 0.4330127018922193, 5, 3, 6, 3, 5, 5, 5, 4
Federated Learning under Label Shifts with Guarantees,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 6, 3, 3, 4
Learning Personalized Causally Invariant Representations for Heterogeneous Federated Clients,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 3, 6, 4
Maximally Expressive GNNs for Outerplanar Graphs,5.2, 6.0, 1.16619037896906, 6, 3, 3, 5, 6, 3, 6, 4, 5, 3
A Unified Causal View of Instruction Tuning,5.0, 6.0, 1.4142135623730951, 6, 3, 3, 3, 6, 1
Deep Orthogonal Hypersphere Compression for Anomaly Detection,8.0, 8.0, 0.0, 8, 3, 8, 4, 8, 4, 8, 5
LeanFlex-GKP: Advancing Hassle-Free Structured Pruning with Simple Flexible Group Count,5.0, 5.0, 0.0, 5, 3, 5, 5, 5, 3
ProtoReg: Prioritizing Discriminative Information for Fine-grained Transfer Learning,4.75, 5.0, 1.0897247358851685, 6, 5, 5, 4, 5, 2, 3, 5
Towards Better Orthogonality Regularization with Disentangled Norm in Training Deep CNNs,3.0, 3.0, 0.0, 3, 4, 3, 4
Domain Adaptation for Large-Vocabulary Object Detectors,5.2, 5.0, 0.39999999999999997, 5, 4, 5, 4, 6, 3, 5, 4, 5, 4
Rethinking Decision Transformer via Hierarchical Reinforcement Learning,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 4, 5, 5
PAE: Reinforcement Learning from External Knowledge for Efficient Exploration,5.5, 5.5, 0.5, 5, 3, 6, 4, 5, 4, 6, 4
Value-Biased Maximum Likelihood Estimation for Model-based Reinforcement Learning in Discounted Linear MDPs,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 6, 3, 3, 5
Classifiers are Forgetful! Balancing the Mutual Causal Effects in Class-Incremental Learning,5.0, 5.5, 1.224744871391589, 6, 3, 3, 4, 5, 4, 6, 4
Exploring the Relationship between In-Context Learning and Instruction Tuning,4.8, 5.0, 1.8330302779823362, 5, 4, 3, 4, 8, 4, 5, 3, 3, 4
A multiobjective continuation method to compute the regularization path of deep neural networks,4.5, 4.5, 1.5, 3, 4, 6, 5, 3, 4, 6, 3
An Efficient Query Strategy for Active Learning via Optimal Transport,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 3, 3, 5, 5, 4
ConvFormer: Revisiting Token-mixers for Sequential User Modeling,5.5, 5.5, 0.5, 5, 5, 6, 4
Toward Generalizability of Graph-based Imputation on Bio-Medical Missing Data,4.6, 5.0, 1.3564659966250536, 3, 3, 3, 5, 6, 4, 6, 3, 5, 5
Advancing Pose-Guided Image Synthesis with Progressive Conditional Diffusion Models,6.25, 6.0, 1.0897247358851685, 5, 4, 6, 4, 8, 3, 6, 5
Bayesian Domain Invariant Learning via Posterior Generalization of Parameter Distributions,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 4, 5, 4, 3, 3
Investigating the Ability of PINNs To Solve Burgers' PDE Near Finite-Time BlowUp,5.0, 5.5, 1.224744871391589, 6, 4, 6, 4, 5, 2, 3, 4
How to Craft Backdoors with Unlabeled Data Alone?,4.0, 4.0, 1.0, 3, 4, 5, 4, 5, 4, 3, 4
Beyond Unimodal Learning: The Importance of Integrating Multiple Modalities for Lifelong Learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 4, 3, 5
Exploring Pointwise Similarity of Representations,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 4
GraSP: Simple yet Effective Graph Similarity Predictions,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 3, 5, 6, 4
Learning from Distinction: Mitigating backdoors using a low-capacity model,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 5, 4, 3, 4
Signed-Binarization: Unlocking Efficiency Through Repetition-Sparsity Trade-Off,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 3, 4, 6, 3
Generalized Temporal Difference Learning Models for Supervised Learning,5.5, 5.5, 1.8027756377319946, 8, 3, 3, 4, 5, 3, 6, 3
Prompt Backdoors in Visual Prompt Learning,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 4, 5, 4
Twinned Interventional Flows,4.0, 3.0, 1.4142135623730951, 3, 3, 3, 3, 6, 3
Enhancing Decision Tree Learning with Deep Networks,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 4, 3, 5
Sparse hyperbolic representation learning,5.0, 6.0, 1.4142135623730951, 6, 3, 6, 4, 3, 4
Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Team Optimization,5.5, 5.5, 1.5, 5, 3, 6, 3, 6, 3, 8, 2, 3, 3, 5, 3
Constructing Sparse Neural Architecture with Deterministic Ramanujan Graphs,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 2, 3, 2, 3, 3
Online Feature Updates Improve Online (Generalized) Label Shift Adaptation,5.25, 5.0, 1.7853571071357126, 3, 3, 5, 3, 5, 3, 8, 4
One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention,6.0, 5.5, 1.224744871391589, 5, 3, 8, 4, 5, 3, 6, 4
Dantzig-Wolfe Decomposition and Deep Reinforcement Learning,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 4
Enhancing Deep Graph Neural Networks via Improving Signal Propagation,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 4, 5, 4, 5, 4
Towards Perpetually Trainable Neural Networks,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 4, 3, 3, 6, 5
Bio-RFX: Refining Biomedical Extraction via Advanced Relation Classification and Structural Constraints,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 3, 6, 4, 6, 4
Domain Feature Perturbation for Domain Generalization,4.0, 4.0, 1.0, 3, 5, 5, 4, 5, 5, 3, 4
Tackling Byzantine Clients in Federated Learning,6.75, 7.0, 1.299038105676658, 6, 3, 5, 2, 8, 2, 8, 3
Interpretable and Generalizable Graph Neural Networks via Subgraph Multilinear Extension,5.75, 6.0, 1.7853571071357126, 6, 3, 8, 2, 6, 3, 3, 3
Rethinking the Effectiveness of Graph Classification Datasets in Benchmarks for Assessing GNNs,5.5, 5.5, 1.8027756377319946, 5, 3, 8, 4, 6, 3, 3, 3
Multi-Scale Protein Language Model for Unified Molecular Modeling,4.75, 5.0, 1.0897247358851685, 3, 5, 6, 3, 5, 3, 5, 4
Benign Overfitting in Two-Layer ReLU Convolutional Neural Networks for XOR Data,5.2, 6.0, 1.16619037896906, 6, 3, 6, 4, 3, 3, 6, 4, 5, 4
SAGMAN: Stability Analysis of Graph Neural Networks (GNNs) on the Manifolds,4.4, 5.0, 1.2, 6, 3, 5, 3, 3, 3, 3, 4, 5, 3
Prometheus: Inducing Evaluation Capability in Language Models,4.0, 5.0, 2.160246899469287, 5, 3, 6, 4, 1, 4
QORA: Zero-Shot Transfer via Interpretable Object-Relational Model Learning,4.25, 4.0, 1.299038105676658, 3, 2, 5, 3, 3, 4, 6, 2
Dissecting Gradient Masking and Denoising in Diffusion Models for Adversarial Purification,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 2, 5, 4, 5, 3
ClimODE: Climate Forecasting With Physics-informed Neural ODEs,7.0, 7.0, 1.0, 6, 4, 6, 3, 8, 3, 8, 3
Querying Easily Flip-flopped Samples for Deep Active Learning,6.25, 6.0, 1.0897247358851685, 6, 3, 5, 4, 6, 3, 8, 4
Stop overkilling simple tasks with black-box models use more transparent models instead,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 5, 5, 5, 3, 3
Multi-Task Learning for Routing Problem with Zero-Shot Generalization,5.0, 4.5, 2.1213203435596424, 3, 5, 6, 2, 8, 5, 3, 4
Attention-based Iterative Decomposition for Tensor Product Representation,5.8, 5.0, 1.16619037896906, 8, 2, 6, 3, 5, 2, 5, 4, 5, 4
NOISY MULTI-VIEW CONTRASTIVE LEARNING FRAMEWORK FOR ENHANCING TOP-K RECOMMENDATION,4.0, 4.0, 1.0, 3, 4, 5, 3, 3, 3, 5, 3
Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 3, 6, 4
Feasible Algorithmic Recourse Without Explicit Structure Prior,5.0, 5.0, 1.8973665961010275, 8, 4, 5, 2, 3, 3, 3, 3, 6, 3
Efficient Instance-Optimal Finite-Sum Minimization,6.0, 5.5, 1.224744871391589, 6, 3, 8, 3, 5, 3, 5, 4
BroGNet: Momentum-Conserving Graph Neural Stochastic Differential Equation for Learning Brownian Dynamics,5.0, 5.5, 1.224744871391589, 3, 3, 6, 4, 6, 3, 5, 3
Forked Diffusion for Conditional Graph Generation,4.0, 4.0, 1.0, 3, 4, 5, 3, 5, 3, 3, 4
Fully Hyperbolic Representation Learning on Knowledge Hypergraph,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 5
Generative Semantic Communication: Diffusion Models Beyond Bit Recovery,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 2, 6, 3, 5, 4
The Role of Forgetting in Fine-Tuning Reinforcement Learning Models,4.75, 4.0, 2.0463381929681126, 8, 4, 3, 4, 3, 4, 5, 4
CompanyKG: A Large-Scale Heterogeneous Graph for Company Similarity Quantification,3.0, 3.0, 0.0, 3, 3, 3, 4, 3, 4, 3, 4
Federated Offline Policy Learning with Heterogeneous Observational Data,5.5, 5.5, 0.5, 6, 4, 5, 3, 5, 3, 6, 3
Some Intriguing Aspects about Lipschitz Continuity of Neural Networks,5.5, 5.5, 1.8027756377319946, 3, 4, 6, 2, 5, 3, 8, 4
Thermodynamics-inspired Structure Hallucination for Protein-protein Interaction Modeling,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 4, 3, 4
WASSERSTEIN-GUIDED SYMBOLIC REGRESSION: MODEL DISCOVERY OF NETWORK DYNAMICS,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 3, 5, 3, 3, 3
Evaluating Language Models Through Negotiations,5.333333333333333, 5.0, 2.0548046676563256, 5, 4, 3, 2, 8, 4
Towards robust unlearnable examples via deep hiding,4.5, 5.0, 0.8660254037844386, 5, 5, 5, 3, 3, 4, 5, 5
Deep Backtracking Counterfactuals for Causally Compliant Explanations,4.6, 5.0, 0.7999999999999999, 5, 4, 5, 3, 3, 2, 5, 4, 5, 4
Enhancing Medical Image Generation with Anatomical Precision: A Multi-Headed VAE-Based Diffusion Model,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 4, 5, 5
On the Role of General Function Approximation in Offline Reinforcement Learning,5.8, 6.0, 1.6, 3, 4, 8, 4, 6, 3, 6, 2, 6, 3
Making Retrieval-Augmented Language Models Robust to Irrelevant Context,5.75, 6.0, 1.7853571071357126, 3, 4, 6, 4, 8, 3, 6, 4
State Chrono Representation for Enhancing Generalization in Reinforcement Learning,4.75, 4.0, 2.0463381929681126, 3, 5, 8, 3, 5, 4, 3, 3
On the Generalization of Gradient-based Neural Network Interpretations,4.0, 3.0, 1.4142135623730951, 3, 3, 6, 4, 3, 4
Restorer Guided Diffusion Models for Variational Inverse Problems,2.5, 3.0, 0.8660254037844386, 1, 5, 3, 5, 3, 4, 3, 5
3D Dense Captioning beyond Nouns: A Middleware for Autonomous Driving,4.0, 3.0, 1.4142135623730951, 6, 5, 3, 4, 3, 5
Analyzing Feed-Forward Blocks in Transformers through the Lens of Attention Map,6.75, 7.0, 1.299038105676658, 6, 3, 5, 4, 8, 4, 8, 3
On the Relation between Gradient Directions and Systematic Generalization,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4
VersVideo: Leveraging Enhanced Temporal Diffusion Models for Versatile Video Generation,5.0, 5.5, 1.224744871391589, 5, 3, 6, 3, 3, 2, 6, 4
Label-Agnostic Forgetting: A Supervision-Free Unlearning in Deep Models,5.5, 5.5, 1.8027756377319946, 5, 3, 3, 4, 6, 4, 8, 4
Controlling Vision-Language Models for Universal Image Restoration,5.25, 6.0, 1.299038105676658, 6, 4, 6, 4, 3, 5, 6, 5
Decomposition Ascribed Synergistic Learning for Unified Image Restoration,5.5, 5.5, 1.8027756377319946, 3, 4, 8, 4, 6, 5, 5, 5
Yet Another ICU Benchmark: A Flexible Multi-Center Framework for Clinical ML,5.4, 5.0, 1.624807680927192, 5, 3, 8, 4, 3, 3, 6, 3, 5, 3
EGraFFBench: Evaluation of Equivariant Graph Neural Network Force Fields for Atomistic Simulations,4.666666666666667, 3.0, 2.357022603955158, 3, 4, 8, 4, 3, 4
SuperPos-Prompt: Enhancing Soft Prompt Tuning of Language Models with Superposition of Multi Token Embeddings,4.75, 5.0, 1.0897247358851685, 6, 3, 3, 4, 5, 4, 5, 4
Asymptotically Free Sketched Ridge Ensembles: Risks Cross-Validation and Tuning,7.5, 8.0, 0.8660254037844386, 6, 4, 8, 3, 8, 4, 8, 3
Unsupervised Learning of Object-Centric Representation from Multi-Viewpoint Scenes,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 3, 5, 4
AdaFlood: Adaptive Flood Regularization,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 4, 5, 3
Crystals with Transformers on Graphs for predictions of crystal material properties,3.25, 3.0, 1.7853571071357126, 6, 3, 3, 2, 3, 3, 1, 5
Identifying Policy Gradient Subspaces,5.0, 5.5, 1.224744871391589, 5, 2, 6, 3, 3, 2, 6, 3
Mixture-of-Experts in Prompt Optimization,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 4, 5, 4, 6, 4
A bi-objective perspective on controllable language models: reward dropout improves off-policy control performance,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 3, 5, 4
Capturing The Channel Dependency Completely Via Knowledge-Episodic Memory For Time Series Forecasting,4.0, 4.0, 1.0, 3, 5, 3, 3, 5, 3, 5, 5
Eye Fairness: A Large-Scale 3D Imaging Dataset for Equitable Eye Diseases Screening and Fair Identity Scaling,5.5, 5.5, 0.5, 5, 5, 6, 4, 5, 4, 6, 3
Effective and Parameter-Efficient Reusing Fine-Tuned Models,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 3
Nemesis: Normalizing the soft-prompt vectors of vision-language models,5.666666666666667, 6.0, 2.0548046676563256, 6, 3, 3, 3, 8, 4
Memory-efficient particle filter recurrent neural network for object localization,4.0, 3.0, 2.943920288775949, 3, 3, 1, 4, 8, 3
Training Graph Transformers via Curriculum-Enhanced Attention Distillation,6.25, 6.0, 1.0897247358851685, 5, 5, 6, 4, 6, 3, 8, 3
Adaptive Stochastic Gradient Algorithm for Black-box Multi-Objective Learning,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 3, 6, 4, 6, 3
Physics Informed Distillation for Diffusion Models,4.25, 4.0, 1.299038105676658, 3, 3, 5, 4, 3, 4, 6, 4
Discovering Minimal Reinforcement Learning Environments,3.0, 3.0, 0.0, 3, 4, 3, 2, 3, 4, 3, 4
Delayed Spiking Neural Network and Exponential Time Dependent Plasticity Algorithm,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 3
DIFFNAT: IMPROVING DIFFUSION IMAGE QUALITY USING NATURAL IMAGE STATISTICS,5.0, 5.5, 1.224744871391589, 6, 4, 6, 3, 5, 2, 3, 4
A First-Order Multi-Gradient Algorithm for Multi-Objective Bi-Level Optimization,5.0, 5.5, 1.224744871391589, 6, 5, 5, 4, 3, 3, 6, 3
Homeomorphic Model Transformation for Boosting Performance and Efficiency in Object Detection Networks,5.0, 4.5, 2.1213203435596424, 3, 4, 3, 5, 6, 4, 8, 4
Post-prediction confidence training complements supervised learning,2.5, 3.0, 0.8660254037844386, 1, 4, 3, 4, 3, 3, 3, 3
Learning to Explore with In-Context Policy for Fast Peer Adaptation,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 6, 3, 3, 4
AgentBench: Evaluating LLMs as Agents,6.0, 6.0, 1.8973665961010275, 5, 4, 8, 4, 6, 4, 8, 3, 3, 4
Simple CNN for Vision,5.5, 5.5, 1.8027756377319946, 6, 1, 3, 4, 8, 1, 5, 4
Is Feature Extraction the most informative dimensionality reduction technique? Revisiting Unsupervised Feature Selection from a Dynamic Approach,4.5, 5.0, 0.8660254037844386, 5, 2, 5, 4, 5, 4, 3, 4
Image Background Serves as Good Proxy for Out-of-distribution Data,5.166666666666667, 5.5, 1.7716909687891083, 3, 4, 3, 3, 5, 3, 6, 5, 6, 2, 8, 3
Augmented Policy Optimization for Safe Reinforcement Learning,4.25, 4.0, 1.299038105676658, 3, 4, 6, 4, 5, 3, 3, 4
ChronoGAM: An End-to-End One-Class Time Series Gaussian Mixture Model,3.5, 4.0, 1.6583123951777, 5, 3, 1, 5, 5, 4, 3, 4
Personalized Facial Expressions and Head Poses for Speech-Driven 3D Facial Animation,5.25, 5.0, 1.7853571071357126, 8, 4, 3, 5, 5, 5, 5, 3
Efficient Meshy Neural Fields for Animatable Human Avatars,5.5, 5.5, 0.5, 6, 4, 5, 4, 6, 3, 5, 4
TADIS: Steering Models for Deep-Thinking about Demonstration Examples,3.75, 3.0, 1.299038105676658, 3, 2, 3, 4, 3, 2, 6, 3
Differentially Private Synthetic Data via Foundation Model APIs 1: Images,6.0, 5.5, 1.224744871391589, 5, 4, 5, 5, 8, 4, 6, 4
Learn What You Need  in Personalized Federated Learning,5.0, 5.5, 1.224744871391589, 3, 4, 6, 3, 5, 4, 6, 5
SENSITIVITY-INFORMED REGULARIZATION FOR OFFLINE BLACK-BOX OPTIMIZATION,5.25, 6.0, 1.299038105676658, 3, 3, 6, 3, 6, 3, 6, 3
Ask more know better: Reinforce-Learned Prompt Questions for Decision Making with  Large Language Models,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 3, 5, 4, 5, 4
CoDBench: A Critical Evaluation of Data-driven Models for Continuous Dynamical Systems,4.5, 4.5, 1.5, 3, 3, 3, 3, 6, 3, 6, 2
SketchEdit: Editing Freehand Sketches At The Stroke-Level,3.6666666666666665, 3.0, 0.9428090415820634, 5, 5, 3, 4, 3, 4
EXPLORING RAIN-/DETAIL-AWARE REPRESENTATION FOR INSTANCE-SPECIFIC IMAGE DE-RAINING,5.0, 5.0, 0.0, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5
Generalization or Specificity? Spectral Meta Estimation and Ensemble (SMEE) with Domain-specific Experts,5.5, 6.5, 2.8722813232690143, 8, 4, 1, 5, 5, 3, 8, 4
Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning,5.25, 5.0, 0.4330127018922193, 6, 2, 5, 4, 5, 4, 5, 3
$\beta$-DQN: Diverse Exploration via Learning a Behavior Function,4.0, 3.0, 1.2649110640673518, 6, 3, 5, 3, 3, 4, 3, 4, 3, 4
HP$^3$-NS: Hybrid Perovskite Property Prediction Using Nested Subgraph,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 3, 5, 4
Edge-free but Structure-aware: Prototype-Guided Knowledge Distillation from GNNs to MLPs,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 5, 4, 3, 5
Early Weight Averaging Meets High Learning Rates for LLM Pre-training,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 3, 3, 4
Beyond IID weights: sparse and low-rank deep Neural Networks are also Gaussian Processes,5.5, 5.5, 1.8027756377319946, 3, 3, 8, 2, 5, 3, 6, 3
Privacy at Interpolation: Precise Analysis for Random and NTK Features,5.333333333333333, 5.0, 0.4714045207910317, 5, 2, 6, 3, 5, 3
Guaranteed Trust Region Optimization via Two-Phase KL Penalization,6.0, 5.5, 2.5495097567963922, 5, 4, 10, 5, 6, 2, 3, 3
What do vision transformers learn? A visual exploration,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 3, 3, 4, 5, 4
Black-Box Gradient Matching for Reliable Offline Black-Box Optimization,5.0, 4.5, 2.1213203435596424, 3, 5, 3, 4, 8, 4, 6, 2
Mitigating Mode Collapse in Sequential Disentanglement via an Architecture Bias,3.5, 4.0, 1.6583123951777, 1, 5, 3, 4, 5, 4, 5, 4
Understanding Addition in Transformers,5.5, 5.5, 2.5, 8, 3, 3, 4, 8, 3, 3, 4
Beating Price of Anarchy and Gradient Descent without Regret in Potential Games,7.0, 7.0, 1.0, 8, 3, 6, 2
Do Large Language Models Know about Facts?,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 3, 5, 4, 3, 4
New recipes for graph anomaly detection: Forward diffusion dynamics and graph generation,5.166666666666667, 5.0, 0.372677996249965, 5, 3, 5, 4, 6, 3, 5, 4, 5, 3, 5, 4
Dual-target Point Cloud Registration Using Representative Overlapping Points,2.3333333333333335, 3.0, 0.9428090415820634, 3, 5, 3, 5, 1, 5
Abstractive Summarization through the PRISM of Decoding Strategies,6.0, 5.5, 1.224744871391589, 5, 4, 6, 3, 5, 4, 8, 3
Achieving Margin Maximization Exponentially Fast via Progressive Norm Rescaling,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 3, 5, 4
In defense of parameter sharing for model-compression,5.5, 5.5, 1.8027756377319946, 3, 4, 5, 4, 8, 3, 6, 2
Kill Two Birds with One Stone: Rethinking Data Augmentation for Deep Long-tailed Learning,6.5, 6.5, 1.5, 8, 4, 5, 3, 5, 4, 8, 5
Decoupling Intrinsic and Measurement Trends: A Crucial Consideration in Time Series Causal Discovery,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 4, 3, 4
Spectral learning of shared dynamics between generalized-linear processes,5.6, 6.0, 0.48989794855663565, 6, 1, 6, 3, 6, 2, 5, 3, 5, 3
Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 5, 3, 8, 3
Language-driven Open-Vocabulary Keypoint Detection for Animal Body and Face,5.0, 5.0, 1.0954451150103321, 6, 4, 5, 4, 5, 4, 3, 4, 6, 5
Bootstrapping Variational Information Pursuit with Foundation Models for Interpretable Image Classification,5.5, 5.5, 0.5, 6, 3, 5, 4
An old dog can learn (some) new tricks: A tale of a three-decade old architecture,5.0, 5.5, 1.224744871391589, 3, 4, 5, 4, 6, 3, 6, 3
Generative Pre-Trained Speech Language Model with Efficient Hierarchical Transformer,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 4, 5, 4, 5, 5
Calibration Attack: A Framework For Adversarial Attacks Targeting Calibration,4.0, 5.0, 1.7320508075688772, 5, 3, 1, 3, 5, 3, 5, 4
Offline RL for Online RL: Decoupled Policy Learning for Mitigating Exploration Bias,6.333333333333333, 6.0, 1.247219128924647, 6, 3, 5, 4, 8, 3
EraseDiff: Erasing Data Influence in Diffusion Models,5.6, 6.0, 1.624807680927192, 5, 4, 8, 3, 3, 3, 6, 3, 6, 4
Contextual Bandits with Online Neural Regression,6.0, 6.0, 1.0954451150103321, 8, 4, 6, 4, 5, 3, 5, 3, 6, 4
Evaluating Large Language Models at Evaluating Instruction Following,7.333333333333333, 8.0, 0.9428090415820634, 8, 4, 6, 3, 8, 3
Be Your Own Neighborhood: Detecting Adversarial Example by the Neighborhood Relations Built on Self-Supervised Learning,6.0, 5.5, 1.224744871391589, 8, 4, 5, 4, 5, 3, 6, 3
On the Global Convergence of Natural Actor-Critic with Neural Network Parametrization,4.0, 4.0, 1.0, 3, 3, 5, 5, 5, 5, 3, 4
How to Fine-Tune Vision Models with SGD,6.6, 6.0, 1.2, 6, 4, 5, 3, 6, 4, 8, 3, 8, 3
Backdoor Contrastive Learning via Bi-level Trigger Optimization,5.0, 5.5, 1.224744871391589, 6, 4, 6, 4, 3, 5, 5, 4
PaLI-3 Vision Language Models: Smaller Faster Stronger,5.666666666666667, 6.0, 2.0548046676563256, 8, 4, 3, 5, 6, 4
Marginal Benefit Induced Unsupervised Environment Design,3.8, 3.0, 0.9797958971132712, 3, 4, 5, 4, 3, 3, 5, 5, 3, 4
A Novel Variational Lower Bound For Inverse Reinforcement Learning,3.25, 2.0, 2.8613807855648994, 1, 3, 1, 5, 8, 4, 3, 4
Push: Concurrent Probabilistic Programming for Bayesian Deep Learning,4.25, 3.0, 2.165063509461097, 3, 4, 3, 4, 3, 4, 8, 4
CAS: A Probability-Based Approach for Universal Condition Alignment Score,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 6, 4, 5, 4
JsonTuning: Towards Generalizable Robust and Controllable Instruction Tuning,5.5, 5.5, 0.5, 5, 4, 5, 4, 6, 5, 6, 3
NAP2: Neural Networks Hyperparameter Optimization Using Weights and Gradients Analysis,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 5, 5, 4
Test Time Augmentations are Worth One Million Images for Out-of-Distribution Detection,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 3, 3, 3
The Certification Paradox: Certifications Admit Better Evasion Attacks,4.25, 4.0, 1.299038105676658, 3, 3, 5, 3, 6, 3, 3, 5
Human-oriented Representation Learning for Robotic Manipulation,5.0, 5.5, 1.224744871391589, 6, 3, 5, 4, 6, 4, 3, 3
PARL: A Unified Framework for Policy Alignment in Reinforcement Learning,6.0, 5.5, 1.224744871391589, 6, 3, 5, 3, 5, 3, 8, 3
SafeDreamer: Safe Reinforcement Learning with World Models,5.25, 5.0, 0.4330127018922193, 5, 5, 6, 5, 5, 4, 5, 4
Demystifying CLIP Data,6.0, 5.5, 1.224744871391589, 6, 4, 5, 5, 8, 4, 5, 3
First-Explore then Exploit: Meta-Learning Intelligent Exploration,4.25, 3.0, 2.165063509461097, 8, 3, 3, 3, 3, 3, 3, 4
A Neural Tangent Kernel Approach for Constrained Policy Gradient Reinforcement Learning,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 4, 6, 3, 5, 3
Making Large Language Models Better Reasoners with Alignment,5.0, 5.5, 1.224744871391589, 3, 4, 6, 4, 5, 4, 6, 4
MetaCoCo: A New Few-Shot Classification Benchmark with Spurious Correlation,6.333333333333333, 6.0, 1.247219128924647, 6, 3, 5, 2, 8, 4
A Joint Spectro-Temporal Relational Thinking Based Acoustic Modeling Framework,3.75, 3.0, 1.299038105676658, 6, 3, 3, 4, 3, 5, 3, 3
Whittle Index with Multiple Actions and State Constraint for Inventory Management,5.333333333333333, 5.0, 2.0548046676563256, 5, 3, 3, 4, 8, 3
Exploring the Generalization Capabilities of AID-based Bi-level Optimization,5.0, 4.5, 2.1213203435596424, 3, 3, 6, 3, 8, 3, 3, 3
A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 3, 5, 3
Looped Transformers are Better at Learning Learning Algorithms,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 6, 4, 5, 4
Sum-Product-Set Networks: Deep Tractable Models for Tree-Structured Graphs,6.0, 5.5, 1.224744871391589, 8, 4, 5, 3, 5, 3, 6, 2
Language-Conditioned Imitation Learning With Base Skill Priors Under Unstructured Data,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4, 3, 3
Margin Discrepancy-based Adversarial Training for Multi-Domain Text Classification,4.25, 4.0, 1.299038105676658, 3, 4, 3, 5, 5, 4, 6, 5
TKG-LM: Temporal Knowledge Graph Extrapolation Enhanced by Language Models,4.0, 4.0, 1.0, 3, 4, 5, 4, 5, 4, 3, 4
Stochastic Adversarial Networks for Multi-Domain Text Classification,3.6666666666666665, 5.0, 1.8856180831641267, 5, 3, 1, 4, 5, 2
Learning Thresholds with Latent Values and Censored Feedback,5.75, 5.0, 1.299038105676658, 5, 4, 5, 2, 5, 3, 8, 3
GenCO: Generating Diverse Solutions to Design Problems with Combinatorial Nature,4.25, 4.0, 1.299038105676658, 3, 3, 5, 3, 6, 4, 3, 3
A space-continuous implementation of Proper Orthogonal Decomposition by means of Neural Networks,3.8, 3.0, 0.9797958971132712, 5, 2, 3, 3, 5, 2, 3, 4, 3, 4
Generating Robot Policy Code for High-Precision and Contact-Rich Manipulation Tasks,4.0, 5.0, 1.7320508075688772, 5, 5, 5, 4, 5, 4, 1, 4
Continual Learning with Orthogonal Weights and Knowledge Transfer,4.5, 4.5, 1.5, 6, 3, 3, 5, 6, 5, 3, 5
A Dataset and Benchmark for Copyright Protection from Text-to-Image Diffusion Models,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 5, 6, 4
Unlocking the Potential of Federated Learning for Deeper Models,3.3333333333333335, 3.0, 2.0548046676563256, 1, 4, 6, 2, 3, 4
Exploring the Relationship Between Model Architecture and In-Context Learning Ability,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 3, 5, 2, 6, 4
Federated Learning with Local Openset Noisy Labels,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 3, 5, 3, 5, 3
Towards a Self-Made Model: Zero-Shot Self-Supervised Purification for Adversarial Attacks,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 2
PINA: a PyTorch Framework for Deep Differential Equation Learning for Research and Production Environments,nan, nan, nan
Benchmarking Smoothness and Reducing High-Frequency Oscillations in Continuous Control Policies,4.75, 5.0, 1.0897247358851685, 3, 5, 6, 3, 5, 3, 5, 5
Towards Cost-Efficient Federated Multi-Agent Reinforcement Learning with Learnable Aggregation,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 4, 5, 4
Improved Function Space Variational Inference with Informative Priors,4.5, 4.5, 1.5, 6, 3, 3, 4, 3, 3, 6, 3
Performance Adjustment for Federated Learning Marketplace,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 5, 4
A counterfactual-based approach to prevent crowding in intelligent subway systems,3.25, 3.0, 1.7853571071357126, 3, 3, 3, 3, 1, 3, 6, 1
Are Transformers with One Layer Self-Attention Using Low-Rank Weight Matrices Universal Approximators?,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 6, 3, 8, 3
Grokking Tickets: Lottery Tickets Accelerate Grokking,4.25, 4.0, 1.299038105676658, 3, 4, 3, 4, 5, 4, 6, 2
OfflineLight: An Offline Reinforcement Learning Model for Traffic Signal Control,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 5, 3, 2
Adaptive Temperature Enhanced Dual-level Hypergraph Contrastive Learning,3.6, 3.0, 1.7435595774162693, 1, 5, 3, 5, 3, 5, 5, 3, 6, 3
Offline Reward Inference on Graph: A New Thinking,6.0, 6.0, 0.0, 6, 2, 6, 4, 6, 4
Language-Interfaced Tabular Oversampling via Progressive Imputation and Self-Authentication,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 3, 6, 3
Certified Adversarial Robustness for Rate Encoded Spiking Neural Networks,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 3, 5, 4, 6, 3
A Change of Heart: Backdoor Attacks on Security-Centric Diffusion Models,4.75, 5.0, 1.0897247358851685, 3, 2, 5, 4, 5, 4, 6, 4
Skill Reinforcement Learning and Planning for Open-World Long-Horizon Tasks,4.0, 4.0, 1.0, 5, 3, 3, 4, 5, 3, 3, 3
Generalizing Poincaré Policy Representations in Multi-agent Reinforcement Learning,4.75, 5.0, 1.0897247358851685, 5, 2, 5, 4, 3, 2, 6, 3
A Framework for PromptOps in GenAI Application Development Lifecycle,2.3333333333333335, 3.0, 0.9428090415820634, 3, 3, 3, 3, 1, 5
Fake It Till Make It: Federated Learning with Consensus-Oriented Generation,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 6, 4, 5, 3
Towards Predicate-powered Learning,3.5, 3.0, 0.8660254037844386, 5, 2, 3, 3, 3, 4, 3, 3
RetPur: Diffusion Purification Model for Defending Hash Retrieval Target Attacks,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 4, 3, 4
Analyzing Deep Transformer Models for Time Series Forecasting via Manifold Learning,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 4, 3, 3, 5, 4
Provably Doubly Accelerated Federated Learning: The First Theoretically Successful Combination of Local Training and Communication Compression,5.5, 5.5, 0.5, 6, 3, 5, 3
SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 4, 5, 3, 5, 3
Customizing Global Model for Diverse Target Distributions in Federated Learning,3.75, 3.0, 1.299038105676658, 3, 3, 3, 4, 3, 5, 6, 4
Mixture-of-Supernets: Improving Weight-Sharing Supernet Training with Architecture-Routed Mixture-of-Experts,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 3
In Search of the Long-Tail: Systematic Generation of Long-Tail Knowledge via Logical Rule Induced Search,4.75, 4.0, 2.0463381929681126, 5, 4, 3, 3, 3, 4, 8, 4
NeRF Compression via Transform Coding,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 4
Learning from Shortcut: A Shortcut-guided Approach for Graph Rationalization,4.333333333333333, 5.0, 0.9428090415820634, 5, 5, 3, 4, 5, 4
Adversarial Attacks on Combinatorial Multi-Armed Bandits,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 2, 5, 4, 6, 4
Explaining Time Series via Contrastive and Locally Sparse Perturbations,4.75, 5.0, 1.0897247358851685, 5, 2, 3, 3, 6, 2, 5, 3
E(3) Equivariant Scalar Interaction Network,4.0, 3.0, 1.4142135623730951, 3, 3, 6, 4, 3, 4
LMO-DP: Accurately Fine-Tuning Language Models with Stronger Differential Privacy,4.75, 5.0, 1.0897247358851685, 5, 3, 6, 3, 5, 4, 3, 4
Semi-HyperGraph Benchmark: Enhancing Flexibility of Hypergraph Learning with Datasets and Benchmarks,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 4
Small Visual Language Models can also be Open-Ended Few-Shot Learners,4.75, 4.0, 2.0463381929681126, 3, 4, 8, 4, 5, 4, 3, 4
Optimal Neural Network Approximation for High-Dimensional Continuous Functions,2.5, 2.0, 1.6583123951777, 3, 4, 5, 3, 1, 3, 1, 2
When Does Bias Transfer in Transfer Learning?,5.25, 5.0, 1.7853571071357126, 5, 3, 3, 4, 5, 4, 8, 4
Fast Multipole Attention: A Divide-and-Conquer Attention Mechanism for Long Sequences,5.0, 5.0, 0.0, 5, 5, 5, 4, 5, 4
LLM4GCL: CAN LARGE LANGUAGE MODEL EM-POWER GRAPH CONTRASTIVE LEARNING?,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 5, 4
GnnX-Bench: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking,5.0, 5.5, 1.224744871391589, 5, 2, 6, 3, 6, 4, 3, 4
Noise Robust Graph Learning under Feature-Dependent Graph-Noise,5.5, 5.5, 1.8027756377319946, 8, 4, 6, 4, 3, 3, 5, 4
Few and Fewer: Learning Better from Few Examples Using Fewer Base Classes,5.4, 5.0, 0.4898979485566356, 6, 4, 5, 4, 5, 3, 5, 4, 6, 4
Quantum sequential scattering model for quantum state learning,3.6666666666666665, 5.0, 1.8856180831641267, 5, 3, 5, 2, 1, 4
Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space,6.0, 6.5, 2.1213203435596424, 8, 4, 5, 4, 8, 3, 3, 3
Adversarial AutoMixup,5.666666666666667, 6.0, 2.0548046676563256, 8, 4, 3, 3, 6, 5
Grounded Object-Centric Learning,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 6, 4, 5, 3
Harnessing the Power of Neural Operators with Automatically Encoded Conservation Laws,4.5, 4.5, 1.5, 3, 4, 6, 2, 3, 5, 6, 2
Communication Bounds for the Distributed Experts Problem,4.75, 4.0, 2.0463381929681126, 3, 4, 5, 3, 8, 3, 3, 3
Spatial Matching Loss Function for Mass Segmentation on Whole Mammography Images,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 3, 4, 5, 4
Spatially-Aware Transformers for Embodied Agents,6.75, 7.0, 1.299038105676658, 6, 4, 8, 4, 5, 3, 8, 3
Pivotal Prompt Tuning for Video Dynamic Editing,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 4, 5, 3
Learning to Extrapolate and Adjust: Two-Stage Meta-Learning for Concept Drift in Online Time Series Forecasting,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 3, 3, 4, 6, 4, 5, 4, 5, 4
On the Stability of Expressive Positional Encodings for Graph Neural Networks,5.0, 5.0, 1.0954451150103321, 6, 4, 5, 4, 3, 3, 5, 3, 6, 4
Who SAID that? Benchmarking Social Media AI Detection,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 4
Curvature-Informed SGD via General Purpose Lie-Group Preconditioners,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 3, 5, 5, 6, 3
Low-Cost High-Power Membership Inference by Boosting Relativity,5.5, 5.5, 0.5, 6, 3, 5, 3, 6, 4, 5, 3
A Causal Ordering Prior for Unsupervised Representation Learning,4.0, 4.0, 1.0, 3, 5, 3, 4, 5, 3, 5, 3
Dynamic Neural Response Tuning,5.25, 5.0, 1.7853571071357126, 5, 3, 3, 3, 8, 4, 5, 3
Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 3
Enhancing Detail Preservation for Customized Text-to-Image Generation: A Regularization-Free Approach,5.0, 5.5, 1.224744871391589, 3, 3, 6, 3, 6, 4, 5, 4
Statistical Perspective of Top-K Sparse Softmax Gating Mixture of Experts,5.666666666666667, 6.0, 0.4714045207910317, 6, 1, 6, 3, 5, 2
DECap: Towards Generalized Explicit Caption Editing via Diffusion Mechanism,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 3, 3, 3
The Devil is in the Neurons: Interpreting and Mitigating Social Biases in Language Models,6.8, 6.0, 0.9797958971132712, 8, 3, 8, 4, 6, 3, 6, 4, 6, 4
Leveraging Behavioral Cloning for Representation Alignment in Cross-Domain Policy Transfer,4.8, 5.0, 1.8330302779823362, 5, 4, 5, 4, 3, 3, 8, 3, 3, 4
Provably Efficient Iterated CVaR Reinforcement Learning with Function Approximation and Human Feedback,5.666666666666667, 6.0, 2.0548046676563256, 6, 4, 8, 3, 3, 4
Enhancing Transfer Learning with Flexible Nonparametric Posterior Sampling,5.0, 5.5, 1.224744871391589, 5, 4, 6, 3, 3, 4, 6, 3
Counterfactual Data Augmentation with Contrastive Learning,4.25, 4.0, 1.299038105676658, 3, 5, 3, 3, 5, 5, 6, 3
ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search,6.75, 7.0, 1.299038105676658, 8, 5, 6, 4, 5, 3, 8, 3
Ensemble Distillation for Unsupervised Constituency Parsing,6.2, 6.0, 1.8330302779823362, 6, 4, 6, 4, 8, 4, 3, 5, 8, 2
Defying Multi-model Forgetting: Orthogonal Gradient Learning to One-shot Neural Architecture Search,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 5
Describe-and-Dissect: Interpreting Neurons in Vision Networks with Language Models,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 4, 5, 4, 5, 3
Exploit Gradient Skew to Circumvent Byzantine Defenses for Federated Learning,4.0, 5.0, 2.160246899469287, 1, 4, 6, 5, 5, 3
S$^6$-DAMON: Unlocking Structured Sparsity in Self-Supervised Speech Models via Data-Model Co-Compression,4.0, 4.0, 1.0, 3, 5, 3, 5, 5, 3, 5, 4
GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 5, 5
Quality Diversity through Human Feedback,4.0, 4.0, 1.0, 5, 2, 3, 2, 5, 3, 3, 4
Understanding Length Generalization by Thinking Like Transformers,5.0, 5.5, 1.224744871391589, 6, 3, 5, 3, 6, 3, 3, 4
Beyond Vanilla Variational Autoencoders: Detecting Posterior Collapse in Conditional and Hierarchical Variational Autoencoders,5.6, 6.0, 1.624807680927192, 3, 2, 6, 4, 6, 3, 5, 2, 8, 4
Training-free Multi-objective Diffusion Model for 3D Molecule Generation,6.25, 6.0, 1.0897247358851685, 8, 3, 5, 4, 6, 4, 6, 2
Perceptual Context and Sensitivity in Image Quality Assessment: A Human-Centric Approach,4.0, 5.0, 1.7888543819998317, 1, 5, 3, 5, 6, 4, 5, 5, 5, 5
Graph Neural Networks with Directional Encodings for Anisotropic Elasticity,4.25, 4.0, 1.299038105676658, 5, 4, 3, 3, 6, 3, 3, 4
Generative AI in healthcare: A trustworthy approach,1.0, 1.0, 0.0, 1, 5, 1, 3, 1, 5
Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement,7.0, 7.0, 1.0, 6, 5, 8, 5, 8, 4, 6, 3
Mean Field Langevin Actor-Critic: Faster Convergence and Global Optimality beyond Lazy Learning,4.8, 5.0, 0.9797958971132712, 3, 2, 5, 5, 5, 3, 5, 3, 6, 3
Neuro-Inspired Information-Theoretic Hierarchical Perception for Multimodal Learning,5.8, 5.0, 1.16619037896906, 6, 3, 5, 3, 5, 3, 5, 3, 8, 3
The Power of Minimalism in Long Sequence Time-series Forecasting,5.0, 5.5, 1.224744871391589, 6, 5, 3, 4, 6, 4, 5, 3
Flag Aggregator: Scalable Distributed Training under Failures and Augmented Losses using Convex Optimization,5.0, 6.0, 1.4142135623730951, 3, 5, 6, 2, 6, 3
Visual Transformer with Differentiable Channel Selection: An Information Bottleneck Inspired Approach,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 5, 5, 3
Universally Amplifying Randomized Smoothing for Certified Robustness with Anisotropic Noise,3.0, 3.0, 0.0, 3, 3, 3, 4, 3, 4, 3, 3
Automatic Hallucination Assessment for Aligned Large Language Models via Transferable Adversarial Attacks,4.0, 4.0, 1.0, 3, 4, 3, 3, 5, 3, 5, 3
PowerGPT: Foundation Model for Power Systems,3.0, 3.0, 1.4142135623730951, 3, 3, 3, 4, 5, 4, 1, 4
Put on your detective hat: What’s wrong in this video?,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 4, 3, 4
FedBiF: Communication-Efficient Federated Learning via Bits Freezing,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 6, 3, 3, 4
Low-Rank Robust Graph Contrastive Learning,3.25, 3.0, 1.7853571071357126, 3, 4, 1, 5, 6, 4, 3, 4
Representation-space diffusion models for generating periodic materials,4.0, 3.0, 1.2649110640673518, 3, 5, 5, 3, 6, 2, 3, 4, 3, 4
Semi-supervised Long-tailed Recognition using Alternate Sampling,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 5, 4, 3, 4
DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 2, 6, 3, 3, 3
Federated Tuning for Black Box Large Models,4.25, 4.0, 1.299038105676658, 3, 4, 5, 5, 6, 3, 3, 4
A Geometric Analysis of Multi-label Learning under Pick-all-label Loss via Neural Collapse,4.5, 4.5, 1.5, 3, 4, 6, 2
Representation Matching Information Bottleneck for Text Matching in Asymmetrical Domains,5.0, 5.5, 1.224744871391589, 5, 2, 6, 4, 3, 4, 6, 4
G4SATBench: Benchmarking and Advancing SAT Solving with Graph Neural Networks,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 6, 4, 5, 3
Learning UI-to-Code Reverse Generator Using Visual Critic Without Rendering,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 2, 5, 3, 5, 4
Understanding Domain Generalization: A Noise Robustness Perspective,4.75, 5.0, 1.0897247358851685, 5, 5, 6, 4, 3, 3, 5, 3
Non-negative Contrastive Learning,4.5, 5.0, 0.8660254037844386, 3, 3, 5, 3, 5, 3, 5, 4
Can Differentiable Decision Trees Learn Interpretable Reward Functions?,5.0, 5.5, 1.224744871391589, 3, 4, 6, 4, 5, 3, 6, 4
Image Clustering Conditioned on Text Criteria,5.0, 5.5, 3.082207001484488, 8, 3, 8, 4, 3, 5, 1, 5
SoftPhy: Soft-Body Physical Concept  Learning  and Reasoning from Videos,4.5, 4.5, 1.5, 3, 5, 3, 4, 6, 2, 6, 4
Correlated Noise Provably Beats Independent Noise for Differentially Private Learning,4.333333333333333, 6.0, 2.357022603955158, 1, 4, 6, 2, 6, 3
Unmasking and Improving Data Credibility: A Study with Datasets for Training Harmless Language Models,5.0, 5.5, 1.224744871391589, 6, 3, 6, 3, 3, 3, 5, 3
Efficient PDE Solutions using Hartley Neural Operators in Physics-Informed Networks: Potentials and Limitations,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 5, 3, 5
XTSFormer: Cross-Temporal-Scale Transformer for Irregular Time Event Prediction,4.5, 4.5, 1.5, 6, 3, 3, 3, 3, 4, 6, 3
Regularized Optimal Transport for Temporal Trajectory Analysis in Single-Cell Data,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 3, 3, 5, 3
Federated Natural Policy Gradient Methods for Multi-task Reinforcement Learning,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 4, 3, 2, 5, 3
Understanding Expressivity of Neural KG Reasoning from Rule Structure Learning,5.75, 6.0, 1.7853571071357126, 8, 3, 6, 3, 6, 3, 3, 3
COLLIE: Systematic Construction of Constrained Text Generation Tasks,7.25, 7.0, 1.920286436967152, 6, 4, 8, 3, 5, 3, 10, 4
A Bayesian Approach for Personalized Federated Learning in Heterogeneous Settings,4.25, 4.0, 1.299038105676658, 6, 3, 3, 3, 5, 4, 3, 4
Hierarchical Graph Latent Diffusion Model for Molecule Generation,4.75, 4.0, 2.0463381929681126, 5, 3, 3, 4, 8, 4, 3, 4
Provable Representation with Efficient Planning for Partially Observable Reinforcement Learning,5.333333333333333, 5.0, 0.4714045207910317, 5, 2, 5, 3, 6, 3
Interactive Model Correction with Natural Language,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 3, 5, 4
Generative Neuro-Symbolic Visual Reasoning by Growing and Reusing Modules,5.5, 5.5, 0.5, 6, 4, 5, 4, 5, 5, 6, 3
FireAct: Toward Language Agent Finetuning,4.25, 4.0, 1.299038105676658, 3, 5, 6, 5, 3, 3, 5, 4
Vanishing Gradients in Reinforcement Finetuning of Language Models,6.0, 5.5, 1.224744871391589, 6, 3, 5, 3, 5, 3, 8, 3
Identifying and Mitigating Vulnerabilities in LLM-Integrated Applications,4.5, 4.5, 1.5, 3, 3, 3, 5, 6, 3, 6, 3
TCIG: Two-Stage Controlled Image Generation with Quality Enhancement through Diffusion,1.5, 1.0, 0.8660254037844386, 1, 5, 3, 4, 1, 5, 1, 5
Improving the efficiency of conformal predictors via test-time augmentation,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 4, 6, 4, 6, 3, 3, 5, 3, 2
Black-Box Privacy Attacks Against GANs via Detector Networks,5.5, 5.5, 1.8027756377319946, 3, 4, 5, 3, 8, 4, 6, 5
Grounding Language Plans in Demonstrations Through Counter-Factual Perturbations,5.666666666666667, 6.0, 2.0548046676563256, 6, 4, 3, 4, 8, 3
Hyper Evidential Deep Learning to Quantify Composite Classification Uncertainty,5.5, 5.5, 0.5, 6, 3, 5, 3, 6, 4, 5, 2
Goodhart's Law in Reinforcement Learning,6.25, 6.0, 1.0897247358851685, 8, 3, 6, 3, 6, 3, 5, 3
Score Regularized Policy Optimization through Diffusion Behavior,5.5, 5.5, 1.8027756377319946, 5, 3, 6, 4, 3, 3, 8, 3
Conservative Prediction via Data-Driven Confidence Minimization,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 4, 6, 2, 5, 4
3D Autoencoding Diffusion Model for Molecule Interpolation and Manipulation,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 3, 3, 5, 2
Robustifying and Boosting Training-Free Neural Architecture Search,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 4, 6, 4
Two Heads are Better than One: Towards Better Adversarial Robustness by Combining Transduction and Rejection,6.0, 6.0, 0.0, 6, 3, 6, 4, 6, 3, 6, 4
Concept Bottleneck Generative Models,4.5, 4.5, 1.5, 3, 4, 3, 3, 6, 3, 6, 3
Non-Intrusive Adaptation: Input-Centric Parameter-efficient Fine-Tuning for Versatile Multimodal Modeling,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 5, 3, 3, 4
MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction Following,5.5, 5.5, 0.5, 5, 3, 6, 2, 5, 4, 6, 4
Latent Consistency Models: Synthesizing High-Resolution Images with Few-step Inference,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 3, 5, 4, 5, 3
Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 3, 5, 4
Reconstruction of Cortical Surfaces with Spherical Topology from Infant Brain MRI via Recurrent Deformation Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 4
DLCNet: Enabling Long-Range Convolution with Data Dependency,4.0, 3.0, 1.4142135623730951, 3, 3, 6, 2, 3, 4
On Memorization in Diffusion Models,4.8, 5.0, 0.9797958971132712, 3, 4, 5, 4, 6, 3, 5, 2, 5, 4
Sparse-Guard: Sparse Coding-Based Defense against Model Inversion Attacks,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 6, 4, 3, 3
Discovering Mathematical Formulas from Data via LSTM-guided Monte Carlo Tree Search,3.75, 4.0, 1.920286436967152, 1, 4, 3, 4, 6, 5, 5, 3
Weakly Supervised Graph Contrastive Learning,4.75, 5.0, 1.0897247358851685, 5, 3, 6, 4, 3, 3, 5, 3
Lipsum-FT: Robust Fine-Tuning of Zero-Shot Models Using Random Text Guidance,5.0, 5.0, 0.0, 5, 5, 5, 2, 5, 4, 5, 4
Evade ChatGPT Detectors via A Single Space,4.0, 3.0, 1.4142135623730951, 6, 3, 3, 4, 3, 5
The Closeness of In-Context Learning and Weight Shifting for Softmax Regression,5.0, 5.0, 0.0, 5, 2, 5, 2, 5, 2
CoSDA: Continual Source-Free Domain Adaptation,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 5, 5, 5, 3, 4, 3, 4
Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies,5.5, 5.5, 1.8027756377319946, 5, 3, 8, 2, 6, 2, 3, 2
Generative Modeling of Regular and Irregular Time Series Data via Koopman VAEs,5.75, 6.0, 0.4330127018922193, 6, 5, 5, 5, 6, 4, 6, 4
Complex Logical Reasoning over Knowledge Graphs using Large Language Models,4.0, 4.0, 1.0, 3, 3, 5, 4, 5, 4, 3, 3
Generating Pragmatic Examples to Train Neural Program Synthesizers,6.0, 5.5, 1.224744871391589, 5, 2, 8, 4, 5, 3, 6, 3
Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness,7.5, 8.0, 0.8660254037844386, 8, 3, 8, 4, 8, 4, 6, 5
Fairness Feedback Loops: Training on Synthetic Data Amplifies Bias,3.0, 3.0, 0.0, 3, 2, 3, 3, 3, 3, 3, 3
Making RL with Preference-based Feedback Efficient via Randomization,5.75, 6.0, 1.7853571071357126, 6, 3, 6, 2, 3, 4, 8, 3
On the Possibilities of AI-Generated Text Detection: A Sample Complexity Analysis,4.75, 5.0, 1.0897247358851685, 6, 3, 3, 3, 5, 4, 5, 2
Reflective Policy Optimization,4.75, 4.0, 2.0463381929681126, 8, 4, 5, 4, 3, 5, 3, 2
GPT-Fathom: Benchmarking Large Language Models to Decipher the Evolutionary Path towards GPT-4 and Beyond,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 3, 3, 4
User Inference Attacks on Large Language Models,5.5, 5.5, 1.8027756377319946, 5, 4, 8, 3, 6, 2, 3, 4
CLIP as Multi-Task Multi-Kernel Learning,4.5, 4.5, 1.5, 3, 3, 6, 3
Merge Then Compress: Demystify Efficient SMoE with Hints from Its Routing Policy,5.666666666666667, 6.0, 2.0548046676563256, 8, 3, 6, 3, 3, 5
RoboGPT : An intelligent agent of making embodied long-term decisions for daily instruction tasks,3.75, 3.0, 1.299038105676658, 3, 4, 6, 4, 3, 4, 3, 4
Adaptive Regret for Bandits Made Possible: Two Queries Suffice,6.0, 6.5, 2.1213203435596424, 8, 4, 5, 5, 3, 3, 8, 3
Universal Off-Policy Selection for Human-Centric Systems via Participant Sub-grouping,4.333333333333333, 5.0, 0.9428090415820634, 3, 2, 5, 2, 5, 3
Delayed Local-SGD for Distributed Learning with Linear Speedup,4.0, 4.0, 1.0, 5, 3, 3, 3, 5, 4, 3, 5
AudoFormer: An Efficient Transformer with Consistent Auxiliary Domain for Source-free Domain Adaptation,5.0, 5.0, 0.0, 5, 2, 5, 5, 5, 4, 5, 4
Generalized Activation via Multivariate Projection,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 4, 5, 3
Conformal Prediction for Deep Classifier via Label Ranking,6.5, 6.5, 1.5, 8, 4, 5, 3, 5, 3, 8, 4
Symmetrized Schrödinger Bridge Matching,3.75, 3.0, 1.299038105676658, 6, 4, 3, 4, 3, 4, 3, 4
Towards Efficient Trace Estimation for Optimal Transport in Domain Adaptation,3.25, 3.0, 1.7853571071357126, 1, 4, 3, 4, 3, 4, 6, 4
Efficient Stagewise Pretraining via Progressive Subnetworks,5.0, 5.5, 1.224744871391589, 3, 3, 6, 4, 5, 3, 6, 3
Batch Bayesian Optimization of Delayed Effects Corrections for Thompson Sampling Bandits: A Practical Tuning Algorithm for Adaptive Interventions,2.3333333333333335, 3.0, 0.9428090415820634, 3, 4, 3, 3, 1, 4
Can AI-Generated Text be Reliably Detected?,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 3, 5, 5, 4
Negatively Correlated Ensemble Reinforcement Learning for Online Diverse Game Level Generation,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 4, 5, 3, 6, 3
Achieving Sample and Computational Efficient Reinforcement Learning by Action Space Reduction via Grouping,5.5, 5.5, 0.5, 6, 3, 6, 3, 5, 3, 5, 3
Learning Hierarchical Polynomials with Three-Layer Neural Networks,5.75, 5.0, 1.299038105676658, 5, 5, 8, 3, 5, 2, 5, 4
Exploring Adversarial Robustness of Graph Neural Networks in Directed Graphs,3.75, 3.0, 1.299038105676658, 3, 5, 3, 4, 3, 4, 6, 5
Minimizing Chebyshev Risk Magically Mitigates the Perils of Overfitting,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 6, 4, 5, 3
Deep Equilibrium Multimodal Fusion,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 5, 3, 6, 4
Demonstration Distillation for Efficient In-Context Learning,3.4, 3.0, 0.8000000000000002, 3, 4, 5, 4, 3, 4, 3, 4, 3, 5
From Stability to Chaos: Analyzing Gradient Descent Dynamics in Quadratic Regression,4.4, 5.0, 1.2, 3, 5, 3, 3, 5, 3, 6, 3, 5, 3
TaskBench: Benchmarking Large Language Models for Task Automation,5.5, 5.5, 1.8027756377319946, 3, 4, 5, 4, 6, 4, 8, 4
On Transferring Expert Knowledge from Tabular Data to Images,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 5, 5, 3, 5, 4
On Bias-Variance Alignment in Deep Models,6.75, 7.0, 1.299038105676658, 8, 4, 5, 3, 6, 3, 8, 3
Mobile Object Rearrangement with Learned Localization Uncertainty,4.0, 4.0, 1.0, 5, 3, 5, 3, 3, 4, 3, 4
Learning Grounded Action Abstractions from Language,5.2, 6.0, 1.16619037896906, 6, 4, 5, 4, 6, 4, 3, 4, 6, 3
Pre-training Sequence Structure and Surface Features for Comprehensive Protein Representation Learning,5.75, 6.0, 0.4330127018922193, 5, 5, 6, 3, 6, 2, 6, 4
On the Safety of Open-Sourced Large Language Models: Does Alignment Really Prevent Them From Being Misused?,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 5, 4, 3, 4
CityGPT: Generative Transformer for City Layout of Arbitrary Building Shape,6.0, 6.5, 2.1213203435596424, 8, 4, 5, 4, 8, 4, 3, 4
Revisiting Subsampling and Mixup for WSI Classification: A Slot-Attention-Based Approach,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 4, 3, 5
Hybrid Classification-Regression Adaptive Loss for Dense Object Detection,3.0, 3.0, 0.0, 3, 5, 3, 5, 3, 3, 3, 4
A Symmetry-Aware Learning Approach for Solving Mixed-Integer Linear Programs,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 3, 3, 3, 3, 4
Clip21: Error Feedback for Gradient Clipping,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 4, 6, 3
Dynamic Demonstrations Controller for In-Context Learning,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 6, 4, 5, 4
A unique M-pattern for micro-expreesion spotting in long videos,6.2, 6.0, 1.8330302779823362, 6, 2, 3, 3, 8, 4, 8, 3, 6, 2
GENIU: A Restricted Data Access Unlearning for Imbalanced Data,4.666666666666667, 5.0, 2.8674417556808756, 8, 4, 5, 3, 1, 3
GFLOWNET TRAINING BY POLICY GRADIENTS,4.2, 5.0, 0.9797958971132712, 3, 4, 5, 4, 5, 4, 5, 2, 3, 4
Invariant Attention: Provable Clustering Under Transformations,4.25, 4.0, 1.299038105676658, 6, 3, 3, 3, 3, 4, 5, 3
MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts,6.75, 7.0, 1.299038105676658, 8, 4, 8, 4, 6, 3, 5, 4
Enhanced Visual Instruction Tuning for Text-Rich Image Understanding,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 5, 4, 6, 4
BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian Inference,5.0, 5.5, 1.224744871391589, 6, 3, 5, 2, 6, 4, 3, 3
In-context Convergence of Transformers,5.0, 5.5, 1.224744871391589, 6, 2, 3, 3, 5, 3, 6, 4
Towards Fair Graph Anomaly Detection: Problem New Datasets and Evaluation,5.5, 5.5, 1.8027756377319946, 8, 4, 6, 3, 5, 3, 3, 1
What and How does In-Context Learning Learn? Bayesian Model Averaging Parameterization and Generalization,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 3, 3, 6, 2
$\mathbb{D}^2$ Pruning: Message Passing for Balancing Diversity & Difficulty in Data Pruning,4.8, 5.0, 0.9797958971132712, 6, 4, 5, 3, 5, 5, 3, 4, 5, 5
Provable Benefit of Adaptivity in Adam,4.75, 4.0, 2.0463381929681126, 3, 4, 8, 4, 5, 4, 3, 5
Online Continual Learning via Pursuing Class-conditional Funtion,4.0, 4.0, 1.0, 5, 4, 3, 4, 5, 4, 3, 4
GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge Graphs,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 4
FedBiOT: a solution for federated large language model fine-tuning with intellectual property protection,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 4, 6, 1, 3, 5
The Human-AI Substitution game: active learning from a strategic labeler,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 3, 6, 3, 6, 3
The Discovery of Binding Modes Requires Rethinking Docking Generalization,5.8, 5.0, 1.16619037896906, 6, 2, 5, 4, 5, 5, 8, 3, 5, 4
Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding,5.333333333333333, 6.0, 1.1055415967851332, 6, 4, 6, 3, 6, 3, 6, 4, 5, 4, 3, 4
Connect Later: Improving Fine-Tuning for Robustness with Targeted Augmentations,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 4
Value Bonuses using Ensemble Errors for Exploration in Reinforcement Learning,4.75, 4.0, 2.0463381929681126, 3, 4, 8, 3, 3, 4, 5, 3
The Impact of Depth and Width on Transformer Language Model Generalization,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 2, 3, 4, 6, 3
Language Model Beats Diffusion - Tokenizer is key to visual generation,8.0, 8.0, 0.0, 8, 4, 8, 4, 8, 3
Improving Generalization in Equivariant Graph Neural Networks with Physical Inductive Biases,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 8, 3, 5, 4
A Sublinear Adversarial Training Algorithm,5.75, 6.0, 1.7853571071357126, 3, 3, 6, 3, 6, 3, 8, 3
Proper Laplacian Representation Learning,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 3, 6, 1, 6, 3
Bi-Directional Goal-Conditioning on Single Policy Function for State Space Search,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 3, 3, 4
Graph Convolutions Enrich the Self-Attention in Transformers!,5.5, 4.5, 2.8722813232690143, 3, 4, 6, 5, 3, 4, 10, 4
Fantastic DNN-Classifier Identification without Testing Dataset,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 4, 3, 4
Spectrally Transformed Kernel Regression,6.8, 6.0, 0.9797958971132712, 6, 4, 6, 3, 8, 2, 6, 3, 8, 3
Maintaining Plasticity in Continual Learning via Regenerative Regularization,nan, nan, nan
Efficient OCR for Building a Diverse Digital History,3.25, 3.0, 1.7853571071357126, 3, 4, 6, 5, 3, 4, 1, 5
Continual Traffic Forecasting via Mixture of Experts,4.0, 4.0, 1.0, 5, 3, 3, 4
LQ-LoRA: Low-rank plus Quantized Matrix Decomposition for Efficient Language Model Finetuning,6.5, 6.5, 1.5, 5, 4, 5, 4, 8, 4, 8, 4
Periodic Set Transformer: Material Property Prediction from Continuous Isometry Invariants,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 3, 5, 6, 3
Online Learning in Varying Feature Spaces with Informative Variation,3.0, 3.0, 0.0, 3, 3, 3, 4, 3, 3
RT-Sketch: Goal-Conditioned Imitation Learning from Hand-Drawn Sketches,5.5, 5.5, 1.8027756377319946, 5, 4, 3, 3, 6, 4, 8, 4
Deep Temporal Graph Clustering,7.0, 8.0, 1.4142135623730951, 8, 4, 5, 4, 8, 5
V-Former: Offline RL with Temporally-Extended Actions,3.75, 3.0, 1.299038105676658, 3, 4, 6, 3, 3, 4, 3, 4
Enhancing Clinical Note Summarization: Iterative Reflexions with Small-model Supervision and Error2Correct Demonstrations,4.25, 3.0, 2.165063509461097, 3, 3, 8, 5, 3, 4, 3, 5
Compositional VLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 4, 5, 4
SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 5, 5, 4
GRADSIMCORE: GRADIENT SIMILARITY BASED REPRESENTATIVE INSTANCES AS CORESET,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 5, 1, 2
Attacking for Inspection and Instruction: Debiasing Self-explaining Text Classification,5.0, 5.0, 1.0954451150103321, 6, 3, 5, 3, 6, 3, 5, 3, 3, 3
Treatment Effects Estimation By Uniform Transformer,6.0, 6.0, 0.0, 6, 4, 6, 4
Demystifying Linear MDPs and Novel Dynamics Aggregation Framework,5.2, 6.0, 1.16619037896906, 6, 4, 5, 3, 6, 2, 3, 3, 6, 3
One Training Fits All: Addressing Model-Heterogeneity Federated Learning via Architecture Probing,4.0, 4.0, 1.0, 3, 5, 5, 4, 5, 4, 3, 3
PostRainBench: A Comprehensive Benchmark and A New Model for Precipitation Forecasting,4.25, 4.0, 1.299038105676658, 3, 5, 6, 4, 3, 4, 5, 5
DISTA: DENOISING SPIKING TRANSFORMER WITH INTRINSIC PLASTICITY AND SPATIOTEMPORAL ATTENTION,4.5, 4.5, 1.5, 3, 5, 3, 4, 6, 4, 6, 4
POPULATION DESCENT: A NATURAL-SELECTION BASED HYPER-PARAMETER TUNING FRAMEWORK,3.5, 3.0, 0.8660254037844386, 3, 2, 3, 4, 5, 5, 3, 4
Towards Aligned Layout Generation via Diffusion Model with Aesthetic Constraints,6.25, 6.0, 1.0897247358851685, 6, 4, 5, 4, 8, 3, 6, 3
A Unified Framework of Theoretically Robust Contrastive Loss against Label Noise,4.4, 5.0, 1.2, 6, 3, 5, 4, 5, 3, 3, 4, 3, 4
Implicit Neural Network on Dynamic Graphs,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 4, 6, 3, 3, 4
LLM-Prop: Predicting Physical And Electronic Properties of Crystalline Solids From Their Text Descriptions,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 3, 3, 3
Unleashing the Potential of Regularization Strategies in Learning with Noisy Labels,3.75, 3.0, 1.299038105676658, 6, 5, 3, 4, 3, 4, 3, 3
Spiking Mixers for Robust and Energy-efficient Vision-and-Language Learning,nan, nan, nan
Multi-agent Optimistic Soft Q-Learning: A co-MARL Algorithm with a Global Convergence Guarantee,4.25, 4.0, 1.299038105676658, 3, 4, 3, 4, 5, 3, 6, 4
AutoDAN: Automatic and Interpretable Adversarial Attacks on Large Language Models,5.75, 5.0, 2.5860201081971503, 5, 4, 10, 4, 5, 4, 3, 5
Efficient Parameter Tuning of Large Protein Language Models for De Novo Protein Design,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 4, 3, 4
Learning-Retrieval-Revision For Large Language Model Domain Adaptation,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 3, 5, 4, 6, 4
Non-asymptotic Analysis of Stochastic Gradient Descent under Local Differential Privacy Guarantee,3.75, 3.0, 1.299038105676658, 6, 3, 3, 5, 3, 4, 3, 3
Adaptive Continual Learning: Rapid Adaptation and Knowledge Refinement,4.25, 4.0, 1.299038105676658, 3, 4, 6, 3, 3, 3, 5, 2
DREAM: Dual Structured Exploration with Mixup for Open-set Graph Domain Adaption,5.6, 6.0, 1.624807680927192, 6, 5, 5, 3, 3, 4, 6, 4, 8, 4
SpecFormer: Guarding Vision Transformer Robustness via Maximum Singular Value Penalization,5.333333333333333, 5.0, 2.0548046676563256, 8, 5, 3, 5, 5, 5
Making Batch Normalization Great in Federated Deep Learning,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 3, 5, 6, 4
Communication-Efficient Federated Non-Linear Bandit Optimization,5.75, 6.0, 0.4330127018922193, 5, 3, 6, 4, 6, 2, 6, 3
DISTPAR:TENSOR PARTITIONING FOR DISTRIBUTED NEURAL NETWORK COMPUTING,1.6666666666666667, 1.0, 0.9428090415820634, 1, 4, 3, 4, 1, 5
PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization,7.0, 8.0, 1.4142135623730951, 5, 4, 8, 3, 8, 3
Online GNN Evaluation Under Test-time Graph Distribution Shifts,7.5, 8.0, 0.8660254037844386, 6, 4, 8, 4, 8, 4, 8, 4
Escaping Saddle Point Efficiently in Minimax and Bilevel Optimizations,5.5, 5.5, 0.5, 6, 3, 5, 3
Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in Open Worlds,5.5, 5.5, 0.5, 6, 3, 5, 3, 5, 4, 6, 4
DAG-Based Column Generation for Adversarial Team Games,6.25, 6.0, 1.0897247358851685, 6, 5, 8, 4, 6, 4, 5, 2
Accurate Link Prediction via PU Learning,6.25, 6.0, 1.0897247358851685, 5, 4, 6, 3, 8, 3, 6, 4
Tackling the Data Heterogeneity in Asynchronous Federated Learning with Cached Update Calibration,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 5, 4, 6, 5
Lightweight Unsupervised Federated Learning with Pretrained Vision Language Model,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 4, 3, 3
An Axiomatic Approach to Model-Agnostic Concept Explanations,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 4, 3, 3
Sample-Efficient Training for Score-Based Diffusion,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 4, 5, 3
Debias your VLM with Counterfactuals: A Unified Approach,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 4, 5, 3
Bias A-head? Analyzing Bias in Transformer-Based Language Model Attention Heads,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 6, 4, 5, 4
Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks,6.75, 6.0, 1.920286436967152, 10, 5, 6, 3, 5, 4, 6, 4
(InThe)WildChat: 570K ChatGPT Interaction Logs In The Wild,6.25, 6.0, 1.0897247358851685, 5, 3, 6, 4, 6, 4, 8, 4
Aligning Brains into a Shared Space Improves Their Alignment to Large Language Model,4.333333333333333, 5.0, 0.9428090415820634, 5, 1, 5, 3, 3, 4
Learning Hierarchical Image Segmentation For Recognition and By Recognition,7.5, 7.0, 1.6583123951777, 8, 4, 6, 4, 10, 4, 6, 3
Distribution Calibration For Few-Shot Learning by Bayesian Relation Inference,4.0, 4.0, 1.0, 3, 2, 5, 4
Waxing-and-Waning: a Generic Similarity-based Framework for Efficient Self-Supervised Learning,4.75, 5.0, 1.0897247358851685, 5, 5, 5, 4, 3, 4, 6, 3
Improved Algorithms for Adversarial Multi-armed Bandit with Unbounded Losses,nan, nan, nan
Extracting Post-Treatment Covariates for Heterogeneous Treatment Effect Estimation,5.0, 5.5, 1.224744871391589, 5, 4, 6, 4, 3, 3, 6, 4
Fast Post-training Analysis of NeRFs Using A Simple Visibility Prediction Network,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 3, 6, 3, 5, 5
On Socially Fair Regression and Low-Rank Approximation,4.5, 4.5, 1.5, 6, 3, 3, 2, 6, 2, 3, 4
Amphibian: A Meta-Learner for Rehearsal-Free Fast Online Continual Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 4, 3, 3
Learning the Unseen: Peer-to-Peer Fine-tuning of Vision Transformers,3.75, 3.0, 1.299038105676658, 3, 4, 3, 2, 3, 4, 6, 4
Counterfactual Fairness With the Human in the Loop,4.25, 4.0, 1.299038105676658, 6, 4, 3, 4, 3, 4, 5, 5
Can Language Models be Instructed to Protect Personal Information?,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 4, 5, 4, 6, 4
MATT: Random Local Implicit Purification for Defending Query-based Attacks,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 3, 5, 4, 5, 4
WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 3, 5, 5, 5, 4
Text Descriptions are Compressive and Invariant Representations for Visual Learning,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 4, 3, 3, 5, 4
DASFormer: Self-supervised Pretraining for Earthquake Monitoring,5.5, 5.5, 0.5, 6, 3, 6, 4, 5, 3, 5, 5
Topology-aware Embedding Memory for Learning on Expanding Graphs,5.4, 6.0, 1.2, 6, 4, 6, 2, 3, 3, 6, 2, 6, 3
Active Prompting with Chain-of-Thought for Large Language Models,3.75, 4.0, 1.920286436967152, 6, 4, 5, 4, 1, 5, 3, 4
LLMs Meet VLMs: Boost Open Vocabulary Object Detection with Fine-grained Descriptors,5.8, 6.0, 0.39999999999999997, 6, 4, 6, 4, 5, 5, 6, 4, 6, 4
Vision-Language Models Provide Promptable Representations for Reinforcement Learning,5.0, 5.0, 0.0, 5, 5, 5, 4, 5, 4, 5, 4
Adversarial Machine Unlearning: A Stackelberg Game Approach,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 4, 6, 4
LMCC-MBC: Metric-Constrained Model-Based Clustering with Wasserstein-2 Distance of Gaussian Markov Random Fields,4.666666666666667, 5.0, 1.247219128924647, 6, 5, 5, 3, 3, 2
InsightMapper: A closer look at inner-instance information for vectorized High-Definition Mapping,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 5, 5, 4, 5, 3
Optimizing Layerwise Polynomial Approximation for Efficient Private Inference on Fully Homomorphically Encryption: A Dynamic Programming Approach,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 3, 4, 5, 4
Language Reward Modulation for Pretraining Reinforcement Learning,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 6, 3, 5, 3
CLIP-MUSED: CLIP-Guided Multi-Subject Visual Neural Information Semantic,6.0, 5.0, 1.4142135623730951, 5, 4, 5, 3, 8, 3
Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models,5.5, 5.5, 1.8027756377319946, 8, 4, 6, 4, 5, 3, 3, 3
URLOST: Unsupervised Representation Learning without Stationarity or Topology,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 1, 6, 4
Protein Discovery with Discrete Walk-Jump Sampling,7.333333333333333, 8.0, 0.9428090415820634, 8, 4, 6, 3, 8, 4
PatchMixer: A Patch-Mixing Architecture for Long-Term Time Series Forecasting,4.75, 4.0, 2.0463381929681126, 3, 5, 3, 4, 8, 3, 5, 4
Enhanced Bayesian Optimization via Preferential Modeling of Abstract Properties,3.0, 3.0, 1.4142135623730951, 5, 4, 1, 4, 3, 4, 3, 3
LogicBench: Towards Systematic Evaluation of Logical Reasoning Ability of Large Language Models,5.4, 5.0, 0.48989794855663565, 6, 5, 5, 2, 5, 2, 6, 5, 5, 4
AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 4, 5, 5, 5, 4
Inducing Precision in Lagrangian Neural Networks : Proof of concept application on Chaotic systems,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 4, 3, 3
X-SHOT: A Single System to Handle Frequent Few-shot and Zero-shot Labels in Classification,4.75, 5.0, 1.0897247358851685, 5, 3, 6, 3, 5, 4, 3, 3
DreamFlow: High-quality text-to-3D generation by Approximating Probability Flow,5.0, 5.5, 1.224744871391589, 3, 4, 6, 3, 6, 4, 5, 4
ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis,7.0, 7.0, 1.0, 6, 4, 8, 3, 8, 3, 6, 4
Theoretically Understanding Data Reconstruction Leakage in Federated Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 4
Consistency Models as a Rich and Efficient Policy Class for Reinforcement Learning,5.0, 6.0, 1.4142135623730951, 3, 4, 6, 3, 6, 3
Learning A Disentangling Representation For PU Learning,3.75, 3.0, 1.299038105676658, 3, 4, 3, 3, 3, 5, 6, 3
Towards Greener and Sustainable Airside Operations: A Deep Reinforcement Learning Approach to Pushback Rate Control for Mixed-Mode Runways,4.0, 4.0, 1.0, 3, 3, 3, 4, 5, 4, 5, 2
Grounding Code Generation with Input-Output Specifications,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 5, 5, 4, 5, 4
Contrastive Preference Learning: Learning from Human Feedback without Reinforcement Learning,6.25, 7.0, 2.0463381929681126, 3, 3, 8, 4, 8, 2, 6, 4
Accurate Differential Operators for Neural Fields,4.75, 4.0, 2.0463381929681126, 3, 4, 8, 4, 5, 4, 3, 4
Revisiting Familiar Places in an Infinite World: Continuing RL in Unbounded State Spaces,4.25, 4.0, 1.299038105676658, 3, 3, 5, 3, 3, 4, 6, 4
Interpreting Age Predictions from Brain Maps via Deep Neural Activations and Tensor Decomposition,1.6666666666666667, 1.0, 0.9428090415820634, 3, 4, 1, 4, 1, 2
Neural Network-Based Score Estimation in Diffusion Models: Optimization and Generalization,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 2, 6, 3, 5, 4
Hybrid Reinforcement Learning for Optimizing Pump Sustainability in Real-World Water Distribution Networks,2.5, 3.0, 0.8660254037844386, 1, 3, 3, 2, 3, 5, 3, 4
scHyena: Foundation Model for Full-Length Single-Cell RNA-Seq Analysis in Brain,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 4, 3, 3, 3, 5
Interpretability Illusions in the Generalization of Simplified Models,4.6, 5.0, 1.3564659966250536, 3, 3, 6, 4, 3, 2, 6, 4, 5, 2
Pipeline Parallelism Optimization with Deep Reinforcement Learning,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 3, 5, 5, 3
Batched Low-Rank Adaptation of Foundation Models,7.5, 8.0, 0.8660254037844386, 8, 4, 6, 3, 8, 2, 8, 4
ToolTalk: Evaluating Tool Usage in a Conversational Setting,3.75, 3.0, 1.299038105676658, 3, 4, 6, 4, 3, 3, 3, 3
Investigating the effective dimensionality of a model using a thermodynamic learning capacity,3.75, 3.0, 1.299038105676658, 3, 3, 3, 3, 3, 3, 6, 4
HyperFields: Towards Zero-Shot Generation of NeRFs from Text,4.75, 4.0, 2.0463381929681126, 3, 4, 5, 4, 8, 4, 3, 4
Adapt On-the-Go: Behavior Modulation for Single-Life Robot Deployment,5.666666666666667, 6.0, 2.0548046676563256, 3, 3, 6, 3, 8, 5
An Invex Relaxation Approach for Minimizing Polarization from Fully and Partially Observed Initial Opinions,4.0, 3.0, 2.943920288775949, 3, 2, 8, 3, 1, 5
The Power of the Senses: Generalizable Manipulation from Vision and Touch through Masked Multimodal Learning,4.333333333333333, 5.0, 0.9428090415820634, 3, 3, 5, 4, 5, 4
PromptFix: Few-shot Backdoor Removal via Adversarial Prompt Tuning,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 3
Evaluating Adversarial Defense in the Era of Large Language Models,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4, 3, 3
Deep Generalized Prediction Set Classifier and Its Theoretical Guarantees,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 3
Outlier-Robust Orthogonal Regression on Manifolds,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 3, 5, 3
Time-Varying Propensity Score to Bridge the Gap between the Past and Present,5.0, 5.5, 1.224744871391589, 5, 2, 3, 4, 6, 2, 6, 4
Does resistance to style-transfer equal Shape Bias? Evaluating shape bias by distorted shape,5.25, 6.0, 1.299038105676658, 6, 4, 6, 4, 3, 4, 6, 4
Stack Attention: Improving the Ability of Transformers to Model Hierarchical Patterns,6.333333333333333, 6.0, 1.247219128924647, 8, 5, 6, 4, 5, 4
Discovering Divergences between Language Models and Human Brains,3.75, 3.0, 1.299038105676658, 3, 4, 3, 3, 3, 5, 6, 1
Soft Merging of Experts with Adaptive Routing,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 3, 6, 5
Debiasing Attention Mechanism in Transformer without Demographics,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 3, 5, 4, 5, 4
Operator Learning Meets Numerical Analysis: Improving Neural Networks through Iterative Methods,2.6, 3.0, 0.8, 3, 5, 3, 3, 3, 4, 3, 3, 1, 4
RA-DIT: Retrieval-Augmented Dual Instruction Tuning,5.75, 6.0, 1.7853571071357126, 3, 3, 6, 3, 6, 4, 8, 4
Differentially Private Bias-Term Fine-tuning of Foundation Models,5.4, 5.0, 1.624807680927192, 5, 3, 6, 3, 5, 4, 3, 4, 8, 3
Variational Language Concepts for Interpreting Pretrained Language Models,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 5, 3, 3, 4
SuperFormer: Superpixel-based Transformers for Salient Object Detection,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 4
Improving Gradient-guided Nested Sampling for Posterior Inference,5.166666666666667, 5.5, 1.7716909687891083, 6, 3, 8, 2, 5, 2, 3, 3, 3, 3, 6, 3
Structured Fine-Tuning Enables Data-Efficient Adaptation of Code Language Models,4.8, 5.0, 1.8330302779823362, 5, 4, 8, 4, 3, 5, 5, 4, 3, 5
SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents,5.666666666666667, 6.0, 2.0548046676563256, 8, 4, 6, 4, 3, 5
Like Oil and Water: Group Robustness Methods and Poisoning Defenses Don't Mix,5.5, 5.5, 0.5, 6, 3, 5, 4, 6, 3, 5, 4
Self-Specialization: Uncovering Latent Expertise within Large Language Models,5.25, 5.0, 1.7853571071357126, 5, 5, 3, 3, 8, 3, 5, 4
Improved Active Learning via Dependent Leverage Score Sampling,6.8, 6.0, 0.9797958971132712, 8, 4, 8, 4, 6, 3, 6, 4, 6, 2
Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection,4.0, 4.0, 1.0, 3, 4, 5, 4, 5, 3, 3, 4
Visual Data-Type Understanding does not emerge from scaling Vision-Language Models,7.0, 8.0, 1.4142135623730951, 5, 3, 8, 3, 8, 4
Revisiting differentially private XGBoost: are random decision trees really better than greedy ones?,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 2, 3, 4, 3, 3
Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs,6.833333333333333, 7.0, 1.2133516482134197, 5, 3, 6, 3, 8, 3, 6, 4, 8, 5, 8, 4
Memory Efficient Neural Processes via Constant Memory Attention Block,5.0, 4.5, 2.1213203435596424, 3, 4, 6, 3, 3, 3, 8, 4
FAIR-Ensemble: Homogeneous Deep Ensembling Naturally Attenuates Disparate Group Performances,3.75, 3.0, 1.299038105676658, 6, 4, 3, 4, 3, 3, 3, 3
GEOFFair: a GEOmetric Framework for Fairness,3.0, 3.0, 1.632993161855452, 1, 4, 5, 3, 3, 3
EFFICIENT QUANTUM STATE RECONSTRUCTION USING UNSUPERVISED LEARNING FOR QUANTUM CIRCUIT CUTTING,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 5, 3
DIVERSITY OF THOUGHT IMPROVES REASONING ABILITIES OF LARGE LANGUAGE MODELS,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4
CoT3DRef: Chain-of-Thoughts Data-Efficient 3D Visual Grounding,6.0, 6.0, 0.0, 6, 3, 6, 5, 6, 4, 6, 4
Re-evaluating Retrosynthesis Algorithms with Syntheseus,5.5, 5.5, 1.8027756377319946, 8, 4, 3, 4, 6, 3, 5, 4
An Efficient Tester-Learner for Halfspaces,6.25, 6.0, 1.0897247358851685, 6, 3, 5, 4, 8, 3, 6, 3
Reclaiming the Source of Programmatic Policies: Programmatic versus Latent Spaces,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4
Can Large Language Models be Good Path Planners? A Benchmark and Investigation on Spatial-Temporal Reasoning,4.0, 4.0, 1.0, 5, 3, 5, 3, 3, 3, 3, 3
Is Pre-training Truly Better Than Meta-Learning?,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 2, 3, 3, 5, 3
Deep Learning-based Discrimination of Pause Episodes in Insertable Cardiac Monitors,1.0, 1.0, 0.0, 1, 5, 1, 5, 1, 5
Fast and Reliable Generation of EHR Time Series via Diffusion Models,4.25, 4.0, 1.299038105676658, 3, 4, 6, 5, 5, 5, 3, 5
Harmonic Prior Flow Matching for Multi-Ligand Docking and Binding Site Design,5.0, 5.0, 1.0954451150103321, 6, 4, 5, 5, 6, 4, 3, 5, 5, 3
Beyond Scale: the Diversity Coefficient as a Data Quality Metric Demonstrates LLMs are Pre-trained on Formally Diverse Data,4.0, 4.5, 2.1213203435596424, 6, 4, 1, 4, 6, 2, 3, 4
JoinGym: An Efficient Query Optimization Environment for Reinforcement Learning,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 5, 2, 3, 5
Learning Conditional Policy for Crystal Design using Offline Reinforcement Learning,4.5, 4.5, 1.5, 6, 2, 6, 2, 3, 5, 3, 4
Privileged Sensing Scaffolds Reinforcement Learning,7.75, 8.0, 1.7853571071357126, 10, 4, 8, 3, 8, 3, 5, 2
Remote Sensing Vision-Language Foundation Models without Annotations via Ground Remote Alignment,6.75, 7.0, 1.299038105676658, 6, 2, 5, 4, 8, 5, 8, 4
LumiNet: The Bright Side of Perceptual Knowledge Distillation,5.0, 5.0, 0.0, 5, 3, 5, 5, 5, 3, 5, 5
DEBOSH: Deep Bayesian Shape Optimization,4.0, 4.0, 1.0, 5, 3, 3, 4, 3, 4, 5, 4
The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 3, 3, 4, 6, 3
Dynamical versus Bayesian Phase Transitions in a Toy Model of Superposition,5.5, 5.5, 1.8027756377319946, 3, 3, 5, 2, 6, 3, 8, 2
On the Fairness ROAD: Robust Optimization for Adversarial Debiasing,6.25, 6.0, 1.0897247358851685, 5, 5, 8, 4, 6, 3, 6, 4
Monsters in the Dark: Sanitizing Hidden Threats with Diffusion Models,5.5, 5.5, 1.8027756377319946, 6, 3, 5, 5, 3, 5, 8, 5
MaSS: Multi-attribute Selective Suppression for Utility-preserving Data Transformation from an Information-theoretic Perspective,5.25, 6.0, 1.299038105676658, 6, 4, 6, 3, 6, 3, 3, 5
One-shot Empirical Privacy Estimation for Federated Learning,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 3, 6, 3
Learning Planning Abstractions from Language,4.75, 4.0, 2.0463381929681126, 5, 4, 8, 3, 3, 3, 3, 3
Towards Neural Architecture Search through Hierarchical Generative Modeling,4.75, 5.0, 1.0897247358851685, 6, 4, 3, 4, 5, 4, 5, 4
Learning to Act without Actions,6.0, 5.5, 1.224744871391589, 5, 4, 5, 4, 8, 3, 6, 4
Sweeping Heterogeneity with Smart MoPs: Mixture of Prompts for LLM Task Adaptation,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 4, 5, 3
Conditional Diffusion Distillation,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 5, 3, 3, 4
FT-SHIELD: A Watermark Against Unauthorized Fine-tuning in Text-to-Image Diffusion Models,3.75, 3.0, 1.299038105676658, 3, 4, 6, 3, 3, 5, 3, 4
Tailoring Self-Rationalizers with Multi-Reward Distillation,6.0, 6.0, 1.0954451150103321, 6, 4, 5, 4, 8, 3, 6, 3, 5, 3
Building Cooperative Embodied Agents Modularly with Large Language Models,6.25, 6.0, 1.0897247358851685, 6, 3, 6, 3, 5, 4, 8, 4
Fast Hyperboloid Decision Tree Algorithms,6.6, 6.0, 1.2, 5, 4, 6, 3, 8, 4, 6, 2, 8, 3
Private Zeroth-Order Nonsmooth Nonconvex Optimization,5.75, 6.0, 1.7853571071357126, 8, 4, 3, 4, 6, 3, 6, 4
Approximate Clustering for Extracting Task Relationships in Multi-Instruction Tuning,4.0, 3.0, 1.4142135623730951, 6, 3, 3, 3, 3, 5
GeRA: Label-Efficient Geometrically Regularized Alignment,5.25, 5.0, 0.4330127018922193, 6, 5, 5, 4, 5, 2, 5, 4
OptiMUS: Optimization Modeling Using mip Solvers and large language models,4.0, 4.0, 1.0, 3, 4, 3, 3, 5, 3, 5, 3
Stochastic Unrolled Federated Learning,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 2, 5, 4
Efficient VideoMAE via Temporal Progressive  Training,4.25, 4.0, 1.299038105676658, 3, 4, 5, 5, 3, 4, 6, 4
Who Leaked the Model? Tracking IP Infringers in Accountable Federated Learning,5.333333333333333, 5.0, 2.0548046676563256, 8, 3, 3, 3, 5, 5
Exact Path Kernels Naturally Decompose Model Predictions,4.333333333333333, 5.0, 0.9428090415820634, 5, 2, 5, 3, 3, 2
SCALE: Scaling up the Complexity for Advanced Language Model Evaluation,4.25, 4.0, 1.299038105676658, 3, 3, 3, 4, 5, 4, 6, 4
Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training,7.5, 8.0, 0.8660254037844386, 8, 4, 8, 3, 6, 4, 8, 3
De Novo Drug Design with Joint Transformers,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 5, 4, 3, 4
Conversational Drug Editing Using Retrieval and Domain Feedback,5.333333333333333, 5.0, 0.4714045207910317, 5, 2, 6, 3, 5, 4
Poly-View Contrastive Learning,6.25, 6.0, 1.0897247358851685, 6, 2, 5, 4, 6, 3, 8, 4
Contextual Biasing with the Knuth-Morris-Pratt Matching Algorithm,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 5, 5, 4
A Probabilistic Framework for Modular Continual Learning,6.5, 6.0, 0.8660254037844386, 6, 4, 6, 3, 8, 4, 6, 4
Boundary Denoising for Video Activity Localization,5.25, 5.0, 1.7853571071357126, 3, 3, 8, 4, 5, 5, 5, 5
Few-Shot Detection of Machine-Generated Text using Style Representations,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 3, 5, 6, 4
Safe and Robust Watermark Injection with a Single OoD Image,5.75, 6.0, 1.7853571071357126, 6, 4, 8, 4, 3, 4, 6, 2
Massive Editing for Large Language Model via Meta Learning,6.75, 6.0, 1.920286436967152, 6, 3, 6, 4, 10, 4, 5, 4
Real-time learning of decay trajectory of Higgs boson using reservoir-in-reservoir architecture,3.5, 4.0, 1.6583123951777, 1, 4, 5, 2, 3, 3, 5, 4
BrainLM: A foundation model for brain activity recordings,5.25, 6.0, 1.299038105676658, 6, 3, 6, 5, 3, 4, 6, 4
On Sarcasm Detection with OpenAI GPT-based Models,3.5, 4.0, 1.6583123951777, 1, 5, 5, 4, 3, 2, 5, 4
SWE-bench: Can Language Models Resolve Real-world Github Issues?,6.25, 6.0, 1.0897247358851685, 5, 3, 6, 4, 8, 4, 6, 2
A simple connection from loss flatness to compressed representations in neural networks,5.0, 4.5, 2.1213203435596424, 3, 4, 8, 3, 6, 5, 3, 4
Always-Sparse Training with Guided Stochastic Exploration,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 5
Data Distillation Can Be Like Vodka: Distilling More Times For Better Quality,5.333333333333333, 5.0, 2.0548046676563256, 8, 3, 3, 4, 5, 5
Object centric architectures enable efficient causal representation learning,6.333333333333333, 6.0, 1.247219128924647, 8, 5, 5, 3, 6, 3
Adaptivity and Modularity for Efficient Generalization Over Task Complexity,5.75, 5.0, 1.299038105676658, 5, 2, 5, 3, 5, 2, 8, 4
($\texttt{PEEP}$) $\textbf{P}$redicting $\textbf{E}$nzym$\textbf{e}$ $\textbf{P}$romiscuity with its Molecule Mate – an Attentive Metric Learning Solution,5.4, 5.0, 0.4898979485566356, 5, 2, 6, 3, 5, 4, 5, 4, 6, 3
Efficient Score Matching with Deep Equilibrium Layers,5.25, 6.0, 1.299038105676658, 3, 4, 6, 4, 6, 4, 6, 3
Improving Prototypical Part Networks with Reward Reweighing Reselection and Retraining,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 3, 5, 4, 5, 4
A Data Perspective on Enhanced Identity Preservation for Diffusion Personalization,4.5, 4.5, 1.5, 6, 3, 6, 4, 3, 3, 3, 4
Error Norm Truncation: Robust Training in the Presence of Data Noise for Text Generation Models,5.5, 5.5, 0.5, 5, 4, 6, 4
Novel Domain Extrapolation with Large Language Models,2.5, 3.0, 0.8660254037844386, 3, 5, 3, 5, 3, 4, 1, 4
Alt-Text with Context: Improving Accessibility for Images on Twitter,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 3, 6, 3
Taming AI Bots: Controllability of Neural States in Large Language Models,4.0, 5.0, 1.7320508075688772, 5, 2, 1, 4, 5, 4, 5, 3
Defining Expertise: Applications to Treatment Effect Estimation,6.5, 6.5, 1.5, 8, 4, 8, 3, 5, 2, 5, 2
VibeSpace: Automatic vector embedding creation for arbitrary domains and mapping between them using large language models,3.0, 3.0, 1.4142135623730951, 1, 5, 5, 4, 3, 4, 3, 4
Depth-Guided Self-Supervised Learning: Seeing the World in 3D,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 4
AMPNet: Attention as Message Passing for Graph Neural Networks,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 5, 4, 3, 4
Alleviating Exposure Bias in Diffusion Models through Sampling with Shifted Time Steps,5.75, 6.0, 0.4330127018922193, 5, 4, 6, 4, 6, 4, 6, 4
End-Effector-Elbow: A New Action Space for Robot Learning,5.333333333333333, 5.0, 2.0548046676563256, 5, 4, 3, 5, 8, 4
Rethinking the Benefits of Steerable Features in 3D Equivariant Graph Neural Networks,5.25, 5.0, 1.7853571071357126, 3, 3, 5, 3, 5, 5, 8, 3
Recurrent Linear Transformers,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 4, 5, 4, 6, 3
Time Series Modeling at Scale: A Universal Representation Across Tasks and Domains,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 5
Loco3D: Indoor Multiuser Locomotion 3D Dataset,4.5, 5.0, 0.8660254037844386, 5, 5, 5, 3, 3, 3, 5, 2
EXPLORING BATTERY USAGE IN ELECTRIC VEHICLES THROUGH GRAPH BASED CASCADED CLUSTERING,3.0, 3.0, 1.632993161855452, 3, 3, 1, 5, 5, 4
Massively Scalable Inverse Reinforcement Learning for Route Optimization,6.5, 6.5, 2.692582403567252, 5, 3, 3, 4, 8, 3, 10, 4
RECURSIVE NEURAL ORDINARY DIFFERENTIAL EQUATIONS FOR PARTIALLY OBSERVED SYSTEM,5.0, 6.0, 1.4142135623730951, 3, 3, 6, 3, 6, 4
Neural SDF Flow for 3D Reconstruction of Dynamic Scenes,6.0, 5.5, 1.224744871391589, 5, 5, 8, 4, 6, 4, 5, 4
Class Probability Matching with Calibrated Networks for Label Shift Adaption,6.75, 7.0, 1.299038105676658, 6, 3, 8, 5, 8, 3, 5, 4
DIFFTACTILE: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation,6.0, 5.5, 1.224744871391589, 8, 3, 5, 3, 6, 1, 5, 3
MAMS: MODEL-AGNOSTIC MODULE SELECTION FRAMEWORK FOR VIDEO CAPTIONING,nan, nan, nan
Tangent Transformers for CompositionPrivacy and Removal,6.0, 6.0, 0.0, 6, 2, 6, 4, 6, 4
Bayes Conditional Distribution Estimation for Knowledge Distillation Based on Conditional Mutual Information,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 3, 5, 3
Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting,6.333333333333333, 6.0, 1.247219128924647, 5, 2, 8, 4, 6, 3
AUTOMATIC NEURAL SPATIAL INTEGRATION,4.0, 4.0, 1.0, 5, 3, 3, 4, 3, 3, 5, 4
Universal Guidance for Diffusion Models,5.0, 5.5, 1.224744871391589, 5, 4, 3, 4, 6, 3, 6, 3
ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 3, 6, 4
Counterfactual Generative Models for Time-Varying Treatments,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 4, 5, 4, 3, 4
Thin-Shell Object Manipulations With Differentiable Physics Simulations,7.0, 8.0, 1.2649110640673518, 8, 4, 8, 4, 8, 3, 6, 3, 5, 3
Simplicial SMOTE: Oversampling Solution to the Imbalanced Learning Problem,4.75, 4.0, 2.0463381929681126, 8, 4, 3, 3, 5, 4, 3, 4
Rephrase Augment Reason: Visual Grounding of Questions for Vision-Language Models,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 3, 6, 4
Model Breadcrumbs: Crafting Multi-Task Models from Pre-Existing Fine-Tuned Foundation Models,3.75, 3.0, 1.299038105676658, 3, 4, 3, 3, 6, 4, 3, 4
Denoising Low-Rank Data Under Distribution Shift: Double Descent and Data Augmentation,4.333333333333333, 5.0, 0.9428090415820634, 5, 2, 5, 3, 3, 4
Prompt Engineering a Prompt Engineer,4.75, 4.0, 2.0463381929681126, 3, 4, 8, 4, 5, 3, 3, 3
A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 2, 5, 3, 6, 4
A Competition Winning Deep Reinforcement Learning Agent in microRTS,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 5, 4, 6, 5
Jensen-Shannon Divergence Based Novel Loss Functions for Bayesian Neural Networks,3.8, 3.0, 0.9797958971132712, 3, 4, 5, 4, 5, 4, 3, 4, 3, 4
Reward Centering,4.4, 5.0, 1.2, 5, 5, 3, 2, 5, 3, 6, 3, 3, 4
Three ways that non-differentiability affects neural network training,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4, 3, 3
A GRAPH-BASED REPRESENTATION LEARNING APPROACH FOR BREAST CANCER RISK PREDICTION USING GENOTYPE DATA,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 5
Adaptive Invariant Representation Learning for Non-stationary Domain Generalization,4.75, 5.0, 1.0897247358851685, 3, 5, 6, 3, 5, 3, 5, 3
Supermodular Rank: Set Function Decomposition and Optimization,5.0, 5.5, 1.224744871391589, 5, 3, 6, 3, 3, 5, 6, 2
Prompt Risk Control: A Rigorous Framework for Responsible Deployment of Large Language Models,6.5, 6.0, 0.8660254037844386, 6, 3, 6, 4, 6, 4, 8, 3
Spectral Neural Networks: Approximation Theory and Optimization Landscape,5.0, 5.0, 1.8973665961010275, 6, 2, 5, 3, 3, 3, 8, 3, 3, 3
GenBot: Generative Simulation Empowers Automated Robotic Skill Learning at Scale,5.5, 5.5, 1.8027756377319946, 3, 3, 8, 3, 6, 5, 5, 5
Energy-conserving equivariant GNN for elasticity of lattice architected metamaterials,3.75, 3.0, 1.299038105676658, 3, 3, 3, 4, 6, 4, 3, 4
Time-sensitive Weight Averaging for Practical Temporal Domain Generalization,4.5, 4.5, 1.5, 6, 4, 6, 4, 3, 4, 3, 4
Large Language Model Routing with Benchmark Datasets,4.25, 4.0, 1.299038105676658, 5, 3, 3, 3, 6, 4, 3, 4
Making Predictors More Reliable with Selective Recalibration,4.75, 4.0, 2.0463381929681126, 5, 4, 3, 2, 8, 5, 3, 3
Adaptive Federated Learning with Auto-Tuned Clients,5.25, 6.0, 1.299038105676658, 6, 3, 6, 3, 3, 3, 6, 2
ToolDec: Syntax Error-Free and Generalizable Tool Use for LLMs via Finite-State Decoding,5.5, 5.5, 1.8027756377319946, 5, 4, 3, 5, 6, 4, 8, 4
Discrete Diffusion Language Modeling by Estimating the Ratios of the Data Distribution,5.2, 5.0, 1.6, 3, 4, 5, 3, 8, 4, 5, 3, 5, 4
Can Sensitive Information Be Deleted From LLMs? Objectives for Defending Against Extraction Attacks,6.75, 7.0, 1.299038105676658, 8, 4, 6, 3, 8, 3, 5, 3
Learning to reason iteratively and parallelly for complex visual reasoning,5.25, 5.0, 0.4330127018922193, 5, 3, 6, 2, 5, 4, 5, 4
Capacity Analysis of Vector Symbolic Architectures,4.0, 4.0, 1.0, 5, 3, 3, 2
Saliency-Guided Hidden Associative Replay for Continual Learning,4.2, 3.0, 1.469693845669907, 3, 4, 6, 3, 3, 5, 3, 5, 6, 2
Measuring Feature Sparsity in Language Models,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 3, 3, 5, 3
($\texttt{PASS}$) Visual Prompt Locates Good Structure Sparisty through a Recurent HyperNetwork,5.25, 5.0, 1.7853571071357126, 3, 4, 5, 4, 8, 2, 5, 3
A Neural-preconditioned Poisson Solver for Mixed Dirichlet and Neumann Boundary Conditions,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 5, 4, 6, 5
Neural Tangent Kernels Motivate Graph Neural Networks with Cross-Covariance Graphs,6.0, 5.0, 1.4142135623730951, 5, 3, 5, 4, 8, 3
If there is no underfitting there is no Cold Posterior Effect,5.75, 5.0, 1.299038105676658, 5, 4, 5, 3, 5, 4, 8, 3
Aligning Text-to-Image Diffusion Models with Reward Backpropagation,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 5, 4, 6, 3
On the Inadequacy of Similarity-based Privacy Metrics: Reconstruction Attacks against ``Truly Anonymous Synthetic Data'',5.2, 5.0, 1.6, 5, 5, 3, 4, 5, 3, 5, 4, 8, 4
Weighted Risk Invariance for Density-Aware Domain Generalization,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 3, 5, 3, 6, 4
Towards Explainable and Efficient Multi-Modality Learning: Domain-Agnostic Concept Space Paired with Domain-Specific Projection Models,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4
Signatures Meet Dynamic Programming: Generalizing Bellman Equations for Trajectory Following,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 3, 5, 3
Detecting Influence Structures in Multi-Agent Reinforcement Learning,4.25, 4.0, 1.299038105676658, 5, 2, 3, 1, 3, 3, 6, 4
Using Machine Learning Models to Predict Genitourinary Involvement Among Gastrointestinal Stromal Tumour Patients,1.0, 1.0, 0.0, 1, 5, 1, 5, 1, 5, 1, 5
Diffusion Models With Learned Adaptive Noise Processes,5.0, 5.5, 1.224744871391589, 6, 3, 3, 4, 5, 4, 6, 4
Sum-of-Parts Models: Faithful Attributions for Groups of Features,4.8, 5.0, 0.9797958971132712, 5, 3, 5, 4, 3, 5, 5, 3, 6, 2
CrossLoco: Human Motion Driven Control of Legged Robots via Guided Unsupervised Reinforcement Learning,6.666666666666667, 6.0, 0.9428090415820634, 6, 4, 6, 4, 8, 3
Online Weight Approximation for Continual Learning,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 5, 3, 4
Clustering Entity Specific Embeddings Towards a Prescribed Distribution,4.25, 4.0, 1.299038105676658, 6, 3, 3, 4, 5, 3, 3, 2
Sinkhorn Distributional Reinforcement Learning,5.0, 5.0, 1.8973665961010275, 3, 3, 6, 3, 5, 4, 8, 3, 3, 5
On input-dependence and recall in convolutional language models,5.666666666666667, 6.0, 2.0548046676563256, 8, 4, 3, 3, 6, 4
Open-Domain Text Evaluation via Contrastive Distribution Methods,4.8, 5.0, 0.9797958971132712, 5, 3, 5, 3, 6, 3, 5, 4, 3, 4
Learning to Reject for Balanced Error and Beyond,7.5, 8.0, 0.8660254037844386, 6, 3, 8, 3, 8, 4, 8, 4
Implicit Latent Causal Representation Learning through Soft Interventions,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 3, 3, 3, 3, 3, 5, 4
Don't Reinvent the Steering Wheel,2.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 3, 4, 1, 5
IntentGPT: Few-Shot Intent Discovery with Large Language Models,4.4, 5.0, 1.2, 5, 5, 3, 4, 6, 3, 3, 4, 5, 4
On the Foundations of Shortcut Learning,6.4, 6.0, 0.7999999999999999, 6, 3, 8, 4, 6, 3, 6, 3, 6, 2
Let Models Speak Ciphers: Multiagent Debate through Embeddings,5.0, 5.5, 1.224744871391589, 3, 4, 6, 3, 6, 4, 5, 4
Interpreting Categorical Distributional Reinforcement Learning: An Implicit Risk-Sensitive Regularization Effect,4.25, 4.0, 1.299038105676658, 6, 3, 3, 3, 5, 4, 3, 4
Towards Training Without Depth Limits: Batch Normalization Without Gradient Explosion,6.0, 6.0, 0.0, 6, 3, 6, 4, 6, 3, 6, 3
On the Joint Interaction of Models Data and Features,6.75, 7.0, 1.299038105676658, 6, 4, 5, 4, 8, 4, 8, 2
Plugin estimators for selective classification with out-of-distribution detection,6.666666666666667, 6.0, 0.9428090415820634, 6, 4, 6, 3, 8, 4
Dynamic Sparse Training with Structured Sparsity,5.4, 5.0, 0.4898979485566356, 5, 4, 6, 2, 5, 3, 5, 4, 6, 4
Efficient Dynamics Modeling in Interactive Environments with Koopman Theory,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 3, 6, 3, 3, 5
Systolic Array Acceleration of Spiking Neural Networks with Application-Independent Split-Time Temporal Coding,4.2, 5.0, 0.9797958971132712, 5, 4, 5, 2, 5, 3, 3, 4, 3, 4
Evaluating and Finetuning Models For Financial Time Series Forecasting,4.0, 4.0, 1.0, 5, 4, 5, 4, 3, 3, 3, 3
HeaP: Hierarchical Policies for Web Actions using LLMs,4.5, 4.5, 1.5, 3, 4, 6, 2, 3, 4, 6, 3
Controlling language over-optimization by targeting reward distribution,3.75, 3.0, 1.299038105676658, 3, 3, 6, 2, 3, 4, 3, 4
Graph is All You Need? Lightweight Data-agnostic Neural Architecture Search without Training,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 6, 4, 3, 4
Learning interpretable control inputs and dynamics underlying animal locomotion,5.0, 5.5, 1.224744871391589, 5, 3, 6, 4, 3, 4, 6, 4
Tight Rates in Supervised Outlier Transfer Learning,6.0, 5.0, 1.4142135623730951, 5, 3, 5, 4, 8, 5
On the Effectiveness of One-Shot Federated Ensembles in Heterogeneous Cross-Silo Settings,4.0, 4.0, 1.0, 3, 5, 3, 3, 5, 5, 5, 3
OpenLEAF: Open-Domain Interleaved Image-Text Generation and Evaluation,4.0, 4.0, 1.0, 3, 5, 5, 4, 3, 4, 5, 4
Continual Reinforcement Learning by Reweighting Bellman Targets,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 3, 3, 2
COINs: Model-based Accelerated Inference for Knowledge Graphs,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 6, 2, 5, 4
Sampling Multimodal Distributions with the Vanilla Score: Benefits of Data-Based Initialization,5.75, 6.0, 1.7853571071357126, 6, 3, 3, 5, 8, 3, 6, 2
Plug-And-Play Controllable Graph Generation With Diffusion Models,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 3, 5, 4, 3, 5
Primal-Dual Continual Learning: Stability and Plasticity through Lagrange Multipliers,4.5, 4.5, 1.5, 6, 4, 6, 3, 3, 3, 3, 5
Actions-to-Action: Inductive Attention for Egocentric Video Action Anticipation,5.0, 5.0, 1.8973665961010275, 6, 3, 3, 5, 3, 3, 8, 3, 5, 5
Sample as you Infer: Predictive Coding with Langevin Dynamics,3.8, 3.0, 0.9797958971132712, 5, 3, 3, 3, 3, 4, 5, 4, 3, 4
Multitask Contrastive Learning,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 6, 4, 5, 4
Beyond Joint Demonstrations: Personalized Expert Guidance for Efficient Multi-Agent Reinforcement Learning,3.75, 3.0, 1.299038105676658, 3, 3, 6, 3, 3, 4, 3, 4
Encodings for Prediction-based Neural Architecture Search,5.333333333333333, 5.0, 2.0548046676563256, 3, 4, 5, 4, 8, 5
Curiosity-driven Red-teaming for Large Language Models,5.75, 6.0, 0.4330127018922193, 5, 3, 6, 3, 6, 3, 6, 4
Unsupervised Learning Based Object Detection Using Contrastive Learning,3.0, 3.0, 1.1547005383792515, 3, 4, 3, 4, 5, 4, 3, 3, 1, 5, 3, 5
A Prefrontal Cortex-inspired Architecture for Planning in Large Language Models,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 3, 5, 4
Understanding prompt engineering may not require rethinking generalization,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 2, 6, 3
MGDC-UNet: Multi-group Deformable Convolution for Medical Image Segmentation,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 2, 5, 4
Addressing Sample Inefficiency in Multi-View Representation Learning,4.75, 4.0, 2.0463381929681126, 5, 3, 3, 4, 3, 3, 8, 3
MoReDrop: Dropout Without Dropping,4.75, 5.0, 1.0897247358851685, 3, 3, 6, 2, 5, 4, 5, 4
Neural mechanisms of cognitive flexibility: Belief updating in dynamic environments with sparse rewards,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 3, 5, 4
Topological data analysis on noisy quantum computers,7.25, 8.0, 1.299038105676658, 5, 2, 8, 2, 8, 3, 8, 4
Adversarial Imitation Learning via Boosting,5.5, 5.5, 0.5, 5, 3, 6, 3, 5, 3, 6, 3
Physics-aware Causal Graph Network for Spatiotemporal Modeling,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 6, 4, 3, 5
Pruning neural networks using FishLeg estimation,4.25, 4.0, 1.299038105676658, 3, 4, 3, 4, 5, 2, 6, 2
Deep ResNIDS: A Multistage AI Framework for Novelty Detection in Network Traffic,nan, nan, nan
Directed Graph Generation with Heat Kernels,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 3, 6, 2, 6, 2
Unsupervised Fact Verification by Language Model Distillation,5.2, 5.0, 1.6, 5, 4, 3, 3, 5, 3, 8, 3, 5, 5
LipSim: A Provably Robust Perceptual Similarity Metric,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 2, 5, 2
Deep Variational Multivariate Information Bottleneck - A Framework for Variational Losses,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 3, 3, 5, 5, 3
Learning to Generate Better than your Large Language Models,4.75, 5.0, 1.0897247358851685, 3, 2, 5, 3, 5, 4, 6, 3
Does Progress On Object Recognition Benchmarks Improve Generalization on Crowdsourced Global Data?,5.5, 5.5, 0.5, 6, 4, 6, 4, 5, 3, 5, 5
TACTiS-2: Better Faster Simpler Attentional Copulas for Multivariate Time Series,6.0, 5.5, 1.224744871391589, 8, 3, 5, 4, 6, 3, 5, 3
A ROBUST DIFFERENTIAL NEURAL ODE OPTIMIZER,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 6, 3, 3, 4
XAI Procedural Fairness Auditing Framework: avoid misguided outcomes by refocusing on fairness properties,3.0, 3.0, 1.4142135623730951, 1, 3, 3, 3, 5, 4, 3, 4
Simultaneous Dimensionality Reduction: A Data Efficient Approach for Multimodal Representations Learning,3.4, 3.0, 1.4966629547095767, 3, 4, 5, 2, 3, 4, 1, 4, 5, 4
HeteroSFL: Split Federated Learning with heterogeneous clients and non-IID data,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 4, 3, 4
Variance-Covariance Regularization Improves Representation Learning,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 4, 5, 3
Simple-TTS: End-to-End Text-to-Speech Synthesis with Latent Diffusion,3.0, 3.0, 1.632993161855452, 1, 5, 3, 3, 5, 5
BaFTA: Backprop-Free Test-Time Adaptation for Zero-shot Vision Language Models,5.5, 5.5, 0.5, 6, 3, 5, 3, 6, 2, 5, 3
Rapid Learning without Catastrophic Forgetting in the Morris Water Maze,4.0, 4.5, 2.1213203435596424, 1, 3, 3, 3, 6, 3, 6, 4
VideoGLUE: Video General Understanding Evaluation of Foundation Models,5.0, 5.5, 1.224744871391589, 5, 4, 3, 4, 6, 3, 6, 5
A Primal-Dual Approach to Solving Variational Inequalities with General Constraints,6.5, 6.0, 0.8660254037844386, 6, 2, 6, 4, 8, 3, 6, 4
TiC-CLIP: Continual Training of CLIP Models,4.5, 4.5, 1.5, 6, 5, 3, 3, 3, 4, 6, 3
Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks,5.25, 6.0, 1.299038105676658, 3, 4, 6, 4, 6, 3, 6, 4
Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 3, 3, 4
Alignment-Enhancing Parallel Code Generation for Semi-Supervised Code Translation,5.0, 5.5, 1.224744871391589, 3, 4, 6, 4, 5, 5, 6, 4
Constrained Decoding for Cross-lingual Label Projection,6.25, 6.0, 1.0897247358851685, 8, 4, 6, 3, 5, 4, 6, 4
Self-RAG: Learning to Retrieve Generate and Critique through Self-Reflection,7.5, 8.0, 0.8660254037844386, 8, 3, 8, 4, 8, 4, 6, 2
Towards Minimal Targeted Updates of Language Models with Targeted Negative Training,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 5, 6, 4, 5, 2
Synaptic Weight Distributions Depend on the Geometry of Plasticity,4.5, 4.5, 2.692582403567252, 1, 4, 8, 4, 3, 2, 6, 3
Channel Vision Transformers: An Image Is Worth C x 16 x 16 Words,6.0, 5.5, 1.224744871391589, 8, 4, 6, 5, 5, 4, 5, 4
Multi-Image Zero-Shot Subject Generation for Visual Storytelling,4.75, 5.0, 1.0897247358851685, 5, 5, 3, 4, 5, 3, 6, 4
Graph Metanetworks for Processing Diverse Neural Architectures,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 4, 6, 3
Node-wise Calibration of Graph Neural Networks under Out-of-Distribution Nodes via Reinforcement Learning,3.75, 3.0, 1.299038105676658, 3, 3, 3, 4, 3, 4, 6, 4
Protein Language Models Enable Accurate Cryptic Ligand Binding Pocket Prediction,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 3, 3, 3, 5, 4
Dropout Enhanced Bilevel Training,6.333333333333333, 8.0, 2.357022603955158, 3, 4, 8, 3, 8, 3
Chunk Align Select: A Simple Long-sequence Processing Method for Transformers,5.5, 5.5, 1.8027756377319946, 6, 3, 8, 4, 3, 4, 5, 4
Adder: Adapted Dense Retrieval,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 4, 5, 4, 3, 3, 6, 4, 5, 3
Wording Image for Domain-Invariant Representation in Domain Generalization,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 3, 5, 5
Fairness Under Demographic Scarce Regime,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 4, 3, 2
Understanding Reconstruction Attacks with the Neural Tangent Kernel and Dataset Distillation,5.666666666666667, 6.0, 0.4714045207910317, 5, 3, 6, 4, 6, 2
Personalized Residuals for Concept-Driven Text-to-Image Generation,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 6, 4, 5, 4
Encoding Ontologies with Holographic Reduced Representations for Transformers,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 3, 6, 4
Privacy Amplification for Matrix Mechanisms,7.0, 7.0, 1.0, 6, 4, 6, 2, 8, 3, 8, 4
Bandits Meet Mechanism Design to Combat Clickbait in Online Recommendation,6.25, 7.0, 2.0463381929681126, 3, 4, 8, 3, 6, 3, 8, 4
ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs,6.0, 6.5, 2.1213203435596424, 3, 4, 8, 4, 8, 4, 5, 5
ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models,5.5, 5.5, 1.8027756377319946, 5, 4, 8, 4, 6, 4, 3, 4
Behaviour Distillation,5.666666666666667, 6.0, 0.4714045207910317, 6, 2, 5, 4, 6, 3
Improving LoRA in Privacy-preserving Federated Learning,5.5, 5.5, 0.5, 6, 4, 5, 3, 5, 3, 6, 4
Faster and Accurate Neural Networks with Semantic Inference,3.75, 3.0, 1.299038105676658, 3, 2, 3, 4, 6, 3, 3, 4
PhyloGFN: Phylogenetic inference with generative flow networks,5.75, 5.0, 1.299038105676658, 5, 4, 5, 3, 8, 4, 5, 4
Training Bayesian Neural Networks with Sparse Subspace Variational Inference,4.666666666666667, 3.0, 2.357022603955158, 3, 4, 8, 3, 3, 4
Speech language models lack important brain-relevant semantics,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 3, 4, 6, 3
Locality-Aware Graph Rewiring in GNNs,4.75, 4.0, 2.0463381929681126, 8, 4, 3, 4, 3, 3, 5, 4
RAND: Robustness Aware Norm Decay For Quantized Seq2seq Models,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 4
AlignDiff: Aligning Diffusion Models for General Few-Shot Segmentation,5.0, 5.5, 1.224744871391589, 5, 4, 3, 4, 6, 4, 6, 4
Complete and continuous representations of Euclidean graphs,5.0, 5.0, 1.8973665961010275, 3, 2, 8, 3, 5, 5, 3, 4, 6, 2
Multi-modality Adversarial Attacks on Latent Diffusion Models,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 3, 5, 4, 3, 4
Prompt-Free Diffusion: Taking “Text” out of Text-to-Image Diffusion Models,3.0, 3.0, 1.4142135623730951, 5, 5, 3, 3, 1, 5, 3, 4
POET: Prompt Offset Tuning for Continual Few-Shot Action Recognition,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 5, 4, 3, 5
Risk-Sensitive Variational Model-Based Policy Optimization,5.333333333333333, 5.0, 2.0548046676563256, 8, 4, 5, 3, 3, 4
Label-efficient Training of Small Task-specific Models by Leveraging Vision Foundation Models,5.0, 5.5, 1.224744871391589, 5, 4, 6, 4, 6, 3, 3, 4
Feedback-guided Data Synthesis for Imbalanced Classification,4.666666666666667, 5.0, 1.247219128924647, 3, 2, 5, 4, 6, 3
Adapting to Distribution Shift by Visual Domain Prompt Generation,6.0, 5.5, 1.224744871391589, 5, 4, 6, 4, 8, 4, 5, 2
Locally Adaptive Federated Learning,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 4
Multimodal Patient Representation Learning with Missing Modalities and Labels,5.5, 5.5, 0.5, 6, 4, 6, 4, 5, 4, 5, 3
Improved sampling via learned diffusions,6.25, 6.0, 1.0897247358851685, 6, 4, 5, 3, 6, 2, 8, 4
Avoiding Pitfalls for Privacy Accounting of Subsampled Mechanisms under Composition,5.0, 4.5, 2.1213203435596424, 3, 4, 8, 3, 6, 3, 3, 3
Learning to Solve New sequential decision-making Tasks with In-Context Learning,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 3, 3, 4, 5, 3
MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 4, 3, 4, 5, 4
Assessing Visually-Continuous Corruption Robustness of Neural Networks Relative to Human Performance,5.0, 4.5, 2.1213203435596424, 3, 3, 6, 4, 8, 4, 3, 4
Bringing robotics taxonomies to continuous domains via GPLVM on hyperbolic manifolds,5.75, 6.0, 0.4330127018922193, 5, 3, 6, 3, 6, 4, 6, 4
ON TRAINING DERIVATIVE-CONSTRAINED NEURAL NETWORKS,4.0, 3.0, 1.4142135623730951, 6, 3, 3, 4, 3, 4
TIGERScore: Building Explainable Metric for All Text Generation Task,5.5, 5.5, 0.5, 6, 4, 5, 4, 6, 4, 5, 4
FedPnP:A Plug and Play Approach For Personalized Graph-Structured Federated Learning,4.0, 4.0, 1.0, 5, 2, 3, 3, 3, 4, 5, 3
SpaFL: Communication-Efficient Federated Learning with Sparse Models and Low Computational Overhead,5.0, 5.0, 0.0, 5, 5, 5, 3, 5, 4, 5, 3
FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance,6.25, 7.0, 2.0463381929681126, 8, 5, 8, 4, 3, 3, 6, 5
Smoothing for exponential family dynamical systems,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 2, 5, 3
Don't forget private retrieval: distributed private similarity search for large language models,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4, 3, 3
"What Data Benefits My Classifier?" Enhancing Model Performance and Interpretability through Influence-Based Data Selection,5.2, 6.0, 1.16619037896906, 3, 4, 6, 3, 5, 4, 6, 4, 6, 4
Do LLMs exhibit human-like response biases? A case study in survey design,5.4, 5.0, 1.624807680927192, 5, 3, 3, 4, 5, 4, 8, 4, 6, 4
Towards Establishing Guaranteed Error for Learned Database Operations,6.0, 6.5, 2.1213203435596424, 3, 3, 8, 2, 5, 4, 8, 3
Quantifying the Plausibility of Context Reliance in Neural Machine Translation,5.5, 5.5, 1.8027756377319946, 6, 2, 3, 2, 8, 4, 5, 2
Automatic Calibration Diagnosis: Interpreting Probability Integral Transform (PIT) Histograms,2.0, 2.0, 1.0, 1, 5, 1, 5, 3, 4, 3, 3
Bayesian Optimization through Gaussian Cox Process Models for Spatio-temporal Data,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 2
Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX,6.0, 5.5, 1.224744871391589, 5, 4, 8, 4, 5, 4, 6, 4
Searching for High-Value Molecules Using Reinforcement Learning and Transformers,5.75, 5.0, 1.299038105676658, 8, 4, 5, 3, 5, 3, 5, 2
Differentiable Euler Characteristic Transforms for Shape Classification,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 3, 6, 3, 6, 3
A Shot-Efficient Differential Equation Integrator using Quantum Neural Networks,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 3, 4, 5, 3
Causally Aligned Curriculum Learning,5.5, 5.5, 1.8027756377319946, 8, 3, 6, 3, 3, 4, 5, 3
Transforming Transformers for Resilient Lifelong Learning,5.5, 5.5, 0.5, 6, 4, 6, 4, 5, 4, 5, 2
Conditional Generative Modeling for High-dimensional Marked Temporal Point Processes,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 5, 5, 3, 3
HHD-Ethiopic: A Historical Handwritten Dataset for Ethiopic OCR with Baseline Models and Human-level Performance,4.0, 4.0, 1.0, 3, 4, 3, 5, 5, 5, 5, 4
Neural Optimizer Equation Decay Function and Learning Rate Schedule Joint Evolution,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4, 3, 4
Improving length generalization in transformers via task hinting,4.25, 4.0, 1.299038105676658, 5, 3, 3, 5, 3, 4, 6, 4
ARE YOU CERTAIN THAT IT IS A DEEPFAKE? DETECTION GENERATION AND SOURCE DETECTION FROM AN UNCERTAINTY PERSPECTIVE,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4
Routing with Rich Text Queries via Next-Vertex Prediction Models,5.0, 5.0, 0.0, 5, 3, 5, 2, 5, 4
Sparling: Learning Latent Representations With Extremely Sparse Activations,3.0, 3.0, 1.4142135623730951, 3, 3, 1, 3, 5, 4, 3, 3
How to fix a broken confidence estimator: Evaluating post-hoc methods for selective classification with deep neural networks,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 4, 5, 4, 5, 4
Faster Sampling from Log-Concave Densities over Polytopes via Efficient Linear Solvers,6.333333333333333, 8.0, 2.357022603955158, 3, 5, 8, 3, 8, 4
On Robustness-Accuracy Characterization of Large Language Models using Synthetic Datasets,3.6666666666666665, 3.0, 0.9428090415820634, 3, 2, 3, 4, 5, 3
Counterfactual Fairness on Graphs: Augmentations Hidden Confounders and Identifiability,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 4, 3, 3, 5, 3
An Invariant Information Geometric Method for High-dimensional Online Optimization,3.6666666666666665, 5.0, 1.8856180831641267, 5, 1, 1, 5, 5, 5
Towards Characterizing Domain Counterfactuals for Invertible Latent Causal Models,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 3, 5, 3, 5, 3
Detecting Language Model Attacks With Perplexity,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 3
Grokking as the transition from lazy to rich training dynamics,6.0, 6.5, 2.1213203435596424, 8, 4, 8, 3, 3, 3, 5, 3
Frequency-Aware Masked Autoencoders for Multimodal Pretraining on Biosignals,5.0, 5.5, 1.224744871391589, 6, 4, 5, 4, 6, 3, 3, 5
SynBench: Evaluating Pretrained Representations for Image Classification using Synthetic Data,4.5, 4.5, 1.5, 3, 4, 3, 3, 6, 2, 6, 3
Performance Bounds for Active Binary Testing with Information Maximization,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 2, 5, 4, 5, 3
RINGER: Conformer Ensemble Generation of Macrocyclic Peptides with Sequence-Conditioned Internal Coordinate Diffusion,5.75, 5.0, 1.299038105676658, 8, 4, 5, 4, 5, 3, 5, 4
Exploiting Causal Graph Priors with Posterior Sampling for Reinforcement Learning,7.0, 7.0, 1.0, 8, 3, 6, 3, 6, 2, 8, 4
Language Model Cascades: Token-Level Uncertainty And Beyond,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 3, 6, 3, 6, 4
The Marginal Value of Momentum for Small Learning Rate SGD,5.5, 5.5, 0.5, 5, 3, 6, 3, 6, 3, 5, 3
Towards Principled Representation Learning from Videos for Reinforcement Learning,6.0, 5.5, 1.224744871391589, 8, 4, 5, 3, 5, 3, 6, 3
GIST: Generating Image-Specific Text for Fine-grained Object Representations,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 5, 6, 4
A Fast and Effective Alternative to Graph Transformers,4.0, 3.0, 1.4142135623730951, 3, 5, 6, 3, 3, 5
Revitalizing Channel-dimension Fourier Transform for Image Enhancement,8.5, 8.0, 0.8660254037844386, 8, 5, 10, 5, 8, 5, 8, 5
Learning Polynomial Problems with $SL(2 \mathbb{R})$-Equivariance,6.0, 5.0, 1.4142135623730951, 5, 5, 8, 3, 5, 2
Mixture of Weak and Strong Experts on Graphs,5.333333333333333, 5.0, 1.4907119849998596, 5, 3, 5, 4, 8, 3, 6, 4, 5, 4, 3, 4
Explicit Foundation Model Optimization with Self-Attentive Feed-Forward Neural Units,3.0, 3.0, 1.4142135623730951, 3, 3, 1, 3, 3, 4, 5, 3
Meta-Learning Strategies through Value Maximization in Neural Networks,5.25, 5.0, 1.7853571071357126, 8, 2, 5, 3, 5, 3, 3, 3
Pylic: Leveraging Source Code for Planning in Structured Environments,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 2
Best Arm Identification for Stochastic Rising Bandits,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 3, 6, 3
Optimal Sample Complexity of Contrastive Learning,7.5, 8.0, 0.8660254037844386, 8, 3, 6, 3, 8, 3, 8, 2
A Unified Framework for Heterogeneous Semi-supervised Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 4
Learning from Integral Losses in Physics Informed Neural Networks,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 5, 4, 6, 1
Transformers can optimally learn regression mixture models,5.2, 5.0, 0.39999999999999997, 5, 4, 6, 3, 5, 3, 5, 3, 5, 3
A Structured Pruning Algorithm for Model-based Deep Learning,4.0, 4.0, 1.0, 3, 3, 5, 2, 3, 4, 5, 4
Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method Perspective,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 5, 3, 6, 3
Fast Stochastic Kernel Approximation by Dual Wasserstein Distance Method,4.0, 3.0, 2.943920288775949, 8, 3, 1, 5, 3, 4
E$^{2}$GAN: Efficient Training of Efficient GANs for Image-to-Image Translation,4.0, 4.0, 1.0, 5, 3, 3, 3, 5, 4, 3, 4
Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 6, 4, 8, 5
Catapults in SGD: spikes in the training loss and their impact on generalization through feature learning,6.25, 6.0, 1.0897247358851685, 5, 4, 8, 4, 6, 4, 6, 4
Reconciling Spatial and Temporal Abstractions for Goal Representation,5.333333333333333, 5.0, 2.0548046676563256, 3, 3, 5, 4, 8, 3
Annotation by Clicks: A Point-Supervised Contrastive Variance Method for Medical Semantic Segmentation,4.0, 4.0, 1.0, 5, 4, 5, 4, 3, 5, 3, 4
Estimating Conditional Mutual Information for Dynamic Feature Selection,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 5
LLM Augmented LLMs: Expanding Capabilities through Composition,6.25, 6.0, 1.0897247358851685, 6, 4, 8, 4, 5, 3, 6, 4
Quadratic models for understanding neural network dynamics,5.4, 5.0, 1.624807680927192, 3, 3, 6, 3, 5, 4, 8, 1, 5, 2
Latent Concept-based Explanation of NLP Models,3.6666666666666665, 3.0, 0.9428090415820634, 5, 2, 3, 2, 3, 4
CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers,4.75, 5.0, 1.0897247358851685, 5, 5, 5, 5, 6, 4, 3, 4
Improved DDIM Sampling with Moment Matching Gaussian Mixtures,4.0, 4.0, 1.0, 5, 4, 3, 4, 3, 4, 5, 3
Inference from Real-World Sparse Measurements,4.25, 4.0, 1.299038105676658, 3, 3, 5, 3, 6, 3, 3, 3
Evaluating Representation Learning on the Protein Structure Universe,6.25, 6.0, 1.0897247358851685, 8, 4, 6, 5, 5, 5, 6, 3
Enhancing Compositional Generalization via Compositional Feature Alignment,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 3, 5, 5
T-MARS: Improving Visual Representations by Circumventing Text Feature Learning,6.25, 6.0, 1.0897247358851685, 8, 4, 5, 4, 6, 2, 6, 2
Nougat: Neural Optical Understanding for Academic Documents,6.5, 6.5, 2.692582403567252, 5, 4, 3, 5, 8, 5, 10, 4
Solving the Quadratic Assignment Problem With Deep Reinforcement Learning,3.75, 4.0, 1.920286436967152, 3, 4, 5, 5, 1, 4, 6, 4
Rank-adaptive spectral pruning of convolutional layers during training,3.0, 3.0, 0.0, 3, 4
Meta-Value Learning: a General Framework for Learning with Learning Awareness,5.2, 5.0, 0.39999999999999997, 5, 4, 5, 4, 5, 4, 5, 3, 6, 2
When can transformers reason with abstract symbols?,6.6, 6.0, 1.2, 8, 3, 5, 1, 8, 3, 6, 4, 6, 4
When Do MLPs Excel in Node Classification? An Information-Theoretic Perspective,4.666666666666667, 3.0, 2.357022603955158, 3, 4, 3, 4, 8, 3
Towards Generative Abstract Reasoning: Completing Raven’s Progressive Matrix via Rule Abstraction and Selection,6.5, 6.0, 0.8660254037844386, 8, 5, 6, 4, 6, 4, 6, 5
A Characterization Theorem for Equivariant Networks with Point-wise Activations,6.0, 5.5, 1.224744871391589, 8, 3, 5, 3, 5, 2, 6, 3
Handling Cost and Constraints with Off-Policy Deep Reinforcement Learning,3.5, 3.0, 0.8660254037844386, 3, 3, 5, 2, 3, 4, 3, 4
Efficient Graph Representation Learning by Non-Local Information Exchange,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 4, 5, 4
Translating cognitive models into neural and statistical descriptions of real-world multi-agent foraging behavior,4.75, 5.0, 1.0897247358851685, 5, 2, 6, 5, 3, 3, 5, 2
Variational quantization for state space models,6.0, 6.0, 0.0, 6, 3, 6, 3, 6, 3
DPAF: Image Synthesis via Differentially Private Aggregation in Forward Phase,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4
On the Tool Manipulation Capability of Open-sourced Large Language Models,5.0, 5.0, 0.0, 5, 4, 5, 5, 5, 4, 5, 3
realSEUDO for real-time calcium imaging analysis,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 5, 4, 6, 2
Confidence-driven Sampling for Backdoor Attacks,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 5, 4, 6, 4
Risk Assessment and Statistical Significance in the Age of Foundation Models,4.833333333333333, 5.5, 1.3437096247164249, 3, 3, 6, 3, 5, 3, 6, 3, 3, 3, 6, 3
A universal metric of dataset similarity for multi-source learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 3, 3, 2
Think before you speak: Training Language Models With Pause Tokens,5.5, 5.5, 2.5, 8, 4, 3, 4, 3, 4, 8, 3
Unlocking Tuning-free Generalization: Minimizing the PAC-Bayes Bound with Trainable Priors,5.4, 5.0, 1.624807680927192, 5, 3, 3, 3, 5, 4, 8, 4, 6, 3
Talk like a Graph: Encoding Graphs for Large Language Models,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 5, 6, 3, 6, 3
Revealing Vision-Language Integration in the Brain with Multimodal Networks,4.2, 3.0, 1.469693845669907, 3, 3, 3, 4, 6, 5, 6, 4, 3, 5
Debiasing Language Models Using Energy-Guided Ordinary Differential Equations,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 5, 3, 3, 3
Post-hoc bias scoring is optimal for fair classification,6.75, 7.0, 1.299038105676658, 5, 4, 8, 3, 6, 4, 8, 4
Coupling Fairness and Pruning in a Single Run: a Bi-level Optimization Perspective,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 3, 5, 3
Sharpness-Aware Data Poisoning Attack,5.5, 6.0, 1.118033988749895, 6, 4, 6, 5, 6, 4, 6, 3, 6, 4, 3, 5
BOtied: Multi-objective Bayesian optimization with tied multivariate ranks,4.25, 4.0, 1.299038105676658, 6, 5, 5, 3, 3, 4, 3, 4
Privately Aligning Language Models with Reinforcement Learning,6.333333333333333, 6.0, 1.247219128924647, 5, 2, 6, 3, 8, 3
YaRN: Efficient Context Window Extension of Large Language Models,6.25, 6.0, 1.0897247358851685, 6, 2, 8, 4, 6, 4, 5, 4
Evaluating and Improving Generation Consistency of Large Language Models via A Divide-Conquer-Reasoning Approach,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 3
On the Generalization of Training-based ChatGPT Detection Methods,5.333333333333333, 5.0, 0.4714045207910317, 6, 2, 5, 4, 5, 4
Divergence at the Interpolation Threshold: Identifying Interpreting & Ablating the Sources of a Deep Learning Puzzle,3.25, 3.0, 1.7853571071357126, 6, 4, 3, 3, 3, 3, 1, 4
BIRB: A Generalization Benchmark for Information Retrieval in Bioacoustics,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 2, 5, 3
What Improves the Generalization of Graph Transformer? A Theoretical Dive into Self-attention and Positional Encoding,5.666666666666667, 6.0, 0.4714045207910317, 5, 2, 6, 3, 6, 3
UGSL: A Unified Framework for Benchmarking Graph Structure Learning,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 4, 3, 4, 3, 4
Accelerating Sinkhorn algorithm with sparse Newton iterations,5.5, 5.5, 0.5, 6, 3, 5, 4, 6, 3, 5, 3
$\sigma$-PCA: a unified neural model for linear and nonlinear principal component analysis,4.0, 4.0, 1.0, 3, 3, 5, 3, 3, 4, 5, 2
Junk DNA Hypothesis: A Task-Centric Angle of LLM Pre-trained Weights through Sparsity,6.666666666666667, 6.0, 0.9428090415820634, 8, 4, 6, 2, 6, 4
UGC: UNIVERSAL GRAPH COARSENING,5.0, 6.0, 1.4142135623730951, 6, 4, 3, 4, 6, 3
Functional Interpolation for Relative Positions improves Long Context Transformers,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 6, 4, 8, 4
Stream: A Generalized Continual Learning Benchmark and Baseline,4.0, 4.0, 1.0, 5, 4, 3, 3, 3, 3, 5, 4
Dream to Adapt: Meta Reinforcement Learning by Latent Context Imagination and MDP Imagination,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 5, 1, 4, 3, 4
Word Importance Explains How Prompts Affect Language Model Outputs,2.5, 3.0, 0.8660254037844386, 3, 3, 3, 5, 3, 3, 1, 3
KNIFE: Distilling Reasoning Knowledge From Free-Text Rationales,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 5, 4, 3, 4
Pre-training with Random Orthogonal Projection Image Modeling,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 6, 4, 8, 4
Correct-by-design Safety Critics using Non-contractive Binary Bellman Operators,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 4, 5, 3
Hypergraph Neural Networks through the Lens of Message Passing: A Common Perspective to Homophily and Architecture Design,4.75, 5.0, 1.0897247358851685, 6, 4, 3, 4, 5, 4, 5, 2
FeatUp: A Model-Agnostic Framework for Features at Any Resolution,5.0, 6.0, 1.4142135623730951, 3, 5, 6, 4, 6, 4
Diversity-aware Continual Learning with Latent Knowledge Hypergraph,4.0, 4.0, 1.0, 5, 4, 3, 5, 5, 4, 3, 3
Mechanistic Neural Networks,4.666666666666667, 3.0, 2.357022603955158, 3, 2, 3, 4, 8, 4
PROSE: Predicting Operators and Symbolic Expressions using Multimodal Transformers,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 5, 4, 3, 4
Generalized Category Discovery with Hierarchical Label Smoothing,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4, 3, 5
Masked Autoencoders with Multi-Window Local-Global Attention Are Better Audio Learners,4.0, 4.0, 1.0, 3, 3, 5, 2, 5, 3, 3, 3
Lagrangian Flow Networks for Conservation Laws,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 6, 3, 8, 3
Compositional Generalization in Multimodal Foundation Models,4.0, 4.0, 1.0, 3, 4, 5, 5, 5, 4, 3, 3
Visual Topics via Visual Vocabularies,3.0, 3.0, 1.632993161855452, 1, 5, 3, 4, 5, 4
Toward Optimal Policy Population Growth in Two-Player Zero-Sum Games,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 2, 6, 3
What when and where? -- Self-Supervised Spatio-Temporal Grounding in Untrimmed Multi-Action Videos from Narrated Instructions,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 5, 5, 3, 5
SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial Understanding,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 5, 5, 4, 5, 5
Algorithm and Hardness for Dynamic Attention Maintenance in Large Language Models,5.0, 4.5, 2.1213203435596424, 8, 3, 6, 4, 3, 2, 3, 3
Sparse Autoencoders Find Highly Interpretable Features in Language Models,4.8, 6.0, 1.9390719429665317, 5, 4, 6, 4, 1, 5, 6, 4, 6, 3
Linearity of Relation Decoding in Transformer Language Models,6.333333333333333, 6.0, 1.247219128924647, 5, 3, 8, 3, 6, 4
Rendering Wireless Environments Useful for Gradient Estimators: A Zero-Order Stochastic Federated Learning Method,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 5, 3, 3, 4, 3, 4, 3, 3
Option Boosting,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 3
Reducing distortions in Real World Image Super Resolution using Attention,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 5, 5, 5
Promoting Sparsity in Continuous-time Neural Networks to Learn Dependence Structures,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 5, 3, 3, 4
Generative Modeling with Phase Stochastic Bridge,7.5, 8.0, 0.8660254037844386, 8, 2, 8, 4, 8, 3, 6, 4
Characterizing Long-Tail Categories on Graphs via A Theory-Driven Framework,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 3, 3, 6, 4
OVOR: OnePrompt with Virtual Outlier Regularization for Rehearsal-Free Class-Incremental Learning,5.333333333333333, 5.0, 0.4714045207910317, 5, 5, 5, 4, 6, 2
Chain of Log-Concave Markov Chains,7.0, 7.0, 1.0, 8, 3, 6, 3, 8, 3, 6, 4
Tree-based Ensemble Learning for Out-of-distribution Detection,4.75, 4.0, 2.0463381929681126, 5, 2, 3, 3, 8, 3, 3, 3
Demonstrating the capacity of a Path-Based variational inference formulation for robust hidden Markov modelling of complex and noisy binary trees,5.0, 5.0, 0.0, 5, 3, 5, 2, 5, 4
Benign Overfitting and Grokking in ReLU Networks for XOR Cluster Data,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 4, 6, 4
Resolving Partial Observability in Decision Processes via the Lambda Discrepancy,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 3, 3, 6, 5
Masked AutoDecoder is Effective Multi-Task Vision Generalist,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 5, 4, 6, 2
HeroLT: Benchmarking Heterogeneous Long-Tailed Learning,4.25, 4.0, 1.299038105676658, 3, 4, 5, 5, 3, 4, 6, 4
CoNO: Complex Neural Operator for Continuous Dynamical Systems,4.0, 4.0, 1.0, 5, 4, 3, 4, 3, 4, 5, 4
Addressing Challenges in Reinforcement Learning for Recommender Systems with Conservative Objectives,4.5, 5.0, 0.8660254037844386, 5, 5, 5, 4, 3, 4, 5, 3
Expecting The Unexpected: Towards Broad Out-Of-Distribution Detection,4.25, 4.0, 1.299038105676658, 6, 4, 5, 3, 3, 4, 3, 2
Breaking Neural Network Scaling Laws with Modularity,6.333333333333333, 6.0, 1.247219128924647, 6, 3, 5, 2, 8, 3
ReLU for Inference Acceleration,4.0, 4.0, 1.0, 5, 4, 3, 5, 3, 4, 5, 4
Sensitivity Sampling for Coreset-Based Data Selection,4.5, 4.5, 1.5, 3, 2, 6, 3, 6, 3, 3, 4
DISCRET: a self-interpretable framework for treatment effect estimation,4.0, 4.0, 1.0, 3, 4, 3, 5, 5, 5, 5, 3
VBH-GNN: Variational Bayesian Heterogeneous Graph Neural Networks for Cross-subject Emotion Recognition,6.666666666666667, 6.0, 0.9428090415820634, 8, 4, 6, 4, 6, 3
Towards Exact Computation of Inductive Bias,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 3, 3, 2, 5, 3
Large Pre-trained time series models for cross-domain Time series analysis tasks,3.8, 3.0, 0.9797958971132712, 3, 5, 5, 5, 5, 3, 3, 4, 3, 5
Efficiency Pentathlon: A Standardized Benchmark for Efficiency Evaluation,5.25, 5.0, 1.7853571071357126, 5, 3, 3, 4, 5, 3, 8, 4
How Robust Are Energy-Based Models Trained With Equilibrium Propagation?,5.25, 5.0, 0.4330127018922193, 6, 2, 5, 2, 5, 4, 5, 3
The Journey Not the Destination: How Data Guides Diffusion Models,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 3, 6, 4, 5, 3
AUGCAL: Improving Sim2Real Adaptation by Uncertainty Calibration on Augmented Synthetic Images,7.0, 7.0, 1.0, 8, 4, 6, 4
Eliciting Attributions from LLMs with Minimal Supervision,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 3, 4, 5, 3
Quality-Diversity through AI Feedback,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 3, 6, 3, 5, 3
Learning from Sparse Offline Datasets via Conservative Density Estimation,6.75, 7.0, 1.299038105676658, 8, 3, 5, 4, 6, 3, 8, 3
Formal Verification for Neural Networks with General Nonlinearities via Branch-and-Bound,5.5, 5.5, 0.5, 5, 4, 5, 4, 6, 5, 6, 3
Castor: Causal Temporal Regime Structure Learning,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 3, 5, 3
PEMs: Pre-trained Epidemic Time-Series Models,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 3, 6, 4, 5, 3
Federated contrastive GFlowNets,4.5, 5.0, 0.8660254037844386, 3, 3, 5, 5, 5, 3, 5, 3
Informed weight initialization of Graph Neural Networks and its effect on Oversmoothing,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 3, 4, 1, 4
Connecting NTK and NNGP: A Unified Theoretical Framework for Neural Network Learning Dynamics in the Kernel Regime,6.0, 6.5, 2.1213203435596424, 8, 4, 3, 3, 8, 3, 5, 5
Automatic Calibration and Error Correction for Generative Large Language Models via Pareto Optimal Self-Supervision,5.5, 5.5, 0.5, 5, 3, 6, 3, 6, 4, 5, 2
On the Expressivity of Objective-Specification Formalisms in Reinforcement Learning,6.5, 6.5, 2.692582403567252, 3, 3, 5, 5, 10, 3, 8, 3
Implicit Maximum a Posteriori Filtering via Adaptive Optimization,6.333333333333333, 6.0, 1.247219128924647, 8, 4, 6, 3, 5, 4
Rethinking Optimal Transport in Offline Reinforcement Learning,5.0, 6.0, 1.4142135623730951, 6, 2, 3, 4, 6, 3
The HIM Solution for Legged Locomotion: Minimal Sensors Efficient Learning and Substantial Agility,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 4, 6, 3, 5, 4
S$2$AC: Energy-Based Reinforcement Learning with Stein Soft Actor Critic,5.714285714285714, 6.0, 1.385051387833237, 5, 5, 6, 3, 6, 4, 8, 3, 6, 3, 6, 3, 3, 4
ERM++: An Improved Baseline for Domain Generalization,4.0, 4.0, 1.0, 3, 4, 5, 3, 5, 3, 3, 5
A Newborn Embodied Turing Test for Comparing Object Segmentation Across Animals and Machines,5.5, 5.5, 2.5, 3, 4, 8, 5, 8, 4, 3, 4
Anomaly Detection with Variance Stabilized Density Estimation,3.0, 3.0, 1.632993161855452, 1, 4, 5, 4, 3, 3
Implicit Chain of Thought Reasoning via Knowledge Distillation,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 3, 3, 4
Robust Model-Based Optimization for Challenging Fitness Landscapes,6.0, 5.5, 1.224744871391589, 5, 1, 8, 3, 5, 2, 6, 3
Solving High Frequency and Multi-Scale PDEs with Gaussian Processes,5.5, 5.5, 0.5, 5, 5, 5, 3, 6, 2, 6, 4
Reinforcement Learning of Diverse Skills using Mixture of Deep Experts,4.5, 5.0, 0.8660254037844386, 3, 3, 5, 3, 5, 3, 5, 3
Learning Fair Representations with High-Confidence Guarantees,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 3
Inductive Link Prediction in Knowledge Graphs using Path-based Neural Networks,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 5, 3, 3
Hierarchically branched diffusion models leverage dataset structure for class-conditional generation,5.5, 5.5, 0.5, 5, 3, 5, 4, 6, 4, 6, 2
Combine and Conquer: A Meta-Analysis on Data Shift and Out-of-Distribution Detection,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 3, 4, 6, 2
OpenWebMath: An Open Dataset of High-Quality Mathematical Web Text,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 3, 6, 4
Task-to-Instance Prompt Learning for Vision-Language Models at Test Time,5.5, 5.5, 0.5, 5, 4, 6, 5, 6, 4, 5, 5
Towards guarantees for parameter isolation in continual learning,4.25, 5.0, 1.920286436967152, 5, 3, 1, 5, 6, 1, 5, 3
Replay across Experiments: A Natural Extension of Off-Policy RL,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 4, 5, 4, 5, 4
High-Dimensional Geometric Streaming for Nearly Low Rank Data,5.666666666666667, 6.0, 2.0548046676563256, 6, 3, 8, 3, 3, 3
Automatically Eliciting Toxic Outputs from Pre-trained Language Models,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 3, 6, 3, 5, 3
BMAD: Benchmarks for Medical Anomaly Detection,4.25, 4.0, 1.299038105676658, 3, 4, 3, 4, 5, 4, 6, 3
PolySketchFormer: Fast Transformers via Sketches for Polynomial Kernels,5.4, 5.0, 2.244994432064365, 8, 4, 5, 3, 8, 3, 3, 3, 3, 4
SiGeo: Sub-One-Shot NAS via Information Theory and Geometry of Loss Landscape,4.2, 5.0, 0.9797958971132712, 5, 3, 5, 4, 3, 5, 3, 4, 5, 4
GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity,5.75, 5.0, 1.299038105676658, 8, 4, 5, 3, 5, 4, 5, 4
CLAM: Class-wise Layer-wise Attribute Model for Explaining Neural Networks,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4, 3, 3
Understanding Transferable Representation Learning and Zero-shot Transfer in CLIP,6.0, 5.5, 1.224744871391589, 6, 3, 5, 2, 5, 3, 8, 3
Dataset Fairness: Achievable Fairness On Your Data With Utility Guarantees,4.0, 3.0, 1.4142135623730951, 6, 2, 3, 4, 3, 3
Image Super-Resolution via Latent Diffusion: A Sampling-Space Mixture of Experts and Frequency-Augmented Decoder Approach,4.25, 4.0, 1.299038105676658, 5, 4, 3, 5, 3, 4, 6, 4
Conditional Variational Diffusion Models,5.2, 5.0, 1.6, 5, 4, 8, 4, 5, 3, 5, 3, 3, 4
Revisiting DeepFool: generalization and improvement,4.75, 5.0, 1.0897247358851685, 3, 3, 6, 5, 5, 5, 5, 4
Better Neural PDE Solvers Through Data-Free Mesh Movers,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 3, 3, 4
Topological Expressive Power of ReLU Neural Networks,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 8, 4, 6, 1
Metric Space Magnitude for Evaluating Unsupervised Representation Learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 4, 3, 2
InfoNet: Missing Information Retrieval in Multi-Stream Sensing Systems,3.0, 3.0, 1.632993161855452, 1, 4, 3, 3, 5, 4
Bridging Autoregressive and Masked Modeling for Enhanced Visual Representation Learning,5.25, 5.0, 0.4330127018922193, 5, 5, 6, 4, 5, 5, 5, 3
NAG-GS: Semi-Implicit Accelerated and Robust Stochastic Optimizer,4.25, 4.0, 1.299038105676658, 3, 3, 5, 4, 3, 4, 6, 3
Mitigating Estimation Errors By Twin TD-Regularized Actor and Critic for Deep Reinforcement Learning,4.0, 4.0, 1.0, 3, 4, 5, 4, 5, 5, 3, 5
Distributed Linear Dimensionality Reduction Assisted by Centralized NN for Classification,2.5, 3.0, 0.8660254037844386, 1, 4, 3, 5, 3, 2, 3, 5
From Latent Graph to Latent Topology Inference: Differentiable Cell Complex Module,6.0, 5.0, 1.4142135623730951, 5, 4, 8, 3, 5, 2
Subtractive Mixture Models via Squaring: Representation and Learning,6.8, 6.0, 0.9797958971132712, 8, 4, 6, 2, 6, 3, 8, 3, 6, 2
Stateless Mean-Field Games: A Framework for Independent Learning with Large Populations,5.333333333333333, 5.0, 2.0548046676563256, 5, 2, 8, 2, 3, 3
Don't trust your eyes: on the (un)reliability of feature visualizations,6.25, 6.0, 1.0897247358851685, 8, 3, 5, 3, 6, 3, 6, 4
Connected Hidden Neurons (CHNNet): An Artificial Neural Network for Rapid Convergence,3.75, 3.0, 1.299038105676658, 3, 5, 3, 4, 3, 4, 6, 3
Spawrious: A Benchmark for Fine Control of Spurious Correlation Biases,5.75, 5.0, 1.299038105676658, 5, 5, 5, 4, 8, 4, 5, 3
Constrained Bayesian Optimization with Adaptive Active Learning of Unknown Constraints,3.75, 4.0, 1.920286436967152, 1, 4, 3, 4, 5, 3, 6, 3
Optimizing the trade-off between utility and performance in interpretable sleep classification,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 2, 3, 4, 5, 3
Loci-Segmented: Improving Scene Segmentation Learning,4.75, 5.0, 1.0897247358851685, 5, 3, 6, 1, 3, 3, 5, 3
A Conceptual Framework for Analyzing Social Representation in Unstructured Data,3.4, 3.0, 0.8000000000000002, 5, 4, 3, 3, 3, 3, 3, 4, 3, 3
Graph-PDE: Coupled ODE Structure for Graph Neural Networks,5.2, 6.0, 1.9390719429665317, 8, 4, 6, 2, 3, 5, 3, 4, 6, 4
Contextual Molecule Representation Learning from Chemical Reaction Knowledge,5.25, 5.0, 1.7853571071357126, 5, 5, 8, 4, 5, 4, 3, 4
Towards Subgraph Isomorphism Counting with Graph Kernels,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 3
A Calibrated Simulation for Offline Training of Reinforcement Learning Agents to Optimize Energy and Emission in Office Buildings,2.5, 2.0, 1.6583123951777, 3, 4, 1, 5, 1, 5, 5, 4
Generating Explanations From Linear Structural Causal Models,3.4, 3.0, 0.8, 3, 4, 3, 2, 3, 3, 5, 2, 3, 4
On the Provable Advantage of Unsupervised Pretraining,7.0, 7.0, 1.0, 6, 3, 8, 4, 8, 2, 6, 3
BEND: Benchmarking DNA Language Models on Biologically Meaningful Tasks,4.25, 4.0, 1.299038105676658, 3, 4, 6, 4, 5, 5, 3, 5
Diversity Modeling for Semantic Shift Detection,4.4, 5.0, 1.2, 5, 3, 6, 4, 5, 4, 3, 3, 3, 4
TorchRL: A data-driven decision-making library for PyTorch,6.25, 6.0, 1.0897247358851685, 6, 5, 5, 3, 8, 4, 6, 3
EchoPrompt: Instructing the Model to Rephrase Queries for Improved In-context Learning,4.25, 4.0, 1.299038105676658, 6, 4, 3, 4, 5, 4, 3, 3
Generalized Adversarial Learning--An Innovative Unsupervised Paradigm In LLM's Calibration,3.75, 3.0, 1.299038105676658, 6, 3, 3, 4, 3, 3, 3, 3
Training Binary Neural Networks in a Binary Weight Space,4.666666666666667, 5.0, 1.247219128924647, 3, 5, 5, 5, 6, 3
Bandits with Ranking Feedback,5.0, 4.5, 2.1213203435596424, 6, 3, 3, 3, 8, 4, 3, 3
Factorized Neural Radiance Field with Depth Covariance Function for Dense RGB Mapping,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 5, 3, 3
Training and inference of large language models using 8-bit floating point,4.0, 3.0, 1.4142135623730951, 6, 3, 3, 3, 3, 4
Convex and Bilevel Optimization for Neuro-Symbolic Inference and Learning,5.25, 6.0, 1.299038105676658, 6, 3, 6, 3, 6, 1, 3, 3
Understanding and Tackling Over-Dilution in Graph Neural Networks,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 3, 3, 3, 5, 4
FigCaps-HF: A Figure-to-Caption Generative Framework and Benchmark with Human Feedback,5.5, 5.5, 0.5, 6, 3, 5, 3, 5, 3, 6, 3
Neural Coherence,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 3, 3, 3, 3, 4
SSC Layer - A replacement for convolutional layers,3.0, 3.0, 0.0, 3, 3, 3, 5, 3, 4, 3, 4
Quality-Diversity Transfer Learning (QDTL),3.5, 3.0, 0.8660254037844386, 3, 4, 5, 3, 3, 3, 3, 2
Learning Deep O($n$)-Equivariant Hyperspheres,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 2, 5, 3, 5, 5
GraphMaker: Can Diffusion Models Generate Large Attributed Graphs?,3.6666666666666665, 3.0, 0.9428090415820634, 5, 5, 3, 4, 3, 4
Constrained Reinforcement Learning as Wasserstein Variational Inference: Formal Methods for Interpretability,5.0, 6.0, 1.4142135623730951, 3, 3, 6, 2, 6, 3
Slicing Mutual Information Generalization Bounds for Neural Networks,5.25, 5.0, 0.4330127018922193, 5, 5, 5, 3, 6, 4, 5, 4
Towards Robust Offline Reinforcement Learning under Diverse Data Corruption,6.5, 6.0, 0.8660254037844386, 6, 5, 6, 4, 6, 4, 8, 3
Distributional Bellman Operators over Mean Embeddings,5.25, 5.0, 1.7853571071357126, 3, 3, 5, 2, 5, 4, 8, 3
On the Identifiability of Switching Dynamical Systems,5.666666666666667, 6.0, 0.4714045207910317, 5, 3, 6, 4, 6, 3
SoundStorm: Efficient Parallel Audio Generation,5.4, 5.0, 1.624807680927192, 5, 4, 6, 3, 5, 5, 3, 3, 8, 5
Hierarchical Empowerment: Towards Tractable Empowerment-Based Skill Learning,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 6, 3, 5, 3
Large Trajectory Models are Scalable Motion Predictors and Planners,5.25, 5.0, 0.4330127018922193, 6, 2, 5, 3, 5, 3, 5, 3
Pre-trained Neural Recommenders: Learning Statistical Representations for Zero-shot Recommender Systems,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 5, 3
Optimization Framework of Transfer Learning and its Feasibility,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 3, 5, 4, 3, 4
Towards Robust Fidelity for Evaluating Explainability of Graph Neural Networks,6.0, 6.5, 2.1213203435596424, 8, 4, 8, 4, 5, 3, 3, 4
Adapt and Diffuse: Sample-adaptive Reconstruction via Latent Diffusion Models,4.5, 4.5, 1.5, 3, 3, 3, 4, 6, 2, 6, 3
Variational Bayesian Last Layers,6.5, 6.5, 2.692582403567252, 8, 4, 10, 4, 3, 4, 5, 4
Piecewise Linear Parametrization of Policies: Towards Interpretable Deep Reinforcement Learning,5.5, 5.5, 1.8027756377319946, 5, 5, 8, 3, 6, 3, 3, 3
Optimal criterion for feature learning of two-layer linear neural network in high dimensional interpolation regime,5.5, 5.5, 1.8027756377319946, 3, 5, 8, 4, 6, 3, 5, 4
Agent Instructs Large Language Models to be General Zero-Shot Reasoners,3.6666666666666665, 5.0, 1.8856180831641267, 5, 5, 1, 5, 5, 4
Neural Optimal Transport with General Cost Functionals,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 3, 5, 3, 6, 4
EQA-MX: Embodied Question Answering using Multimodal Expression,6.25, 7.0, 2.0463381929681126, 8, 3, 6, 3, 3, 4, 8, 4
When Witnesses Defend: A Witness Graph Topological Layer for Adversarial Graph Learning,5.0, 5.0, 0.0, 5, 2, 5, 4
Constrained Variational Generation for Generalizable Graph Learning,5.5, 5.5, 1.8027756377319946, 3, 4, 5, 4, 8, 3, 6, 4
From PDEs to Wingbeats: A Novel Convolutional Fourier Layer-based ResNet Model,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 5, 3, 2, 3, 4
DiracDiffusion: Denoising and Incremental Reconstruction with Assured Data-Consistency,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 3, 5, 4, 5, 4
Reinforcement Learning with Partial Order Representation for Monotonic Physical System,4.0, 4.0, 1.0, 3, 5, 5, 5, 5, 4, 3, 3
ILPO-NET: convolution network for the recognition of arbitrary volumetric patterns,4.5, 5.0, 0.8660254037844386, 3, 3, 5, 3, 5, 2, 5, 4
A Topological Perspective on Demystifying GNN-Based Link Prediction Performance,4.0, 4.0, 1.0, 5, 2, 3, 4, 5, 3, 3, 4
Time-Efficient Reinforcement Learning with Stochastic Stateful Policies,6.0, 5.0, 1.4142135623730951, 5, 4, 8, 4, 5, 3
MI-NeRF: Learning a Single Face NeRF from Multiple Identities,6.0, 6.0, 0.0, 6, 4, 6, 3, 6, 3, 6, 4
Beyond Implicit Bias: The Insignificance of SGD Noise in Online Learning,5.333333333333333, 5.0, 0.4714045207910317, 5, 1, 6, 3, 5, 2
General-Purpose In-Context Learning by Meta-Learning Transformers,3.75, 4.0, 1.920286436967152, 3, 4, 5, 2, 1, 1, 6, 3
Retrieval-based Disentangled Representation Learning with Natural Language Supervision,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 5, 3, 8, 3
Scalable Long Range Propagation on Continuous-Time Dynamic Graphs,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 5, 6, 3, 5, 5
Structured Packing in LLM Training Improves Long Context Utilization,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 3, 6, 4
Planning to Go Out-of-Distribution in Offline-to-Online Reinforcement Learning,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 5, 5, 3
Open the Black Box: Step-based Policy Updates for Temporally-Correlated Episodic Reinforcement Learning,4.0, 4.0, 1.0, 5, 3, 5, 3, 3, 3, 3, 3
Large Language Models as Gaming Agents,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 4, 3, 4
Emergent Communication with Conversational Repair,5.666666666666667, 6.0, 2.0548046676563256, 8, 4, 6, 3, 3, 3
Distributed Training of Large Graph Neural Networks with Variable Communication Rates,nan, nan, nan
Bridging the Gap between Binary Neural Networks and Spiking Neural Networks for Efficient Computer Vision,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 4, 5, 5
Efficient Network Embedding in the Exponentially Large Quantum Hilbert Space: A High-Dimensional Perspective on Embedding,6.0, 6.0, 0.0, 6, 2, 6, 2, 6, 4
Hyperion: Fused Multi-Trial and Gradient Descent for Joint Hyperparameter and Neural Architecture Optimization,3.0, 3.0, 1.4142135623730951, 1, 5, 5, 5, 3, 5, 3, 4
Learning with Instance-Dependent Noisy Labels by Hard Sample Selection with Anchor Hallucination,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 4
Learning Abstract World Models for Value-preserving Planning with Options,4.75, 4.0, 2.0463381929681126, 3, 4, 8, 4, 3, 4, 5, 3
Coresets for Clustering with Noisy Data,5.5, 5.5, 0.5, 5, 4, 5, 4, 6, 4, 6, 3
Policy Learning For Video Streaming,4.0, 4.0, 1.0, 3, 4, 5, 4, 5, 4, 3, 5
Contextual Vision Transformers for Robust Representation Learning,5.25, 5.0, 0.4330127018922193, 6, 2, 5, 4, 5, 3, 5, 4
Unsupervised ASR via Cross-Lingual Pseudo-Labeling,5.0, 5.5, 1.224744871391589, 6, 4, 6, 5, 3, 5, 5, 4
Federated Ensemble-Directed Offline Reinforcement Learning,5.0, 5.5, 1.224744871391589, 6, 3, 3, 4, 6, 4, 5, 3
Latent Representation and Simulation of Markov Processes via Time-Lagged Information Bottleneck,6.666666666666667, 6.0, 0.9428090415820634, 6, 2, 8, 4, 6, 2
ResBit: Residual Bit Vector for Categorical Values,3.0, 3.0, 1.632993161855452, 3, 3, 1, 4, 5, 2
Non-Exchangeable Conformal Risk Control,5.25, 5.0, 1.7853571071357126, 3, 4, 5, 4, 5, 5, 8, 4
Simplifying Self-Supervised Object Detection Pretraining,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 3, 5, 4
Learning From Multi-Expert Demonstrations: A Multi-Objective Inverse Reinforcement Learning Approach,3.5, 3.0, 0.8660254037844386, 3, 3, 5, 4, 3, 4, 3, 4
On the Markov Property of Neural Algorithmic Reasoning: Analyses and Methods,6.8, 6.0, 0.9797958971132712, 6, 3, 8, 3, 8, 4, 6, 3, 6, 4
Provably Efficient UCB-type Algorithms For Learning Predictive State Representations,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 4, 6, 3, 6, 3
Lifting Architectural Constraints of Injective Flows,5.0, 5.5, 1.224744871391589, 3, 4, 6, 5, 5, 4, 6, 5
Provably Accurate ODE Forecasting Through Explicit Trajectory Optimization,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 3, 3, 3, 3, 4
LM-Switch: Transforming Word Embedding Space for Flexible Language Model Steering,5.25, 5.0, 1.7853571071357126, 5, 3, 3, 4, 8, 3, 5, 4
TRAM: Bridging Trust Regions and Sharpness Aware Minimization,5.75, 6.0, 0.4330127018922193, 5, 4, 6, 4, 6, 3, 6, 4
Image Clustering via the Principle of Rate Reduction in the Age of Pretrained Models,5.4, 5.0, 2.244994432064365, 5, 4, 8, 4, 3, 4, 8, 5, 3, 4
Towards Universal Multi-Modal Personalization: A Language Model Empowered Generative Paradigm,5.75, 5.0, 1.299038105676658, 8, 3, 5, 4, 5, 2, 5, 4
The Extrapolation Power of Implicit Models,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 3
Understanding Sparse Feature Updates in Deep Networks using Iterative Linearisation,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 4, 5, 4
Orbit-Equivariant Graph Neural Networks,6.25, 7.0, 2.0463381929681126, 3, 2, 8, 4, 6, 2, 8, 3
VideoFactory: Swap Attention in Spatiotemporal Diffusions for Text-to-Video Generation,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 5, 6, 3, 5, 4
Object-Centric Learning with Slot Mixture Module,6.25, 6.0, 1.0897247358851685, 5, 4, 8, 4, 6, 3, 6, 5
EXCOST: Semi-Supervised Classification with Exemplar-Contrastive Self-Training,4.0, 4.0, 1.0, 5, 4, 3, 4, 3, 3, 5, 3
Enhancing Graph Neural Networks with Quantum Computed Encodings,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 5, 3
Text-Aware Diffusion Policies,3.8, 3.0, 0.9797958971132712, 5, 2, 3, 3, 5, 3, 3, 3, 3, 4
Ring-A-Bell! How Reliable are Concept Removal Methods For Diffusion Models?,5.25, 5.0, 0.4330127018922193, 6, 3, 5, 5, 5, 5, 5, 3
Accelerated Deep Learning by Gaussian Continuation,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 3, 3, 4, 3, 4
Learning Counterfactually Invariant Predictors,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 3, 3, 5
Pi-DUAL: Using privileged information to distinguish clean from noisy labels,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 4, 6, 3
DiffSim: Aligning Diffusion Model and Molecular Dynamics Simulation for Accurate Blind Docking,3.5, 3.0, 0.8660254037844386, 3, 5, 5, 3, 3, 4, 3, 5
More Context Less Distraction: Zero-shot Visual Classification by Inferring and Conditioning on Contextual Attributes,6.0, 5.5, 1.224744871391589, 8, 3, 5, 4, 5, 4, 6, 3
Interpretable Concept Discovery and Learning from Pretrained Vision-Language Models,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 3, 3, 4
A Lennard-Jones Layer for Distribution Normalization,4.25, 4.0, 1.299038105676658, 3, 4, 5, 3, 6, 3, 3, 3
Dissecting Language Models: Machine Unlearning via Selective Pruning,5.5, 5.5, 0.5, 5, 4, 5, 4, 6, 3, 6, 4
ELoRA: Efficient Low-Rank Adaptation with Random Matrices,6.25, 7.0, 2.0463381929681126, 8, 4, 3, 2, 8, 3, 6, 3
Explaining Emergent In-Context Learning as Kernel Regression,4.8, 5.0, 0.9797958971132712, 5, 4, 6, 3, 5, 4, 3, 4, 5, 3
Asymmetric Momentum: A Rethinking of Gradient Descent,3.0, 3.0, 1.4142135623730951, 1, 4, 5, 4, 3, 3, 3, 4
Explaining grokking through circuit efficiency,5.0, 5.5, 1.224744871391589, 6, 4, 3, 5, 5, 4, 6, 4
Lookahead Sharpness-Aware Minimization,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 3, 4, 6, 3
Joint Representations for Reinforcement Learning with Multiple Sensors,5.25, 5.0, 1.7853571071357126, 5, 5, 8, 5, 5, 3, 3, 4
From Interpolation to Extrapolation: Complete Length Generalization for Arithmetic Transformers,5.5, 5.5, 0.5, 6, 4, 6, 4, 5, 4, 5, 4
How far can we go without finetuning?,3.0, 3.0, 1.4142135623730951, 5, 4, 3, 4, 3, 4, 1, 4
AntGPT: Can Large Language Models Help Long-term Action Anticipation from Videos?,5.75, 5.0, 1.299038105676658, 5, 4, 8, 4, 5, 4, 5, 3
A Plug-and-Play Image Registration Network,5.5, 5.5, 1.8027756377319946, 6, 4, 8, 4, 5, 1, 3, 3
BENO: Boundary-embedded Neural Operators for Elliptic PDEs,5.2, 6.0, 1.9390719429665317, 3, 4, 8, 4, 3, 3, 6, 4, 6, 4
What Makes for Good Visual Tokenizers for Large Language Models,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 5, 5, 4
DisCo-DSO: Coupling Discrete and Continuous Optimization for Efficient Generative Design in Hybrid Spaces,4.25, 4.0, 1.299038105676658, 3, 3, 6, 3, 5, 3, 3, 3
Bayesian Neural Controlled Differential Equations for Treatment Effect Estimation,5.5, 5.5, 1.8027756377319946, 5, 3, 8, 3, 6, 3, 3, 3
Stochastic Competition Networks for Deep Learning on Tabular Data,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 3, 2, 5, 3
Disentangling the Link Between Image Statistics and Human Perception,5.25, 5.0, 1.7853571071357126, 5, 5, 5, 4, 8, 3, 3, 4
ARTIST: Towards Disentangled Text Painter with Diffusion Models,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 4, 5, 5, 5, 3
MapLearn: Indoor Mapping using Audio,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 4, 5, 3, 3, 3
Efficiently Quantifying Individual Agent Importance in Cooperative MARL,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 5, 3, 4, 5, 4
3D Interacting Hands Diffusion Model,6.0, 5.5, 1.224744871391589, 5, 5, 8, 3, 5, 5, 6, 4
Aligning Agents like Large Language Models,4.0, 4.0, 1.0, 5, 4, 3, 3, 3, 3, 5, 4
Segment Select Correct: A Framework for Weakly-Supervised Referring Segmentation,4.0, 4.0, 1.0, 5, 3, 5, 3, 3, 5, 3, 4
Identifying Interpretable Features in Convolutional Neural Networks,4.0, 5.0, 1.7320508075688772, 5, 4, 5, 5, 1, 3, 5, 5
Training Socially Aligned Language Models on Simulated Social Interactions,5.8, 6.0, 0.39999999999999997, 6, 3, 6, 3, 6, 3, 6, 3, 5, 3
DynVideo-E: Harnessing Dynamic NeRF for Large-Scale Motion- and View-Change Human-Centric Video Editing,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 5, 5, 4
Language Decision Transformers with Exponential Tilt for Interactive Text Environments,3.0, 3.0, 0.0, 3, 3, 3, 4
The Expressive Leaky Memory Neuron: an Efficient and Expressive Phenomenological Neuron Model Can Solve Long-Horizon Tasks.,6.0, 5.5, 1.224744871391589, 5, 4, 8, 3, 5, 3, 6, 4
Distributed DPHelmet: Differentially Private Non-interactive Convex Blind Averaging,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 3, 3, 4, 5, 4
Incentivized Truthful Communication for Federated Bandits,4.75, 5.0, 1.0897247358851685, 5, 2, 5, 5, 6, 2, 3, 4
What Apples Tell About Oranges: Connecting Pruning Masks and Hessian Eigenspaces,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 3, 5, 3, 3, 4
Learning Graph Representations via Graph Entropy Maximization,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 4, 5, 3, 6, 3
Large-scale training of foundation models for wearable biosignals,6.75, 7.0, 1.299038105676658, 8, 5, 5, 4, 8, 5, 6, 5
The Central Spanning Tree Problem,4.25, 4.0, 1.299038105676658, 3, 3, 3, 4, 5, 4, 6, 3
Sparkles: Unlocking Chats Across Multiple Images for Multimodal Instruction-Following Models,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 6, 3, 5, 4
Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization,6.25, 6.0, 1.0897247358851685, 5, 4, 6, 4, 8, 2, 6, 2
Language Conditioned Equivariant Grasp,4.6, 5.0, 1.3564659966250536, 3, 3, 6, 2, 6, 3, 3, 4, 5, 3
Adaptive Knowledge Transfer for Generalized Category Discovery,5.8, 5.0, 1.16619037896906, 5, 5, 5, 4, 6, 3, 5, 4, 8, 4
Learning Multi-Objective Program Through Online Learning,3.0, 3.0, 0.0, 3, 3, 3, 2, 3, 3
FedEve: On Bridging the Client Drift and Period Drift for Cross-device Federated Learning,4.5, 4.5, 1.5, 6, 4, 3, 4
Contractive Systems Improve Graph Neural Networks Against Adversarial Attacks,5.5, 5.5, 0.5, 5, 4, 5, 4, 6, 1, 6, 2
On Trajectory Augmentations for Off-Policy Evaluation,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 4
Rethinking the Noise Schedule of Diffusion-Based Generative Models,5.5, 5.5, 1.5, 6, 3, 5, 4, 5, 3, 8, 4, 6, 3, 3, 4
Efficient Certification of Physics-Informed Neural Networks,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 3, 5, 4, 5, 3
A Note on Some Statistical Properties of Signature Transform Under Stochastic Integrals,5.75, 5.0, 1.299038105676658, 5, 3, 5, 2, 5, 3, 8, 4
Part-based bird classifiers with an explainable editable language bottleneck,4.25, 4.0, 1.299038105676658, 6, 3, 5, 4, 3, 5, 3, 2
DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing,5.0, 6.0, 1.4142135623730951, 6, 4, 6, 4, 3, 5
Federated Wasserstein Distance,5.0, 5.5, 1.224744871391589, 6, 4, 6, 4, 3, 4, 5, 3
Leveraging Heterogeneous Side Information via Diffusion Models for Time-series Anomaly Detection,4.333333333333333, 5.0, 0.9428090415820634, 3, 3, 5, 4, 5, 4
A Pipeline-Based Approach for Object Detection on Resource Constrained Internet of Things Devices,1.6666666666666667, 1.0, 0.9428090415820634, 1, 5, 1, 5, 3, 3
LNL+K: Enhancing Learning with Noisy Labels Through Noise Source Knowledge Integration,3.4, 3.0, 1.4966629547095767, 1, 4, 5, 4, 3, 5, 5, 5, 3, 2
Variance-Reduced Meta-Learning via Laplace Approximation,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 5, 4, 6, 3
Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D,5.25, 6.0, 2.5860201081971503, 6, 4, 6, 3, 8, 3, 1, 4
Fit Like You Sample: Sample-Efficient Generalized Score Matching from Fast Mixing Diffusions,6.0, 5.0, 1.4142135623730951, 5, 2, 5, 2, 8, 3
Injecting a Structural Inductive Bias into a Seq2Seq Model by Simulation,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 6, 3, 5, 2
Adversarial Imitation Learning from Visual Observations using Latent Information,5.333333333333333, 5.0, 2.0548046676563256, 5, 3, 3, 4, 8, 5
Meta-Referential Games to Learn Compositional Learning Behaviours,5.5, 5.5, 0.5, 6, 3, 6, 3, 5, 3, 5, 2
Non-Vacuous Generalization Bounds for Large Language Models,6.4, 6.0, 1.3564659966250536, 5, 3, 8, 2, 6, 4, 5, 3, 8, 3
Clifford Group Equivariant Simplicial Message Passing Networks,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 3, 6, 3
Efficient calibration as a binary top-versus-all problem for classifiers with many classes,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 6, 3, 3, 3
Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation,5.0, 5.5, 1.224744871391589, 6, 4, 6, 3, 5, 4, 3, 4
RL Simplex: Bringing Computational Efficiency in Linear Programming via Reinforcement Learning,3.25, 3.0, 1.7853571071357126, 3, 5, 6, 2, 1, 5, 3, 3
Regulating the level of manipulation in text augmentation with systematic adjustment and advanced sentence-embedding,3.25, 3.0, 1.7853571071357126, 3, 4, 1, 4, 6, 4, 3, 4
The (co)limit of metabeliefs,5.2, 5.0, 1.6, 5, 3, 5, 2, 5, 1, 3, 4, 8, 4
FTFT: efficient and robust Fine-Tuning by transFerring Training dynamics,4.0, 4.0, 1.0, 3, 3, 5, 4, 5, 3, 3, 4
CAUSAL NEURAL NETWORKS FOR CONTINUOUS TREATMENT EFFECT ESTIMATION,3.4, 3.0, 0.8000000000000002, 3, 4, 5, 4, 3, 4, 3, 4, 3, 4
On Using Admissible Bounds for Learning Forward Search Heuristics,5.0, 5.0, 1.8973665961010275, 3, 3, 3, 2, 8, 3, 6, 4, 5, 3
MultiContrievers: Analysis of Dense Retrieval Representations,4.25, 4.0, 1.299038105676658, 3, 3, 5, 4, 3, 3, 6, 4
Vision-by-Language for Training-Free Compositional Image Retrieval,5.0, 5.0, 0.0, 5, 5, 5, 4, 5, 4, 5, 4
Benign Oscillation of Stochastic Gradient Descent with Large Learning Rate,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 6, 3, 8, 3
RobustTSF: Towards Theory and Design of Robust Time Series Forecasting with Anomalies,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 3, 3, 6, 4
Typing to Listen at the Cocktail Party: Text-Guided Target Speaker Extraction,5.5, 5.5, 1.8027756377319946, 3, 4, 5, 4, 8, 5, 6, 4
SMPE: A Framework for Multi-Dimensional Permutation Equivariance,5.75, 6.0, 0.4330127018922193, 6, 2, 6, 4, 6, 3, 5, 2
Model-Based Transfer RL with Task-Agnostic Offline Pretraining,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 3, 5, 4
Targeted Model Inversion: Distilling Style Encoded in Predictions,5.25, 5.0, 1.7853571071357126, 3, 2, 5, 5, 8, 4, 5, 3
Understanding the Effects of RLHF on LLM Generalisation and Diversity,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 6, 4, 8, 4
CAMIL: Context-Aware Multiple Instance Learning for Cancer Detection and Subtyping in Whole Slide Images,6.0, 5.5, 1.224744871391589, 6, 4, 5, 3, 5, 4, 8, 4
Multi-Level Contrastive Learning for Dense Prediction Task,4.75, 5.0, 1.0897247358851685, 5, 5, 6, 4, 5, 5, 3, 5
Model-Decoupling-Based Federated Learning with Consistency via Knowledge Distillation Using Conditional Generator,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 3, 5, 5, 6, 3
Theoretical Hardness and Tractability of POMDPs in RL with Partial Online State Information,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 5, 3, 6, 3
GAIA: Data-driven Zero-shot Talking Avatar Generation,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 3, 5, 5, 6, 4
Equivariant Quantum Graph Neural Network for Mixed-Integer Linear Programming,4.25, 3.0, 2.165063509461097, 3, 3, 3, 4, 3, 3, 8, 4
Accelerating Diffusion Models for Inverse Problems through Shortcut Sampling,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 2, 3, 3
Learning Team-Level Information Integration in Multi-Agent Communication,4.0, 4.0, 1.0, 5, 4, 3, 2, 5, 5, 3, 4
Are machines automating morality?,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 2, 3, 3
Adaptive Learning of Quantum Hamiltonians,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 3, 6, 3, 5, 3
3D Tissue Reconstruction and Generation for Single-Cell Spatial Transcriptomics using Neural Radiance Fields,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 3
DyST: Towards Dynamic Neural Scene Representations on Real-World Videos,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 6, 3, 8, 3
Graph layouts and graph contrastive learning via neighbour embeddings,4.666666666666667, 5.0, 1.247219128924647, 6, 2, 3, 4, 5, 3
Off-the-Grid MARL: Datasets with Baselines for Offline Multi-Agent Reinforcement Learning,5.0, 5.5, 1.224744871391589, 3, 4, 5, 5, 6, 3, 6, 3
The Devil is in the Edges: Monocular Depth Estimation with Edge-aware Consistency Fusion,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 3, 5, 5
Probabilistic Self-supervised Representation Learning via Scoring Rules Minimization,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 5, 5, 3
IMPLICIT STACKED AUTOREGRESSIVE MODEL FOR WEATHER FORECASTING,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 5, 4
Radar Spectra-language Model for Automotive Scene Parsing,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 6, 3, 3, 4
DORSal: Diffusion for Object-centric Representations of Scenes $\textit{et al.}$,5.0, 5.5, 1.224744871391589, 5, 4, 6, 4, 6, 3, 3, 4
Mark My Words: Repurposing LLMs for Specialized Domains via Ability Tokens,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 4
Estimating Post-Synaptic Effects for Online Training of Feed-Forward SNNs,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 3
ODEdit: Blind Face Restoration through Ordinary Differential Equations,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 5, 5, 4, 3, 3
SummaryMixing: A Linear-Complexity Alternative to Self-Attention for Speech Recognition and Understanding,4.75, 4.0, 2.0463381929681126, 3, 4, 5, 4, 8, 5, 3, 5
Quantifying and Defending against the Privacy Risk in Logit-based Federated Learning,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 5, 6, 3, 5, 3
Fool Your Large (Vision and) Language Models with Embarrassingly Simple Permutations,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 4, 5, 3
Subgraph Mining for Graph Neural Networks,3.75, 3.0, 1.299038105676658, 6, 3, 3, 4, 3, 3, 3, 5
Sparse MoE as a New Treatment: Addressing Forgetting Fitting Learning Issues in Multi-Modal Multi-Task Learning,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 4, 6, 3, 5, 4
Sparse Cocktail: Every Sparse Pattern Every Sparse Ratio All At Once,5.666666666666667, 6.0, 2.0548046676563256, 6, 4, 8, 4, 3, 3
PeriodNet:Lightweight And Efficient Time Series Prediction Model Based On Periodic Characteristics,2.5, 3.0, 0.8660254037844386, 3, 4, 1, 4, 3, 4, 3, 4
DOMAIN-GROUNDING OF NEURAL NETWORKS FOR SPATIOTEMPORAL REASONING,3.25, 3.0, 1.7853571071357126, 3, 2, 1, 3, 6, 3, 3, 4
Protecting Sensitive Data through Federated Co-Training,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 4, 5, 4
T-Rep: Representation Learning for Time Series using Time-Embeddings,5.0, 5.0, 1.0954451150103321, 3, 4, 6, 3, 5, 5, 6, 4, 5, 4
Variational Inference with Singularity-Free Planar Flows,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 5, 6, 3, 5, 5
Looping LOCI: Developing Object Permanence from Videos,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 4, 3, 4
Knowledge Accumulation in Continually Learned Representations and the Issue of Feature Forgetting,3.75, 3.0, 1.299038105676658, 3, 4, 6, 5, 3, 5, 3, 4
Computing high-dimensional optimal transport by flow neural networks,4.2, 5.0, 0.9797958971132712, 5, 3, 3, 4, 3, 4, 5, 4, 5, 4
WEAR: An Outdoor Sports Dataset for Wearable and Egocentric Activity Recognition,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 3, 6, 3, 3, 4
Clustering with Geometric Modularity,5.0, 4.5, 2.1213203435596424, 8, 4, 3, 3, 3, 4, 6, 4
Complexity-Limited Multi-Task Training for Compositional Emergent Communication,3.0, 3.0, 0.0, 3, 3, 3, 1, 3, 3
Diffusion Models for Open-Vocabulary Segmentation,5.0, 5.5, 1.224744871391589, 6, 5, 5, 3, 6, 3, 3, 4
Audio Image Generation for Denoising,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 3, 4, 5, 4
Segmenting the Unknown: Discrete Diffusion Models for Non-Deterministic Segmentation,3.6666666666666665, 5.0, 1.8856180831641267, 1, 5, 5, 4, 5, 3
Improving Sample Efficiency of Model-Free Algorithms for Zero-Sum Markov Games,5.25, 5.0, 0.4330127018922193, 5, 3, 6, 3, 5, 4, 5, 2
Closed-Form Diffusion Models,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 3, 5, 5, 5, 4
MorphGrower: A Synchronized Layer-by-layer Growing Approach for Plausible and Diverse Neuronal Morphology Generation,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 3, 6, 3
JOSENet: A Joint Stream Embedding Network for Violence Detection in Surveillance Videos,3.75, 3.0, 1.299038105676658, 6, 4, 3, 3, 3, 4, 3, 3
ParFam - Symbolic Regression Based on Continuous Global Optimization,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 2, 3, 3, 5, 4
On partial prototype collapse in clustering-based self-supervised learning,5.0, 5.5, 1.224744871391589, 6, 4, 3, 5, 6, 4, 5, 4
Bilevel Optimization under Unbounded Smoothness: A New Algorithm and Convergence Analysis,5.4, 5.0, 1.624807680927192, 5, 4, 5, 3, 3, 4, 6, 3, 8, 4
LLaVA-Plus: Learning to Use Tools for Creating Multimodal Agents,5.0, 4.5, 2.1213203435596424, 8, 4, 3, 4, 6, 3, 3, 5
SINGLE-IMAGE COHERENT RECONSTRUCTION OF OBJECTS AND HUMANS,4.25, 4.0, 1.299038105676658, 5, 3, 3, 2, 6, 4, 3, 5
Enhancing the Cross-Size Generalization for Solving Vehicle Routing Problems via Continual Learning,4.666666666666667, 5.0, 1.247219128924647, 6, 2, 5, 4, 3, 4
Is Memorization Actually Necessary for Generalization?,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 3, 5, 6, 3
Beyond Stationarity: Convergence Analysis of Stochastic Softmax Policy Gradient Methods,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 8, 3, 6, 3
End-to-End Training of  Unsupervised Trees: KAURI and DOUGLAS,3.5, 3.0, 0.8660254037844386, 3, 3, 5, 3, 3, 4, 3, 4
Diffusion Random Feature Model,4.166666666666667, 4.0, 1.2133516482134197, 5, 4, 3, 5, 3, 4, 6, 3, 3, 4, 5, 3
ResiDual: Transformer with Dual Residual Connections,4.6, 5.0, 1.8547236990991407, 6, 3, 5, 3, 1, 5, 6, 2, 5, 3
Ask Your Distribution Shift if Pre-Training is Right for You,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 3, 3, 4
SliceGPT: Compress Large Language Models by Deleting Rows and Columns,5.0, 5.0, 1.0954451150103321, 3, 4, 6, 4, 6, 4, 5, 3, 5, 5
Revealing The Intrinsic Ability of Generative Text Summarizers for Outlier Paragraph Detection,2.5, 3.0, 0.8660254037844386, 3, 3, 1, 4, 3, 4, 3, 3
Ada-Instruct: Adapting Instruction Generators For Complex Reasoning,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 4, 5, 3
Enhancing Robustness of Visual Object Localization by Introducing Retina-Inspired Mapping to Convolutional Neural Networks,3.0, 3.0, 1.4142135623730951, 1, 4, 5, 4, 3, 5, 3, 5
Experimental Design for Multi-Channel Imaging via Task-Driven Feature Selection,6.0, 6.0, 0.0, 6, 2, 6, 3, 6, 3, 6, 2
Revisiting the Static Model in Robust Reinforcement Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 3, 5, 2
Subword embedding from bytes against embedding-based attacks,6.0, 5.0, 1.4142135623730951, 5, 3, 8, 4, 5, 3
Bounds on Representation-Induced Confounding Bias for Treatment Effect Estimation,5.75, 5.0, 1.299038105676658, 5, 3, 5, 2, 5, 4, 8, 4
Convolutional Deep Kernel Machines,5.25, 5.0, 0.4330127018922193, 6, 3, 5, 4, 5, 3, 5, 4
From Malicious to Marvelous: The Art of Adversarial Attack as Diffusion,4.5, 4.5, 2.692582403567252, 1, 4, 6, 4, 3, 4, 8, 4
Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 5, 5, 4, 6, 3
Random Walk Diffusion For Graph Generation,4.5, 4.5, 1.5, 3, 5, 6, 4, 3, 4, 6, 4
Chain-of-Experts: When LLMs Meet Complex Operations Research Problems,5.5, 5.5, 1.8027756377319946, 3, 3, 6, 4, 8, 4, 5, 4
On the Reliability of Watermarks for Large Language Models,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 4, 6, 5
Objectives Are All You Need: Solving Deceptive Problems Without Explicit Diversity Maintenance,4.0, 3.0, 1.4142135623730951, 3, 2, 3, 4, 6, 4
Nash Equilibria in Reward-Potential Markov Games: Algorithms Complexity and Applications,4.6, 5.0, 0.7999999999999999, 5, 4, 3, 4, 5, 2, 5, 4, 5, 3
Near-Optimal Solutions of Constrained Learning Problems,5.2, 6.0, 1.16619037896906, 5, 3, 6, 3, 6, 3, 3, 2, 6, 4
Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding,6.0, 5.5, 1.224744871391589, 6, 2, 5, 4, 5, 3, 8, 4
VIDEOPROMPTER: AN ENSEMBLE OF FOUNDATIONAL MODELS FOR ZERO-SHOT VIDEO UNDERSTANDING,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 5, 5, 4, 5, 3
Counterfactual Fairness for Predictions using Generative Adversarial Networks,4.0, 4.0, 1.0, 5, 3, 3, 4, 5, 4, 3, 5
Comprehensive Comparison between Vision Transformers and Convolutional Neural Networks for Face Recognition Tasks,4.25, 4.0, 1.299038105676658, 3, 4, 5, 5, 6, 4, 3, 5
Leave-one-out Distinguishability in Machine Learning,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 3, 6, 2
TopoFormer: Topology-aware Transformer for Reactive Motion Prediction in Close Interactions,4.0, 4.0, 1.0, 5, 3, 3, 4, 3, 4, 5, 4
NaviFormer: A Deep Reinforcement Learning Transformer-like Model to Holistically Solve the Navigation Problem,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 4, 5, 3
Transformers Get Stable: An End-to-End Signal Propagation Theory for Language Models,5.0, 5.5, 1.224744871391589, 3, 4, 6, 2, 5, 4, 6, 3
EHI: End-to-end learning of Hierarchical Index for Efficient Dense Retrieval,5.5, 5.5, 1.8027756377319946, 3, 5, 6, 4, 8, 3, 5, 4
Distilling ODE Solvers of Diffusion Models into Smaller Steps,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 4
Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 3, 6, 3
Brain decoding: toward real-time reconstruction of visual perception,6.0, 5.5, 1.224744871391589, 6, 4, 8, 4, 5, 4, 5, 4
Linear Log-Normal Attention with Unbiased Concentration,5.75, 5.0, 1.299038105676658, 5, 3, 5, 4, 5, 4, 8, 3
Copyright Plug-in Market for The Text-to-Image Copyright Protection,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 2, 6, 3
Learning to Count without Annotations,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 5, 3, 4
Understanding Parameter Saliency via Extreme Value Theory,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 2
A Demon at Work: Leveraging Neuron Death for Efficient Neural Network Pruning,4.0, 4.0, 1.0, 3, 3, 5, 4, 5, 3, 3, 3
Exploiting Implicit Rigidity Constraints via Weight-Sharing Aggregation for Scene Flow Estimation from Point Clouds,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 4, 6, 3
Block-local learning with probabilistic latent representations,5.0, 5.0, 0.0, 5, 2, 5, 5, 5, 3, 5, 3
Non-ergodicity in reinforcement learning: robustness via ergodic transformations,3.4, 3.0, 1.4966629547095767, 3, 3, 1, 4, 3, 4, 5, 3, 5, 3
Model Explanation Disparities as a Fairness Diagnostic,5.0, 5.0, 1.0954451150103321, 5, 2, 3, 4, 5, 2, 6, 3, 6, 4
Retro: Reusing teacher projection head for efficient embedding distillation on Lightweight Models via Self-supervised Learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 5
Diffusion Models for Tabular Data Imputation and Synthetic Data Generation,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 4, 5, 5, 6, 5
CodeIt: Abstract Reasoning with Iterative Policy-Guided Program Synthesis,5.5, 5.5, 0.5, 6, 5, 6, 4, 5, 4, 5, 3
DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 8, 4, 6, 3
From Categories to Classifier: Name-Only Continual Learning by Exploring the Web,5.0, 5.0, 1.0954451150103321, 3, 4, 5, 5, 6, 5, 5, 2, 6, 4
Solving Multiobjective Combinatorial Optimization via Learn to Improve Method,5.5, 6.5, 2.8722813232690143, 5, 4, 8, 3, 8, 4, 1, 3
Multi-Fidelity Active Learning with GFlowNets,5.0, 4.5, 2.1213203435596424, 8, 3, 6, 4, 3, 4, 3, 4
United We Train Divided We Fail! Representation Learning for Time Series by Pretraining from 75 Datasets at Once,3.75, 3.0, 1.299038105676658, 6, 4, 3, 4, 3, 4, 3, 3
Impact of Computation in Integral Reinforcement Learning for Continuous-Time Control,6.25, 6.0, 1.0897247358851685, 8, 3, 6, 2, 6, 2, 5, 3
Prioritized Soft Q-Decomposition for Lexicographic Reinforcement Learning,5.0, 6.0, 1.4142135623730951, 6, 3, 3, 4, 6, 4
FedGT: Identification of Malicious Clients in Federated Learning with Secure Aggregation,4.5, 4.5, 1.5, 3, 3, 6, 2, 6, 4, 3, 3
Energy-guided Entropic Neural Optimal Transport,6.0, 6.0, 0.0, 6, 3, 6, 3, 6, 3
IDEA: Invariant Causal Defense for Graph Adversarial Robustness,5.25, 5.0, 0.4330127018922193, 5, 3, 6, 2, 5, 3, 5, 2
ZeroI2V: Zero-Cost Adaptation of Pre-Trained Transformers from Image to Video,6.0, 5.5, 1.224744871391589, 5, 4, 5, 3, 6, 3, 8, 4
Spike Accumulation Forwarding for Effective Training of Spiking Neural Networks,4.0, 4.0, 1.0, 5, 5, 3, 4, 3, 4, 5, 3
A Symbolic Framework for Evaluating Mathematical Reasoning with Transformers,4.5, 4.5, 1.5, 6, 3, 3, 3, 3, 3, 6, 4
Zipformer: A faster and better encoder for automatic speech recognition,7.5, 8.0, 0.8660254037844386, 8, 4, 6, 5, 8, 5, 8, 4
Can Synthetic Data Reduce Conservatism of Distributionally Robust Adversarial Training?,nan, nan, nan
Self Semi and Fully Supervised Training for Autoencoders using Ternary Classification,2.3333333333333335, 3.0, 0.9428090415820634, 1, 5, 3, 4, 3, 4
Learning Semantic Proxies from Visual Prompts for Parameter-Efficient Fine-Tuning in Deep Metric Learning,6.333333333333333, 6.0, 1.247219128924647, 6, 3, 8, 4, 5, 3
Adversarial latent representation for positive unlabeled learning,3.75, 3.0, 1.299038105676658, 3, 3, 3, 4, 3, 4, 6, 4
Enhancing Offline Reinforcement Learning with an Optimal Supported Dataset,5.0, 5.0, 1.7320508075688772, 3, 2, 5, 4, 5, 3, 6, 4, 8, 2, 3, 3
Fine-Tuned Language Models Generate Stable Inorganic Materials as Text,5.666666666666667, 6.0, 0.4714045207910317, 6, 5, 5, 3, 6, 3
TextField3D: Towards Enhancing Open-Vocabulary 3D Generation with Noisy Text Fields,6.0, 5.0, 1.4142135623730951, 5, 4, 5, 5, 8, 3
Non-uniform Noise Injection For Enhancing DNN Adversarial Robustness And Efficiency,4.25, 4.0, 1.299038105676658, 3, 5, 6, 4, 5, 2, 3, 4
Fishnets: Information-Optimal Scalable Aggregation for Sets and Graphs,4.285714285714286, 5.0, 1.1605769149479943, 3, 2, 3, 4, 5, 4, 3, 4, 6, 2, 5, 4, 5, 3
UniVis: A Universal Framework for Computer Vision Tasks,5.75, 5.0, 1.299038105676658, 5, 4, 5, 4, 8, 3, 5, 4
Zero-shot Cross-task Preference Alignment for Offline RL via Optimal Transport,4.0, 4.0, 1.0, 5, 3, 5, 4, 3, 3, 3, 4
Efficient Hyperparameter Optimization with Adaptive Fidelity Identification,4.666666666666667, 5.0, 1.247219128924647, 3, 5, 6, 4, 5, 3
Masks Signs And Learning Rate Rewinding,5.666666666666667, 6.0, 0.4714045207910317, 5, 3, 6, 4, 6, 3
Homotopy Relaxation Training Algorithms for Infinite-Width Two-Layer ReLU Neural Networks,3.0, 3.0, 0.0, 3, 3, 3, 4, 3, 3
GlucoBench: Curated List of Continuous Glucose Monitoring Datasets with Prediction Benchmarks,6.0, 5.0, 1.4142135623730951, 5, 4, 5, 3, 8, 4
Multimodal Chain-of-Thought Reasoning in Language Models,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 3, 5, 4, 6, 4
Aligning brain functions boosts the decoding of videos in novel subjects,4.25, 4.0, 1.299038105676658, 3, 4, 3, 3, 6, 3, 5, 3
Quantifying and Enhancing Multi-modal Robustness with Modality Preference,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 3, 6, 4
FedGP: Buffer-based Gradient Projection for Continual Federated Learning,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 3
EXPLAIN AGREE and LEARN: A Recipe for Scalable Neural-Symbolic Learning,4.0, 4.0, 1.0, 5, 2, 3, 4, 3, 4, 5, 4
Data Distribution Valuation with Incentive Compatibility,2.0, 2.0, 1.0, 3, 3, 1, 4
Adversarial Machine Learning in Latent Representations of Neural Networks,4.4, 5.0, 1.2, 3, 4, 5, 5, 6, 3, 5, 3, 3, 4
Towards reporting bias in visual-language datasets: bimodal augmentation by decoupling object-attribute association,5.5, 5.5, 0.5, 5, 4, 6, 3, 6, 5, 5, 3
Advancing the Lower Bounds: an Accelerated Stochastic Second-order Method with Optimal Adaptation to Inexactness,4.75, 6.0, 2.165063509461097, 6, 3, 6, 4, 1, 5, 6, 3
Transformers vs. Message Passing GNNs: Distinguished in Uniform,5.75, 6.0, 1.7853571071357126, 6, 2, 8, 4, 3, 3, 6, 3
Faster Approximation of Probabilistic and Distributional Values via Least Squares,6.25, 6.0, 1.0897247358851685, 5, 4, 6, 3, 8, 2, 6, 3
A Reparameterized Discrete Diffusion Model for Text Generation,5.5, 5.5, 1.8027756377319946, 8, 4, 5, 4, 3, 4, 6, 5
SCALE: Synergized Collaboration of Asymmetric Language Translation Engines,5.0, 6.0, 1.4142135623730951, 3, 5, 6, 4, 6, 4
Intuitive or Dependent? Investigating LLms’ Robustness to Conflicting Prompts,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 3, 3, 3
Rigid Protein-Protein Docking via Equivariant Elliptic-Paraboloid Interface Prediction,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 6, 3, 8, 3
A Bayesian Framework for Clustered Federated Learning,5.0, 5.0, 0.0, 5, 2, 5, 3
OpenPatch: a 3D patchwork for Out-Of-Distribution detection,3.75, 3.0, 1.299038105676658, 6, 2, 3, 3, 3, 4, 3, 4
Improved Algorithms for Replicable Bandits,4.0, 4.0, 1.0, 5, 4, 3, 3, 5, 5, 3, 5
Explaining recommendation systems through contrapositive perturbations,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 2
Gradual Domain Adaptation via Gradient Flow,6.0, 6.0, 0.0, 6, 4, 6, 3, 6, 2, 6, 4
AttributionLab: Faithfulness of Feature Attribution Under Controllable Environments,5.5, 5.5, 0.5, 6, 4, 5, 2, 6, 2, 5, 4
HIPODE: Enhancing Offline Reinforcement Learning with High-Quality Synthetic Data from a Policy-Decoupled Approach,5.0, 5.5, 1.224744871391589, 6, 4, 5, 5, 6, 4, 3, 5
Adversarial Attacks as Near-Zero Eigenvalues in The Empirical Kernel of Neural Networks,5.25, 5.0, 0.4330127018922193, 6, 3, 5, 3, 5, 3, 5, 2
A Theoretically Grounded Extension of Universal Attacks from the Attacker's Viewpoint,4.0, 4.0, 1.0, 5, 4, 3, 4, 3, 3, 5, 4
Learning Multi-modal Representations Under Incomplete Data Via Dual Level Alignments,3.0, 3.0, 0.0, 3, 3, 3, 2, 3, 5, 3, 4
EduGym: An Environment Suite for Reinforcement Learning Education,4.0, 3.0, 1.2649110640673518, 6, 3, 3, 5, 5, 4, 3, 3, 3, 4
Spatio-Temporal Graph Knowledge Distillation,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 4, 5, 3, 3, 3
Incentive-Aware Federated Learning with Training-Time Model Rewards,5.0, 5.5, 1.224744871391589, 6, 2, 6, 3, 5, 2, 3, 3
DynaEval: A Dynamic Interaction-based Evaluation Framework for Assessing LLMs in Real-world Scenarios,4.75, 4.0, 2.0463381929681126, 3, 2, 5, 4, 8, 3, 3, 4
On Gaussian Mixture Models,3.6, 3.0, 1.7435595774162693, 6, 3, 3, 5, 3, 4, 1, 3, 5, 2
Removing Biases from Molecular Representations via Information Maximization,5.5, 5.5, 1.8027756377319946, 6, 2, 8, 3, 3, 3, 5, 3
Sequential Condition Evolved Interaction Knowledge Graph for Traditional Chinese Medicine Recommendation,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 3, 5, 3, 5, 4
Neural Architecture Retrieval,7.333333333333333, 8.0, 0.9428090415820634, 8, 5, 8, 5, 6, 5
DAG-based Generative Regression,3.0, 3.0, 0.0, 3, 3, 3, 5, 3, 3, 3, 4, 3, 4
Early Neuron Alignment in Two-layer ReLU Networks with Small Initialization,6.0, 5.5, 1.224744871391589, 5, 3, 8, 4, 5, 3, 6, 4
Rethinking the Uniformity Metric in Self-Supervised Learning,5.5, 5.5, 1.8027756377319946, 5, 4, 3, 5, 6, 2, 8, 3
Maximum Entropy Heterogeneous-Agent Reinforcement Learning,6.75, 7.0, 1.299038105676658, 8, 4, 5, 3, 6, 5, 8, 3
Rethinking Semantic Few-Shot Image Classification,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 5, 3, 4, 5, 4
Data augmentation guided Decouple Knowledge Distillation for low-resolution fine-grained image classification,3.5, 3.0, 0.8660254037844386, 3, 5, 5, 3, 3, 4, 3, 3
Rethinking Self-Supervise Learning: An Instance-wise Similarity Perspective,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 5
DiffFlow: A Unified SDE for Score-Based Diffusion Models and Generative Adversarial Networks,5.0, 5.5, 1.224744871391589, 6, 3, 5, 3, 6, 3, 3, 4
Evaluating model bias requires characterizing model mistakes,5.75, 5.0, 1.299038105676658, 8, 2, 5, 4, 5, 4, 5, 4
URRL-IMVC: Unified and Robust Representation Learning for Incomplete Multi-View Clustering,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 3, 5, 5
Learning Decentralized Partially Observable Mean Field Control for Artificial Collective Behavior,5.666666666666667, 6.0, 2.0548046676563256, 6, 2, 3, 2, 8, 3
ExoViP: Step-by-step Verification and Exploration with Exoskeleton Modules for Compositional Visual Reasoning,5.5, 5.5, 0.5, 6, 2, 5, 3, 5, 5, 6, 3
TAB: Temporal Accumulated Batch Normalization in Spiking Neural Networks,5.0, 5.5, 1.224744871391589, 6, 4, 3, 5, 5, 3, 6, 3
Catch the Shadow: Automatic Shadow Variables Generation for Treatment Effect Estimation under Collider Bias,6.25, 7.0, 2.0463381929681126, 3, 3, 8, 4, 8, 4, 6, 3
The Unreasonable Effectiveness of Pretraining in Graph OOD,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 4, 3, 4
StructComp: Substituting propagation with Structural Compression in Training Graph Contrastive Learning,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 3, 5, 3
Central Force Field: Unifying Generative and Discriminative Models While Harmonizing Energy-Based and Score-Based Models,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4
Using Forwards-Backwards Models to Approximate MDP Homomorphisms,3.75, 3.0, 1.299038105676658, 3, 2, 3, 4, 3, 4, 6, 3
Hybrid Directional Graph Neural Network for Molecules,5.333333333333333, 5.0, 2.0548046676563256, 5, 3, 8, 2, 3, 4
Perfect Alignment May be Poisonous to Graph Contrastive Learning,5.6, 6.0, 1.624807680927192, 3, 5, 6, 3, 6, 3, 8, 4, 5, 4
Communication-Efficient Heterogeneous Federated Learning with Generalized Heavy-Ball Momentum,4.5, 4.5, 1.5, 3, 5, 3, 3, 6, 4, 6, 4
When Treatment Effect Estimation Meets Collider Bias: A Dual Counterfactual Generative Approach,4.25, 4.0, 1.299038105676658, 3, 3, 6, 4, 3, 5, 5, 3
Particle Guidance: non-I.I.D. Diverse Sampling with Diffusion Models,5.5, 5.5, 0.5, 5, 5, 5, 4, 6, 4, 6, 4
On Adversarial Training without Perturbing all Examples,5.75, 6.0, 1.7853571071357126, 3, 4, 6, 3, 8, 4, 6, 3
Diving Segmentation Model into Pixels,6.0, 6.0, 0.0, 6, 3, 6, 3, 6, 3, 6, 3
Collaborative Prompt Tuning for Black-Box Vision-Language Models,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 2, 5, 3
Unified Long-Term Time-Series Forecasting  Benchmark,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 2, 3, 4
General Stability Analysis for Zeroth-Order Optimization Algorithms,6.25, 7.0, 2.0463381929681126, 8, 3, 8, 3, 3, 4, 6, 4
Hybrid Sharing for Multi-Label Image Classification,5.0, 5.0, 0.0, 5, 5, 5, 5, 5, 4
Symmetric Single Index Learning,6.25, 6.0, 1.0897247358851685, 6, 4, 8, 3, 5, 4, 6, 2
An improved analysis of per-sample and per-update clipping in federated learning,5.4, 5.0, 0.48989794855663565, 6, 2, 6, 3, 5, 3, 5, 4, 5, 5
Sample-Efficiency in Multi-Batch Reinforcement Learning: The Need for Dimension-Dependent Adaptivity,6.333333333333333, 6.0, 1.247219128924647, 8, 3, 5, 3, 6, 2
Benchmarking Diffusion Based Text-Guided Image Editing Methods,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 5, 4, 6, 3
MetaGPT: Meta Programming for Multi-Agent Collaborative Framework,6.5, 6.5, 1.5, 8, 4, 5, 2
On the Power of the Weisfeiler-Leman Test for Graph Motif Parameters,6.25, 6.0, 1.0897247358851685, 6, 2, 6, 4, 8, 2, 5, 3
On convex decision regions in deep network representations,4.5, 5.0, 0.8660254037844386, 5, 2, 3, 4, 5, 3, 5, 3
Unbiased Watermark for Large Language Models,6.2, 6.0, 0.9797958971132712, 6, 3, 6, 4, 6, 1, 8, 4, 5, 4
Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust Closed-Loop Control,6.0, 5.5, 1.224744871391589, 8, 3, 5, 2, 6, 4, 5, 2
Enhancing Mutual Information Estimation in Self-Interpretable Graph Neural Networks,5.5, 5.5, 0.5, 5, 4, 6, 2, 6, 3, 5, 3
The Underlying Scaling Laws and Universal Statistical Structure of Complex Datasets,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 4, 5, 3
PAC Prediction Sets Under Label Shift,5.8, 5.0, 1.16619037896906, 8, 4, 5, 3, 5, 3, 5, 3, 6, 3
PREDICTING ACCURATE LAGRANGIAN MULTIPLIERS FOR MIXED INTEGER LINEAR PROGRAMS,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 3, 3, 4
FedNovel: Federated Novel Class Learning,5.5, 5.5, 1.8027756377319946, 5, 3, 3, 5, 6, 4, 8, 3
How the Level Sampling Process impacts Zero-Shot Generalisation in Deep Reinforcement Learning,5.666666666666667, 6.0, 2.0548046676563256, 6, 3, 3, 3, 8, 4
4D Tensor Multi-task Continual Learning for Disease Dynamic Prediction,4.5, 5.0, 0.8660254037844386, 5, 2, 5, 4, 3, 4, 5, 4
Memorization in Self-Supervised Learning Improves Downstream Generalization,6.0, 5.0, 1.4142135623730951, 5, 4, 5, 3, 8, 3
The Curse of Diversity in Ensemble-Based Exploration,7.25, 8.0, 1.299038105676658, 8, 4, 5, 4, 8, 5, 8, 4
Identifiability Matters: Revealing the Hidden Recoverable Condition in Unbiased Learning to Rank,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 4, 5, 3, 5, 4
Exploring Deep Learning Parameter Space with a-GPS: Approximate Gaussian Proposal Sampler,2.5, 3.0, 0.8660254037844386, 1, 3, 3, 5, 3, 4, 3, 4
Implicit Intermediate Supervision for Learning Complex Functions,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 5, 3, 6, 4
Multilinear Operator Networks,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 3, 2, 5, 3
Leveraging Generative Models for Unsupervised Alignment of Neural Time Series Data,6.5, 6.0, 0.8660254037844386, 6, 3, 8, 4, 6, 3, 6, 4
UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition,5.333333333333333, 5.0, 2.0548046676563256, 5, 4, 3, 5, 8, 4
Neuroformer: Multimodal and Multitask Generative Pretraining for Brain Data,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 3, 6, 4, 3, 3
Off-Policy Primal-Dual Safe Reinforcement Learning,6.0, 6.5, 2.1213203435596424, 5, 4, 3, 4, 8, 3, 8, 4
Localized Text-to-Image Generation For Free via Cross Attention Control,4.25, 3.0, 2.165063509461097, 3, 4, 3, 4, 3, 4, 8, 4
Understanding Community Bias Amplification in Graph Representation Learning,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 5, 3, 6, 2
Afterstate Reinforcement Learning for Continuous Control,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 4
Implicit Neural Representations for Joint Sparse-View CT Reconstruction,5.5, 5.5, 1.8027756377319946, 8, 2, 6, 3, 5, 5, 3, 4
An Extensible Framework for Open Heterogeneous Collaborative Perception,5.75, 6.0, 0.4330127018922193, 6, 5, 5, 5, 6, 5, 6, 5
LARG2 Language-based Automatic Reward and Goal Generation,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4, 3, 3
TopoFR: A Closer Look at Topology Alignment on Face Recognition,6.25, 6.0, 1.0897247358851685, 6, 4, 6, 3, 8, 3, 5, 4
Quantum Architecture Search with Unsupervised Representation Learning,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 4, 5, 3
Learning a Diffusion Model Policy from Rewards via Q-Score Matching,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 3, 3, 4
Meta-Collaboration in Distillation: Pooled Learning from Multiple Students,4.5, 5.0, 0.8660254037844386, 5, 5, 3, 4, 5, 4, 5, 4
A Game Theoretic Approach to Meta-Learning: Nash Model-Agnostic Meta-Learning,4.0, 5.0, 1.7320508075688772, 5, 4, 5, 3, 5, 3, 1, 4
FedORION: Aggregation-Assisted Proxyless Distillation for Heterogeneous Federated Learning,4.25, 4.0, 1.299038105676658, 3, 3, 6, 4, 3, 5, 5, 4
Benchmarking Multimodal Variational Autoencoders: CdSprites+ Dataset and Toolkit,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 4, 6, 3, 5, 3
Neural structure learning with stochastic differential equations,6.75, 7.0, 1.299038105676658, 5, 3, 6, 4, 8, 3, 8, 3
Neural Eigenfunctions Are Structured Representation Learners,6.25, 6.0, 1.0897247358851685, 6, 4, 6, 3, 8, 3, 5, 3
STARC: A General Framework For Quantifying Differences Between Reward Functions,6.25, 6.0, 1.0897247358851685, 8, 4, 5, 3, 6, 4, 6, 3
GAIA: a benchmark for General AI Assistants,6.75, 8.0, 2.165063509461097, 8, 4, 8, 3, 8, 5, 3, 4
Adaptive Compression of the Latent Space in Variational Autoencoders,4.0, 5.0, 1.7320508075688772, 5, 2, 1, 4, 5, 4, 5, 4
Mutual Information Estimation via $f$-Divergence and Data Derangement Based Learning Models,4.8, 5.0, 0.9797958971132712, 5, 3, 5, 4, 5, 4, 3, 4, 6, 3
BrainPy: a differentiable brain simulator bridging brain simulation and brain-inspired computing,6.8, 6.0, 1.9390719429665317, 6, 3, 10, 4, 8, 4, 5, 3, 5, 4
SQS: Speech Quality Assessment in the Data Annotation Context,4.25, 4.0, 1.299038105676658, 3, 5, 3, 4, 5, 5, 6, 4
FLea: Improving federated learning on scarce and label-skewed data via  privacy-preserving feature augmentation,4.75, 5.0, 1.0897247358851685, 3, 5, 6, 4, 5, 3, 5, 3
FOSI: Hybrid First and Second Order Optimization,6.25, 6.0, 1.0897247358851685, 6, 2, 8, 4, 5, 3, 6, 4
Privacy Preserving API Fine-tuning for LLMs,3.5, 4.0, 1.6583123951777, 3, 4, 5, 3, 5, 5, 1, 4
MPPN: Multi-Resolution Periodic Pattern Network  For Long-Term Time Series Forecasting,4.2, 5.0, 0.9797958971132712, 3, 4, 3, 4, 5, 4, 5, 3, 5, 4
Lagrangian Proximal Gradient Descent for Learning Convex Optimization Models,4.5, 4.5, 1.5, 6, 4, 6, 3, 3, 4, 3, 4
Fine-tuning can cripple foundation models; preserving features may be the solution,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 4, 5, 3, 5, 4
GraphAgent: Exploiting Large Language Models for Interpretable Learning on Text-attributed Graphs,4.0, 4.0, 1.0, 3, 4, 5, 4, 5, 3, 3, 5
Untrained Networks' Class Bias: A Theoretical Investigation,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4, 3, 4
GML-NeRF: Gate-guided Mutual Learning Framework for Neural Rendering,5.0, 5.0, 0.0, 5, 4, 5, 2, 5, 3, 5, 5
Lost in Translation: Conceptual Blind Spots in Text-to-Image Diffusion Models,4.0, 3.0, 1.4142135623730951, 6, 3, 3, 4, 3, 4
Convergence of SVGD in KL divergence via approximate gradient flow,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 3, 6, 4, 5, 3
Offline Tracking with Object Permanence,4.0, 4.0, 1.0, 3, 4, 3, 3, 5, 4, 5, 3
Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach,6.666666666666667, 6.0, 0.9428090415820634, 6, 2, 8, 2, 6, 4
CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction,6.75, 7.0, 1.299038105676658, 5, 4, 8, 5, 6, 4, 8, 4
Fine-Tuning Is All You Need to Mitigate Backdoor Attacks,4.2, 5.0, 0.9797958971132712, 3, 4, 5, 4, 5, 4, 5, 4, 3, 4
Understanding and Mitigating Extrapolation Failures in Physics-Informed Neural Networks,5.75, 5.0, 1.299038105676658, 5, 4, 5, 4, 8, 5, 5, 4
Unraveling the Key Components of OOD Generalization via Diversification,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 3, 6, 4, 5, 4
Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI,7.333333333333333, 8.0, 0.9428090415820634, 8, 2, 8, 4, 6, 3
Cross-modality Interpretable image classification via Concept Decomposition Vector of Visual Language Models,4.25, 5.0, 1.920286436967152, 6, 4, 5, 3, 5, 4, 1, 3
Deep Generative Clustering with Multimodal Diffusion Variational Autoencoders,6.333333333333333, 6.0, 1.247219128924647, 8, 3, 5, 4, 6, 4
Towards Pareto-Optimality for Test-Time Adaptation,4.25, 4.0, 1.299038105676658, 3, 5, 5, 4, 6, 3, 3, 4
Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning,5.5, 5.5, 0.5, 6, 4, 6, 4, 5, 4, 5, 4
JudgeLM : Fine-tuned Large Language Models are Scalable Judges,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 4, 5, 4, 5, 4
Identifiable State Disentanglement for Reinforcement Learning with Policy Optimality,3.4, 3.0, 0.8, 3, 3, 3, 4, 3, 4, 5, 3, 3, 5
Experts on Demand: Dynamic Routing for Personalized Diffusion Models,3.5, 3.0, 0.8660254037844386, 5, 5, 3, 3, 3, 4, 3, 4
Learned Mixing Weights for Transferable Tabular Data Augmentation,4.4, 5.0, 1.2, 3, 3, 5, 4, 3, 3, 6, 3, 5, 3
Q-TAPE: A Task-Agnostic Pre-Trained Approach for Quantum Properties Estimation,5.75, 6.0, 1.7853571071357126, 6, 4, 8, 4, 3, 5, 6, 5
A Parallel Multi-compartment Spiking Neuron For Multi-scale Sequential Modeling,4.8, 5.0, 0.9797958971132712, 5, 2, 3, 5, 5, 3, 5, 3, 6, 3
Tiny-StyleWizard: Unleashing the Potential of Small Language Models in Complex Style Transfer,3.75, 3.0, 1.299038105676658, 3, 3, 3, 5, 6, 4, 3, 5
DOG: Discriminator-only Generation Beats GANs on Graphs,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 6, 3, 3, 4
Learning Scalar Fields for Molecular Docking with Fast Fourier Transforms,6.333333333333333, 6.0, 1.247219128924647, 8, 4, 5, 3, 6, 3
Analytic DAG Constraints for Differentiable DAG Learning,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 3, 5, 4, 6, 4
Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?,5.5, 5.5, 1.8027756377319946, 3, 3, 6, 4, 8, 4, 5, 4
The Alignment Problem from a Deep Learning Perspective: A Position Paper,5.25, 5.0, 1.7853571071357126, 5, 1, 3, 3, 8, 3, 5, 2
Unified Anomaly Detection via Multi-Scale Contrasted Memory,5.0, 5.0, 0.0, 5, 5, 5, 5, 5, 4
Meta-CoT: Generalizable Chain-of-Thought Prompting in Mixed-task Scenarios with Large Language Models,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 4
$MC^2$: Multimodal Concept-based Continual learning,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 5, 5, 3, 3, 4
Discovering Temporally-Aware Reinforcement Learning Algorithms,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 8, 4, 5, 5
Enhancing Machine Learning System Reliability in Healthcare through Uncertainty Estimation and Multi-Modal Learning,1.6666666666666667, 1.0, 0.9428090415820634, 3, 3, 1, 4, 1, 4
Guiding Masked Representation Learning to Capture Spatio-Temporal Relationship of Electrocardiogram,6.5, 6.5, 1.5, 8, 5, 5, 3, 5, 4, 8, 4
How Realistic Is Your Synthetic Data? Constraining Deep Generative Models for Tabular Data,5.5, 5.5, 1.8027756377319946, 5, 3, 3, 3, 8, 3, 6, 3
Towards Eliminating Hard Label Constraints in Gradient Inversion Attacks,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 1, 6, 4, 6, 2
Expected Probabilistic Hierarchies,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 3, 6, 3
Lost in Transformation: Current roadblocks for Transformers in 3D medical image segmentation,3.5, 4.0, 1.6583123951777, 1, 4, 5, 4, 5, 3, 3, 4
GPT as Visual Explainer,5.5, 5.5, 0.5, 5, 4, 6, 3
GTMGC: Using Graph Transformer to Predict Molecule’s Ground-State Conformation,6.333333333333333, 8.0, 2.357022603955158, 3, 4, 8, 4, 8, 4
Bias Resilient Multi-Step Off-Policy Goal-Conditioned Reinforcement Learning,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 3, 3, 4
From Zero to Turbulence: Generative Modeling for 3D Flow Simulation,6.75, 7.0, 1.299038105676658, 8, 3, 8, 4, 5, 3, 6, 4
Slingshot Perturbation to Learning in Monotone Games,6.25, 6.0, 1.0897247358851685, 6, 4, 8, 3, 6, 3, 5, 4
LDINet: Latent Decomposition and Interpolation for Single Image FMO Deblatting,5.75, 6.0, 1.7853571071357126, 6, 3, 8, 5, 6, 3, 3, 5
SOLO: Surrogate Online Learning at Once for Spiking Neural Networks,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 3, 4, 5, 5
Understanding Deep Neural Networks as Dynamical Systems: Insights into Training and Fine-tuning,3.2, 3.0, 2.5612496949731396, 1, 2, 8, 4, 1, 5, 3, 3, 3, 4
Non-Redundant Graph Neural Networks with Improved Expressiveness,4.25, 4.0, 1.299038105676658, 3, 4, 5, 3, 6, 3, 3, 3
A Structured Matrix Method for Nonequispaced Neural Operators,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 8, 2, 6, 5
Multi-modal Latent Diffusion,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 3, 6, 4, 3, 2
MuseCoco: Generating Symbolic Music from Text,5.5, 5.5, 1.8027756377319946, 6, 4, 3, 4, 5, 3, 8, 4
How Two-Layer Networks Learn One (Giant) Step at a Time,nan, nan, nan
PolyNet: Learning Diverse Solution Strategies for Neural Combinatorial Optimization,4.5, 5.0, 0.8660254037844386, 5, 1, 3, 3, 5, 5, 5, 3
Generalization of Deep ResNets in the Mean-Field Regime,6.333333333333333, 6.0, 1.247219128924647, 5, 3, 6, 4, 8, 4
Good Better Best: Self-Motivated Imitation Learning For Noisy Demonstrations,4.25, 4.0, 1.299038105676658, 5, 4, 6, 3, 3, 5, 3, 4
ODE Discovery for Longitudinal Heterogeneous Treatment Effects Inference,6.4, 6.0, 1.3564659966250536, 5, 4, 8, 4, 5, 3, 6, 2, 8, 3
Energy-Guided Continuous Entropic Barycenter Estimation for General Costs,5.75, 5.0, 1.299038105676658, 5, 4, 5, 3, 8, 3, 5, 3
INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection,6.25, 6.0, 1.0897247358851685, 8, 4, 6, 4, 5, 3, 6, 3
Hieros: Hierarchical Imagination on Structured State Space Sequence World Models,4.666666666666667, 3.0, 2.357022603955158, 8, 4, 3, 4, 3, 3
Freenets: Learning Layerfree Neural Network Topologies,3.3333333333333335, 3.0, 2.0548046676563256, 3, 4, 1, 2, 6, 3
Beyond Labeling Oracles: What does it mean to steal ML models?,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 4, 3, 3, 5, 4
Denoising Graph Dissipation Model Improves Graph Representation Learning,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 4, 5, 2, 5, 3
DisenBooth: Identity-Preserving Disentangled Tuning for Subject-Driven Text-to-Image Generation,6.25, 6.0, 1.0897247358851685, 6, 4, 6, 4, 8, 2, 5, 4
The Convergence of Variance Exploding Diffusion Models under the Manifold Hypothesis,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 5, 3, 6, 2
Towards Provably Efficient Learning of Extensive-Form Games with Imperfect Information and Linear Function Approximation,5.0, 5.5, 1.224744871391589, 5, 3, 6, 2, 3, 4, 6, 3
An Efficient Multi-Task Transformer for 3D Face Alignment,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 3, 5, 4
Learning energy-based models by self-normalising the likelihood,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 4
Emergent Language based Dialog for Collaborative Multi-agent Navigation,5.25, 5.0, 0.4330127018922193, 5, 2, 6, 4, 5, 3, 5, 3
Improving equilibrium propagation without weight symmetry through Jacobian homeostasis,5.5, 5.5, 0.5, 5, 3, 6, 3, 5, 4, 6, 4
A Dynamic Mixup Approach Towards Improved Robustness of Classifiers,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 5, 3, 3, 5
SEGO: Sequential Subgoal Optimization for Mathematical Problem-Solving,5.0, 5.5, 1.224744871391589, 6, 3, 5, 3, 6, 3, 3, 4
DIFAIR: Towards learning differenciated and interpretable representations,3.4, 3.0, 0.8000000000000002, 5, 3, 3, 4, 3, 3, 3, 4, 3, 4
Safe Online Bid Optimization with Return On Investment and Budget Constraints,4.25, 4.0, 1.299038105676658, 3, 3, 5, 2, 3, 3, 6, 3
Towards Demystifying the Generalization Behaviors When Neural Collapse Emerges,3.5, 4.0, 1.6583123951777, 3, 5, 5, 4, 5, 3, 1, 4
Learning Hierarchical World Models with Adaptive Temporal Abstractions from Discrete Latent Dynamics,6.666666666666667, 6.0, 0.9428090415820634, 8, 4, 6, 3, 6, 3
The Trifecta: Three simple techniques for training deeper Forward-Forward networks,5.0, 5.5, 1.224744871391589, 3, 5, 6, 4, 6, 2, 5, 4
Uniform Localized Convergence and Sharper Generalization Bounds for Minimax Problems,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 4, 5, 3, 5, 4
A Best-of-Both-Worlds Algorithm for MDPs with Long-Term Constraints,5.0, 5.5, 1.224744871391589, 5, 3, 3, 5, 6, 3, 6, 3
Evolving Computation Graphs,4.25, 4.0, 1.299038105676658, 6, 4, 3, 4, 5, 4, 3, 5
Revisiting Data Augmentation in Deep Reinforcement Learning,5.75, 6.0, 0.4330127018922193, 5, 4, 6, 3, 6, 5, 6, 3
Value Factorization for Asynchronous Multi-Agent Reinforcement Learning,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 4, 5, 4, 5, 4
Structural Inference with Dynamics Encoding and Partial Correlation Coefficients,6.0, 5.0, 1.4142135623730951, 8, 4, 5, 3, 5, 3
MACCA: Offline Multi-agent Reinforcement Learning with Causal Credit Assignment,5.0, 5.5, 1.224744871391589, 3, 4, 5, 4, 6, 3, 6, 4
Prediction without Preclusion: Recourse Verification with Reachable Sets,4.5, 4.5, 1.5, 3, 3, 6, 3, 3, 2, 6, 3
Simplicial Representation Learning with Neural $k$-Forms,5.8, 5.0, 1.16619037896906, 6, 2, 5, 4, 5, 2, 8, 2, 5, 4
Pseudo-Mask and Language: A Simple Recipe for Open-Vocabulary Semantic Segmentation,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 5, 5, 3
Improved Analysis of Sparse Linear Regression in Local Differential Privacy Model,6.333333333333333, 6.0, 1.247219128924647, 8, 3, 5, 3, 6, 3
Toward effective protection against diffusion-based mimicry through score distillation,4.25, 4.0, 1.299038105676658, 3, 4, 3, 3, 5, 4, 6, 4
TextBind: Multi-turn Interleaved Multimodal Instruction-following in the Wild,6.0, 5.5, 1.224744871391589, 6, 3, 5, 4, 5, 5, 8, 4
EdVAE: Mitigating Codebook Collapse with Evidential Discrete Variational Autoencoders,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 5, 3, 4
Sign2GPT: Leveraging Large Language Models for Gloss-Free Sign Language Translation,5.5, 5.5, 0.5, 6, 5, 5, 4, 6, 4, 5, 5
Learning Good Interventions in Causal Contextual Bandits with Adaptive Context,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 3
Cauchy-Schwarz Divergence Information Bottleneck for Regression,5.2, 6.0, 1.16619037896906, 5, 4, 6, 2, 3, 4, 6, 2, 6, 4
Learning System Dynamics from Sensory Input under Optimal Control Principles,3.5, 4.0, 1.6583123951777, 3, 4, 5, 4, 1, 5, 5, 3
PIANO PERFORMANCE EVALUATION DATASET WITH MULTI-LEVEL PERCEPTUAL FEATURES,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 3, 6, 3, 3, 4, 6, 3, 3, 4
MeMo: Meaningful Modular Controllers Via Information Bottlenecks,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 4, 5, 3, 3, 4
SALMONN: Towards Generic Hearing Abilities for Large Language Models,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 3, 6, 4
Riemannian Multiclass Logistics Regression for SPD Neural Networks,4.0, 4.0, 1.0, 5, 3, 3, 5, 3, 4, 5, 4
Variational Bayes Classifier,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 5, 4, 3, 3
Copy Suppression: Comprehensively Understanding an Attention Head,5.5, 5.5, 1.8027756377319946, 8, 3, 6, 3, 5, 2, 3, 3
In-context Prompt Learning for Test-time Vision Recognition with Frozen Vision-Language Model,5.0, 5.0, 0.0, 5, 3, 5, 5, 5, 4, 5, 2
Kalman Filter Online Learning from non-Stationary Data,6.0, 6.0, 0.0, 6, 3, 6, 4, 6, 4, 6, 3
Magnushammer: A Transformer-Based Approach to Premise Selection,7.5, 8.0, 0.8660254037844386, 6, 4, 8, 5, 8, 3, 8, 4
Molecule Generation by Heterophilious Triple Flows,4.0, 4.0, 1.0, 5, 3, 3, 4, 5, 3, 3, 3
Babel-ImageNet: Massively Multilingual Evaluation of Vision-and-Language Representations,6.25, 6.0, 1.0897247358851685, 5, 4, 8, 4, 6, 3, 6, 4
Dispatching Ambulances using Deep Reinforcement Learning,5.333333333333333, 5.0, 2.0548046676563256, 5, 5, 8, 3, 3, 4
Uncertainty Quantification Using a Codebook of Encoders,4.25, 5.0, 1.920286436967152, 5, 4, 5, 3, 1, 4, 6, 3
Unified Mirror Descent: Towards a Big Unification of Decision Making,4.2, 5.0, 0.9797958971132712, 3, 4, 5, 4, 5, 3, 3, 3, 5, 3
Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go Indifferent,4.2, 5.0, 0.9797958971132712, 5, 3, 3, 3, 3, 4, 5, 3, 5, 2
Revealing the Mystery of Distribution Correction Estimation via Orthogonal-gradient Update,7.0, 7.0, 1.0, 8, 4, 6, 4, 6, 4, 8, 3
Contrastive Grouping-based Invariant Learning for Generalizable Graph Learning,3.0, 3.0, 1.4142135623730951, 3, 5, 3, 5, 5, 3, 1, 3
Large-Batch Iteration-Efficient Neural Bayesian Design Optimization,5.0, 4.5, 2.1213203435596424, 8, 3, 3, 3, 6, 4, 3, 4
Bayesian Uncertainty Quantification Meets Topology,3.0, 3.0, 0.0, 3, 3, 3, 2, 3, 4
A Weight Variation-Aware Training Method for Hardware Neuromorphic Chips,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 5, 5, 5, 3, 4
Tree-based Action-Manipulation Attack Against Continuous Reinforcement Learning with Provably Efficient Support,4.75, 5.0, 1.0897247358851685, 5, 2, 6, 4, 3, 3, 5, 3
Stochastic Subgoal Representation for Hierarchical Reinforcement Learning,4.75, 6.0, 2.165063509461097, 6, 3, 6, 4, 6, 4, 1, 4
It's About Time: Temporal References in Emergent Communication,3.75, 3.0, 1.299038105676658, 3, 2, 3, 4, 3, 5, 6, 3
Domain Generalization Using Large Pretrained Models With Mixture-of-Adapters,3.0, 3.0, 1.4142135623730951, 3, 4, 3, 4, 1, 4, 5, 4
Learning to Compose: Improving Object Centric Learning by Injecting Compositionality,6.25, 6.0, 1.0897247358851685, 6, 4, 6, 4, 8, 4, 5, 4
Adam through a Second-Order Lens,4.5, 5.5, 2.0615528128088303, 1, 5, 6, 3, 5, 3, 6, 3
Estimation of Concept Explanations Should be Uncertainty Aware,4.8, 6.0, 1.469693845669907, 3, 4, 6, 3, 3, 3, 6, 4, 6, 3
Causal Inference on Distributional Outcomes under Continuous Treatments,4.0, 4.0, 1.0, 5, 3, 3, 3, 3, 3, 5, 3
FLAIM: AIM-based Synthetic Data Generation in the Federated Setting,4.666666666666667, 3.0, 2.357022603955158, 3, 3, 3, 5, 8, 3
Proximal Curriculum with Task Correlations for Deep Reinforcement Learning,5.25, 5.0, 1.7853571071357126, 5, 3, 5, 3, 8, 3, 3, 4
SelfClean: A Self-Supervised Data Cleaning Strategy,4.75, 6.0, 2.165063509461097, 6, 4, 1, 5, 6, 4, 6, 4
MPXGAT: An Attention based Deep Learning Model for Multiplex Graphs Embedding,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 5
FINE-GRAINED AUDIO-VISUAL JOINT REPRESENTATIONS FOR MULTIMODAL LARGE LANGUAGE MODELS,4.0, 4.0, 1.0, 5, 3, 5, 4, 3, 4, 3, 4
Gated recurrent neural networks discover attention,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 5, 6, 3, 5, 3
Label-encoding Risk Minimization under Label Insufficient Scenarios,5.5, 5.5, 0.5, 5, 4, 5, 3, 6, 5, 6, 3
Leveraging characteristics of the output distribution for identifying adversarial audio examples,4.5, 5.0, 0.8660254037844386, 3, 3, 5, 4, 5, 3, 5, 3
Light Schrödinger Bridge,5.8, 5.0, 1.9390719429665317, 8, 4, 5, 3, 3, 4, 8, 2, 5, 3
Promptbreeder: Self-Referential Self-Improvement via Prompt Evolution,5.6, 5.0, 1.2, 5, 5, 8, 3, 5, 3, 5, 2, 5, 3
Prompt2Rec : Prompt based user and item Re-characterizing method for Recommendation,3.2, 3.0, 1.6, 3, 5, 1, 5, 6, 4, 3, 4, 3, 3
Dirichlet-based Uncertainty Quantification for Personalized Federated Learning with Improved Posterior Networks,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 5
Reward-Free Curricula for Training Robust World Models,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 4, 5, 3, 5, 3
Beam Enumeration: Probabilistic Explainability For Sample Efficient Self-conditioned Molecular Design,5.333333333333333, 5.0, 2.0548046676563256, 3, 4, 5, 5, 8, 4
PreCoT: Problem Representation Enhances Reasoning in Large Language Models,4.25, 4.0, 1.299038105676658, 6, 4, 5, 5, 3, 4, 3, 4
MMPareto: Innocent Uni-modal Assistance for Enhanced Multi-modal Learning,5.25, 5.0, 1.7853571071357126, 3, 4, 5, 3, 5, 4, 8, 3
MusicAOG: an Energy-Based Model for Learning and Sampling a Hierarchical Representation of Symbolic Music,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 2, 5, 3, 3, 4
Learning Interpretable Characteristic Kernels via Decision Forests,4.0, 4.0, 1.0, 3, 3, 5, 4, 5, 4, 3, 4
DITTO: Offline Imitation Learning with World Models,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 3, 3, 4, 3, 5, 5, 4, 3, 4
LLaMA Rider: Spurring Large Language Models to Explore the Open World,4.0, 4.5, 2.1213203435596424, 3, 4, 1, 4, 6, 4, 6, 3
Leveraging Uncertainty Estimates To Improve Classifier Performance,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 4, 6, 3
C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion,5.25, 5.0, 0.4330127018922193, 6, 3, 5, 5, 5, 4, 5, 4
Disco-Bench: A Context-Aware Evaluation Benchmark for Language Modelling,4.25, 4.0, 1.299038105676658, 3, 4, 5, 2, 3, 4, 6, 2
DURENDAL: Graph deep learning framework for temporal heterogeneous networks,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 6, 5, 3, 3
Advantage-Aware Policy Optimization for Offline Reinforcement Learning,4.8, 5.0, 0.9797958971132712, 3, 4, 5, 4, 5, 4, 6, 3, 5, 4
Enhancing Fine-Tuning Performance of Large-Scale Text-to-Image Models on Specialized Datasets,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 3, 4, 5, 4
Retrieval-augmented Vision-Language Representation for Fine-grained Recognition,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 8, 3, 6, 3
DEEP NEURAL NETWORK INITIALIZATION WITH SPARSITY INDUCING ACTIVATIONS,6.0, 5.5, 1.224744871391589, 5, 4, 6, 3, 8, 3, 5, 2
Local Vs. Global Interpretability: A Computational Perspective,5.75, 6.0, 0.4330127018922193, 5, 5, 6, 1, 6, 1, 6, 3
Post-Nonlinear Causal Relationship with Finite Samples: A Maximal Correlation Perspective,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 3, 5, 3
Self-supervised debiasing using low rank regularization,4.0, 3.0, 1.4142135623730951, 3, 3, 6, 4, 3, 4
Elastic Load Balancing for Dynamic LLMs,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 4
Multilingual Code Retrieval Without Paired Data: New Datasets and Benchmarks,5.0, 5.5, 1.224744871391589, 6, 3, 6, 3, 5, 4, 3, 4
Curve Your Attention: Mixed-Curvature Transformers for Graph Representation Learning,3.6666666666666665, 5.0, 1.8856180831641267, 1, 5, 5, 4, 5, 4
Bridging Sub-Tasks to Long-Horizon Task in Hierarchical Goal-Based Reinforcement Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 5, 4, 3, 5
Zero-shot Image Restoration via Diffusion Inversion,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 5, 2, 3, 5
PeFLL: Personalized Federated Learning by Learning to Learn,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 3, 4, 5, 3
Unsupervised motion segmentation in one go: Smooth long-term model over a video,5.0, 5.0, 0.0, 5, 4, 5, 5, 5, 3
Improving Non-Transferable Representation Learning by Harnessing Content and Style,6.666666666666667, 6.0, 0.9428090415820634, 6, 2, 8, 3, 6, 3
A Semi-smooth Self-shifting and Singular Newton Method for Sparse Optimal Transport,4.6, 5.0, 1.3564659966250536, 6, 2, 3, 3, 6, 2, 5, 3, 3, 4
PASTA: Pretrained Action-State Transformer Agents,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 3, 3, 6, 4
Eureka-Moments in Transformers: Multi-Step Tasks Reveal Softmax Induced Optimization Problems,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 4, 6, 4, 3, 4
Sparse Model Soups: A Recipe for Improved Pruning via Model Averaging,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 2, 5, 4, 3, 4
DP-SGD Without Clipping: The Lipschitz Neural Network Way,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 8, 3, 6, 4
Neural Networks Trained by Weight Permutation are Universal Approximators,6.0, 5.5, 1.224744871391589, 5, 4, 6, 3, 5, 3, 8, 3
AutoHall: Automated Hallucination Dataset Generation for Large Language Models,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4
High-dimensional robust regression under heavy-tailed data: Asymptotics and Universality,6.0, 5.0, 1.4142135623730951, 8, 3, 5, 3, 5, 3
Provable and Practical: Efficient Exploration in Reinforcement Learning via Langevin Monte Carlo,6.333333333333333, 6.0, 1.247219128924647, 8, 3, 6, 2, 5, 4
Mitigating Uni-modal Sensory Bias in Multimodal Object Detection with Counterfactual Intervention and Causal Mode Multiplexing,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 3, 4, 6, 3
Human Feedback is not Gold Standard,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 3, 6, 4, 6, 4
Can long-context large language models understand long contexts?,4.25, 3.0, 2.165063509461097, 3, 4, 3, 4, 3, 5, 8, 4
Integrating Visual Cues via Prompting for Low-Resource Multimodal Named Entity Recognition,2.5, 2.0, 1.6583123951777, 1, 5, 3, 3, 1, 5, 5, 5
ModernTCN: A Modern Pure Convolution Structure for General Time Series Analysis,7.0, 8.0, 1.4142135623730951, 8, 3, 5, 4, 8, 4
Abstract Interpretation of ReLU Neural Networks with Optimizable Polynomial Relaxations,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 4, 5, 3
Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 4, 6, 3, 5, 3
AFFINE INVARIANCE IN CONTINUOUS-DOMAIN CONVOLUTIONAL NEURAL NETWORKS,3.0, 3.0, 0.0, 3, 3, 3, 1, 3, 4, 3, 3
High-Probability Convergence for Composite and Distributed Stochastic Minimization and Variational Inequalities with Heavy-Tailed Noise,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 2
Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel,5.75, 5.0, 1.299038105676658, 5, 4, 5, 4, 8, 3, 5, 2
Solving Continual Offline Reinforcement Learning with Decision Transformer,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 2, 5, 3
Assessing Large Language Models on Climate Information,4.25, 3.0, 2.165063509461097, 8, 4, 3, 5, 3, 5, 3, 5
DiffPoseTalk: Speech-Driven Stylistic 3D Facial Animation and Head Pose Generation via Diffusion Models,5.5, 5.5, 1.8027756377319946, 6, 4, 8, 4, 3, 4, 5, 4
LRQ: Optimizing Post-Training Quantization for Large Language Models by Learning Low-Rank Weight-Scaling Matrices,5.25, 6.0, 1.299038105676658, 3, 5, 6, 3, 6, 3, 6, 4
Compensating for Nonlinear Reduction with Linear Computations in Private Inference,4.0, 5.0, 2.160246899469287, 1, 5, 5, 2, 6, 2
First-order ANIL provably learns representations despite overparametrisation,6.0, 5.5, 1.224744871391589, 6, 3, 5, 4, 8, 3, 5, 4
The Fundamental Limits of Least-Privilege Learning,5.4, 5.0, 0.48989794855663565, 6, 3, 5, 4, 5, 4, 6, 3, 5, 3
Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning,6.75, 7.0, 1.299038105676658, 6, 4, 5, 3, 8, 4, 8, 2
How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions,6.25, 7.0, 2.0463381929681126, 8, 4, 3, 3, 6, 3, 8, 4
APBench: A Unified Benchmark for Availability Poisoning Attacks and Defenses,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 3, 5, 6, 4
Visual Encoders for Data-Efficient Imitation Learning in Modern Video Games,3.0, 3.0, 1.4142135623730951, 3, 4, 1, 5, 5, 5, 3, 4
CPPO: Continual Learning for Reinforcement Learning with Human Feedback,5.75, 5.0, 1.299038105676658, 5, 4, 8, 2, 5, 4, 5, 2
Learning Optimal Contracts: How to Exploit Small Action Spaces,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 3, 6, 4
Proper Backward Connection Placement Boosts Spiking Neural Networks,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 5, 5, 4
AGILE3D: Attention Guided Interactive Multi-object 3D Segmentation,5.5, 5.5, 1.8027756377319946, 6, 3, 5, 4, 8, 3, 3, 4
Invisible and Adaptive Training-Phase Target-Conditioned Backdoors,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 5, 4, 3, 5
The Noise Geometry of Stochastic Gradient Descent: A Quantitative and Analytical Characterization,4.25, 4.0, 1.299038105676658, 6, 2, 3, 4, 5, 3, 3, 3
Rethinking Out-of-Distribution Detection on Imbalanced Data Distribution,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 4, 6, 4, 5, 3
Neural Translation of Input Specifications into Formal Grammars for Test Case Generation,2.5, 3.0, 0.8660254037844386, 3, 2, 3, 3, 1, 4, 3, 3
Memory-Efficient Backpropagation through Large Linear Layers,3.75, 3.0, 1.299038105676658, 3, 5, 3, 3, 6, 4, 3, 4
Continual Supervised Anomaly Detection,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 4, 6, 3
$\texttt{PREMIER-TACO}$ is a Few-Shot Policy Learner: Pretraining Multitask Representation via Temporal Action-Driven Contrastive Loss,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 2
A Multi-Level Framework for Accelerating Training Transformer Models,5.75, 6.0, 0.4330127018922193, 6, 5, 6, 2, 5, 4, 6, 2
Stealthy Imitation: Reward-guided Environment-free Policy Stealing,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 4, 5, 3
Incremental Successive Halving for Hyperparameter Optimization with Budget Constraints,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 5, 5, 2, 3, 5
AV-PEA: PARAMETER-EFFICIENT ADAPTER FOR AUDIO-VISUAL MULTIMODAL LEARNING,4.25, 4.0, 1.299038105676658, 3, 3, 6, 4, 5, 4, 3, 4
RODEO: Robust Out-of-Distribution Detection Via Exposing Adaptive Outliers,6.0, 5.5, 1.224744871391589, 5, 5, 8, 4, 5, 5, 6, 2
HAICO-CN: Human-AI Collaboration By Cluster-wise Noisy-Label Augmentation,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 3, 5, 4
Online Information Acquisition: Hiring Multiple Agents,6.25, 6.0, 1.0897247358851685, 6, 2, 8, 4, 5, 3, 6, 3
Perturb-and-Compare Approach for Detecting Out-of-Distribution Samples in Constrained Access Environments,5.25, 5.0, 1.7853571071357126, 3, 4, 5, 4, 8, 3, 5, 4
Split-and-Denoise: Protect large language model inference with local differential privacy,4.0, 4.0, 1.0, 5, 3, 3, 3, 3, 2, 5, 4
Planning with Theory of Mind for Few-Shot Adaptation in Sequential Social Dilemmas,4.5, 4.5, 1.5, 6, 4, 6, 3, 3, 4, 3, 4
M$^4$LE: A Multi-Ability Multi-Range Long Context Evaluation Benchmark for Large Language Models,4.75, 5.0, 1.0897247358851685, 5, 5, 6, 4, 5, 4, 3, 4
Learning Multi-Faceted Prototypical User Interests,6.333333333333333, 6.0, 1.247219128924647, 5, 3, 8, 3, 6, 4
Detection and Segmentation of Solar Farms in Satellite Imagery: A Study of  Deep Neural Network Architectures,2.5, 2.0, 1.6583123951777, 5, 4, 1, 4, 1, 4, 3, 3
Algorithmic Stability Unleashed: Generalization Bounds with Unbounded Losses,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 5, 3, 3, 5, 3
LMEye: An Interactive Perception Network for Large Language Models,5.5, 5.5, 1.8027756377319946, 8, 5, 5, 4, 3, 4, 6, 4
Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 5, 3, 4
Bandits with Replenishable Knapsacks: the Best of both Worlds,5.75, 6.0, 0.4330127018922193, 5, 4, 6, 3, 6, 3, 6, 4
Autonomous Catheterization with Open-source Simulator and Expert Trajectory,4.333333333333333, 5.0, 0.9428090415820634, 3, 3, 5, 4, 5, 3
Tall Tales at Different Scales: Evaluating Scaling Trends For Deception in Language Models,3.6666666666666665, 5.0, 1.8856180831641267, 5, 3, 1, 4, 5, 2
Multi-Label Generalized Zero Shot Chest Xray Classification  Using Feature Disentanglement and Multi-Modal Dictionaries,1.6666666666666667, 1.0, 0.9428090415820634, 1, 5, 1, 4, 3, 4
FARSE-CNN: Fully Asynchronous Recurrent and Sparse Event-Based CNN,5.25, 5.0, 0.4330127018922193, 6, 3, 5, 5, 5, 4, 5, 4
AROID: Improving Adversarial Robustness through Online Instance-wise Data Augmentation,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 5, 3, 4, 6, 3
Learning Embeddings for Sequential Tasks Using Population of Agents,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 5, 3, 6, 3
$R^2$: Range Regularization for Model Compression and Quantization,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 5, 3, 4, 5, 4
ARB: Advanced Reasoning Benchmark for Large Language Models,5.5, 5.5, 0.5, 6, 2, 6, 3, 5, 3, 5, 3
Conservative World Models,4.25, 4.0, 1.299038105676658, 3, 4, 3, 3, 5, 3, 6, 4
Out-of-Variable Generalisation for Discriminative Models,6.25, 6.0, 1.0897247358851685, 5, 2, 6, 4, 6, 3, 8, 3
Semi-supervised batch learning from logged data,5.5, 5.5, 0.5, 6, 4, 6, 4, 5, 4, 5, 3
Improved Variational Bayesian Phylogenetic Inference using Mixtures,5.0, 5.5, 1.224744871391589, 5, 2, 6, 3, 6, 3, 3, 3
Training Unbiased Diffusion Models From Biased Dataset,5.5, 5.5, 1.8027756377319946, 6, 3, 5, 3, 8, 4, 3, 4
Towards Robust Out-of-Distribution Generalization Bounds via Sharpness,5.5, 5.5, 1.8027756377319946, 8, 4, 5, 3, 3, 4, 6, 3
Meta-Prior: Meta learning for Adaptive Inverse Problem Solvers,3.0, 3.0, 1.4142135623730951, 5, 4, 3, 3, 1, 4, 3, 4
The optimality of kernel classifiers in Sobolev space,5.25, 5.0, 0.4330127018922193, 5, 2, 5, 4, 5, 3, 6, 2
Corgi$^2$: A Hybrid Offline-Online Approach To Storage-Aware Data Shuffling For SGD,4.25, 4.0, 1.299038105676658, 6, 3, 3, 4, 3, 4, 5, 3
Learning a Reusable Meta Denoiser for Learning with Noisy Labels on Multiple Target Domains,4.25, 4.0, 1.299038105676658, 6, 3, 3, 3, 5, 3, 3, 4
Getting a-Round Guarantees: Floating-Point Attacks on Certified Robustness,4.25, 4.0, 2.5860201081971503, 3, 4, 8, 4, 1, 5, 5, 3
Neural Fourier Transform: A General Approach to Equivariant Representation Learning,7.0, 7.0, 1.0, 6, 3, 8, 3, 8, 3, 6, 4
On Harmonizing Implicit Subpopulations,5.75, 6.0, 1.7853571071357126, 3, 3, 6, 3, 8, 3, 6, 3
Can Class-Priors Help Single-Positive Multi-Label Learning?,5.5, 5.5, 1.8027756377319946, 5, 3, 3, 4, 6, 3, 8, 3
Mastering Robot Manipulation with Multimodal Prompts through Pretraining and Multi-task Fine-tuning,5.0, 5.5, 1.224744871391589, 6, 5, 5, 4, 3, 4, 6, 3
Spectral Self-supervised Feature Selection,4.0, 3.0, 1.2649110640673518, 3, 4, 6, 3, 5, 3, 3, 4, 3, 3
Towards Cheaper Inference in Deep Networks with Lower Bit-Width Accumulators,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 5, 3, 6, 4
EquiAV: Single-modal Equivariance Promotes Audio-Visual Contrastive Learning,3.75, 3.0, 1.299038105676658, 3, 4, 6, 3, 3, 5, 3, 2
Multi-Objective Reinforcement Learning for Forward-Backward Markov Decision Processes,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 3
Personas as a way to Model Truthfulness in Language Models,4.0, 4.0, 1.0, 5, 5, 5, 3, 3, 3, 3, 3
FL-GNN: A Fuzzy-logic Graph Neural Network,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 3, 5, 3
Continual Learning in the Presence of Spurious Correlations: Analyses and a Simple Baseline,5.5, 5.5, 0.5, 5, 3, 5, 3, 6, 4, 6, 3
Rethinking Branching on Exact Combinatorial Optimization Solver: The First Deep Symbolic Discovery Framework,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 8, 4, 6, 4
Is Training Necessary for Representation Learning,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 3, 3, 6, 3
Accelerating Federated Learning with Quick Distributed Mean Estimation,5.5, 5.5, 0.5, 5, 4, 6, 2, 6, 3, 5, 5
MAPE-PPI: Towards Effective and Efficient Protein-Protein Interaction Prediction via Microenvironment-Aware Protein Embedding,5.666666666666667, 6.0, 2.0548046676563256, 8, 4, 6, 4, 3, 4
Negative Label Guided OOD Detection with Pretrained Vision-Language Models,6.5, 6.0, 0.8660254037844386, 6, 4, 8, 4, 6, 4, 6, 5
Close the Gap: Lightweight Image Captioning via Retrieval Augmentation,3.6, 3.0, 1.2, 3, 4, 3, 3, 3, 4, 6, 5, 3, 4
Chain of Images for Intuitively Reasoning,4.0, 4.0, 1.0, 5, 3, 3, 4, 3, 4, 5, 4
Continual Memory Neurons,4.25, 4.0, 1.299038105676658, 3, 5, 5, 3, 3, 4, 6, 4
Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors,6.5, 6.5, 1.5, 5, 4, 8, 5, 5, 5, 8, 4
Feature Map Matters in Out-of-distribution Detection,5.25, 5.0, 0.4330127018922193, 5, 3, 6, 4, 5, 4, 5, 4
Data Prediction Denoising Models: The Pupil Outdoes the Master,5.5, 5.5, 1.8027756377319946, 8, 2, 3, 3, 6, 3, 5, 3
Periodic and Random Sparsity for Multivariate Long-Term Time-Series Forecasting,5.0, 5.5, 1.224744871391589, 6, 5, 3, 5, 5, 4, 6, 3
Adversarial Adaptive Sampling: Unify PINN and Optimal Transport for the Approximation of PDEs,6.0, 5.5, 3.082207001484488, 8, 4, 10, 5, 3, 3, 3, 4
Probabilistically Rewired Message-Passing Neural Networks,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 5, 4, 6, 2
Towards a Better Theoretical Understanding of Independent Subnetwork Training,5.25, 5.0, 0.4330127018922193, 5, 3, 6, 3, 5, 3, 5, 2
HGMD: Rethinking Hard Sample Distillation for GNN-to-MLP Knowledge Distillation,5.0, 5.0, 0.0, 5, 4, 5, 5, 5, 4, 5, 4
Iterative Search Attribution for Deep Neural Networks,4.5, 4.5, 1.5, 6, 4, 6, 3, 3, 4, 3, 3
BadEdit: Backdooring Large Language Models by Model Editing,5.6, 6.0, 1.624807680927192, 3, 5, 6, 4, 5, 4, 6, 3, 8, 2
Efficient Differentiable Approximation of the Generalized Low-rank Regularization,5.2, 5.0, 1.6, 5, 3, 5, 3, 8, 3, 3, 3, 5, 5
Dilated convolution neural operator for multiscale partial differential equations,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 4
Incentivizing Data Collection from Heterogeneous Clients in Federated Learning,4.25, 4.0, 1.299038105676658, 3, 4, 3, 2, 6, 2, 5, 3
Robust Training of Federated Models with Extremely Label Deficiency,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 3, 6, 4, 6, 3
An Instance-Level Framework for Multi-tasking Graph Self-Supervised Learning,5.25, 5.0, 0.4330127018922193, 6, 5, 5, 3, 5, 3, 5, 4
On Accelerating Diffusion-Based Sampling Processes via Improved Integration Approximation,5.5, 5.5, 0.5, 6, 3, 6, 2, 5, 3, 5, 4
Efficient Algorithms for the CCA Family: Unconstrained Objectives with Unbiased Gradients,6.333333333333333, 6.0, 1.247219128924647, 6, 2, 5, 2, 8, 2
Segment Anything Model is a Good Teacher for Local Feature Learning,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 5, 6, 4, 5, 3
Temporal Flexibility in Spiking Neural Networks: A Novel Training Method for Enhanced Generalization Across Time Steps,5.0, 6.0, 1.4142135623730951, 3, 5, 6, 4, 6, 4
Explaining the Complex Task Reasoning of Large Language Models with Template-Content Structure,5.5, 5.5, 0.5, 6, 3, 5, 2
DECENTRALIZED MULTI-AGENT REINFORCEMENT LEARNING VIA ANTICIPATION SHARING,4.75, 5.0, 1.0897247358851685, 5, 3, 6, 4, 3, 4, 5, 2
A Study of Generalization in Offline Reinforcement Learning,6.25, 6.0, 1.0897247358851685, 6, 4, 6, 4, 5, 4, 8, 4
Emergent mechanisms for long timescales depend on training curriculum and affect performance in memory tasks,5.5, 5.5, 1.8027756377319946, 6, 3, 8, 3, 5, 3, 3, 4
OPTIMAL ROBUST MEMORIZATION WITH RELU NEURAL NETWORKS,6.0, 5.0, 1.4142135623730951, 5, 4, 5, 3, 8, 3
Neural Contractive Dynamical Systems,6.0, 5.0, 1.4142135623730951, 8, 3, 5, 3, 5, 4
Sparsistency for inverse optimal transport,6.75, 7.0, 1.299038105676658, 5, 3, 8, 3, 8, 2, 6, 2
What Do GNNs Actually Learn? Towards Understanding their Representations,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 3, 5, 3, 3, 3
ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation,6.0, 6.5, 2.1213203435596424, 8, 4, 5, 4, 3, 4, 8, 4
A Recipe for Watermarking Diffusion Models,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 6, 3, 3, 4
Scalable Modular Network: A Framework for Adaptive Learning via Agreement Routing,6.0, 6.0, 0.0, 6, 4, 6, 3, 6, 2, 6, 4
Noise-free Score Distillation,6.25, 6.0, 1.0897247358851685, 6, 3, 8, 4, 6, 5, 5, 5
DINAR: Fine-Grained Privacy Preserving Federated Learning,4.0, 4.0, 1.0, 3, 3, 3, 4, 5, 4, 5, 4
Scalable Lipschitz Estimation for CNNs,4.25, 4.0, 1.299038105676658, 3, 3, 3, 4, 6, 4, 5, 3
Differentially Private Principal Component Analysis for Vertically Partitioned Data,4.333333333333333, 6.0, 2.357022603955158, 1, 5, 6, 5, 6, 3
Small Variance Big Fairness: A Path to Harmless Fairness without Demographics,5.0, 5.5, 1.224744871391589, 6, 3, 6, 3, 5, 5, 3, 4
Near-Optimal Quantum Algorithm for Minimizing the Maximal Loss,6.0, 5.5, 1.224744871391589, 6, 2, 8, 3, 5, 3, 5, 3
Consistent4D: Consistent 360° Dynamic Object Generation from Monocular Video,6.6, 6.0, 1.7435595774162693, 10, 4, 5, 5, 6, 3, 6, 4, 6, 4
Diverse Projection Ensembles for Distributional Reinforcement Learning,5.5, 5.5, 2.5, 3, 5, 8, 3, 8, 3, 3, 4
KEFI: Kernel-based Feature Identification for Generalizable Classification,4.0, 4.0, 1.0, 3, 3, 5, 3, 3, 5, 5, 4
SCoRF: Single-stage convolutional radiance fields for effective 3D scene representation,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 3, 5, 5, 4
Momentum-SAM: Sharpness Aware Minimization without Computational Overhead,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 5, 5, 6, 4
Constructive Large Language Model Alignment with Diverse Feedback,4.75, 5.0, 1.0897247358851685, 6, 3, 3, 4, 5, 4, 5, 4
Towards Interpretable Controllability in Object-Centric Learning,4.333333333333333, 6.0, 2.357022603955158, 1, 3, 6, 4, 6, 4
USTAM: UNIFIED SPATIO-TEMPORAL ATTENTION MIXFORMER FOR VISUAL OBJECT TRACKING,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 5, 5, 5
MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations,6.666666666666667, 6.0, 0.9428090415820634, 6, 4, 8, 3, 6, 4
The Cyclical Chaos And Its Equilibrium,3.4, 3.0, 0.8000000000000002, 3, 3, 5, 2, 3, 4, 3, 4, 3, 2
Intriguing Properties of Data Attribution on Diffusion Models,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 4, 5, 4
SoftTreeMax: Exponential Variance Reduction in Policy Gradient via Tree Expansion,6.0, 5.5, 1.224744871391589, 5, 3, 8, 3, 5, 3, 6, 3
Robust Backdoor Attack with Visible Semantic Sample-specific and Compatible Triggers,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 3
Fully Hyperbolic Convolutional Neural Networks for Computer Vision,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 4, 6, 3
RGLA: Reverse Gradient Leakage Attack using Inverted Cross-Entropy Loss Function,4.666666666666667, 5.0, 1.247219128924647, 3, 5, 5, 3, 6, 4
Text-guided Diffusion Model for 3D Molecule Generation,3.75, 4.0, 1.920286436967152, 1, 4, 6, 4, 3, 4, 5, 3
TabGFN: Tabular data generation based on GFlowNets,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 2, 5, 3, 3, 5
Benchmarking Structural Inference Methods for Interacting Dynamical Systems with Synthetic Data,5.5, 5.5, 0.5, 6, 2, 5, 2, 6, 4, 5, 4
Scaling Laws for Associative Memories,7.0, 8.0, 2.0, 8, 3, 8, 2, 3, 3, 8, 4, 8, 2
Learning multi-modal generative models with permutation-invariant encoders and tighter variational bounds,4.6, 5.0, 1.3564659966250536, 3, 4, 5, 3, 3, 4, 6, 3, 6, 3
Enhancing One-Shot Pruned Generative Pre-training Language Models through Sparse-Dense-Sparse Mechanism,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 4, 6, 3
Enhancing Transferable Adversarial Attacks on Vision Transformers through Gradient Normalization Scaling and High-Frequency Adaptation,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 4
An interpretable error correction method for enhancing code-to-code translation,5.0, 6.0, 1.4142135623730951, 3, 4, 6, 3, 6, 3
May the Forgetting Be with You: Alternate Replay for Learning with Noisy Labels,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 4, 5, 4, 5, 3
Counterfactual Image Generation for adversarially robust and interpretable Classifiers,3.0, 3.0, 1.4142135623730951, 3, 4, 5, 4, 1, 4, 3, 5
RLIF: Interactive Imitation Learning as Reinforcement Learning,5.0, 5.5, 1.224744871391589, 5, 4, 3, 4, 6, 3, 6, 4
Bidirectional-Reachable Hierarchical RL with Mutually Responsive Policies,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 3, 6, 4
Balanced learning with Token Selection for Few-shot Classification,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 3, 5, 5, 3
PowerGraph: A power grid benchmark dataset for graph neural networks,4.75, 4.0, 2.0463381929681126, 5, 3, 3, 3, 8, 3, 3, 4
Boosting Adverse Weather Crowd Counting via Multi-queue Contrastive Learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 5, 5, 4, 3, 5
DiffSound: Differentiable Modal Sound Simulation for Inverse Reasoning,4.0, 4.0, 1.0, 3, 3, 5, 3, 5, 4, 3, 3
ProteiNexus: Illuminating Protein Pathways through Structural Pre-training,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 4
Rotation Invariant Quantization for Model Compression,5.25, 5.0, 1.7853571071357126, 3, 4, 5, 5, 5, 2, 8, 5
The Need for Speed: Pruning Transformers with One Recipe,5.666666666666667, 6.0, 0.4714045207910317, 5, 3, 6, 2, 6, 3
Bongard-OpenWorld: Few-Shot Reasoning for Free-form Visual Concepts in the Real World,6.0, 5.5, 1.224744871391589, 8, 3, 5, 4, 5, 5, 6, 4
Towards 3D Molecule-Text Interpretation in Language Models,5.0, 5.5, 1.224744871391589, 5, 3, 3, 5, 6, 4, 6, 1
Effective pruning of web-scale datasets based on complexity of concept clusters,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 5, 6, 4
Encoding Speaker-Specific Latent Speech Feature for Speech Synthesis,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 3, 3, 4
Stochastic Extragradient with Flip-Flop Shuffling & Anchoring: Provable Improvements,4.666666666666667, 3.0, 2.357022603955158, 3, 4, 8, 3, 3, 4
AttEXplore: Attribution for Explanation with model parameters eXploration,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 3, 6, 4, 5, 3
BRUSLEATTACK: QUERY-EFFICIENT SCORE-BASED SPARSE ADVERSARIAL ATTACK,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 4, 5, 3, 3, 4
Win-Win: Training High-Resolution Vision Transformers from Two Windows,5.0, 5.5, 1.224744871391589, 3, 4, 5, 3, 6, 3, 6, 5
COSA: Concatenated Sample Pretrained Vision-Language Foundation Model,6.0, 5.5, 1.224744871391589, 8, 3, 5, 3, 5, 5, 6, 4
SOInter: A Novel Deep Energy-Based Interpretation Method for Explaining Structured Output Models,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 1, 5, 3, 6, 4
A Private Watermark for Large Language Models,5.0, 5.5, 1.224744871391589, 6, 2, 3, 3, 5, 3, 6, 3
Text2Reward: Dense Reward Generation with Language Models for Reinforcement Learning,5.0, 5.5, 1.224744871391589, 5, 5, 3, 4, 6, 4, 6, 3
Improving Neural Program Induction by Reflecting on Failures,3.75, 3.0, 1.299038105676658, 3, 3, 3, 2, 6, 4, 3, 3
Constructing Adversarial Examples for Vertical Federated Learning: Optimal Client Corruption through Multi-Armed Bandit,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 3, 5, 4
Efficient Action Robust Reinforcement Learning with Probabilistic Policy Execution Uncertainty,5.0, 5.0, 0.0, 5, 5, 5, 4, 5, 4
Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy Actor Critic,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 4, 5, 5
Attribute-Guided Diffusion for Unsupervised Few-Shot Font Generation,4.0, 4.0, 1.0, 5, 4, 5, 4, 3, 4, 3, 5
Generative Learning for Solving Non-Convex Problem with Multi-Valued Input-Solution Mapping,5.5, 5.5, 1.8027756377319946, 8, 4, 6, 4, 3, 3, 5, 3
Interpretable Diffusion via Information Decomposition,5.0, 6.0, 1.4142135623730951, 6, 4, 3, 5, 3, 3, 6, 3, 6, 4, 6, 2
Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models,5.0, 5.5, 1.224744871391589, 5, 4, 6, 4, 6, 3, 3, 4
Algorithms for Caching and MTS with reduced number of predictions,8.0, 8.0, 0.0, 8, 3, 8, 4, 8, 4, 8, 3
PETformer: Long-term Time Series Forecasting via Placeholder-enhanced Transformer,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 5, 5, 4
Interpretable Deep Clustering,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 6, 4, 8, 4
Spectrum-guided Multi-view Graph Fusion,4.0, 4.0, 1.0, 5, 3, 3, 5, 3, 4, 5, 3
FrAug: Frequency Domain Augmentation for Time Series Forecasting,4.6, 5.0, 0.7999999999999999, 5, 4, 5, 4, 3, 4, 5, 4, 5, 4
Two-timescale Extragradient for Finding Local Minimax Points,7.0, 7.0, 1.0, 6, 3, 8, 3, 8, 3, 6, 2
FedEBA+: Towards Fair and Effective Federated Learning via Entropy-based Model,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 3, 5, 3
Zero-Shot Visual Classification with Guided Cropping,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 3, 5, 5, 4
Uncertainty-aware Constraint Inference in Inverse Constrained Reinforcement Learning,5.5, 5.5, 0.5, 5, 3, 6, 3, 6, 3, 5, 3
NaturalSigner: Diffusion Models are Natural Sign Language Generator,4.75, 4.0, 2.0463381929681126, 5, 4, 8, 5, 3, 5, 3, 5
Generalized Convergence Analysis of Tsetlin Machines: A Probabilistic Approach to Concept Learning,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 3, 6, 3, 5, 2
TeG-Instruct: Towards Premium Instruction-Tuning Data via Text-Grounded Task Design,4.0, 4.0, 1.0, 5, 3, 5, 4, 3, 4, 3, 4
Iteration and Stochastic First-order Oracle Complexities of Stochastic Gradient Descent using Constant and Decaying Learning Rates,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 1, 5
LSSInst: Improving Geometric Modeling in LSS-Based BEV Perception with Instance Representation,4.5, 5.0, 0.8660254037844386, 5, 5, 3, 4, 5, 5, 5, 4
AutoChunk: Automated Activation Chunk for Memory-Efficient Deep Learning Inference,6.5, 6.5, 1.5, 5, 3, 8, 3
Scalable and Effective Implicit Graph Neural Networks on Large Graphs,5.5, 5.5, 1.8027756377319946, 8, 4, 3, 5, 6, 3, 5, 3
A qualitative theory of dynamical systems for assessing stability in ResNets,4.666666666666667, 3.0, 2.357022603955158, 3, 4, 3, 4, 8, 3
Distributional Distance Classifiers for Goal-Conditioned Reinforcement Learning,5.8, 5.0, 1.9390719429665317, 8, 4, 3, 2, 5, 5, 8, 2, 5, 2
Retrieval is Accurate Generation,6.75, 7.0, 1.299038105676658, 6, 4, 8, 4, 8, 4, 5, 3
Fair Classifiers Without Fair Training: An Influence-Guided Data Sampling Approach,4.6, 5.0, 0.7999999999999999, 5, 2, 5, 2, 3, 5, 5, 4, 5, 2
Data Descriptions from Large Language Models with Influence Estimation,2.5, 3.0, 0.8660254037844386, 3, 5, 3, 3, 1, 5, 3, 5
Towards Imitation Learning to Branch for MIP: A Hybrid Reinforcement Learning based Sample Augmentation Approach,5.333333333333333, 5.0, 0.4714045207910317, 5, 5, 6, 3, 5, 4
BTBS-LNS: A Binarized-Tightening Branch and Search Approach of Learning Large Neighborhood Search Policies for MIP,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 4, 3, 4, 5, 5
AnoRand - Deep Learning-Based Semi-Supervised Anomaly Detection with Synthetic Labels,3.0, 3.0, 0.0, 3, 5, 3, 5, 3, 4
Protein Captioning: Bridging the Gap between Protein Sequences and Natural Languages,4.5, 4.5, 1.5, 6, 4, 3, 3, 3, 5, 6, 4
Label Space-Induced Pseudo Label Refinement for Multi-Source Black-Box Domain Adaptation,2.5, 3.0, 0.8660254037844386, 3, 5, 1, 5, 3, 3, 3, 5
Fairness Through Matching for better group fairness,5.5, 5.5, 0.5, 6, 3, 5, 4
Decoupling Weighing and Selecting for Integrating Multiple Graph Pre-training Tasks,6.0, 5.5, 1.224744871391589, 5, 3, 6, 3, 5, 4, 8, 3
FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 3, 5, 3
Trend/Seasonality based Causal Structure for Time Series Counterfactual Outcome Prediction,3.75, 3.0, 1.299038105676658, 3, 4, 3, 2, 6, 4, 3, 2
Conceptual Graph Counterfactuals,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 3, 5, 4, 5, 2
Normalized Space Alignment: A Versatile Metric for Representation Space Discrepancy Minimization,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 5, 3, 2, 3, 4
MATLABER: Material-Aware Text-to-3D via LAtent BRDF auto-EncodeR,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 5, 5, 3, 3
MAP IT to Visualize Representations,6.0, 6.5, 2.1213203435596424, 3, 3, 5, 4, 8, 4, 8, 2
GraphGPT: Graph Learning with Generative Pre-trained Transformers,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 3, 3, 5, 3
LIMANS: Linear Model of the Adversarial Noise Space,5.5, 5.5, 0.5, 6, 4, 5, 4, 5, 3, 6, 3
Measuring Vision-Language STEM Skills of Neural Models,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 4, 5, 4
Latent Diffusion Counterfactual Explanations,5.0, 6.0, 1.4142135623730951, 6, 3, 6, 2, 3, 3
Finite Sample Analysis for Single-Loop Single-Timescale Natural Actor-Critic Algorithm,4.0, 4.0, 1.0, 3, 3, 5, 5, 3, 3, 5, 4
DUAL DENOISING LOGICAL REASONING FOR INDUCTIVE KNOWLEDGE GRAPH COMPLETION,2.5, 2.0, 1.6583123951777, 1, 5, 1, 4, 5, 4, 3, 4
Query and Response Augmentation Cannot Help Out-of-domain Math Reasoning Generalization,5.5, 5.5, 0.5, 6, 4, 5, 3
Tell Don't Show: Internalized Reasoning influences how LLMs generalize,3.5, 4.0, 1.6583123951777, 1, 4, 5, 3, 3, 4, 5, 3
Multiple Object Stitching for Unsupervised Representation Learning,4.75, 4.0, 2.0463381929681126, 3, 5, 3, 4, 8, 3, 5, 5
$\sigma$-zero: Gradient-based Optimization of \\$\ell_0$-norm Adversarial Examples,5.5, 5.5, 0.5, 6, 4, 5, 5, 6, 5, 5, 5
On Double-Descent in Reinforcement Learning with LSTD and Random Features,7.0, 7.0, 1.0, 6, 3, 8, 3, 8, 4, 6, 3
Forward-Backward Reasoning in Large Language Models for Mathematical Verification,4.666666666666667, 3.0, 2.357022603955158, 8, 4, 3, 5, 3, 4
MIXCON3D: SYNERGIZING MULTI-VIEW AND CROSS-MODAL CONTRASTIVE LEARNING FOR ENHANCING 3D REPRESENTATION,4.5, 5.0, 0.8660254037844386, 5, 5, 5, 5, 3, 4, 5, 4
Connectivity-based Token Condensation for Efficient Vision Transformer,4.25, 4.0, 1.299038105676658, 3, 4, 6, 4, 3, 4, 5, 4
Stability and Generalization in Free Adversarial Training,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 5, 4, 6, 4
Barycentric Alignment of Mutually Disentangled Modalities,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 5, 3, 6, 3
Dozerformer: Sequence Adaptive Sparse Transformer for Multivariate Time Series Forecasting,4.5, 4.5, 1.5, 3, 4, 6, 2, 3, 4, 6, 4
Towards Reliable Backdoor Attacks on Vision Transformers,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 3, 3, 3
The Wasserstein Believer: Learning Belief Updates for Partially Observable Environments through Reliable Latent Space Models,6.75, 6.0, 1.920286436967152, 6, 3, 6, 4, 5, 3, 10, 5
Modulated Phase Diffusor: Content-Oriented Feature Synthesis for Detecting Unknown Objects,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 5, 5, 6, 3
Large Language Models can Learn Rules,4.75, 4.0, 2.0463381929681126, 3, 3, 8, 4, 5, 3, 3, 4
Unified Medical Image Pre-training in Language-Guided Common Semantic Space,5.0, 5.5, 1.224744871391589, 6, 4, 6, 4, 5, 5, 3, 5
Towards Assessing and Benchmarking Risk-Return Tradeoff of Off-Policy Evaluation,6.5, 6.5, 1.5, 8, 3, 5, 2, 8, 3, 5, 3
Large Scene Synthesis Controlled With Detailed Text Using View-wise Conditional Joint Diffusion With Hierarchical Spatial Controls,4.5, 4.5, 1.5, 3, 4, 6, 5, 6, 4, 3, 2
Why Diffusion Models Are Stable and How to Make Them Faster: An Empirical Investigation and Optimization,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 4
Model2Scene: Learning 3D Scene Representation via Contrastive Language-CAD Models Pre-training,4.25, 4.0, 1.299038105676658, 6, 3, 3, 4, 5, 3, 3, 3
Synthetic data shuffling accelerates the convergence of federated learning under data heterogeneity,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 5, 5, 4, 5, 4
Characterizing ResNet's Universal Approximation Capability,5.5, 5.5, 1.8027756377319946, 8, 5, 3, 4, 5, 4, 6, 4
Optimal Multiple Transport with Applications to Visual Matching Model Fusion and Beyond,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 4, 5, 4
Provable Memory Efficient Self-Play Algorithm for Model-free Reinforcement Learning,5.0, 5.5, 1.224744871391589, 6, 4, 6, 3, 3, 3, 5, 3
Bilevel Optimization without Lower-Level Strong Convexity from the Hyper-Objective Perspective,4.166666666666667, 4.0, 1.2133516482134197, 5, 4, 6, 3, 3, 2, 3, 3, 5, 3, 3, 3
Benchmarks for Reinforcement Learning with Biased Offline Data and Imperfect Simulators,3.75, 3.0, 1.299038105676658, 3, 3, 3, 3, 3, 4, 6, 3
Locally Optimal Descent for Adaptive Stepsize Scheduling,nan, nan, nan
Transformer Fusion with Optimal Transport,6.0, 6.0, 0.0, 6, 3, 6, 3, 6, 4, 6, 4
Phrase Grounding-based Style Transfer for Single-Domain Generalized Object Detection,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 3, 5, 5
Exact Mean Square Linear Stability Analysis for SGD,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 3, 5, 2
Towards Meta-Pruning via Optimal Transport,6.2, 6.0, 1.8330302779823362, 8, 3, 8, 5, 6, 4, 6, 5, 3, 3
Reliable Classifications with Guaranteed Confidence using the Dempster-Shafer Theory of Evidence,4.75, 4.0, 2.0463381929681126, 3, 5, 5, 4, 8, 2, 3, 3
MoLE: Mixture of LoRA Experts,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 6, 4, 5, 4
Super Floating-Point (SuFP): Efficient To All. Multi-Region Piecewise Quantization using Scalable Bias with Hardware Optimization,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 5, 3, 4
PointHR: Exploring High-Resolution Architectures for 3D Point Cloud Segmentation,4.0, 3.0, 1.4142135623730951, 6, 5, 3, 5, 3, 5
Improving MLP Module in Vision Transformer,4.75, 4.0, 2.0463381929681126, 5, 4, 8, 5, 3, 5, 3, 5
Leveraging Graph Neural Networks to Boost Fine-Grained Image Classification,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 5, 4, 3, 4
Unleash Data Generation for Efficient and Effective Data-free Knowledge Distillation,4.75, 5.0, 1.0897247358851685, 5, 5, 5, 4, 6, 4, 3, 4
Calibrated on Average but not Within Each Slice: Few-shot Calibration for All Slices of a Distribution,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 3, 6, 4, 3, 4
On the Posterior Distribution in Denoising: Application to Uncertainty Quantification,5.5, 5.5, 1.8027756377319946, 6, 3, 3, 3, 5, 3, 8, 5
Provable Domain Generalization via Information Theory Guided Distribution Matching,5.5, 5.5, 1.8027756377319946, 6, 4, 3, 4, 8, 4, 5, 4
Learning Constraints from Offline Dataset via Inverse Dual Values Estimation,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 3, 5, 3
LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic Constraints,5.75, 5.0, 1.299038105676658, 5, 4, 5, 3, 8, 4, 5, 2
Turning large language models into cognitive models,6.75, 7.0, 1.299038105676658, 5, 3, 8, 5, 6, 5, 8, 5
Memory-Modular Classification: Learning to Generalize with Memory Replacement,4.75, 5.0, 1.0897247358851685, 3, 3, 6, 5, 5, 4, 5, 4
Skip-Attention: Improving Vision Transformers by Paying Less Attention,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 8, 4, 6, 4
Know2BIO: A Comprehensive Dual-View Benchmark for Evolving Biomedical Knowledge Graphs,3.75, 4.0, 1.920286436967152, 1, 3, 3, 3, 6, 5, 5, 4
Domain-Agnostic Self-Training for Semi-Supervised Learning,3.6666666666666665, 3.0, 0.9428090415820634, 5, 5, 3, 5, 3, 4
Refining Corpora from a Model Calibration Perspective for Chinese Spelling Correction,5.333333333333333, 5.0, 0.4714045207910317, 5, 2, 6, 4, 5, 2
Benchmarking and Improving Generator-Validator Consistency of Language Models,6.0, 5.0, 1.4142135623730951, 5, 4, 8, 5, 5, 4
Large Language Models Can Be Good Privacy Protection Learners,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 4, 3, 3, 5, 4
Enhancing Weakly Supervised 3D Medical Image Segmentation through Probabilistic-aware Learning,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 3, 3, 4
Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization,5.0, 5.0, 0.0, 5, 4, 5, 5, 5, 4
LogoRA: Local-Global Representation Alignment for Robust Time Series Classification,5.0, 5.0, 1.0954451150103321, 6, 3, 5, 4, 5, 4, 6, 4, 3, 5
Weakly Supervised Fine-grained Scene Graph Generation via Large Language Model,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 5, 4, 6, 5
InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation,6.0, 5.5, 1.224744871391589, 5, 4, 8, 5, 6, 4, 5, 5
A General Formulation of Independent Policy Optimization in Fully Decentralized MARL,3.3333333333333335, 3.0, 2.0548046676563256, 1, 5, 3, 3, 6, 3
Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization,6.25, 6.0, 1.0897247358851685, 5, 5, 6, 3, 8, 4, 6, 3
Knowledge Crosswords: Geometric Reasoning over Structured Knowledge with Large Language Models,4.25, 4.0, 1.299038105676658, 3, 4, 3, 4, 5, 3, 6, 4
Dictionary Contrastive Forward Learning via Adaptive Label Embeddings,5.666666666666667, 6.0, 2.0548046676563256, 6, 3, 8, 4, 3, 3
Guide Your Anomaly with Language,3.5, 3.0, 0.8660254037844386, 3, 5, 5, 3, 3, 4, 3, 5
Soft iEP: On the Exploration Inefficacy of Gradient Based Strong Lottery Exploration,5.0, 5.0, 1.0954451150103321, 3, 5, 5, 4, 6, 3, 6, 3, 5, 3
How Large Language Models Implement Chain-of-Thought?,6.25, 6.0, 2.48746859276655, 10, 5, 6, 3, 3, 4, 6, 4
Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments,7.25, 7.0, 1.920286436967152, 6, 4, 5, 3, 8, 3, 10, 4
FlowHash: Accelerating Audio Search with Balanced Hashing via Normalizing Flow,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 4, 3, 4
Finetuning Text-to-Image Diffusion Models for Fairness,7.333333333333333, 6.0, 1.8856180831641267, 6, 2, 10, 4, 6, 2
Bandit Learning in Matching: Unknown Preferences On Both Sides,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 5, 5, 3, 3, 3
Deep Geodesic Canonical Correlation Analysis for Covariance-Based Neuroimaging Data,5.666666666666667, 6.0, 0.4714045207910317, 6, 2, 6, 1, 5, 4
LLM Blueprint: Enabling Text-to-Image Generation with Complex and Detailed Prompts,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 6, 4, 5, 3
DeformUX-Net: Exploring a 3D Foundation Backbone for Medical Image Segmentation with Depthwise Deformable Convolution,4.5, 5.0, 0.8660254037844386, 3, 5, 5, 4, 5, 4, 5, 3
FFB: A Fair Fairness Benchmark for In-Processing Group Fairness Methods,6.0, 6.5, 2.1213203435596424, 8, 4, 3, 4, 8, 1, 5, 4
DSparsE: Dynamic Sparse Embedding for Knowledge Graph Completion,4.0, 4.0, 1.0, 3, 4, 5, 3, 5, 3, 3, 4
Creative Style Transfer,2.5, 2.0, 1.6583123951777, 1, 5, 3, 5, 5, 2, 1, 5
SWAP-NAS: Sample-Wise Activation Patterns for Ultra-fast NAS,6.5, 6.0, 0.8660254037844386, 8, 2, 6, 4, 6, 4, 6, 3
FFCA-Net: Stereo Image Compression via Fast Cascade Alignment of Side Information,5.666666666666667, 6.0, 0.4714045207910317, 5, 3, 6, 3, 6, 4
Invariance-based Learning of Latent Dynamics,4.5, 5.0, 0.8660254037844386, 3, 3, 5, 2, 5, 3, 5, 3
AUTOPARLLM: GNN-Guided Automatic Code Parallelization using Large Language Models,4.75, 4.0, 2.0463381929681126, 3, 5, 5, 3, 3, 3, 8, 5
Robotic Task Generalization via Hindsight Trajectory Sketches,7.0, 8.0, 1.4142135623730951, 5, 4, 8, 4, 8, 5
Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer,5.5, 5.5, 0.5, 6, 4, 5, 2, 5, 3, 6, 3
Permutations improve performance in three-dimensional bin packing problem,4.0, 4.0, 1.0, 5, 3, 3, 5, 5, 2, 3, 3
ExcelFormer: Making Neural Network Excel in Small Tabular Data Prediction,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 3, 5, 5, 4
Masked Structural Growth for 2x Faster Language Model Pre-training,6.333333333333333, 6.0, 1.247219128924647, 8, 4, 6, 3, 5, 3
NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers,7.0, 7.0, 1.0, 8, 5, 6, 4, 6, 5, 8, 3
Go beyond End-to-End Training: Boosting Greedy Local Learning with Context Supply,4.666666666666667, 5.0, 1.247219128924647, 3, 5, 6, 2, 5, 4
Communication-Efficient Federated Learning with Accelerated Client Gradient,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 3, 3, 3
Federated Optimization Algorithms with Random Reshuffling and Gradient Compression,5.25, 6.0, 1.299038105676658, 6, 3, 6, 4, 3, 5, 6, 4
Robust Self-supervised Learning in Heterogeneous Graph Based on Feature-Topology Balancing,4.0, 3.0, 1.4142135623730951, 6, 3, 3, 4, 3, 5
Attribute Based Interpretable Evaluation Metrics for Generative Models,5.333333333333333, 5.0, 2.0548046676563256, 3, 3, 8, 5, 5, 4
MMICL: Empowering Vision-language Model with Multi-Modal In-Context Learning,5.2, 6.0, 1.9390719429665317, 3, 4, 8, 4, 6, 5, 6, 4, 3, 3
Learning to Generate Predictor for Long-Term Time Series Forecasting,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 5, 5, 3, 3, 4
ContextNER: Contextual Phrase Generation at Scale,4.0, 3.0, 1.4142135623730951, 3, 2, 3, 3, 6, 4
A Simple Data Augmentation for Feature Distribution Skewed Federated Learning,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 6, 3, 5, 3
BeGin: Extensive Benchmark Scenarios and An Easy-to-use Framework for Graph Continual Learning,4.25, 4.0, 1.299038105676658, 5, 3, 3, 4, 6, 3, 3, 4
Efficient Transfer Learning in Diffusion Models via Adversarial Noise,5.75, 6.0, 0.4330127018922193, 5, 5, 6, 3, 6, 3, 6, 2
L2B: Learning to Bootstrap Robust Models for Combating Label Noise,5.0, 5.5, 1.224744871391589, 6, 4, 3, 5, 5, 4, 6, 2
Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author Prompt Editing,6.0, 5.5, 1.224744871391589, 6, 3, 5, 3, 5, 4, 8, 4
RSAM: Learning on Manifolds with Riemannian Sharpness-Aware Minimization,3.0, 3.0, 1.632993161855452, 5, 3, 1, 5, 3, 4
${\rm EFO}_k$-CQA: Towards Knowledge Graph Complex Query Answering beyond Set Operation,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 3, 3, 3, 5, 3
Converging and Stabilizing Generative Adversarial Imitation Learning,3.0, 3.0, 0.0, 3, 4, 3, 2, 3, 4, 3, 4
StudentEval: A Benchmark of Student-Written Prompts for Large Language Models of Code,4.0, 4.0, 1.0, 5, 5, 5, 3, 3, 4, 3, 4
Dynamic Continuous Hyperparameter Tuning for Generalized Linear Contextual Bandits,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 3
Label-Noise Robust Diffusion Models,5.5, 5.5, 0.5, 6, 3, 6, 4, 5, 4, 5, 3
EasyTPP: Towards Open Benchmarking Temporal Point Processes,5.5, 4.5, 2.8722813232690143, 6, 4, 3, 3, 3, 5, 10, 4
Solving Inverse Problem With Unspecified Forward Operator Using Diffusion Models,3.75, 3.0, 1.299038105676658, 3, 5, 3, 4, 6, 2, 3, 4
ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection,6.25, 6.0, 1.0897247358851685, 5, 4, 6, 3, 8, 4, 6, 2
Adaptive Window Pruning for Efficient Local Motion Deblurring,5.666666666666667, 6.0, 2.0548046676563256, 8, 5, 6, 4, 3, 5
Sparser Better Deeper Stronger: Improving Sparse Training with Exact Orthogonal Initialization,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 5, 5, 3
A unified sampling framework for solver searching of Diffusion Probabilistic Models,5.6, 6.0, 0.4898979485566356, 5, 4, 6, 4, 6, 4, 6, 4, 5, 3
Hierarchical Classification by Training to Diffuse on the Manifold,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 3, 6, 4
xCodeEval: An Execution based Large Scale Multilingual Multitask Benchmark for Code Understanding Generation Translation and Retrieval,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 3, 4, 5, 5
ERA-Solver: Error-Robust Adams Solver for Fast Sampling of Diffusion Probabilistic Models,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 4, 3, 3
A representation-learning game for classes of prediction tasks,6.75, 7.0, 1.299038105676658, 5, 3, 8, 2, 6, 2, 8, 4
ORBIS: Open Dataset Can Rescue You From Dataset Bias,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 2
In-Context Learning with Iterative Demonstration Selection,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 5, 5, 4, 5, 4
Learning to Optimize for Reinforcement Learning,5.0, 5.5, 1.224744871391589, 3, 5, 6, 4, 6, 3, 5, 4
Knowledge Is Not Wisdom: Weight Balancing Mechanism for Local and Global Training in Federated Learning,3.5, 4.0, 1.6583123951777, 3, 4, 5, 4, 1, 5, 5, 4
Towards Interpretable Continual Learning Through Controlling Concepts,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 5, 4, 3, 3
Graph Representation Learning enhanced Semi-supervised Feature Selection,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 6, 4, 5, 3
AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 4, 5, 2
Fairness Improves Learning from Noisily Labeled Long-Tailed Data,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 6, 2, 3, 3
Meta-Knowledge Extraction: Uncertainty-Aware Prompted Meta-Learning,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 2
Key point is key in resolving the offline three-dimensional bin packing problem,2.3333333333333335, 3.0, 0.9428090415820634, 3, 4, 1, 5, 3, 5
Elephant Neural Networks: Born to Be a Continual Learner,3.0, 3.0, 1.632993161855452, 5, 4, 1, 5, 3, 5
Source-Free Unsupervised Domain Adaptation with Hypothesis Consolidation of Prediction Rationale,4.4, 5.0, 1.2, 3, 4, 5, 4, 5, 5, 3, 4, 6, 3
DebateGPT: Fine-tuning Large Language Models with Multi-agent Debate Supervision,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 4
Train Short Test Long In Combinatorial Optimization,3.5, 4.0, 1.6583123951777, 1, 4, 3, 4, 5, 3, 5, 3
Learning Unorthogonalized Matrices for Rotation Estimation,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 3, 3, 5
MissDiff: Training Diffusion Models on Tabular Data with Missing Values,6.25, 6.0, 1.0897247358851685, 6, 3, 5, 3, 6, 2, 8, 4
Probabilistic Graphical Model for Robust Graph Neural Networks against Noisy Labels,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 4, 5, 4, 5, 3
Submodular Reinforcement Learning,6.75, 7.0, 1.299038105676658, 8, 3, 5, 4, 8, 4, 6, 3
InfoAug: Mutual Information Informed Augmentation for Representation Learning,3.75, 3.0, 1.299038105676658, 6, 3, 3, 5, 3, 3, 3, 4
A Case Study for the Behaviors of Generalists and Specialists in Competitive Games,3.75, 3.0, 1.299038105676658, 3, 2, 3, 4, 6, 3, 3, 3
Data-Efficient Molecular Generation with Hierarchical Textual Inversion,5.25, 6.0, 1.299038105676658, 6, 4, 6, 3, 6, 4, 3, 4
Advancing Test-Time Adaptation for Acoustic Foundation Models in Open-World Shifts,5.5, 5.5, 0.5, 5, 5, 5, 3, 6, 4, 6, 2
Quantifying Anonymity in Score-Based Generators with Adversarial Fingerprinting,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 4, 3, 4
Neuron-Enhanced AutoEncoder Matrix Completion: Theory and Practice,6.75, 7.0, 1.299038105676658, 5, 4, 6, 5, 8, 5, 8, 5
Estimating Heterogeneous Treatment Effect with Delayed Response,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 3, 4, 6, 3
What If You Were Not There? Learning Causally-Aware Representations of Multi-Agent Interactions,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 3, 6, 4
$\infty$-Diff: Infinite Resolution Diffusion with Subsampled Mollified States,5.5, 5.5, 1.8027756377319946, 3, 4, 8, 5, 6, 3, 5, 3
What Will My Model Forget? Forecasting Forgotten Examples in Language Model Refinement,6.0, 5.5, 1.224744871391589, 8, 3, 5, 3, 6, 4, 5, 3
Opponent Modeling based on Sub-Goal Inference,4.25, 4.0, 1.299038105676658, 3, 4, 3, 5, 5, 2, 6, 4
Stochastic Modified Equations and Dynamics of Dropout Algorithm,5.0, 5.5, 1.224744871391589, 3, 4, 5, 4, 6, 3, 6, 2
Stochastic Gradient Langevin Dynamics Based on Quantization with Increasing Resolution,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 5, 3, 3, 3
Towards Readable Scalable Vector Graphic Generation,4.0, 4.0, 1.0, 5, 5, 5, 3, 3, 5, 3, 4
Contrastive Positive Unlabeled Learning,5.5, 5.5, 1.8027756377319946, 5, 3, 8, 4, 3, 4, 6, 3
Text2NKG: Fine-Grained N-ary Relation Extraction for N-ary relational Knowledge Graph Construction,4.0, 4.0, 1.0, 5, 3, 5, 4, 3, 4, 3, 3
Fairness without Sensitive attributes via Noise and Uncertain Predictions,4.0, 4.0, 1.0, 5, 5, 3, 3
Bayesian Pseudo-Coresets via Contrastive Divergence,2.5, 3.0, 0.8660254037844386, 1, 5, 3, 4, 3, 3, 3, 5
Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 6, 4, 5, 4
3D-GOI: 3D GAN Omni-Inversion for Multifaceted and Multi-object Editing,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 4, 6, 3
How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 3, 3, 4
Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 3, 5, 3
Prompt-Based Length Controlled Generation with Reinforcement Learning,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 4, 5, 4, 5, 4
Transferring Learning Trajectories of Neural Networks,6.0, 6.0, 0.0, 6, 3, 6, 3, 6, 3
Resolving Knowledge Conflicts in Large Language Models,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 6, 4, 5, 4
Understanding Vision and Language Representations under the Lens of Intrinsic Dimension,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 4, 5, 2
Average Sensitivity of Hierarchical Clustering,4.25, 4.0, 1.299038105676658, 6, 4, 5, 4, 3, 4, 3, 3
Best Possible Q-Learning,4.25, 4.0, 1.299038105676658, 5, 4, 3, 2, 3, 2, 6, 3
VQ-TR: Vector Quantized Attention for Time Series Forecasting,5.0, 6.0, 1.4142135623730951, 6, 4, 3, 4, 6, 4
Benchmarking Multivariate Time Series Anomaly Detection with Large-Scale Real-World Datasets,3.75, 3.0, 1.299038105676658, 3, 5, 3, 4, 3, 4, 6, 4
Decoupled Marked Temporal Point Process using Neural Ordinary Differential Equations,5.666666666666667, 6.0, 2.0548046676563256, 8, 3, 3, 3, 6, 4
Unsupervised Order Learning,5.25, 5.0, 0.4330127018922193, 5, 5, 5, 4, 5, 3, 6, 4
ResolvNet: A Graph Convolutional Network with multi-scale Consistency,5.5, 5.5, 1.8027756377319946, 3, 4, 6, 3, 8, 2, 5, 3
CRL-NET: ACCELERATED MAGNETIC RESONANCE IMAGING RECONSTRUCTION THROUGH COIL REPRESENTATION LEARNING,1.6666666666666667, 1.0, 0.9428090415820634, 1, 5, 1, 4, 3, 4
Making Pre-trained Language Models Great on Tabular Prediction,5.25, 6.0, 1.299038105676658, 6, 4, 6, 4, 3, 2, 6, 3
T1: Scaling Diffusion Probabilistic Fields to High-Resolution on Unified Visual Modalities,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 5, 3, 4, 3, 3
A Vision-free Baseline for Multimodal Grammar Induction,2.3333333333333335, 3.0, 0.9428090415820634, 3, 5, 1, 4, 3, 2
Domain Prompt Matters a Lot in Multi-Source Few-Shot Domain Adaptation,3.25, 3.0, 1.7853571071357126, 1, 5, 6, 4, 3, 5, 3, 3
Transferable Deep Clustering Model,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 6, 3, 3, 3
SSCBench: Monocular 3D Semantic Scene Completion Benchmark in Street Views,5.75, 5.0, 1.299038105676658, 5, 4, 8, 3, 5, 4, 5, 4
Fixed Non-negative Orthogonal Classifier: Inducing Zero-mean Neural Collapse with Feature Dimension Separation,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 6, 3, 5, 4
Linear Attention via Orthogonal Memory,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 3, 5, 5, 6, 3
Sequential Bayesian Continual Learning with Meta-Learned Neural Networks,5.333333333333333, 5.0, 0.4714045207910317, 5, 2, 6, 4, 5, 4
FreeLM: Fine-Tuning-Free Language Model,2.0, 2.0, 1.0, 3, 3, 1, 5, 3, 4, 1, 4
Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT-4,3.75, 3.0, 1.299038105676658, 3, 4, 6, 3, 3, 4, 3, 4
Collaborating Heterogeneous Natural Language Processing Tasks via Federated Learning,7.0, 7.0, 1.0, 6, 2, 8, 3
pFedSAM: Secure Federated Learning Against Backdoor Attacks via Personalized Sharpness-Aware Minimization,3.75, 3.0, 1.299038105676658, 3, 4, 3, 5, 6, 4, 3, 4
Enhanced Model-agnostic Training of Deep Tabular Generation Models,3.75, 4.0, 1.920286436967152, 6, 3, 1, 3, 3, 4, 5, 4
Parsimonious Demonstrations and Fine-Tuning for Large Language Models,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 3, 3, 5, 3
Solving Inverse Problems with Latent Diffusion Models via Hard Data Consistency,6.5, 6.0, 0.8660254037844386, 6, 3, 6, 4, 6, 3, 8, 4
Learning to Branch with Offline Reinforcement Learning,4.8, 5.0, 1.8330302779823362, 5, 5, 3, 4, 3, 4, 8, 3, 5, 4
Polynomial-based Self-Attention for Table Representation learning,6.333333333333333, 6.0, 1.247219128924647, 6, 3, 8, 3, 5, 4
Interpreting Reward Models in RLHF-Tuned Language Models Using Sparse Autoencoders,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 3
SimTeG: A Frustratingly Simple Approach Improves Textual Graph Learning,4.666666666666667, 5.0, 1.247219128924647, 5, 5, 3, 4, 6, 4
Benchmarks and Custom Package for Electrical Load Forecasting,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 3, 4, 5, 4
Extending to New Domains without Visual and Textual Oracles,5.333333333333333, 5.0, 2.0548046676563256, 3, 4, 5, 4, 8, 3
LegoMT2: Non-Blocking Federated Learning for Massive Multilingual Machine Translation,5.333333333333333, 5.0, 0.4714045207910317, 5, 5, 6, 3, 5, 3
MaGIC: Multi-modality Guided Image Completion,6.0, 5.0, 1.4142135623730951, 8, 4, 5, 3, 5, 4
The False Promise of Imitating Proprietary Language Models,6.5, 6.5, 1.5, 8, 4, 5, 4, 8, 4, 5, 3
AmortizedPeriod: Attention-based Amortized Inference for Periodicity Identification,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 4, 6, 3, 5, 2
How Do Transformers Learn In-Context Beyond Simple Functions? A Case Study on Learning with Representations,6.25, 6.0, 1.0897247358851685, 6, 4, 8, 3, 6, 4, 5, 3
EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision,6.5, 6.5, 1.5, 5, 3, 8, 3, 8, 4, 5, 4
Coreset Selection For Object Detection,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 6, 4, 5, 4
Rethinking the OoD Generalization for Deep Neural Network: A Frequency Domain Perspective,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 3, 5, 4
Combinatorial Bandits for Maximum Value Reward Function under Value-Index Feedback,5.25, 6.0, 1.299038105676658, 6, 3, 6, 3, 3, 3, 6, 3
Sample-Efficient Linear Representation Learning from Non-IID Non-Isotropic Data,6.25, 6.0, 1.0897247358851685, 6, 3, 8, 4, 5, 3, 6, 3
Alice Benchmarks: Connecting Real World Object Re-Identification with the Synthetic,5.5, 5.5, 1.8027756377319946, 3, 5, 5, 5, 8, 4, 6, 4
SpikeBERT: A Language Spikformer Learned from BERT with Knowledge Distillation,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 6, 5, 8, 4
Large Language Models as Generalizable Policies for Embodied Tasks,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 4, 5, 3, 5, 3
LLM-driven Hateful Meme Detection via Cross-modal Memorizing and Self-rejection Training,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 2, 6, 4, 5, 4
Video Language Planning,7.0, 7.0, 1.0, 6, 4, 8, 3, 8, 3, 6, 4
Fair Attribute Classification via Distance Covariance,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 3, 5, 4
NanoLM: An Affordable LLM Study Benchmark via Accurate Loss Prediction Across Scales,5.25, 5.0, 0.4330127018922193, 5, 3, 6, 4, 5, 3, 5, 3
Youku-mPLUG: A 10 Million Large-scale Chinese Video-Language Dataset for Pre-training and Benchmarks,6.0, 5.5, 1.224744871391589, 5, 4, 5, 5, 8, 4, 6, 5
Diffusion-Stego: Training-free Diffusion Generative Steganography via Message Projection,3.0, 3.0, 1.4142135623730951, 5, 4, 3, 5, 3, 4, 1, 4
PAGAR: Taming Reward Misalignment in Inverse Reinforcement Learning-Based Imitation Learning with Protagonist Antagonist Guided Adversarial Reward,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 5, 3, 3, 3
LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment,5.25, 6.0, 1.299038105676658, 6, 5, 6, 4, 3, 4, 6, 3
An Efficient Membership Inference Attack for the Diffusion Model by Proximal Initialization,7.5, 8.0, 0.8660254037844386, 8, 4, 6, 4, 8, 4, 8, 4
InfoNet: An Efficient Feed-Forward Neural Estimator for Mutual Information,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 6, 4, 5, 3
Neural Architecture Search for TinyML with Reinforcement Learning,4.6, 5.0, 0.7999999999999999, 5, 4, 5, 3, 3, 4, 5, 4, 5, 2
A Novel Evaluation Framework for Image Inpainting via Multi-Pass Self-Consistency,3.0, 3.0, 1.4142135623730951, 1, 4, 3, 5, 3, 4, 5, 3
Mol-Instructions - A Large-Scale Biomolecular Instruction Dataset for Large Language Models,6.75, 7.0, 1.299038105676658, 6, 3, 8, 4, 8, 3, 5, 4
Solving Diffusion ODEs with Optimal Boundary Conditions for Better Image Super-Resolution,6.0, 5.0, 1.4142135623730951, 5, 4, 8, 5, 5, 3
Learning Directed Graphical Models with Optimal Transport,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 3
PyTrial: Machine Learning Software and Benchmark for Clinical Trial Applications,5.0, 5.0, 0.0, 5, 3, 5, 5, 5, 4, 5, 3
ViCor: Bridging Visual Understanding and Commonsense Reasoning with Large Language Models,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 5, 5, 4, 6, 4
Reduce Reuse and Recycle: Navigating Test-Time Adaptation with OOD-Contaminated Streams,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 4, 5, 5, 6, 4
Confident Sinkhorn Allocation for Pseudo-Labeling,5.5, 5.5, 1.8027756377319946, 8, 3, 6, 3, 3, 4, 5, 4
Information Retention via Learning Supplemental Features,5.4, 6.0, 1.2, 6, 4, 6, 2, 6, 3, 3, 4, 6, 4
Don't Play Favorites: Minority Guidance for Diffusion Models,5.0, 5.5, 1.224744871391589, 6, 4, 6, 4, 5, 4, 3, 5
Learning from Aggregate responses: Instance Level versus Bag Level Loss Functions,5.6, 6.0, 0.48989794855663565, 5, 3, 6, 4, 5, 3, 6, 3, 6, 4
C-MCTS: Safe Planning with Monte Carlo Tree Search,4.0, 4.0, 1.0, 5, 3, 3, 5, 3, 3, 5, 3
Bayesian Preference Elicitation for Personalized Prefactual Recommendation,4.25, 4.0, 1.299038105676658, 3, 5, 5, 4, 6, 4, 3, 3
ObjectNet Captions: Models are not superhuman captioners,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 4
Robust Multimodal Learning with Missing Modalities via Parameter-Efficient Adaptation,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 3, 5, 5, 3, 4
HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments,6.25, 6.0, 1.0897247358851685, 8, 3, 6, 4, 6, 4, 5, 3
ProofNet: Autoformalizing and Formally Proving Undergraduate-Level Mathematics,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 4, 3, 4, 5, 4
Noise-guided Unsupervised Outlier Detection,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 4
Mayfly: a Neural Data Structure for Graph Stream Summarization,7.0, 8.0, 1.4142135623730951, 8, 4, 8, 3, 5, 4
LCA-on-the-Line: Benchmarking Out-of-Distribution Generalization with Class Taxonomies,5.333333333333333, 5.0, 2.0548046676563256, 3, 4, 5, 3, 8, 3
Reinforcement Learning-based Layer-wise Aggregation for Personalized Federated Learning,5.0, 6.0, 1.4142135623730951, 6, 3, 3, 4, 6, 3
PromptCoT: Align Prompt Distribution via Adapted Chain-of-Thought,4.5, 4.5, 1.5, 6, 2, 3, 3
SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models,6.2, 6.0, 0.9797958971132712, 6, 4, 8, 4, 5, 4, 6, 5, 6, 4
Visual Semantic Learning via Early Stopping in Inverse Scale Space,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 5, 2, 6, 3
Rethinking Label Smoothing as a Tool for Embedding Perturbation Uncertainty,5.0, 5.5, 1.224744871391589, 6, 3, 5, 3, 3, 3, 6, 3
FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things,4.75, 5.0, 1.0897247358851685, 6, 3, 3, 4, 5, 4, 5, 3
Exploring the Common Appearance-Boundary Adaptation for Nighttime Optical Flow,8.0, 8.0, 1.632993161855452, 10, 3, 8, 2, 6, 4
Tackling Non-Stationarity in Reinforcement Learning via Causal-Origin Representation,4.0, 3.0, 2.0, 3, 4, 3, 4, 3, 4, 8, 3, 3, 3
Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models,6.333333333333333, 6.0, 1.247219128924647, 8, 3, 6, 3, 5, 2
A One-Step MSE Estimation of Models in Production,3.4, 3.0, 0.8000000000000002, 5, 4, 3, 2, 3, 3, 3, 3, 3, 2
Temporal Generalization Estimation in Evolving Graphs,5.8, 5.0, 1.16619037896906, 5, 4, 8, 3, 5, 3, 5, 5, 6, 3
Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining,6.25, 6.0, 1.0897247358851685, 6, 3, 8, 3, 6, 1, 5, 3
On Learning with a Concurrent Verifier: Convexity Improving Bounds and Complex Requirements,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 3, 2, 6, 3
Model Inversion Robustness: Can Transfer Learning Help?,4.75, 5.0, 1.0897247358851685, 3, 5, 6, 5, 5, 4, 5, 4
On the Hardness of Online Nonconvex Optimization with Single Oracle Feedback,6.25, 6.0, 1.0897247358851685, 5, 4, 6, 3, 8, 3, 6, 3
METRA: Scalable Unsupervised RL with Metric-Aware Abstraction,7.0, 7.0, 1.0, 8, 3, 6, 3, 6, 5, 8, 4
On the Vulnerability of Adversarially Trained Models Against Two-faced Attacks,7.0, 8.0, 1.4142135623730951, 5, 5, 8, 4, 8, 5
Physics-infused Intention Network for Crowd Simulation,5.333333333333333, 5.0, 2.0548046676563256, 8, 3, 3, 4, 5, 3
Graphical Multioutput Gaussian Process with Attention,5.5, 5.5, 1.8027756377319946, 3, 4, 5, 4, 6, 4, 8, 4
MOFI: Learning Image Representations from Noisy Entity Annotated Images,6.0, 5.5, 1.224744871391589, 6, 4, 5, 4, 8, 4, 5, 5
A Game-theoretic Approach to Personalized Federated Learning Based on Target Interpolation,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 3, 5, 3
CropNet: An Open Large-Scale Dataset with Multiple Modalities for Climate Change-aware Crop Yield Predictions,3.25, 3.0, 1.7853571071357126, 3, 4, 1, 5, 6, 3, 3, 5
Dynamic Training Guided by Training Dynamics,4.0, 4.0, 1.0, 5, 2, 3, 3, 5, 5, 3, 3
Accelerating Simulation-Based Influence Maximization via Bayesian Optimization,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 3, 4, 6, 4
Soft Contrastive Learning for Time Series,6.0, 5.5, 1.224744871391589, 8, 4, 5, 4, 6, 4, 5, 5
Efficient Integrators for Diffusion Generative Models,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 8, 3, 6, 2
Learning Over Molecular Conformer Ensembles: Datasets and Benchmarks,6.333333333333333, 6.0, 1.247219128924647, 8, 4, 5, 5, 6, 3
Enhancing Personal Decentralized Federated Learning through Model Decoupling,4.75, 5.0, 1.0897247358851685, 6, 3, 3, 3, 5, 2, 5, 3
Splitted Wavelet Differential Inclusion,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 1, 5, 3
YoooP: You Only Optimize One Prototype per Class for Non-Exemplar Incremental Learning,5.0, 5.5, 1.224744871391589, 6, 5, 3, 4, 5, 4, 6, 4
Feynman-Kac Operator Expectation Estimator: An Innovative Method for Enhancing MCMC Efficiency and Reducing Variance,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4, 3, 2
Provably Robust Conformal Prediction with Improved Efficiency,6.25, 6.0, 1.0897247358851685, 6, 3, 6, 4, 8, 3, 5, 4
DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 6, 3, 8, 4
Boosting Fast and High-Quality Speech Synthesis with Linear Diffusion,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 6, 4, 3, 5
FedImpro: Measuring and Improving Client Update in Federated Learning,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 2, 5, 3, 6, 3
Deep Reinforcement Learning from Weak Hierarchical Preference Feedback,4.0, 4.0, 1.0, 3, 3, 3, 4, 5, 3, 5, 5
How to Guess a Gradient,5.0, 5.5, 1.224744871391589, 3, 3, 6, 4, 6, 4, 5, 4
Compose and Conquer: Diffusion-Based 3D Depth Aware Composable Image Synthesis,6.0, 6.0, 0.0, 6, 3, 6, 4, 6, 4
A New Theoretical Perspective on Data Heterogeneity in Federated Averaging,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 3, 6, 3, 3, 3
Diff-Transfer: Model-based Robotic Manipulation Skill Transfer via Differentiable Physics Simulation,3.4, 3.0, 1.4966629547095767, 5, 3, 5, 2, 3, 3, 1, 4, 3, 3
A Unified Framework for Bayesian Optimization under Contextual Uncertainty,5.0, 5.5, 1.224744871391589, 6, 3, 5, 4, 3, 3, 6, 3
Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection,6.0, 5.0, 1.4142135623730951, 5, 4, 8, 4, 5, 3
STAGE Net: Spatio-Temporal Attention-based Graph Encoding for Learning Multi-Agent Interactions in the presence of Hidden Agents,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 3, 6, 4, 5, 4
Free from Bellman Completeness: Trajectory Stitching via Model-based Return-conditioned Supervised Learning,5.0, 5.5, 1.224744871391589, 6, 3, 6, 4, 3, 5, 5, 3
Diffusion Models for Multi-Task Generative Modeling,5.0, 5.0, 0.0, 5, 4, 5, 2, 5, 5, 5, 4
WebArena: A Realistic Web Environment for Building Autonomous Agents,6.333333333333333, 6.0, 1.247219128924647, 5, 3, 6, 3, 8, 4
Efficient Realistic Avatar Generation via Model Compression and Enhanced Rendering,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 5, 4, 3, 5
Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers,5.25, 6.0, 1.299038105676658, 6, 2, 6, 3, 6, 3, 3, 4
Towards Faithful Neural Network Intrinsic Interpretation with Shapley Additive Self-Attribution,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 4, 6, 3
Sparse Weight Averaging with Multiple Particles for Iterative Magnitude Pruning,5.8, 5.0, 1.16619037896906, 5, 4, 5, 4, 6, 3, 8, 4, 5, 4
WildFusion: Learning 3D-Aware Latent Diffusion Models in View Space,5.75, 6.0, 1.7853571071357126, 3, 4, 6, 4, 8, 3, 6, 4
Causal Inference with Conditional Front-Door Adjustment and Identifiable Variational Autoencoder,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 5, 4, 6, 3
HOVER: Hyperbolic Video-text Retrieval,4.25, 4.0, 1.299038105676658, 3, 5, 5, 4, 3, 4, 6, 4
Towards Better Propagation of Non-parametric GNNs,3.5, 3.0, 0.8660254037844386, 3, 5, 5, 5, 3, 4, 3, 5
Enhancing Group Fairness in Online Settings Using Oblique Decision Forests,5.8, 6.0, 1.6, 6, 4, 3, 3, 8, 4, 6, 3, 6, 3
Generative Learning for Financial Time Series with Irregular and Scale-Invariant Patterns,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 3, 5, 2
MetaDist: An Infrastructure for Automatic Parallelism via ShardCombine Algorithm,3.75, 3.0, 1.299038105676658, 3, 3, 3, 4, 3, 5, 6, 4
Multiscale Positive-Unlabeled Detection of AI-Generated Texts,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 5, 6, 4, 6, 2
Diffusion Sampling with Momentum for Mitigating Divergence Artifacts,6.25, 6.0, 1.0897247358851685, 8, 4, 5, 3, 6, 2, 6, 3
ProGO: Probabilistic Global Optimizer,4.25, 4.0, 1.299038105676658, 3, 3, 6, 4, 3, 4, 5, 3
Differentially Private Low-dimensional Synthetic Data from High-dimensional Datasets,4.0, 5.0, 1.7320508075688772, 1, 4, 5, 4, 5, 3, 5, 3
A Lightweight Method for Tackling Unknown Participation Statistics in Federated Averaging,6.0, 5.5, 1.224744871391589, 6, 4, 5, 4, 5, 4, 8, 3
Posterior Probability-Based Label Recovery Attack in Federated Learning,5.333333333333333, 5.0, 0.4714045207910317, 5, 5, 5, 4, 6, 4
Learning Spatio-Temporal Representation for Multivariate Time Series,4.0, 3.0, 1.2649110640673518, 3, 5, 3, 4, 6, 3, 5, 4, 3, 4
Nugget 2D: Dynamic Contextual Compression for Scaling Decoder-only Language Models,5.5, 5.5, 0.5, 6, 3, 5, 4
Deep PDE Solvers for Subgrid Modelling and Out-of-Distribution Generalization,4.0, 4.0, 1.0, 3, 4, 5, 2, 3, 2, 5, 4
Unleashing the Power of Visual Prompting At the Pixel Level,4.0, 3.0, 1.4142135623730951, 3, 5, 3, 4, 6, 3
Active Test-Time Adaptation: Theoretical Analyses and An Algorithm,6.5, 6.5, 1.5, 5, 4, 5, 3, 8, 4, 8, 5
AlignDiff: Aligning Diverse Human Preferences via Behavior-Customisable Diffusion Model,6.75, 7.0, 1.299038105676658, 8, 2, 8, 3, 5, 3, 6, 3
Evaluating Multi-Agent Coordination Abilities in Large Language Models,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 4
Non-Visible Light Data Synthesis: A Case Study for Synthetic Aperture Radar Imagery,5.25, 5.0, 1.7853571071357126, 3, 4, 5, 4, 5, 4, 8, 4
Doubly Robust Proximal Causal Learning for Continuous Treatments,6.0, 6.0, 0.0, 6, 3, 6, 4, 6, 4
One-hot Generalized Linear Model for Switching Brain State Discovery,6.333333333333333, 8.0, 2.357022603955158, 8, 5, 3, 4, 8, 4
RetroDiff: Retrosynthesis as Multi-stage Distribution Interpolation,4.666666666666667, 3.0, 2.357022603955158, 8, 4, 3, 3, 3, 4
ZegOT: Zero-shot Segmentation Through Optimal Transport of Pixels to Text Prompts,5.0, 6.0, 1.4142135623730951, 3, 4, 6, 3, 6, 4
Neural Auto-designer for Enhanced Quantum Kernels,4.25, 5.0, 1.920286436967152, 1, 5, 5, 5, 5, 4, 6, 4
Functional Geometry Guided Protein Sequence and Backbone Structure Co-Design,3.0, 3.0, 0.0, 3, 5, 3, 3, 3, 4
The Phase Transition Phenomenon of Shuffled Regression,5.8, 5.0, 1.16619037896906, 8, 2, 5, 4, 5, 3, 5, 2, 6, 2
Error-Feedback Meets Stochastic Approximation with Two Time Scales,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 4, 3, 4
Exploring Counterfactual Alignment Loss towards Human-Centered AI,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 4, 3, 4
The Blessings of Multiple Treatments and Outcomes in Treatment Effect Estimation,5.25, 5.0, 0.4330127018922193, 5, 3, 6, 5, 5, 4, 5, 3
On the Parameterization of Second-Order Optimization Effective towards the Infinite Width,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 8, 4, 6, 3
Visual Attention-Prompted Prediction and Learning,4.25, 4.0, 1.299038105676658, 3, 4, 3, 4, 6, 3, 5, 3
GPT-Driver: Learning to Drive with GPT,4.5, 5.0, 0.8660254037844386, 5, 5, 3, 3, 5, 3, 5, 4
OSRT: An Online Sparse Approximation Model for Scattered Data,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 4, 5, 3
Understanding and Improving Adversarial Attacks on Latent Diffusion Model,4.6, 5.0, 1.3564659966250536, 6, 4, 6, 3, 3, 4, 5, 4, 3, 3
SiT:   Symmetry-invariant Transformers for Generalisation in Reinforcement Learning,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 6, 3, 5, 4
Graph Structure and Feature Extrapolation for Out-of-Distribution Generalization,4.75, 5.0, 1.0897247358851685, 6, 2, 3, 4, 5, 4, 5, 4
Rehearsal NeRF: Disentangling Dynamic Illuminations in Neural Radiance Fields,4.25, 4.0, 1.299038105676658, 6, 4, 5, 4, 3, 4, 3, 3
Vec-Tok Speech: Speech Vectorization and Tokenization for Neural Speech Generation,4.8, 5.0, 1.8330302779823362, 3, 4, 5, 4, 3, 4, 8, 4, 5, 4
Which mode is better for federated learning? Centralized or Decentralized,4.5, 4.5, 1.5, 6, 3, 3, 4, 3, 4, 6, 3
Large Language Models as Decision Makers for Autonomous Driving,3.75, 3.0, 1.299038105676658, 6, 3, 3, 4, 3, 4, 3, 3
Identifying the Risks of LM Agents with an LM-Emulated Sandbox,7.333333333333333, 8.0, 0.9428090415820634, 6, 3, 8, 4, 8, 5
The Blessing of Randomness: SDE Beats ODE in General Diffusion-based Image Editing,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 4, 5, 3
CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 3, 6, 4, 6, 2
Finite-Time Analysis of Federated Temporal Difference Learning with Linear Function Approximation under Environment and Computation Heterogeneity,4.0, 3.0, 1.4142135623730951, 6, 3, 3, 5, 3, 4
Complex-valued Scattering Representations,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 4, 6, 4, 3, 3
$\textbf{\textit{M}}^\textbf{\textit{3}}$: Towards Robust Multi-Modal Reasoning via Model Selection,5.5, 5.5, 0.5, 6, 4, 5, 4, 6, 4, 5, 3
Holmex: Human-Guided Spurious Correlation Detection and Black-box Model Fixing,4.5, 4.5, 1.5, 6, 4, 3, 4, 3, 4, 6, 4
A Latent Generative Model for Closed-set and Open-set Recognition,5.333333333333333, 5.0, 2.0548046676563256, 3, 4, 5, 5, 8, 3
Class-Incremental Continual Learning for Multi-View Clustering,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 5, 5, 5
Split and Merge Proxy: pre-training protein inter-chain contact prediction by mining rich information from monomer data,5.5, 5.5, 0.5, 6, 3, 5, 3, 6, 4, 5, 4
KVTQ: Compressing the KV Cache to Hardware Efficient Ternary Digits by Fine-Grained Dynamic Quantization,4.4, 5.0, 1.2, 5, 4, 6, 2, 3, 5, 5, 4, 3, 2
Normalizing Flows For Out of Distribution Detection via Latent Density Estimation,3.4, 3.0, 0.8, 3, 5, 3, 3, 3, 4, 5, 4, 3, 4
Coeditor: Leveraging Repo-level Diffs for Code Auto-editing,6.0, 6.5, 2.1213203435596424, 5, 5, 8, 3, 8, 4, 3, 4
Ref-Diff: Zero-shot Referring Image Segmentation with Generative Models,3.75, 3.0, 1.299038105676658, 3, 4, 3, 5, 3, 4, 6, 4
DistillSpec: Improving Speculative Decoding via Knowledge Distillation,5.0, 6.0, 1.4142135623730951, 6, 4, 3, 3, 6, 3
Boosting the Adversarial Robustness of Graph Neural Networks: An OOD Perspective,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 5, 6, 4, 5, 3
Conditional Support Alignment for Domain Adaptation with Label Shift,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 3, 4, 5, 4
FedSRC: Federated Learning with Self-Regulating Clients,3.4, 3.0, 0.8, 3, 4, 3, 4, 3, 4, 3, 4, 5, 4
DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning,5.75, 6.0, 0.4330127018922193, 5, 3, 6, 3, 6, 4, 6, 4
LRR: Language-Driven Resamplable Continuous Representation against Adversarial Tracking Attacks,5.666666666666667, 6.0, 0.4714045207910317, 5, 5, 6, 4, 6, 4
Leveraging Human Revisions for Improving Text-to-Layout Models,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 3, 3, 4, 5, 3
Divide and Orthogonalize: Efficient Continual Learning with Local Model Space Projection,5.75, 5.0, 1.299038105676658, 5, 4, 5, 3, 8, 3, 5, 2
FITS: Modeling Time Series with $10k$ Parameters,6.5, 6.0, 0.8660254037844386, 6, 2, 6, 3, 6, 4, 8, 4
Differentially Private One Permutation Hashing,4.6, 5.0, 0.7999999999999999, 5, 3, 5, 3, 3, 3, 5, 3, 5, 2
Benchmarking Deletion Metrics with the Principled Explanations,5.5, 5.5, 2.5, 8, 4, 3, 4, 3, 3, 8, 3
PUMA: Secure Inference of LLaMA-7B in Five Minutes,5.0, 5.5, 1.224744871391589, 6, 3, 3, 4, 6, 4, 5, 3
Data Curation for Large Scale Detection Pretraining,4.0, 4.0, 1.0, 3, 5, 5, 4, 5, 4, 3, 4
Structural Knowledge Informed Continual Multivariate Time Series Forecasting,5.333333333333333, 5.0, 2.0548046676563256, 3, 4, 8, 4, 5, 3
Prediction-Consistent Koopman Autoencoders,3.25, 2.0, 2.8613807855648994, 3, 4, 8, 2, 1, 5, 1, 5
Meta-Transformer: A Unified Framework for Multimodal Learning,4.6, 5.0, 1.3564659966250536, 6, 3, 3, 4, 6, 4, 3, 4, 5, 3
Harnessing the Power of Federated Learning in Federated Contextual Bandits,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 3
Investigating Human-Identifiable Features Hidden in Adversarial Perturbations,4.8, 5.0, 2.9933259094191533, 10, 5, 1, 5, 5, 4, 3, 4, 5, 5
Sp-R-IP: A Decision-Focused Learning Strategy for Linear Programs that Avoids Overfitting,4.6, 5.0, 1.3564659966250536, 5, 3, 3, 4, 3, 4, 6, 3, 6, 4
Causal Discovery with Unobserved Variables: A Proxy Variable Approach,4.5, 4.5, 1.5, 3, 5, 6, 3, 3, 4, 6, 3
CICD-Coder: Chinese EMRs Based ICD Coding With Multi-axial  Supported Clinical Evidence,3.75, 4.0, 1.920286436967152, 6, 2, 3, 4, 5, 3, 1, 4
Gradient norm as a powerful proxy to out-of-distribution error estimation,5.5, 5.5, 0.5, 6, 4, 5, 3, 6, 4, 5, 4
Measuring Information in Text Explanations,5.5, 5.5, 2.5, 3, 4, 3, 4, 8, 4, 8, 2
Enhancing Neural Network Performance with Leader-Follower Architecture and Local Error Signals,5.25, 5.0, 0.4330127018922193, 6, 3, 5, 3, 5, 4, 5, 3
SPTNet: An Efficient Alternative Framework for Generalized Category Discovery with Spatial Prompt Tuning,6.0, 6.0, 0.0, 6, 5, 6, 4, 6, 2
Exploring Federated Optimization by Reducing Variance of Adaptive Unbiased Client Sampling,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 3
Adversarially Robust and Privacy-Preserving Representation Learning via Information Theory,3.0, 3.0, 0.0, 3, 4
DIA: Diffusion based Inverse Network Attack on Collaborative Inference,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 4, 3, 3
Patch-Prompt Aligned Bayesian Prompt Tuning for Vision-Language Models,5.0, 5.5, 1.224744871391589, 6, 4, 6, 3, 3, 5, 5, 5
Rotation-Equivariance and Position Encodings for Enhancing Local Descriptors,4.75, 5.0, 1.0897247358851685, 5, 5, 6, 3, 3, 5, 5, 4
Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning,6.0, 5.5, 1.224744871391589, 6, 4, 5, 4, 8, 4, 5, 4
Enhancing Adversarial Robustness on Categorical Data via Attribution Smoothing,5.166666666666667, 5.5, 1.0671873729054748, 6, 3, 6, 2, 5, 4, 6, 4, 5, 4, 3, 4
FP-IRL: Fokker-Planck-based Inverse Reinforcement Learning --- A Physics-Constrained Approach to Markov Decision Processes,4.25, 3.0, 2.165063509461097, 3, 4, 3, 4, 8, 4, 3, 3
Rethinking Complex Queries on Knowledge Graphs with Neural Link Predictors,7.0, 7.0, 1.0, 8, 4, 8, 3, 6, 4, 6, 3
The Dark Side of the Hyperbolic Moon,6.0, 6.0, 1.0, 6, 4, 8, 3, 6, 3, 6, 3, 5, 4, 5, 3
Regulating Imbalanced Deep Models with User-Specified Metrics,4.5, 4.5, 1.5, 3, 4, 3, 3, 6, 4, 6, 4
Neural Active Learning Beyond Bandits,6.25, 6.0, 1.0897247358851685, 6, 3, 5, 3, 8, 3, 6, 2
Structure-Rich Text Benchmark for Knowledge Inference Evaluation,3.25, 3.0, 1.7853571071357126, 3, 4, 1, 4, 3, 3, 6, 3
Quantized Local Independence Discovery for Fine-Grained Causal Dynamics Learning in Reinforcement Learning,5.0, 5.0, 1.0954451150103321, 6, 3, 5, 3, 6, 3, 3, 3, 5, 3
From Graphs to Hypergraphs: Hypergraph Projection and its Remediation,6.75, 7.0, 1.299038105676658, 5, 4, 8, 5, 6, 3, 8, 5
MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models,7.25, 8.0, 1.299038105676658, 8, 4, 8, 4, 8, 3, 5, 3
Synergistic Patch Pruning for Vision Transformer: Unifying Intra- & Inter-Layer Patch Importance,6.25, 6.0, 1.0897247358851685, 6, 4, 5, 4, 8, 4, 6, 4
Query-Policy Misalignment in Preference-Based Reinforcement Learning,5.5, 5.5, 0.5, 5, 3, 6, 4
ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 8, 2, 5, 4
DeepDRK: Deep Dependency Regularized Knockoff for Feature Selection,5.75, 6.0, 0.4330127018922193, 5, 2, 6, 2, 6, 3, 6, 2
Investigating Uncertainty Calibration of Aligned Language Models under the Multiple-Choice Setting,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 4, 5, 4, 6, 3
FedSKU: Defending Backdoors in Federated Learning Through Selective Knowledge Unlearning,6.0, 5.5, 1.224744871391589, 8, 3, 5, 4, 5, 4, 6, 2
LeetPrompt: Leveraging Collective Human Intelligence to Study LLMs,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 4, 5, 3, 3, 3
Score-based Neural Processes,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 3, 5, 3
On Formal Feature Attribution and Its Approximation,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 3, 6, 3, 5, 2
Feature-aligned N-BEATS with Sinkhorn divergence,6.333333333333333, 6.0, 1.247219128924647, 8, 3, 5, 3, 6, 3
Traceable Federated Continual Learning,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 3, 5, 3, 5, 3
Diffusion Models without Attention,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4, 3, 3
Towards Out-of-federation Generalization in Federated Learning,5.5, 5.5, 0.5, 5, 4, 6, 3, 6, 3, 5, 4
On the Effect of Batch Size in Byzantine-Robust Distributed Learning,5.333333333333333, 5.0, 0.4714045207910317, 5, 5, 5, 3, 6, 3
Distort Distract Decode: Instruction-Tuned Model Can Refine its Response from Noisy Instructions,5.75, 6.0, 1.7853571071357126, 8, 4, 3, 4, 6, 3, 6, 4
Large Language Model Cascades with Mixture of Thought Representations for Cost-Efficient Reasoning,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 6, 3, 8, 4
Unpaired Image-to-Image Translation via Neural Schrödinger Bridge,6.0, 5.5, 1.224744871391589, 6, 4, 5, 3, 5, 4, 8, 1
Set-based Neural Network Encoding,4.75, 4.0, 2.0463381929681126, 3, 5, 8, 3, 3, 3, 5, 3
Examining the Achilles' Heel of CLIP Models: The Worst-Performing Categories,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 5
Rethinking Spectral Graph Neural Networks with Spatially Adaptive Filtering,5.25, 5.0, 0.4330127018922193, 5, 3, 6, 4, 5, 5, 5, 3
Optimum Shifting to Stabilize Training and Improve Generalization of Deep Neural Networks,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 4, 5, 4, 3, 3
CrossTVR: Multi-Grained Re-Ranker for Text Video Retrieval with Frozen Image Encoders,5.0, 5.0, 0.0, 5, 5, 5, 5, 5, 4
Revisiting Plasticity in Visual Reinforcement Learning: Data Modules and Training Stages,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 4, 5, 4, 5, 5
Consistent Multi-Class Classification from Multiple Unlabeled Datasets,5.4, 5.0, 1.624807680927192, 5, 4, 8, 4, 6, 4, 5, 3, 3, 5
A Paradigm Shift in Machine Translation: Boosting Translation Performance of Large Language Models,6.25, 6.0, 1.0897247358851685, 6, 4, 5, 4, 6, 4, 8, 4
Ins-DetCLIP: Aligning Detection Model to Follow Human-Language Instruction,6.0, 5.5, 1.224744871391589, 5, 4, 5, 3, 6, 4, 8, 3
Continual Nonlinear ICA-Based Representation Learning,3.0, 3.0, 0.0, 3, 2, 3, 4, 3, 4
Reshape and Adapt for Output Quantization (RAOQ): Quantization-aware Training for In-memory Computing Systems,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 4, 5, 4, 5, 5
Scaling Supervised Local Learning with Augmented Auxiliary Networks,5.25, 6.0, 1.299038105676658, 6, 4, 6, 5, 3, 3, 6, 4
Elucidating the design space of classifier-guided diffusion generation,4.2, 5.0, 0.9797958971132712, 5, 5, 5, 5, 3, 4, 5, 4, 3, 5
Teach LLMs to Phish: Stealing Private Information from Language Models,6.0, 5.0, 1.4142135623730951, 5, 4, 8, 4, 5, 4
Spatial-Temporal Mutual Distillation for Lightweight Sleep Stage Classification,5.5, 5.5, 1.8027756377319946, 8, 4, 6, 3, 5, 4, 3, 5
Fleet Policy Learning via Weight Merging and An Application to Robotic Tool-Use,6.0, 5.0, 1.4142135623730951, 5, 3, 5, 4, 8, 3
Memoria: Hebbian Memory Architecture for Human-Like Sequential Processing,5.6, 6.0, 1.624807680927192, 5, 3, 6, 4, 6, 4, 3, 3, 8, 4
CO-MOT: Boosting End-to-end Transformer-based Multi-Object Tracking via Coopetition Label Assignment and Shadow Sets,5.75, 6.0, 1.7853571071357126, 3, 5, 6, 5, 8, 4, 6, 2
InfoCon: Concept Discovery with Generative and Discriminative Informativeness,6.25, 6.0, 1.0897247358851685, 5, 4, 6, 3, 6, 3, 8, 3
Prompt Tuning Is All We Need?,4.25, 4.0, 1.299038105676658, 3, 5, 3, 5, 6, 4, 5, 4
Meta Koopman Decomposition for Time Series Forecasting Under Distribution Shifts,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 5, 5, 4, 5, 4
AutoJoin: Efficient Adversarial Training against Gradient-Free Perturbations for Ro- bust Maneuvering via Denoising Autoencoder and Joint Learning,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 1, 5, 3, 6, 4
Sample-efficient Learning of Infinite-horizon Average-reward MDPs with General Function Approximation,5.75, 5.0, 1.299038105676658, 5, 3, 5, 3, 8, 2, 5, 3
Alphazero-like Tree-Search can guide large language model decoding and training,5.5, 5.5, 0.5, 5, 4, 5, 4, 6, 4, 6, 3
Revisit and Outstrip Entity Alignment: A Perspective of Generative Models,5.333333333333333, 5.0, 2.0548046676563256, 8, 4, 3, 3, 5, 3
CaStRL: Context-Aware State Representation learning with Transformer,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 5, 5, 4
Learning Scalable Causal Discovery Policies with Adversarial Reinforcement Learning,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 3, 5, 3, 6, 4
MSPipe: Minimal Staleness Pipeline for Efficient Temporal GNN Training,4.25, 5.0, 1.920286436967152, 5, 3, 5, 4, 6, 3, 1, 4
CCA Merge: Merging Many Neural Networks with Canonical Correlation Analysis,4.5, 4.5, 1.5, 6, 3, 3, 3, 6, 3, 3, 5
MoveAnything: Controllable Scene Generation with Text-to-Image Diffusion Models,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 4, 5, 2, 5, 1
ImplicitSLIM and How it Improves Embedding-based Collaborative Filtering,5.0, 4.5, 2.1213203435596424, 6, 4, 8, 4, 3, 1, 3, 4
Prompt Learning with Quaternion Networks,6.5, 6.5, 1.5, 8, 3, 5, 4
ControlVideo: Conditional Control for Text-driven Video Editing and Beyond,4.0, 4.0, 1.0, 3, 2, 5, 5, 5, 4, 3, 4
Adapting Retrieval Models to Task-Specific Goals using Reinforcement Learning,4.0, 4.0, 1.0, 3, 3, 3, 2, 5, 4, 5, 3
SpikePoint: An Efficient Point-based Spiking Neural Network for Event Cameras Action Recognition,5.75, 6.0, 1.7853571071357126, 6, 4, 6, 4, 3, 5, 8, 3
GraphLLM: Boosting Graph Reasoning Ability of Large Language Model,4.0, 4.0, 1.0, 3, 4, 5, 4, 5, 4, 3, 4
Overcoming the Stability Gap in Continual Learning,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 4, 5, 5, 5, 4
Last-Iterate Convergence Properties of Regret-Matching Algorithms in Games,5.8, 5.0, 1.9390719429665317, 8, 3, 8, 2, 5, 3, 3, 4, 5, 3
Improving Sample Efficiency in Off-policy RL with Low-dimensional Policy Representation,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 5, 4, 3, 4
DoReMi: Grounding Language Model by Detecting and Recovering from Plan-Execution Misalignment,5.5, 5.5, 1.8027756377319946, 5, 5, 6, 4, 8, 3, 3, 4
Boosting Dataset Distillation with the Assistance of Crucial Samples,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 4, 5, 5
Assessing the Impact of Distribution Shift on Reinforcement Learning Performance,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 3, 3, 3
Enhancing Parameter Efficiency in Summarization via Expertise Separation,5.0, 5.5, 1.224744871391589, 6, 3, 5, 3, 6, 4, 3, 4
Align before Adapt: Efficient and Generalizable Video Action Recognition with Text Corpus,5.0, 5.0, 1.0954451150103321, 6, 4, 6, 4, 5, 4, 5, 5, 3, 5
Causal Disentangled Representation Learning with VAE and Causal Flows,3.0, 3.0, 1.4142135623730951, 3, 5, 1, 5, 5, 3, 3, 4
Meta-Learning Priors Using Unrolled Proximal Neural Networks,6.75, 7.0, 1.299038105676658, 8, 2, 8, 3, 6, 4, 5, 3
Bidirectional Temporal Diffusion Model for Temporally Consistent Human Animation,5.75, 6.0, 1.7853571071357126, 6, 4, 6, 4, 8, 4, 3, 3
Uncertainty Quantification via Stable Distribution Propagation,6.0, 6.0, 1.0954451150103321, 8, 4, 5, 4, 6, 3, 6, 3, 5, 4
InfoIGL: Invariant Graph Learning Driven by Information Theory,3.5, 3.0, 0.8660254037844386, 5, 2, 3, 4, 3, 4, 3, 4
LAURAGPT: LISTEN ATTEND UNDERSTAND AND REGENERATE AUDIO WITH GPT,5.5, 5.5, 0.5, 5, 4, 6, 3, 6, 5, 5, 4
MOFDiff: Coarse-grained Diffusion for Metal-Organic Framework Design,6.75, 7.0, 1.299038105676658, 8, 4, 8, 3, 5, 3, 6, 4
Enhanced Gradient Aligned Continual Learning via Pareto Optimization,4.5, 5.0, 0.8660254037844386, 5, 5, 5, 4, 5, 5, 3, 4
AugUndo: Scaling Up Augmentations for Unsupervised Depth Completion,4.2, 3.0, 1.469693845669907, 6, 4, 6, 4, 3, 5, 3, 4, 3, 4
A Database-based Rather Than a Language Model-based Natural Language Processing Method,nan, nan, nan
UniAP: Unifying Inter- and Intra-Layer Automatic Parallelism by Mixed Integer Quadratic Programming,5.0, 6.0, 1.4142135623730951, 6, 3, 6, 4, 3, 4
Red Teaming Game: A Game-Theoretic Framework for Red Teaming Language Models,2.5, 2.0, 1.6583123951777, 3, 4, 1, 4, 5, 3, 1, 4
FedWon: Triumphing Multi-domain Federated Learning Without Normalization,5.25, 5.0, 1.7853571071357126, 5, 3, 3, 4, 5, 3, 8, 5
Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction,6.666666666666667, 6.0, 0.9428090415820634, 8, 4, 6, 3, 6, 5
Learning Causal Dynamics Models in Object-Oriented Environments,5.2, 5.0, 0.39999999999999997, 5, 4, 5, 2, 5, 4, 6, 3, 5, 3
Text-Free Federated Transformers Knowledge Distillation Without GAN,4.25, 4.0, 1.299038105676658, 3, 4, 6, 3, 3, 4, 5, 4
Vocabulary for Universal Approximation: A Linguistic Perspective of Mapping Compositions,6.333333333333333, 6.0, 1.247219128924647, 6, 1, 8, 2, 5, 3
GRepsNet: A Simple Equivariant Network for Arbitrary Matrix Groups,4.75, 4.0, 2.0463381929681126, 3, 3, 5, 3, 3, 5, 8, 4
A-Loc: Efficient Alternating Iterative Methods for Locating the $k$ Largest/Smallest Elements in a Factorized Tensor,2.5, 2.0, 1.6583123951777, 1, 3, 5, 3, 1, 4, 3, 4
LayerDiff: Exploring Text-guided Multi-layered Composable Image Synthesis via Layer-Collaborative Diffusion Model,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 3
Understanding In-context Learning with a Pelican Soup Hypothesis,5.2, 6.0, 1.16619037896906, 6, 2, 6, 2, 3, 4, 5, 4, 6, 4
TransNeXt: Aggregating Diverse Attentions in One Vision Model,4.5, 5.0, 0.8660254037844386, 5, 5, 5, 5, 5, 4, 3, 4
BOOT: Data-free Distillation of Denoising Diffusion Models with Bootstrapping,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 4, 3, 4
Inverse Approximation Theory for Nonlinear Recurrent Neural Networks,5.5, 5.5, 0.5, 5, 3, 6, 1, 6, 4, 5, 2
TAIL: Task-specific Adapters for Imitation Learning with Large Pretrained Models,5.8, 5.0, 1.16619037896906, 8, 4, 5, 3, 5, 4, 6, 3, 5, 4
L2P-MIP: Learning to Presolve for Mixed Integer Programming,5.5, 5.5, 0.5, 5, 3, 6, 4, 6, 3, 5, 4
Continual Learning Knowledge Graph Embeddings for Dynamic Knowledge Graphs,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 3, 3, 4, 5, 3
Exploring the cloud of feature interaction scores in a Rashomon set,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 5, 3, 6, 4
A Backdoor-based Explainable AI Benchmark for Improved Fidelity in Evaluating Attribution Methods,nan, nan, nan
EigenGuard: Backdoor Defense in Eigenspace,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 2, 5, 3, 3, 5
BOSS: Diversity-Difficulty Balanced One-Shot Subset Selection for Data-Efficient Deep Learning,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 5
Image-driven Video Editing with Latent Diffusion Models,4.0, 4.0, 1.0, 5, 3, 3, 5, 5, 4, 3, 3
Regulating Model Reliance on Non-Robust Features by Smoothing Marginal Density of Input,nan, nan, nan
AED: Adaptable Error Detection for Few-shot Imitation Policy,4.0, 5.0, 2.160246899469287, 6, 4, 5, 3, 1, 3
Long-Short-Range Message-Passing: A Fragmentation-Based Framework to Capture Non-Local Atomistic Interactions,5.75, 6.0, 0.4330127018922193, 6, 5, 5, 4, 6, 3, 6, 2
TPE: Towards Better Compositional Reasoning over Conceptual Tools with Multi-persona Collaboration,4.0, 5.0, 2.160246899469287, 1, 4, 6, 4, 5, 4
Hierarchical Approach to Explaining Poisoned AI Models,3.75, 3.0, 1.299038105676658, 3, 2, 3, 4, 3, 4, 6, 3
Asking Before Acting: Gather Information in Embodied Decision-Making with Language Models,4.5, 4.5, 1.5, 6, 3, 3, 4, 6, 5, 3, 3
HGAMLP: A Scalable Training Framework for Heterogeneous Graph Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 5
A Study of Bayesian Neural Network Surrogates for Bayesian Optimization,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 6, 3, 8, 4
Kernel Metric Learning for In-Sample Off-Policy Evaluation of Deterministic RL Policies,6.0, 5.0, 1.4142135623730951, 5, 3, 5, 3, 8, 3
Large Language Models as Analogical Reasoners,6.0, 5.5, 1.224744871391589, 8, 4, 5, 5, 6, 4, 5, 3
Multi-modal Gaussian Process Variational Autoencoders for Neural and Behavioral Data,5.4, 5.0, 1.624807680927192, 8, 4, 3, 4, 6, 4, 5, 3, 5, 4
Large Language Models are Efficient Learners of Noise-Robust Speech Recognition,8.0, 8.0, 1.4142135623730951, 8, 4, 6, 4, 10, 4, 8, 3
POSITION EMBEDDING INTERPOLATION IS ALL YOU NEED FOR EFFICIENT IMAGE-TO-IMAGE VIT,4.0, 4.0, 1.0, 5, 5, 3, 4, 3, 5, 5, 4
UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling,5.25, 6.0, 1.299038105676658, 6, 4, 3, 4, 6, 2, 6, 4
TROJFSL: TROJAN INSERTION IN FEW SHOT PROMPT LEARNING,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 3, 4, 5, 4
Multil-Level Multimodal Alignment with Knowledge-Guided Instance-Wise Discrimination,4.333333333333333, 5.0, 0.9428090415820634, 3, 3, 5, 3, 5, 2
NeuralFuse: Learning to Recover the Accuracy of Access-Limited Neural Network Inference in Low-Voltage Regimes,5.75, 5.0, 1.299038105676658, 5, 4, 5, 4, 5, 5, 8, 3
BCN: Batch Channel Normalization,nan, nan, nan
What Makes ImageNet Look Unlike LAION,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 5, 5, 4, 5, 3
GPS-SSL: Guided Positive Sampling to Inject Prior into Self-Supervised Learning,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 3
Learning Transferable Robust Representations for Few-shot Learning via Multi-view Consistency,4.666666666666667, 5.0, 1.247219128924647, 3, 5, 5, 5, 6, 3
A Multi-In-Single-Out Network for Video Frame Interpolation without optical flow,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 3, 5, 1, 3, 5
Unsupervised Event Outlier Detection in Continuous Time,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 5, 4, 6, 3
Prediction Risk and Estimation Risk of the Ridgeless Least Squares Estimator under General Assumptions on Regression Errors,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 3, 6, 3
An Entropic Risk Measure for Robust Counterfactual Explanations,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 4, 3, 4, 3, 4
Learning to Model the World with Language,5.0, 5.5, 1.224744871391589, 3, 3, 6, 4, 6, 4, 5, 2
Annealing Self-Distillation Rectification Improves Adversarial Training,5.5, 5.5, 0.5, 5, 3, 6, 4, 5, 3, 6, 4
Symmetrization of Loss Functions for Robust Training of Neural Networks in the Presence of Noisy Labels and the Multi-class Unhinged Loss Function,4.666666666666667, 5.0, 1.247219128924647, 3, 5, 5, 4, 6, 4
Differentially Private Latent Diffusion Models,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 6, 4, 5, 4
Resource Efficient Test-Time Training with Slimmable Network,5.5, 5.5, 0.5, 6, 3, 5, 4, 6, 4, 5, 4
Weakly Supervised Monocular 3D Detection with a Single-View Image,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 5, 6, 4, 5, 4
Incentivized Black-Box Model Sharing,6.0, 5.5, 1.224744871391589, 8, 1, 5, 3, 6, 2, 5, 2
Stochastic Gradient Discrete Langevin Dynamics,4.666666666666667, 5.0, 1.247219128924647, 3, 2, 5, 4, 6, 2
Stochastic Adaptive Sequential  Black-box Optimization for  Diffusion Targeted Generation,5.0, 5.5, 1.224744871391589, 5, 2, 6, 2, 3, 3, 6, 2
Multiclass Alignment of Confidences and Softened Target Occurrences for Train-time Calibration,3.5, 4.0, 1.6583123951777, 1, 5, 3, 4, 5, 4, 5, 3
Don't Judge by the Look: A Motion Coherent Augmentation for Video Recognition,5.75, 6.0, 1.7853571071357126, 3, 5, 8, 4, 6, 3, 6, 2
Cooperative Minibatching in Graph Neural Networks,4.0, 5.0, 2.160246899469287, 1, 5, 6, 3, 5, 3
Time-LLM: Time Series Forecasting by Reprogramming Large Language Models,5.4, 5.0, 1.624807680927192, 8, 4, 5, 3, 5, 4, 6, 4, 3, 5
BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction,6.25, 6.0, 1.0897247358851685, 8, 3, 6, 3, 6, 3, 5, 3
Offline Data Enhanced On-Policy Policy Gradient with Provable Guarantees,6.75, 7.0, 1.299038105676658, 6, 4, 8, 3, 5, 4, 8, 3
Forward Gradient Training of Spiking Neural Networks,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 3
Embarrassingly Simple Dataset Distillation,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 5, 5, 2
H2O-SDF: Two-phase Learning for 3D Indoor Reconstruction using Object Surface Fields,6.25, 6.0, 1.0897247358851685, 6, 4, 5, 5, 8, 4, 6, 3
Visual Analysis of the Bumpiness and Ruggedness of Residual Neural Network Landscapes,3.0, 3.0, 0.0, 3, 2, 3, 4, 3, 5
Optimal Kernel Choice for Score Function-based Causal Discovery,4.4, 5.0, 1.2, 5, 4, 5, 3, 3, 4, 3, 3, 6, 3
Revisiting the Temporal Modeling in Spatio-Temporal Predictive Learning under A Unified View,4.25, 4.0, 1.299038105676658, 5, 3, 3, 4, 6, 3, 3, 3
MADiff: Offline Multi-agent Learning with Diffusion Models,4.8, 5.0, 0.9797958971132712, 3, 4, 5, 4, 6, 3, 5, 3, 5, 3
Semi-supervised Diffusion Solver for Travelling Salesman Problem,4.25, 4.0, 1.299038105676658, 3, 3, 5, 5, 3, 5, 6, 3
Domain Generalization Deep Graph Transformation,5.0, 5.5, 1.224744871391589, 5, 3, 6, 3, 3, 4, 6, 3
Towards Fair Knowledge Distillation using Student Feedback,5.0, 5.5, 1.224744871391589, 6, 3, 6, 3, 3, 5, 5, 4
CoMNet: Where Biology Meets ConvNets,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 5, 6, 2, 3, 3
Hierarchical Data-efficient Representation Learning for Tertiary Structure-based RNA Design,4.0, 3.0, 1.4142135623730951, 3, 5, 3, 4, 6, 4
Neural Characteristic Activation Value Analysis for Improved ReLU Network Feature Learning,5.0, 6.0, 1.4142135623730951, 6, 2, 3, 3, 6, 3
Memory-Assisted Sub-Prototype Mining for Universal Domain Adaptation,5.5, 5.5, 1.8027756377319946, 6, 4, 5, 4, 3, 4, 8, 5
Source-free Cross-modal Knowledge Transfer by Unleashing the Potential of Task-Irrelevant Data,4.0, 4.0, 1.0, 5, 4, 3, 3, 3, 3, 5, 4, 3, 4, 5, 4
RFold: RNA Secondary Structure Prediction with Decoupled Optimization,4.5, 4.5, 1.5, 3, 5, 3, 3, 6, 3, 6, 2
Observable Propagation: Uncovering Feature Vectors in Transformers,4.333333333333333, 5.0, 0.9428090415820634, 3, 2, 5, 3, 5, 3
Large Language Models as Tool Makers,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 5, 6, 3, 3, 4
CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing,6.0, 5.5, 1.224744871391589, 5, 3, 8, 5, 6, 4, 5, 4
ACHIEVING DYNAMIC ACCURACY IN MACHINE-LEARNED CG POTENTIALS BY MODULATING POTENTIAL ENERGY LANDSCAPE,3.0, 3.0, 1.4142135623730951, 5, 4, 3, 3, 1, 5, 3, 4
Are Large Language Models Post Hoc Explainers?,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 2
Sample-Efficient Quality-Diversity by Cooperative Coevolution,4.666666666666667, 3.0, 2.357022603955158, 3, 5, 3, 5, 8, 3
Multi-Agent Interpolated Policy Gradients,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 4, 6, 2
Geometrically Aligned Transfer Encoder for Inductive Transfer in Regression Tasks,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 3, 5, 2, 5, 3
Objective-Agnostic Enhancement of Molecule Properties via Multi-Stage VAE,1.6666666666666667, 1.0, 0.9428090415820634, 1, 5, 3, 4, 1, 4
Hierarchical Gaussian Mixture Normalizing Flows Modeling for Multi-Class Anomaly Detection,4.5, 4.5, 1.5, 3, 3, 6, 3
Learning to (Learn at Test Time),3.75, 3.0, 1.299038105676658, 3, 5, 3, 3, 6, 4, 3, 4
Stoichiometry Representation Learning with Polymorphic Crystal Structures,5.333333333333333, 5.0, 2.0548046676563256, 5, 3, 3, 5, 8, 4
Adaptive Multi-head Contrastive Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 4
Zero and Few-shot Semantic Parsing with Ambiguous Inputs,6.75, 7.0, 1.299038105676658, 8, 3, 5, 2, 6, 4, 8, 4
Find Your Optimal Assignments On-the-fly: A Holistic Framework for Clustered Federated Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 3, 4, 5, 3
Theoretical insights into pseudo-label-based semi-supervised learning: Convergence rate and sample complexity analysis,3.0, 3.0, 1.4142135623730951, 5, 4, 3, 4, 1, 3, 3, 5
Graph Generation with  $K^2$-trees,6.5, 6.5, 1.5, 5, 3, 5, 4, 8, 4, 8, 3
Clustering for Protein Representation Learning,3.75, 3.0, 2.5860201081971503, 1, 4, 3, 4, 8, 2, 3, 3
Strategic Classification with Unforeseeable Outcomes,3.75, 3.0, 1.299038105676658, 3, 4, 3, 3, 6, 3, 3, 3
CI-VAE: a Generative Deep Learning Model for Class-Specific Data Interpolation,2.0, 2.0, 1.0, 3, 4, 1, 4
Learning Guarantees for Non-convex Pairwise SGD with Heavy Tails,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 3, 5, 3
Self-Supervision is Not All You Need: In Defense of Semi-Supervised Learning,4.0, 4.0, 1.0, 5, 4, 3, 4, 3, 5, 5, 4
LayerNAS: Neural Architecture Search in Polynomial Complexity,5.75, 5.0, 1.299038105676658, 5, 5, 5, 3, 8, 4, 5, 4
Representation Norm Amplification for Out-of-Distribution Detection in Long-Tail Learning,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 4, 3, 4, 5, 4
Manifold Preserving Guided Diffusion,6.0, 5.5, 1.224744871391589, 5, 2, 6, 3, 5, 4, 8, 3
Neural Common Neighbor with Completion for Link Prediction,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 8, 4, 6, 4
Latent Intuitive Physics: Learning to Transfer Hidden Physics from a 3D Video,6.5, 6.0, 0.8660254037844386, 6, 4, 6, 1, 6, 3, 8, 3
When and Why Momentum Accelerates SGD: An Empirical Study,3.75, 3.0, 1.299038105676658, 3, 4, 6, 3, 3, 3, 3, 4
Privacy-Preserving In-Context Learning for Large Language Models,5.5, 5.5, 1.8027756377319946, 8, 4, 5, 2, 6, 4, 3, 2
PyTorch Geometric High Order: A Unified Library for High Order Graph Neural Network,4.0, 4.0, 1.0, 5, 3, 5, 3, 3, 5, 3, 3
Hardware-Friendly Post-Training Quantization: Input- and Output-Channelwise Scale and Offset,5.75, 5.0, 1.299038105676658, 5, 5, 5, 5, 5, 4, 8, 4
Masked Distillation Advances Self-Supervised Transformer Architecture Search,5.75, 6.0, 0.4330127018922193, 6, 2, 6, 4, 5, 5, 6, 4
Adaptive Self-training Framework for Fine-grained Scene Graph Generation,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 8, 5, 6, 3
DPFormer: Learning Differentially Private Transformer on Long-Tailed Data,5.0, 5.5, 1.224744871391589, 6, 4, 5, 3, 6, 4, 3, 3
FedRC: Tackling Diverse Distribution Shifts Challenge in Federated Learning by Robust Clustering,7.0, 8.0, 1.4142135623730951, 5, 4, 8, 4, 8, 4
Exploring Effective Stimulus Encoding via Vision System Modeling for Visual Prostheses,6.25, 6.0, 1.0897247358851685, 6, 3, 6, 3, 8, 4, 5, 3
Towards Foundation Models for Knowledge Graph Reasoning,6.75, 7.0, 1.299038105676658, 6, 4, 8, 3, 5, 5, 8, 4
COCO-Periph: Bridging the Gap Between Human and Machine Perception in the Periphery,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 4, 3, 4
DIFUSCO-LNS: Diffusion-Guided Large Neighbourhood Search for Integer Linear Programming,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 4
CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement,4.25, 3.0, 2.165063509461097, 3, 4, 3, 5, 3, 5, 8, 3
Towards Non-Asymptotic Convergence for Diffusion-Based Generative Models,7.0, 7.0, 1.0, 8, 2, 6, 4, 8, 5, 6, 3
More is Better: when Infinite Overparameterization is Optimal and Overfitting is Obligatory,6.333333333333333, 6.0, 1.247219128924647, 5, 2, 8, 3, 6, 4
IMProv: Inpainting-based Multimodal Prompting for Computer Vision Tasks,5.5, 5.5, 1.8027756377319946, 8, 5, 3, 5, 6, 3, 5, 4
SALMON: Self-Alignment with Principle-Following Reward Models,6.25, 6.0, 1.0897247358851685, 6, 3, 6, 3, 5, 4, 8, 3
Frustratingly Easy Model Generalization by Dummy Risk Minimization,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 3, 5, 3, 5, 3
One by One Continual Coordinating with Humans via Hyper-Teammate Identification,4.666666666666667, 5.0, 1.247219128924647, 3, 5, 5, 4, 6, 3
Indeterminate Probability Theory,3.0, 3.0, 1.632993161855452, 3, 3, 1, 5, 5, 4
BPQP: A Differentiable Convex Optimization Framework for Efficient End-to-End Learning,4.5, 4.5, 1.5, 3, 4, 6, 4, 6, 2, 3, 5
DiffSDS: A geometric sequence diffusion model for protein backbone inpainting,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 3
Aligning Large Multimodal Models with Factually Augmented RLHF,5.0, 5.5, 1.224744871391589, 6, 4, 5, 3, 6, 4, 3, 3
TimelyGPT: Recurrent Convolutional Transformer for Long Time-series Representation,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 5, 6, 3, 3, 4
Efficient Identification of Direct Causal Parents via Invariance and Minimum Error Testing,5.666666666666667, 6.0, 0.4714045207910317, 5, 3, 6, 4, 6, 3
ControlVideo: Training-free Controllable Text-to-video Generation,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 5, 6, 4, 5, 5
Topo-Diffusion: Topological Diffusion Model for Image and Point Cloud Generation,6.5, 6.0, 0.8660254037844386, 8, 3, 6, 3, 6, 2, 6, 2
RETSim: Resilient and Efficient Text Similarity,6.25, 6.0, 1.0897247358851685, 5, 4, 6, 4, 8, 4, 6, 4
KW-Design: Pushing the Limit of Protein Deign via Knowledge Refinement,5.5, 5.5, 0.5, 5, 5, 6, 3
GPT Is Becoming a Turing Machine: Here Are Some Ways to Program It,4.25, 4.0, 1.299038105676658, 6, 3, 3, 4, 5, 3, 3, 3
SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore,7.25, 8.0, 1.299038105676658, 8, 3, 8, 4, 8, 4, 5, 4
Trainable Transformer in Transformer,5.75, 5.0, 1.299038105676658, 5, 2, 5, 3, 8, 2, 5, 2
Momentum-driven Noise-free Guided Conditional Sampling for Denoising Diffusion Probabilistic Models,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 4, 5, 3
A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Actively Validating Low-Confidence Generation,5.25, 5.0, 1.7853571071357126, 5, 4, 5, 4, 8, 3, 3, 4
Improving Convergence and Generalization Using Parameter Symmetries,7.25, 8.0, 1.299038105676658, 5, 3, 8, 3, 8, 3, 8, 2
NPEFF: Non-Negative Per-Example Fisher Factorization,5.0, 5.5, 1.224744871391589, 6, 3, 5, 3, 6, 4, 3, 4
Certified Deductive Reasoning with Language Models,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 4, 5, 3
ViCo: Plug-and-play Visual Condition for Personalized Text-to-image Generation,5.5, 5.5, 0.5, 6, 3, 5, 3, 5, 4, 6, 2
OneBNet: Binarized Neural Networks using Decomposed 1-D Binarized Convolutions on Edge Device,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 4, 3, 4, 3, 3
Neural implicit mapping via nested neighborhoods: real-time rendering of neural SDFs with textures,4.75, 5.0, 1.0897247358851685, 3, 5, 6, 4, 5, 2, 5, 3
Fusing Models with Complementary Expertise,5.25, 5.0, 0.4330127018922193, 5, 3, 6, 3, 5, 4, 5, 3
SciRE-Solver: Accelerating  Diffusion Models Sampling by Score-integrand Solver with Recursive Difference,6.0, 5.5, 1.224744871391589, 5, 4, 6, 4, 8, 4, 5, 2
HyperRep: Hypergraph-Based Self-Supervised Multimodal Representation Learning,6.25, 6.0, 1.0897247358851685, 8, 2, 5, 3, 6, 4, 6, 4
Magnitude Invariant Parametrizations Improve Hypernetwork Learning,6.0, 5.5, 1.224744871391589, 5, 4, 8, 3, 6, 3, 5, 3
Active Continual Learning: On Balancing Knowledge Retention and Learnability,4.25, 4.0, 1.299038105676658, 6, 4, 3, 2, 5, 3, 3, 4
Detecting Out-of-distribution with Insights from Neural Collapse,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 3, 4, 5, 4
A Versatile Causal Discovery Framework to Allow Causally-Related Hidden Variables,7.5, 8.0, 0.8660254037844386, 8, 3, 6, 4, 8, 4, 8, 4
CodeScore: Evaluating Code Generation by Learning Code Execution,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 5, 3, 4, 3, 3
Flow Matching on General Geometries,7.333333333333333, 8.0, 0.9428090415820634, 8, 3, 6, 4, 8, 4
Teaching Large Language Models to Self-Debug,4.5, 4.5, 1.5, 3, 5, 6, 4, 3, 4, 6, 3
Interpretable word-level context-based sentiment analysis,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4
Learning An Efficient-And-Rigorous Neural Multigrid Solver,3.75, 3.0, 1.299038105676658, 3, 4, 3, 3, 6, 3, 3, 4
Pre-trained Transformers as Plug-in Defenders Against Adversarial Perturbations,3.0, 3.0, 0.0, 3, 2, 3, 3, 3, 5, 3, 4
Adversarial Defense using Targeted Manifold Manipulation,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 3, 5, 4
A LOCAL POLYAK-ŁOJASIEWICZ AND DESCENT LEMMA OF GRADIENT DESCENT FOR OVERPARAMETERIZED LINEAR MODELS,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 4, 3, 2, 5, 3
Self-Prompt SAM: Automatic Prompt SAM Adaptation for Medical Image Segmentation,3.5, 3.0, 0.8660254037844386, 3, 5, 5, 4, 3, 4, 3, 4
Global Convergence Rate of Deep Equilibrium Models with General Activations,3.75, 4.0, 1.920286436967152, 3, 5, 6, 3, 1, 2, 5, 4
Identifiable Latent Causal Content for Domain Adaptation under Latent Covariate Shift,4.75, 5.0, 2.48746859276655, 8, 4, 1, 5, 5, 3, 5, 3
Achieving Human Parity in Content-Grounded Datasets Generation,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 3
Efficient Long Sequence Modeling via State Space Augmented Transformer,5.4, 5.0, 1.624807680927192, 3, 4, 5, 3, 8, 4, 5, 4, 6, 2
Learning an Inventory Control Policy with General Inventory Arrival Dynamics,3.0, 3.0, 0.0, 3, 2, 3, 2
Federated Recommendation with Additive Personalization,6.333333333333333, 8.0, 2.357022603955158, 3, 4, 8, 4, 8, 5
Identifiable Latent Polynomial Causal Models through the Lens of Change,4.6, 5.0, 1.3564659966250536, 6, 3, 3, 4, 6, 4, 5, 4, 3, 3
MiniGPT-v2: Large Language Model as a Unified Interface for Vision-Language Multi-task Learning,5.5, 5.5, 1.8027756377319946, 3, 4, 6, 4, 5, 4, 8, 4
Certifying LLM Safety against Adversarial Prompting,3.5, 4.0, 1.6583123951777, 3, 4, 1, 4, 5, 4, 5, 4
Test-Time Adaptation with CLIP Reward for Zero-Shot Generalization in Vision-Language Models,6.333333333333333, 6.0, 1.247219128924647, 8, 4, 5, 4, 6, 5
Balancing Fairness and Accuracy in Data-Restricted Binary Classification,4.0, 4.0, 1.0, 5, 3, 5, 4, 3, 3, 3, 4
Linking Finite-Time Lyapunov Exponents to RNN Gradient Subspaces and Input Sensitivity,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 3, 3, 3, 5, 3
Taming Self-Training for Open-Vocabulary Object Detection,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 5, 5, 4, 3, 4
Just How Flexible are Neural Networks in Practice?,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 4
Enhancing Length Extrapolation in Sequential Models with Pointer-Augmented Neural Memory,5.333333333333333, 5.0, 2.0548046676563256, 3, 5, 5, 2, 8, 3
Future Language Modeling from Temporal Document History,7.0, 8.0, 1.4142135623730951, 8, 4, 8, 3, 5, 3
SemiReward: A General Reward Model for Semi-supervised Learning,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 4, 5, 4
Modeling non-uniform uncertainty in Reaction Prediction via Boosting and Dropout,4.333333333333333, 5.0, 0.9428090415820634, 5, 5, 5, 3, 3, 3
Dynamic Discounted Counterfactual Regret Minimization,7.5, 8.0, 0.8660254037844386, 8, 3, 6, 3, 8, 4, 8, 5
Ghost on the Shell: An Expressive Representation of General 3D Shapes,7.25, 8.0, 1.299038105676658, 8, 3, 8, 5, 8, 4, 5, 5
Active Teacher Selection for Reinforcement Learning from Human Feedback,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 5, 5, 6, 3
Towards general neural surrogate PDE solvers with specialized neural accelerators,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 3, 5, 3, 6, 4
Comparative Knowledge Distillation,3.75, 3.0, 1.299038105676658, 3, 4, 6, 5, 3, 4, 3, 5
DATS: Difficulty-Aware Task Sampler for Meta-Learning Physics-Informed Neural Networks,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 4, 5, 4
Robust Algorithmic Recourse Design Under Model Shifts,4.0, 4.0, 1.0, 3, 5, 3, 4, 5, 2, 5, 4
LIPEx -- Locally Interpretable Probabilistic Explanations -- To Look Beyond The True Class,3.5, 3.0, 0.8660254037844386, 3, 5, 5, 3, 3, 4, 3, 4
Mildly Constrained Evaluation Policy for Offline Reinforcement Learning,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 3, 5, 4
Investigating Feature Alignment Under An Infant-Inspired Visual Distribution Shift,5.0, 5.0, 1.0954451150103321, 3, 4, 5, 3, 6, 5, 5, 2, 6, 3
Modulate Your Spectrum in Self-Supervised Learning,6.0, 6.0, 0.0, 6, 4, 6, 3, 6, 4
Improving Intrinsic Exploration by Creating Stationary Objectives,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 3, 3, 5, 4
Why Sanity Check for Saliency Metrics Fails?,3.75, 3.0, 2.5860201081971503, 1, 4, 3, 5, 8, 2, 3, 1
FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning,7.25, 7.0, 1.920286436967152, 5, 3, 8, 5, 10, 4, 6, 4
A Computational Framework for Solving Wasserstein Lagrangian Flows,5.4, 5.0, 1.624807680927192, 6, 1, 8, 3, 3, 3, 5, 3, 5, 3
Automatic Fine-Tuned Offline-to-Online Reinforcement Learning via Increased Simple Moving Average Q-value,4.5, 4.5, 1.5, 6, 4, 3, 5, 6, 4, 3, 4
Würstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models,6.75, 7.0, 1.299038105676658, 6, 4, 8, 4, 8, 5, 5, 4
Constructing Semantics-Aware Adversarial Examples with Probabilistic Perspective,4.75, 5.0, 1.0897247358851685, 6, 2, 5, 3, 3, 5, 5, 3
LDReg: Local Dimensionality Regularized Self-Supervised Learning,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 5, 3, 6, 4
Fisher Information Guided Backdoor Purification Via Naive Exploitation of Smoothness,5.75, 6.0, 1.7853571071357126, 6, 2, 6, 4, 8, 4, 3, 4
Empirical Likelihood for Fair Classification,5.0, 6.0, 1.4142135623730951, 3, 3, 6, 3, 6, 4
LLark: A Multimodal Foundation Model for Music,5.25, 6.0, 1.299038105676658, 3, 5, 6, 4, 6, 4, 6, 4
Mamba: Linear-Time Sequence Modeling with Selective State Spaces,6.25, 7.0, 2.0463381929681126, 8, 4, 8, 5, 6, 2, 3, 5
Compositional Image Decomposition with Diffusion Models,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 5, 4, 8, 4
Diversity-Aware Agnostic Ensemble of Sharpness Minimizers,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 6, 2, 3, 3
GIO: Gradient Information Optimization for Training Dataset Selection,5.5, 5.5, 1.8027756377319946, 5, 3, 8, 3, 3, 3, 6, 4
Improving Factuality and Reasoning in Language Models through Multiagent Debate,5.5, 5.5, 0.5, 5, 4, 5, 5, 6, 4, 6, 3
Can Euclidean Symmetry Help in Reinforcement Learning and Planning?,4.25, 4.0, 1.299038105676658, 3, 3, 3, 5, 6, 3, 5, 3
The No Free Lunch Theorem Kolmogorov Complexity and the Role of Inductive Biases in Machine Learning,5.0, 5.5, 1.224744871391589, 6, 5, 5, 3, 3, 4, 6, 2
FusionShot: Boosting Few Shot Learners with Focal-Diversity Optimized Ensemble Method,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 4
Smooth ECE: Principled Reliability Diagrams via Kernel Smoothing,6.0, 6.0, 0.0, 6, 3, 6, 4, 6, 3, 6, 3
Probabilistic Adaptation of Black-Box Text-to-Video Models,5.5, 5.5, 1.8027756377319946, 6, 5, 5, 5, 8, 3, 3, 4
Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings,4.25, 4.0, 1.299038105676658, 3, 4, 6, 4, 3, 4, 5, 4
Horizon-Free Regret for Linear Markov Decision Processes,5.5, 5.5, 0.5, 6, 3, 5, 3, 6, 2, 5, 4
Faithful Rule Extraction for Differentiable Rule Learning Models,6.5, 6.5, 1.5, 5, 3, 8, 3, 8, 2, 5, 2
A Cooperative-Game-Theoretical Model for Ad Hoc Teamwork,4.25, 4.0, 1.299038105676658, 3, 2, 5, 3, 3, 4, 6, 3
SYRAC: Synthesize Rank and Count,4.666666666666667, 5.0, 1.247219128924647, 5, 5, 3, 5, 6, 5
Delving into LLMs’ visual understanding ability using SVG to bridge image and text,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 3, 5, 4
Sparse Backpropagation for MoE Training,4.75, 5.0, 1.0897247358851685, 3, 3, 6, 3, 5, 3, 5, 4
High-dimensional Bayesian Optimization via Semi-supervised Learning with Optimized Unlabeled Data Sampling,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 5, 4, 6, 2
Cross-Modal Self-Supervised Learning with Effective Contrastive Units for Point Clouds,3.75, 3.0, 1.299038105676658, 3, 4, 6, 3, 3, 4, 3, 5
Mining latent labels for imbalance classification: a regrouping perspective,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 5, 5, 2
Score-based generative models break the curse of dimensionality in learning a family of sub-Gaussian distributions,6.75, 7.0, 1.299038105676658, 8, 3, 6, 3, 8, 3, 5, 3
SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training,7.0, 7.0, 1.0, 8, 5, 6, 5, 8, 4, 6, 4
Scalable Diffusion for Materials Generation,6.25, 6.0, 1.0897247358851685, 6, 4, 8, 3, 5, 2, 6, 4
Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection,5.0, 6.0, 1.4142135623730951, 6, 4, 3, 3, 6, 4
Guess & Sketch: Language Model Guided Transpilation,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 8, 2, 5, 2
FedJETs: Efficient Just-In-Time Personalization with Federated Mixture of Experts,5.0, 6.0, 1.4142135623730951, 3, 5, 6, 3, 6, 3
Making PPO even better: Value-Guided Monte-Carlo Tree Search decoding,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 5, 3, 4, 3, 2
Motif: Intrinsic Motivation from Artificial Intelligence Feedback,6.75, 7.0, 1.299038105676658, 5, 4, 8, 3, 8, 3, 6, 3
On Differentially Private Federated Linear Contextual Bandits,7.0, 7.0, 1.0, 6, 4, 8, 3, 8, 3, 6, 4
LaMPP: Language Models as Probabilistic Priors for Perception and Action,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 3, 5, 4
Leveraging Hierarchical Feature Sharing for Efficient Dataset Condensation,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 3, 6, 2, 6, 3
Cascaded Contrastive Medical Language-Image Pretraining on Radiology Images,5.25, 5.0, 1.7853571071357126, 8, 3, 5, 4, 3, 4, 5, 4
ALMANACS: A Simulatability Benchmark for Language Model Explainability,5.0, 4.5, 2.1213203435596424, 3, 3, 3, 3, 6, 3, 8, 4
Generative Human Motion Stylization in Latent Space,5.5, 5.5, 0.5, 5, 4, 6, 4, 5, 3, 6, 4
In-Context Learning with Retrieval Augmented Encoder-Decoder Language Models,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 2, 6, 3
Neural Neighborhood Search for Multi-agent Path Finding,5.0, 5.5, 1.224744871391589, 5, 3, 3, 4, 6, 4, 6, 5
Detecting and Removing Adversarial Patches using Frequency Signatures,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 5, 3, 5, 3, 4
A General Single-Cell Analysis Framework via Conditional Diffusion Generative Models,5.25, 5.0, 1.7853571071357126, 3, 4, 5, 3, 5, 3, 8, 5
Evidential Conservative Q-Learning for Dynamic Recommendations,4.333333333333333, 5.0, 0.9428090415820634, 5, 5, 3, 4, 5, 4
Teaching Language Models to Hallucinate Less with Synthetic Tasks,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 4, 6, 3
Space-Time Attention with Shifted Non-Local Search,5.0, 5.0, 0.0, 5, 2, 5, 3, 5, 2
Compositional Instruction Following with Language Models and Reinforcement Learning,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 3, 4, 5, 4
Enable Lanuguage Models to Implicitly Learn Self-Improvement From Data,5.75, 6.0, 0.4330127018922193, 5, 3, 6, 3, 6, 3, 6, 3
Learning Personalized Story Evaluation,5.75, 5.0, 1.299038105676658, 5, 4, 5, 3, 5, 4, 8, 5
Stochastic Safe Action Model Learning,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 4, 3, 2
Fantastic Gains and Where to Find Them: On the Existence and Prospect of General Knowledge Transfer between Any Pretrained Model,7.25, 8.0, 1.299038105676658, 8, 3, 8, 4, 8, 3, 5, 4
Speed Up Federated Learning in Heterogeneous Environment: A Dynamic Tiering Approach,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 3, 3, 3
Training-free Deep Concept Injection Enables Language Models for Crossmodal Tasks,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 3, 6, 3, 6, 3
G-TIGRE: A new generative framework for Multivariate Time Series Imputation By Graph Neural Networks,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 3, 3, 4
ReLoRA: High-Rank Training Through Low-Rank Updates,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 4, 5, 4, 6, 4
UpFusion: Novel View Diffusion from Unposed Sparse View Observations,5.25, 5.0, 0.4330127018922193, 5, 5, 6, 4, 5, 4, 5, 5
Hopfield Encoding Networks,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 3
Learning with Language-Guided State Abstractions,4.666666666666667, 5.0, 1.247219128924647, 3, 5, 5, 3, 6, 4
Multimodal Molecular Pretraining via Modality Blending,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 5, 5, 2
Image as First-Order Norm+Linear Autoregression: Unveiling Mathematical Invariance,5.0, 5.5, 1.224744871391589, 3, 4, 5, 3, 6, 3, 6, 3
Generative modeling for RNA splicing code predictions and design,5.5, 5.5, 0.5, 5, 5, 6, 4, 6, 4, 5, 3
D^3: Distributional Dataset Distillation with Latent Priors,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 4, 6, 3
ThEBES: Thorough Energy-Based Evolution Strategy,2.5, 3.0, 0.8660254037844386, 1, 5, 3, 4, 3, 5, 3, 3
MoMo: Momentum Models for Adaptive Learning Rates,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4
Understanding when Dynamics-Invariant Data Augmentations Benefit Model-free Reinforcement Learning Updates,6.0, 6.5, 2.1213203435596424, 8, 4, 8, 3, 3, 4, 5, 4
Robustifying State-space Models for Long Sequences via Approximate Diagonalization,5.75, 6.0, 0.4330127018922193, 5, 3, 6, 3, 6, 4, 6, 2
UGradSL: Machine Unlearning Using Gradient-based Smoothed Label,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 2
On-Policy Policy Gradient Reinforcement Learning Without On-Policy Sampling,5.25, 5.0, 1.7853571071357126, 5, 4, 3, 2, 5, 4, 8, 4
On the power of graph neural networks and the role of the activation function,3.75, 4.0, 1.920286436967152, 5, 3, 1, 5, 6, 3, 3, 5
JoMA: Demystifying Multilayer Transformers via Joint Dynamics of MLP and Attention,5.75, 6.0, 0.4330127018922193, 5, 2, 6, 3, 6, 3, 6, 2
Sample Efficient Myopic Exploration Through Multitask Reinforcement Learning with Diverse Tasks,6.0, 5.5, 1.224744871391589, 5, 3, 6, 4, 8, 3, 5, 2
Provable Offline Preference-Based Reinforcement Learning,6.75, 7.0, 2.5860201081971503, 6, 2, 8, 2, 3, 3, 10, 3
FedBPT: Efficient Federated Black-box Prompt Tuning for Large Language Models,5.0, 5.0, 1.0, 5, 3, 5, 4, 3, 5, 5, 4, 6, 4, 6, 3
Can LLMs Keep a Secret? Testing  Privacy  Implications of Language Models  via Contextual Integrity Theory,6.25, 7.0, 2.0463381929681126, 6, 3, 8, 3, 3, 4, 8, 3
Graph Neural Networks Provably Benefit from Structural Information: A Feature Learning Perspective,5.0, 5.0, 1.0954451150103321, 3, 3, 6, 3, 6, 3, 5, 4, 5, 5
Quantifying Interactions in Semi-supervised Multimodal Learning: Guarantees and Applications,6.333333333333333, 6.0, 1.247219128924647, 8, 4, 6, 3, 5, 4
Provable Reward-Agnostic Preference-Based Reinforcement Learning,6.75, 7.0, 1.299038105676658, 6, 4, 8, 2, 8, 2, 5, 3
Adaptive Retrieval and Scalable Indexing for k-NN Search with Cross-Encoders,5.75, 6.0, 1.7853571071357126, 3, 4, 6, 3, 8, 3, 6, 3
Explainable Steerable Models with Natural Language Parameters and Constraints,4.0, 4.0, 1.0, 3, 4, 5, 3, 3, 3, 5, 4
The Truth Is In There: Improving Reasoning with Layer-Selective Rank Reduction,6.333333333333333, 6.0, 2.8674417556808756, 6, 3, 3, 4, 10, 4
Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models,4.75, 5.0, 1.0897247358851685, 6, 4, 3, 4, 5, 3, 5, 4
DeepZero: Scaling Up Zeroth-Order Optimization for Deep Model Training,5.666666666666667, 6.0, 1.4907119849998596, 5, 4, 3, 2, 6, 3, 6, 4, 8, 3, 6, 3
Provable Knowledge Transfer using Successor Feature for Deep Reinforcement Learning,5.0, 4.5, 2.1213203435596424, 3, 3, 3, 3, 6, 4, 8, 3
Multi-Resolution Diffusion Models for Time Series Forecasting,5.75, 6.0, 0.4330127018922193, 5, 3, 6, 4, 6, 3, 6, 4
Mechanism of clean-priority learning in early stopped neural networks of infinite width,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 3, 5, 2
COMPRESSION AND ACCELERATION OF DEEP NEURAL NETWORKS: A VECTOR QUANTIZATION APPROACH,4.666666666666667, 5.0, 1.247219128924647, 3, 5, 5, 3, 6, 4
Advantage-Conditioned Diffusion: Offline RL via Generalization,4.25, 4.0, 1.299038105676658, 3, 4, 3, 3, 5, 4, 6, 4
Unleashing the Potential of Fractional Calculus in Graph Neural Networks with FROND,5.75, 6.0, 1.7853571071357126, 6, 3, 6, 3, 3, 4, 8, 4
CLIP the Bias: How Useful is Balancing Data in Multimodal Learning?,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 5, 3, 6, 4
Robust Core-periphery Constrained Transformer for Domain Adaptation,3.75, 4.0, 1.920286436967152, 6, 3, 1, 4, 3, 4, 5, 4
On Error Propagation of Diffusion Models,6.25, 7.0, 2.0463381929681126, 8, 4, 6, 2, 3, 4, 8, 2
The Update Equivalence Framework for Decision-Time Planning,4.75, 4.0, 2.0463381929681126, 3, 3, 5, 2, 3, 3, 8, 2
Soft Mixture Denoising: Beyond the Expressive Bottleneck of Diffusion Models,6.0, 6.5, 2.1213203435596424, 8, 4, 8, 4, 5, 4, 3, 4
Learning to Stylize Soundscapes from In-the-Wild Videos,4.0, 4.0, 1.0, 5, 3, 3, 3, 3, 4, 5, 3
LabelDP-Pro: Learning with Label Differential Privacy via Projections,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 4, 6, 5, 6, 3
SDM-RL: Steady-State Divergence Maximization for Robust Reinforcement Learning,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 3, 4, 5, 4
Larger language models do in-context learning differently,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 4, 5, 4, 5, 4
Efficient Continual Pre-training for Building Domain Specific Large Language Models,5.5, 5.5, 0.5, 6, 4, 5, 4, 6, 5, 5, 3
Computing Low-Entropy Couplings for Large-Support Distributions,4.666666666666667, 5.0, 1.247219128924647, 5, 2, 6, 3, 3, 3
AUC-CL: A Batchsize-Robust Framework for Self-Supervised Contrastive Representation Learning,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 4, 5, 5, 5, 2
Maestro: Uncovering Low-Rank Structures via Trainable Decomposition,5.75, 5.0, 1.299038105676658, 5, 4, 8, 3, 5, 4, 5, 3
Chain-of-Thought Reasoning is a Policy Improvement Operator,4.75, 4.0, 2.0463381929681126, 8, 5, 3, 3, 3, 4, 5, 4
Split-Ensemble: Efficient OOD-aware Ensemble via Task and Model Splitting,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 4, 5, 4
Fractal Patterns May Unravel the Intelligence in Next-Token Prediction,4.333333333333333, 6.0, 2.357022603955158, 1, 3, 6, 4, 6, 3
Instruction Mining: Instruction Data Selection for Tuning Large Language Models,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 6, 4, 5, 4
MetaPhysiCa: Improving OOD Robustness in Physics-informed Machine Learning,6.25, 6.0, 1.0897247358851685, 5, 5, 8, 3, 6, 2, 6, 3
Demystifying the Myths and Legends of Nonconvex Convergence of SGD,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 1, 4
Density Ratio Estimation-based Bayesian Optimization with Semi-Supervised Learning,5.0, 5.5, 1.224744871391589, 5, 4, 3, 4, 6, 3, 6, 3
Teaching Arithmetic to Small Transformers,4.2, 5.0, 0.9797958971132712, 3, 3, 5, 4, 3, 4, 5, 3, 5, 4
ReMasker: Imputing Tabular Data with Masked Autoencoding,5.333333333333333, 5.0, 2.0548046676563256, 3, 3, 5, 3, 8, 4
Towards Universal Robust Federated Learning via Meta Stackelberg Game,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 3, 3, 5, 5, 3
Topology Matters in Fair Graph Learning: a Theoretical Pilot Study,4.666666666666667, 5.0, 1.247219128924647, 3, 5, 5, 5, 6, 3
ReLU soothes NTK conditioning and accelerates optimization for wide neural networks,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 3
Variance Reduced Halpern Iteration for Finite-Sum Monotone Inclusions,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 3, 5, 3
TpopT: Efficient Trainable Template Optimization on Low-Dimensional Manifolds,5.5, 5.5, 1.8027756377319946, 6, 3, 8, 4, 5, 4, 3, 4
A Dynamical View of the Question of Why,5.0, 4.5, 2.1213203435596424, 3, 4, 6, 3, 3, 4, 8, 3
MMToM-QA: Multimodal Theory of Mind Question Answering,4.75, 5.0, 1.0897247358851685, 6, 4, 3, 4, 5, 2, 5, 4
Learning Reusable Dense Rewards for Multi-Stage Tasks,5.5, 5.5, 2.5, 3, 4, 8, 3, 3, 4, 8, 3
Todyformer: Towards Holistic Dynamic Graph Transformers with Structure-Aware Tokenization,4.25, 4.0, 1.299038105676658, 3, 4, 5, 3, 3, 4, 6, 3
Fair Classifiers that Abstain without Harm,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 6, 4, 8, 4
Carrying over Algorithm in Transformers,6.0, 5.5, 2.5495097567963922, 3, 4, 6, 2, 5, 4, 10, 4
Aligning Relational Learning with Lipschitz Fairness,5.5, 5.5, 0.5, 5, 1, 6, 3, 5, 3, 6, 3
Rethinking the Smoothness of Node Features Learned by Graph Convolutional Networks,5.0, 5.5, 1.224744871391589, 3, 5, 5, 3, 6, 4, 6, 3
Listen Think and Understand,6.25, 6.0, 1.0897247358851685, 6, 4, 5, 4, 8, 5, 6, 5
Unsupervised Image-to-Video Domain Adaptation for Fine-Grained Video Understanding,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 1, 4, 3, 4
Safeguarding Data in Multimodal AI: A Differentially Private Approach to CLIP Training,5.0, 5.5, 3.082207001484488, 3, 4, 8, 2, 8, 4, 1, 4
Don't Pre-train Teach Your Small Model,3.0, 3.0, 1.4142135623730951, 5, 3, 1, 5, 3, 4, 3, 3
Curvature Explains Loss of Plasticity,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 5, 4, 6, 4
GOAt: Explaining Graph Neural Networks via Graph Output Attribution,6.0, 5.5, 1.224744871391589, 5, 5, 8, 3, 6, 2, 5, 4
Time Fairness in Online Knapsack Problems,6.333333333333333, 6.0, 1.247219128924647, 6, 3, 5, 4, 8, 2
Compress Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt,5.25, 5.0, 1.7853571071357126, 5, 4, 5, 4, 3, 4, 8, 3
A Lie Group Approach to Riemannian Normalization for SPD Neural Networks,4.5, 4.5, 2.692582403567252, 6, 3, 3, 3, 8, 5, 1, 4
Strategies and impact of learning curve estimation for CNN-based image classification,3.75, 3.0, 1.299038105676658, 3, 2, 3, 2, 3, 2, 6, 3
Bi-Level Optimization for Pseudo-Labeling Based Semi-Supervised Learning,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 4, 5, 3
Text-driven Prompt Generation for Vision-Language Models in Federated Learning,5.5, 5.5, 0.5, 5, 5, 6, 3, 6, 3, 5, 3
Graph Positional and Structural Encoder,3.5, 4.0, 1.6583123951777, 5, 4, 3, 4, 1, 4, 5, 5
Views Can Be Deceiving: Improved SSL Through Feature Space Augmentation,6.0, 5.5, 1.224744871391589, 5, 4, 8, 4, 5, 3, 6, 3
PAGER: A Framework for Failure Analysis of Deep Regression Models,6.0, 6.0, 0.0, 6, 2, 6, 2, 6, 4
Fisher-aware Quantization for DETR Detectors with Critical-category Objectives,5.666666666666667, 6.0, 0.4714045207910317, 5, 3, 6, 3, 6, 2
T-Measure: A Measure for Model Transferabilty,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 3, 3, 5, 3
SGD batch saturation for training wide neural networks,3.5, 4.0, 1.6583123951777, 1, 5, 5, 3, 5, 3, 3, 5
RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought,4.666666666666667, 5.0, 1.247219128924647, 5, 5, 3, 4, 6, 3
Borda Regret Minimization for Generalized Linear Dueling Bandits,5.75, 5.0, 1.299038105676658, 8, 3, 5, 2, 5, 4, 5, 3
On the Hardness of Constrained Cooperative Multi-Agent Reinforcement Learning,5.833333333333333, 6.0, 0.372677996249965, 5, 3, 6, 2, 6, 4, 6, 4, 6, 3, 6, 2
MultiLayerDiffusion: Composing Global Contexts and Local Details in Image Generation,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 3, 5, 5, 4
FLIRT: Feedback Loop In-context Red Teaming,5.0, 5.5, 1.224744871391589, 5, 4, 3, 4, 6, 3, 6, 4
Interpreting and improving diffusion models using the Euclidean distance function,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 6, 3, 8, 3
Det-CGD: Compressed Gradient Descent with Matrix Stepsizes for Non-Convex Optimization,5.0, 6.0, 1.4142135623730951, 3, 5, 6, 2, 6, 2
Intrinsic Riemannian Classifiers on the Deformed SPD Manifolds: A Unified Framework,4.25, 4.0, 1.299038105676658, 3, 3, 5, 4, 3, 4, 6, 3
Editable Graph Neural Network for Node Classifications,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 4, 3, 4
Causal-StoNet: Causal Inference for High-Dimensional Complex Data,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 4, 5, 3
Conditional Information Bottleneck Approach for Time Series Imputation,6.25, 6.0, 1.0897247358851685, 8, 4, 5, 4, 6, 4, 6, 4
RepoFusion: Training Code Models to Understand Your Repository,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 3, 3, 4
ATraDiff: Accelerating Online Reinforcement Learning with Imaginary Trajectories,4.4, 5.0, 1.2, 3, 5, 5, 3, 5, 4, 3, 3, 6, 4
The Optimal Constant Solution: Predictable Extrapolation in Deep Neural Networks,6.75, 7.0, 1.299038105676658, 8, 3, 5, 4, 6, 3, 8, 4
Language Models as Semantic Indexers,5.0, 5.5, 1.224744871391589, 6, 4, 3, 3, 6, 3, 5, 4
Global minima recoverability thresholds and higher-order structure in GNNs,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 3, 3, 4
RLCD: Reinforcement Learning from Contrastive Distillation for LM Alignment,5.2, 6.0, 1.16619037896906, 5, 3, 3, 3, 6, 3, 6, 2, 6, 3
Zeroth-Order Optimization Meets Human Feedback: Provable Learning via Ranking Oracles,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 6, 4, 5, 4
Selective Prediction via Training Dynamics,4.8, 5.0, 0.9797958971132712, 5, 5, 3, 4, 5, 4, 6, 3, 5, 4
Entropy Coding of Unordered Data Structures,6.25, 6.0, 1.0897247358851685, 8, 4, 6, 3, 6, 3, 5, 2
Benchmarking Zero-Shot Recognition with Vision-Language Models: Challenges on Granularity and Specificity,5.2, 6.0, 1.9390719429665317, 8, 5, 3, 4, 3, 4, 6, 4, 6, 4
Neurosymbolic Grounding for Compositional Generalization,5.5, 5.5, 0.5, 6, 4, 5, 4
EvolMPNN: Predicting Mutational Effect on Homologous Proteins by Evolution Encoding,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 4, 6, 3
Towards More Robust NLP System Evaluation: Handling Missing Scores in Benchmarks,5.5, 5.5, 1.8027756377319946, 8, 3, 3, 3, 6, 3, 5, 4
Multiobjective Stochastic Linear Bandits under Lexicographic Ordering,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 3, 4, 5, 3
InCo: Enhance Domain Generalization in Noisy Environments,5.0, 5.0, 1.0954451150103321, 5, 3, 6, 4, 5, 3, 6, 3, 3, 3
OpenTab: Advancing Large Language Models as Open-domain Table Reasoners,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 8, 4, 6, 4
Deep Graph Predictions using Dirac-Bianconi Graph Neural Networks,4.2, 5.0, 0.9797958971132712, 5, 4, 5, 3, 3, 4, 5, 3, 3, 4
OS-net: Orbitally Stable Neural Networks,3.5, 3.0, 0.8660254037844386, 3, 2, 3, 2, 3, 4, 5, 2
Incentivized Collaborative Learning: Architectural Design and Insights,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 4
Adaptive Sharpness-Aware Pruning for Robust Sparse Networks,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 2, 6, 4, 6, 4
SiBBlInGS: Similarity-driven Building Block Inference using Graphs across States,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 5, 4, 6, 2
Personalized Federated Learning of Probabilistic Models: A PAC-Bayesian Approach,5.5, 5.5, 1.8027756377319946, 3, 4, 8, 3, 5, 3, 6, 3
Revisiting GNNs for Boolean Satisfiability,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 6, 3, 5, 3
MBR and QE Finetuning: Training-time Distillation of the Best and Most Expensive Decoding Methods,6.0, 5.5, 1.224744871391589, 5, 5, 6, 3, 5, 4, 8, 4
Federated Orthogonal Training: Mitigating Global Catastrophic Forgetting in Continual Federated Learning,5.666666666666667, 6.0, 0.4714045207910317, 5, 3, 6, 4, 6, 3
Self-Consuming Generative Models Go MAD,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 6, 4, 8, 3
A Local Graph Limits Perspective on Sampling-Based GNNs,5.5, 5.5, 0.5, 5, 4, 6, 3, 6, 2, 5, 5
Pricing with Contextual Elasticity and Heteroscedastic Valuation,5.0, 5.5, 1.224744871391589, 6, 5, 6, 4, 5, 3, 3, 3
The Hidden Language of Diffusion Models,5.0, 5.5, 1.224744871391589, 5, 5, 6, 5, 3, 3, 6, 4
Overcome Data Heterogeneity in Federated Learning with Filter Decomposition,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 3, 3, 4
Confidence-Based Model Selection: When to Take Shortcuts in Spurious Settings,5.333333333333333, 5.0, 2.0548046676563256, 3, 3, 5, 4, 8, 4
Exposure Bias Mitigation for Self Information Updating of Large Language Models,5.0, 5.5, 1.224744871391589, 3, 4, 6, 3, 6, 3, 5, 4
Augmentation-aware Self-Supervised Learning with Conditioned Projector,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 4, 6, 4, 3, 5
Reasoning with Latent Diffusion in Offline Reinforcement Learning,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 5, 5, 4
Zero redundancy distributed learning with differential privacy,6.5, 6.5, 1.5, 8, 2, 5, 2
Learning Sequence Attractors in Recurrent Networks with Hidden Neurons,5.25, 5.0, 1.7853571071357126, 5, 5, 5, 3, 8, 4, 3, 4
Project and Probe: Sample-Efficient Adaptation by Interpolating Orthogonal Features,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 3, 5, 4
Automated Search-Space Generation Neural Architecture Search,4.0, 4.0, 1.0, 3, 3, 3, 4, 5, 5, 5, 5
Implicit bias of SGD in $L_2$-regularized linear DNNs: One-way jumps from high to low rank,7.25, 7.0, 1.920286436967152, 6, 4, 8, 3, 5, 4, 10, 3
Low Rank Matrix Completion via Robust Alternating Minimization in Nearly Linear Time,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 5, 4, 6, 3
Non-Asymptotic Analysis for Single-Loop (Natural) Actor-Critic with Compatible Function Approximation,6.333333333333333, 6.0, 0.7453559924999298, 8, 2, 6, 4, 6, 3, 6, 2, 6, 4, 6, 2
DiffusionNAG: Predictor-guided Neural Architecture Generation with Diffusion Models,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 2, 6, 3, 5, 4
Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations,5.5, 5.5, 1.8027756377319946, 8, 4, 3, 4, 6, 4, 5, 2
Federated Causal Discovery from Heterogeneous Data,6.2, 5.0, 1.469693845669907, 5, 4, 5, 4, 8, 3, 5, 4, 8, 3
CellPLM: Pre-training of Cell Language Model Beyond Single Cells,6.333333333333333, 6.0, 1.247219128924647, 8, 4, 5, 2, 6, 2
Language Control Diffusion: Efficiently Scaling through Space Time and Tasks,5.5, 5.5, 0.5, 5, 3, 6, 3, 5, 4, 6, 3
CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV Perception,6.0, 6.0, 0.0, 6, 5, 6, 3, 6, 5
Unsupervised Feature Learning with Emergent Data-Driven Prototypicality,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 2, 5, 4
Principled Architecture-aware Scaling of Hyperparameters,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 4, 6, 3
Learning Multiplex Embeddings on Text-rich Networks with One Text Encoder,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 3, 6, 4, 5, 3
Gradient-free Proxy for Efficient Language Model Search,5.25, 5.0, 1.7853571071357126, 5, 2, 8, 4, 5, 4, 3, 4
Provable Robust Watermarking for AI-Generated Text,7.0, 7.0, 1.0, 8, 3, 8, 4, 6, 3, 6, 2
EGALA: Efficient Gradient Approximation for Large-scale Graph Adversarial Attack,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 3, 4, 5, 4
Str2Str: A Score-based Framework for Zero-shot Protein Conformation Sampling,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 4, 6, 3, 6, 3
CCIL: Continuity-Based Data Augmentation for Corrective Imitation Learning,5.5, 5.5, 0.5, 5, 4, 6, 4, 6, 4, 5, 3
Memory-Consistent Neural Networks for Imitation Learning,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 3, 5, 4, 6, 4
Learning dynamic representations of the functional connectome in neurobiological networks,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 5, 4, 8, 5
Skill or Luck? Return Decomposition via Advantage Functions,6.25, 6.0, 1.0897247358851685, 6, 3, 5, 5, 8, 3, 6, 4
Coarse-Tuning Models of Code with Reinforcement Learning Feedback,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 3, 6, 4, 5, 4
Structured Pruning of CNNs at Initialization,4.0, 4.0, 1.0, 3, 4, 3, 5, 5, 5, 5, 3
Belief-Enriched Pessimistic Q-Learning against Adversarial State Perturbations,6.25, 6.0, 1.0897247358851685, 6, 2, 6, 2, 5, 4, 8, 4
FedGT: Federated Node Classification with Scalable Graph Transformer,5.333333333333333, 5.0, 2.0548046676563256, 8, 4, 3, 4, 5, 5
Whole-song Hierarchical Generation of Symbolic Music Using Cascaded Diffusion Models,6.25, 6.0, 1.0897247358851685, 6, 5, 8, 3, 5, 4, 6, 4
Toward $\textbf{F}$aithfulness-guided $\textbf{E}$nsemble $\textbf{I}$nterpretation of Neural Network,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 5, 2, 3, 2
SmartPlay : A Benchmark for LLMs as Intelligent Agents,6.0, 5.5, 1.224744871391589, 6, 4, 5, 4, 5, 2, 8, 3
MSA Generation with Seqs2Seqs Pretraining: Advancing Protein Structure Predictions,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 3, 3, 4
Evaluating the Zero-shot Robustness of Instruction-tuned Language Models,6.75, 7.0, 1.299038105676658, 8, 4, 5, 4, 6, 4, 8, 4
Conditional Instrumental Variable Regression with Representation Learning for Causal Inference,6.25, 6.0, 1.0897247358851685, 6, 4, 6, 4, 8, 4, 5, 3
Learning with Temporal Label Noise,5.25, 5.0, 1.7853571071357126, 8, 4, 5, 4, 3, 3, 5, 4
On the efficacy of group-wise clipping in differentially private optimization,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 5, 5, 3, 6, 3
ivrit.ai: A Comprehensive Dataset of Hebrew Speech for AI Research and Development,2.5, 3.0, 0.8660254037844386, 3, 3, 1, 5, 3, 4, 3, 5
WATT FOR WHAT: RETHINKING DEEP LEARNING’S ENERGY-PERFORMANCE RELATIONSHIP,3.0, 3.0, 1.4142135623730951, 3, 5, 3, 4, 1, 4, 5, 3
DPO-Diff: On Discrete Prompt Optimization of Text-to-Image Diffusion Models,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 3, 5, 3
Illuminating Protein Function Prediction through Inter-Protein Similarity Modeling,4.5, 5.0, 1.224744871391589, 6, 3, 5, 3, 3, 3, 6, 4, 5, 4, 5, 3, 3, 4, 3, 3
Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation,5.666666666666667, 6.0, 2.0548046676563256, 6, 4, 3, 4, 8, 4
Look Remember and Reason: Grounded Reasoning in Videos with Language Models,5.75, 6.0, 0.4330127018922193, 5, 5, 6, 3, 6, 3, 6, 4
Cross-Model Semi-Supervised Prompt Learning for Vision-Language Models,4.5, 4.5, 1.5, 6, 4, 6, 5, 3, 4, 3, 4
Co-Learning Empirical Games & World Models,5.0, 5.0, 1.8973665961010275, 6, 4, 3, 4, 8, 3, 5, 4, 3, 4
Structured Inverse-Free Natural Gradient: Memory-Efficient & Numerically-Stable KFAC for Large Neural Nets,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 3, 6, 3, 5, 3
SOHES: Self-supervised Open-world Hierarchical Entity Segmentation,5.666666666666667, 6.0, 0.4714045207910317, 5, 3, 6, 3, 6, 5
Beyond adversarial examples: sampling and repairing diverse failures with RADIUM,1.0, 1.0, 0.0, 1, 5
Multi-fidelity Deep Symbolic Optimization,5.2, 5.0, 1.6, 5, 4, 5, 3, 8, 3, 5, 3, 3, 3
Natural Counterfactuals With Necessary Backtracking,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 1, 5, 3
Graph Representation Learning with Multi-granular Semantic Ensemble,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 4, 5, 3
Understanding Unfairness via Training Concept Influence,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 3, 3, 4
Grid Cell-Inspired Fragmentation and Recall for Efficient Map Building,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 5, 3, 4
Augmenting Negative Representation for Continual Self-Supervised Learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 3, 3, 4
Semi-supervised Domain Adaptation via Joint Error based Triplet Alignment,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 1, 5, 3, 3
Optimisation-Based Multi-Modal Semantic Image Editing,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 4, 5, 2, 6, 3
LETI: Learning to Generate from Textual Interactions,5.2, 5.0, 1.6, 3, 3, 8, 4, 5, 4, 5, 4, 5, 4
IBCL: Zero-shot Model Generation for Task Trade-offs in Continual Learning,4.0, 4.0, 1.0, 5, 3, 3, 4
EquiformerV2: Improved Equivariant Transformer for Scaling to Higher-Degree Representations,6.0, 6.0, 0.0, 6, 5, 6, 4, 6, 4
Neural varifolds: an aggregate representation for quantifying geometry of point clouds,5.0, 5.0, 0.0, 5, 2, 5, 4, 5, 3
DOMINO: A Dual-System for Multi-step Visual Language Reasoning,6.0, 5.0, 1.4142135623730951, 5, 4, 5, 3, 8, 3
Concept Matching: Clustering-based Federated Continual Learning,3.75, 3.0, 1.299038105676658, 3, 4, 6, 3, 3, 4, 3, 4
Chameleon: Increasing Label-Only Membership Leakage with Adaptive Poisoning,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 4, 5, 4
Adaptive Bilevel Optimization,4.6, 5.0, 1.3564659966250536, 6, 2, 3, 4, 5, 4, 3, 5, 6, 3
Understanding Graph Transformers by Generalized Propagation,4.25, 4.0, 1.299038105676658, 3, 2, 6, 4, 5, 4, 3, 4
Token Alignment via Character Matching for Subword Completion,4.0, 4.0, 1.0, 5, 4, 3, 4, 5, 3, 3, 4
Decomposing the Enigma: Subgoal-based Demonstration Learning for Formal Theorem Proving,7.0, 7.0, 1.0, 8, 2, 6, 3
Reward Adaptation Via Q-Manipulation,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 4, 3, 4, 3, 4
Robust NAS benchmark under adversarial training: assessment theory and beyond,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 4, 5, 4
Critical Learning Periods Emerge Even in Deep Linear Networks,5.75, 5.0, 1.299038105676658, 5, 3, 5, 3, 8, 3, 5, 3
InfoScissors: Defense against Data Leakage in Collaborative Inference through the Lens of Mutual Information,4.2, 5.0, 0.9797958971132712, 3, 3, 3, 5, 5, 4, 5, 4, 5, 4
On the Equivalence of Graph Convolution and Mixup,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 5, 3, 3, 4
Partition and Conquer: A Multimodal Autoregressive Model for Time-Aligned and Contextual Modalities,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 3, 3, 5, 3
Exponentially Expanding the Compiler Phase-Ordering Problem's Search Space through the Learning of Dormant Information,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 3, 4, 5, 4
Conformal Language Modeling,6.25, 7.0, 2.0463381929681126, 8, 4, 8, 3, 3, 2, 6, 4
MOTOR: A Time-To-Event Foundation Model For Structured Medical Records,7.5, 8.0, 0.8660254037844386, 8, 4, 8, 3, 6, 3, 8, 4
Representation Deficiency in Masked Language Modeling,6.5, 6.5, 2.692582403567252, 3, 4, 10, 5, 8, 4, 5, 4
Hyper-parameter Tuning for Fair Classification without Sensitive Attribute Access,4.333333333333333, 5.0, 0.9428090415820634, 5, 5, 3, 2, 5, 3
GenSim: Generating Robotic Simulation Tasks via Large Language Models,7.5, 8.0, 0.8660254037844386, 8, 4, 8, 3, 6, 3, 8, 4
$\lambda$-AC: Effective decision-aware reinforcement learning with latent models,5.0, 4.5, 2.1213203435596424, 8, 2, 6, 3, 3, 2, 3, 4
Neural Network Expressive Power Analysis Via Manifold Topology,4.75, 4.0, 2.0463381929681126, 3, 4, 5, 2, 8, 3, 3, 2
Polynomial Width is Sufficient for Set Representation with High-dimensional Features,6.75, 7.0, 1.299038105676658, 8, 3, 8, 3, 6, 3, 5, 3
Learning Variational Neighbor Labels for Test-Time Domain Generalization,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 5, 3, 6, 3
Reward Collapse in Aligning Large Language Models,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 4, 5, 3
Parametric Augmentation for Time Series Contrastive Learning,5.0, 5.0, 2.280350850198276, 5, 4, 1, 4, 5, 4, 8, 4, 6, 4
Microenvironment Probability Flows as Proficient Protein Engineers,5.75, 5.0, 1.299038105676658, 8, 3, 5, 3, 5, 3, 5, 4
Robustness Guarantees for Adversarial Training on Non-Separable Data,5.75, 6.0, 1.7853571071357126, 6, 3, 6, 3, 3, 4, 8, 3
Prediction Error-based Classification for Class-Incremental Learning,5.0, 4.5, 2.1213203435596424, 3, 4, 3, 3, 6, 3, 8, 3
Test-Time Training on Nearest Neighbors for Large Language Models,5.25, 5.0, 0.4330127018922193, 5, 5, 5, 4, 5, 4, 6, 4
Data-Centric Defense: Shaping Loss Landscape with Augmentations to Counter Model Inversion,3.75, 3.0, 1.299038105676658, 6, 5, 3, 5, 3, 4, 3, 5
Understanding Augmentation-based Self-Supervised Representation Learning via RKHS Approximation and Regression,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 2, 6, 3, 6, 3
READ: Recurrent Adaptation of Large Transformers,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 3
Improved Probabilistic Image-Text Representations,6.0, 5.0, 1.4142135623730951, 5, 5, 8, 3, 5, 3
A Label is a Label is a Label: Relation Augmentation for Scene Graph Generation,3.8, 3.0, 0.9797958971132712, 5, 3, 5, 4, 3, 5, 3, 4, 3, 5
SynerGPT: In-Context Learning for Personalized Drug Synergy Prediction and Drug Design,4.0, 4.0, 1.0, 5, 5, 3, 5, 5, 2, 3, 4
Using Attention to Weight Particles in Particle Filters,3.0, 3.0, 1.4142135623730951, 3, 5, 3, 4, 5, 3, 1, 4
Buffered Asynchronous Federated Learning with Local Differential Privacy,3.0, 3.0, 1.4142135623730951, 3, 4, 5, 5, 1, 4, 3, 4
Securing Deep Generative Models with Universal Adversarial Signature,5.0, 5.5, 1.224744871391589, 3, 3, 6, 4, 6, 5, 5, 4
DisCo: Disentangled Control for Realistic Human Dance Generation,4.0, 4.0, 1.0, 3, 3, 3, 4, 5, 3, 5, 4
Soon Filter: Advancing Feed-Forward Neural Architectures for Inference at the Edge,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 5, 5, 3
Alignment and Outer Shell Isotropy for Hyperbolic Graph Contrastive Learning,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 5, 3, 6, 2
InstructZero: Efficient Instruction Optimization for Black-Box Large Language Models,5.333333333333333, 5.0, 2.0548046676563256, 5, 3, 3, 4, 8, 3
SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos,6.25, 6.0, 1.0897247358851685, 6, 3, 8, 4, 6, 4, 5, 5
Task adaptation by biologically inspired stochastic comodulation,5.25, 5.0, 1.7853571071357126, 5, 3, 3, 3, 5, 4, 8, 2
Confession Networks: Boosting Accuracy and Improving Confidence in Classification,3.5, 4.0, 1.6583123951777, 3, 5, 5, 3, 1, 5, 5, 4
Shape-aware Graph Spectral Learning,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 4, 6, 4, 6, 4
Polarity-Aware Semantic Retrieval with Fine-Tuned Sentence Embeddings,4.0, 4.0, 1.0, 3, 3, 3, 5, 5, 3, 5, 3
DUDE: Deep Unsupervised Domain adaptation using variable nEighbors for physiological time series analysis,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 6, 2, 3, 4
BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection,6.0, 5.5, 1.224744871391589, 5, 4, 8, 5, 5, 4, 6, 2
Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks,6.5, 6.5, 1.5, 8, 3, 8, 2, 5, 4, 5, 3
System Identification of Neural Systems: Going Beyond Images to Modelling Dynamics,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 4, 3, 4, 5, 4
Sparse Iso-FLOP Transformations for Maximizing Training Efficiency,4.0, 4.0, 1.0, 5, 4, 5, 4, 3, 4, 3, 3
What does GPT store in its MLP weights? A case study of long-range dependencies,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 3, 3, 2
Sudden Drops in the Loss: Syntax Acquisition Phase Transitions and Simplicity Bias in MLMs,7.25, 8.0, 2.5860201081971503, 3, 4, 8, 4, 8, 4, 10, 3
Prompting Language-Informed Distribution for Compositional Zero-Shot Learning,5.25, 5.0, 0.4330127018922193, 5, 5, 6, 3, 5, 4, 5, 5
Is Self-Repair a Silver Bullet for Code Generation?,6.333333333333333, 6.0, 1.247219128924647, 8, 4, 6, 4, 5, 3
MgNO: Efficient Parameterization of Linear Operators via Multigrid,6.25, 6.0, 1.0897247358851685, 6, 3, 5, 2, 6, 2, 8, 4
Dissecting Neural Network Robustness Proofs,6.0, 6.0, 0.0, 6, 3, 6, 3, 6, 2, 6, 2
Differentially Private SGD Without Clipping Bias: An Error-Feedback Approach,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 2, 6, 3, 5, 3
A Linear Algebraic Framework for Counterfactual Generation,4.5, 4.5, 1.5, 6, 3, 3, 3, 3, 4, 6, 3
DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genomes,6.0, 5.5, 1.224744871391589, 5, 4, 8, 4, 6, 4, 5, 5
CookingCLIP：Learning a Contextualized Multimodal Embedding from Instructional Cooking Videos for Zero-shot Recipe Generation,3.0, 3.0, 1.4142135623730951, 5, 3, 3, 4, 3, 4, 1, 3
Learning Stackable and Skippable LEGO Bricks for Efficient Reconfigurable and Variable-Resolution Diffusion Modeling,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 6, 3, 5, 3
Latent 3D Graph Diffusion,5.4, 5.0, 0.4898979485566356, 6, 3, 5, 5, 5, 4, 5, 3, 6, 3
Spectral Greedy Coresets for Graph Neural Networks,5.142857142857143, 5.0, 1.6413036132965795, 5, 3, 6, 4, 5, 3, 3, 5, 3, 4, 8, 4, 6, 4
Reward Design for Justifiable Sequential Decision-Making,6.25, 6.0, 1.0897247358851685, 6, 2, 5, 3, 6, 2, 8, 3
Beyond Gradient and Priors in Privacy Attacks: Leveraging Pooler Layer Inputs of Language Models in Federated Learning,4.4, 6.0, 2.0591260281974, 1, 3, 6, 4, 6, 3, 6, 3, 3, 3
Calibrated Dataset Condensation for Faster Hyperparameter Search,5.0, 5.5, 1.224744871391589, 6, 5, 6, 3, 5, 4, 3, 4
SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation,6.75, 8.0, 2.165063509461097, 8, 4, 8, 4, 3, 4, 8, 3
3D Diffuser Actor: Multi-task 3D Robot Manipulation with Iterative Error Feedback,4.25, 5.0, 1.920286436967152, 5, 4, 1, 4, 6, 4, 5, 2
VIMEX: A Memory-Centered Task Description Framework for Vision-Based Robotics,5.0, 5.5, 1.224744871391589, 3, 4, 6, 3, 5, 3, 6, 4
LILO: Learning Interpretable Libraries by Compressing and Documenting Code,6.0, 5.5, 1.224744871391589, 6, 4, 8, 4, 5, 3, 5, 5
Matryoshka Diffusion Models,5.75, 5.0, 1.299038105676658, 5, 4, 5, 4, 8, 4, 5, 4
Curriculum Dynamic Graph Invariant Learning under Distribution Shift,3.75, 3.0, 1.299038105676658, 3, 4, 6, 4, 3, 4, 3, 4
Two Birds with One Stone: Protecting DNN Models Against Unauthorized Inference and Domain Transfer,4.0, 4.0, 1.0, 5, 2, 5, 4, 3, 4, 3, 5
SE(3)-Stochastic Flow Matching for Protein Backbone Generation,6.75, 7.0, 1.299038105676658, 8, 4, 5, 3, 8, 4, 6, 4
Efficient Interactive Preference Learning in Evolutionary Algorithms: Active Dueling Bandits and Active Learning Integration,3.0, 3.0, 0.0, 3, 3, 3, 4, 3, 3, 3, 3
MITIGATING BIAS IN DATASET DISTILLATION,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 4, 5, 3, 5, 4
On the Hyperparameter Loss Landscapes of Machine Learning Algorithms,4.0, 4.0, 1.0, 3, 5, 5, 4, 3, 4, 5, 4
On the Stochasticity in Graph Neural Networks,4.0, 3.0, 1.4142135623730951, 3, 3, 3, 4, 6, 2
Risk-Controlling Model Selection via Guided Bayesian Optimization,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 2, 5, 3, 3, 3
Optimized Tradeoffs for Private Majority Ensembling,5.0, 4.5, 2.1213203435596424, 8, 3, 6, 3, 3, 3, 3, 4
Exploring Memorization in Fine-tuned Language Models,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 5, 6, 3
Scalable Neural Network Kernels,6.5, 6.5, 1.5, 5, 4, 5, 3, 8, 3, 8, 3
Model Merging by Uncertainty-Based Gradient Matching,5.75, 6.0, 0.4330127018922193, 6, 5, 5, 2, 6, 4, 6, 3
Efficient Detection of LLM-generated Texts with a Bayesian Surrogate Model,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 4, 6, 3
Conservative Reinforcement Learning by Q-function Disagreement,3.0, 3.0, 0.0, 3, 4, 3, 4
FedConv: Enhancing Convolutional Neural Networks for Handling Data Heterogeneity in Federated Learning,4.5, 4.5, 1.5, 6, 4, 3, 4, 3, 5, 6, 4
Representation Learning from Interventional Data,4.0, 4.0, 1.0, 5, 4, 3, 3, 3, 4, 5, 3
PlugVFL: Robust and IP-Protecting Vertical Federated Learning against Unexpected Quitting of Parties,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 3, 5, 3, 3, 4
Evaluating the Robustness of Text-to-image Diffusion Models against Real-world Attacks,5.5, 5.5, 1.8027756377319946, 8, 3, 6, 4, 3, 3, 5, 4
Differentially Private Model Compression via Selective Pretraining,5.0, 4.5, 2.1213203435596424, 8, 4, 6, 4, 3, 4, 3, 4
DP-OPT: Make Large Language Model Your Differentially-Private Prompt Engineer,5.5, 5.5, 1.8027756377319946, 8, 3, 6, 4, 3, 3, 5, 4
HowToCaption: Prompting LLMs to Transform Video Annotations at Scale,5.0, 5.0, 0.0, 5, 5, 5, 3, 5, 3, 5, 4
Interaction-centric Hypersphere Reasoning for Multi-person Video HOI Recognition,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 3, 3, 4
BenthIQ: a Transformer-Based Benthic Classification Model for Coral Restoration,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 5, 6, 3
Video Anomaly Detection via Semantic Attributes,4.0, 4.0, 1.0, 5, 5, 3, 5, 3, 4, 5, 4
$\alpha$TC-VAE: On the relationship between Disentanglement and Diversity,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 3, 6, 3
Spectral-Bias and Kernel-Task Alignment in Physically Informed Neural Networks,4.0, 3.0, 1.4142135623730951, 6, 2, 3, 4, 3, 3
A Restoration Network as an Implicit Prior,5.25, 5.0, 1.7853571071357126, 3, 4, 5, 4, 8, 5, 5, 4
Spaced Scheduling Enhances Instruction-Prompted Reasoning in Large Language Models,4.0, 4.0, 1.0, 5, 4, 3, 3, 5, 4, 3, 3
Sparsify the Weights but Let the Gradients Flow!,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 3, 3, 4
Geographic Location Encoding with Spherical Harmonics and Sinusoidal Representation Networks,6.0, 5.5, 1.224744871391589, 5, 4, 6, 3, 8, 3, 5, 4
The Reasonableness Behind Unreasonable Translation Capability of Large Language Model,5.0, 5.5, 1.224744871391589, 3, 4, 6, 4, 5, 3, 6, 3
Leveraging Neuron Activation Patterns to Explain and Improve Deep Learning Classifiers,3.75, 4.0, 1.920286436967152, 3, 2, 5, 4, 6, 4, 1, 4
Fast Value Tracking for Deep Reinforcement Learning,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 6, 3, 3, 4
Oracle Efficient Algorithms for Groupwise Regret,6.25, 7.0, 2.0463381929681126, 6, 5, 8, 4, 8, 3, 3, 4
PcLast: Discovering Plannable Continuous Latent States,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 3, 6, 4, 5, 3
Searching for Parameter-Efficient Tuning Architecture for Text-to-image Diffusion Models,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 5, 6, 3, 5, 4
GREAT Score: Global Robustness Evaluation of Adversarial Perturbation using Generative Models,5.0, 5.5, 1.224744871391589, 3, 4, 5, 3, 6, 2, 6, 3
PoisoningGuard: Provable Defense against Data Poisoning Attacks to Multi-label Classification,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 3, 5, 5, 5, 3
Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across Language Models,6.25, 6.0, 1.0897247358851685, 6, 4, 5, 4, 6, 3, 8, 2
Small-scale proxies for large-scale Transformer training instabilities,7.25, 8.0, 1.299038105676658, 8, 4, 5, 3, 8, 2, 8, 3
Variational Quantum Linear Solver enhanced Quantum Support Vector machine,3.0, 3.0, 1.4142135623730951, 1, 5, 5, 3, 3, 4, 3, 4
The Entity-Deduction Arena: A playground for probing the conversational reasoning and planning capabilities of LLMs,5.25, 5.0, 1.7853571071357126, 5, 3, 5, 4, 3, 5, 8, 3
Causality is Invariance Across Heterogeneous Units,4.25, 4.0, 1.299038105676658, 3, 4, 5, 3, 6, 3, 3, 3
Long-distance Targeted Poisoning Attacks on Graph Neural Networks,4.5, 4.5, 1.5, 6, 3, 3, 4, 3, 4, 6, 3
Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and Execution of LLM Agents in an Auction Arena,3.75, 3.0, 1.299038105676658, 6, 4, 3, 4, 3, 4, 3, 5
FairVLM: Mitigating Bias In Pre-Trained Vision-Language Models,6.0, 5.5, 1.224744871391589, 6, 4, 5, 3, 8, 1, 5, 4
Selective Perception: Learning Concise State Descriptions for Language Model Actors,4.25, 4.0, 1.299038105676658, 5, 4, 3, 5, 6, 4, 3, 3
Generalized Schrödinger Bridge Matching,6.75, 7.0, 1.299038105676658, 8, 4, 8, 2, 5, 5, 6, 4
Persistent homology for high-dimensional data based on spectral methods,4.0, 4.0, 1.0, 5, 5, 3, 4, 3, 4, 5, 3
Time Series Anomaly Detection using Reconstruction and RBF Similarity Scores,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 4, 3, 4
Efficient Video Diffusion Models via Content-Frame Motion-Latent Decomposition,6.75, 7.0, 1.299038105676658, 5, 5, 8, 4, 8, 4, 6, 2
A General Framework for User-Guided Bayesian Optimization,6.0, 5.5, 1.224744871391589, 6, 3, 5, 4, 5, 3, 8, 4
MAMBA: an Effective World Model Approach for Meta-Reinforcement Learning,5.5, 5.5, 0.5, 6, 4, 5, 4, 6, 4, 5, 3
Efficient and Quantization-Friendly Ternary Fourier Convolution Algorithms,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 3, 4, 5, 2
Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit,7.5, 8.0, 0.8660254037844386, 8, 4, 6, 4, 8, 4, 8, 3
Learning Concept-Based Visual Causal Transition and Symbolic Reasoning for Visual Planning,4.25, 4.0, 1.299038105676658, 3, 4, 5, 2, 3, 4, 6, 3
CRAFT: Cross-Representation modeling on Audio waveForms and specTrograms,4.0, 4.0, 1.0, 3, 5, 3, 2, 5, 4, 5, 3
Is Scale All You Need For Anomaly Detection?,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 4, 3, 4
High-Dimensional Safe Exploration via Optimistic Local Latent Safe Optimization,4.75, 5.0, 1.0897247358851685, 6, 3, 3, 3, 5, 3, 5, 3
Evaluating the Evaluators: Are Current Few-Shot Learning Benchmarks Fit for Purpose?,5.0, 4.5, 2.1213203435596424, 3, 3, 8, 4, 3, 2, 6, 2
ELEGANT: Certified Defense on the Fairness of Graph Neural Networks,4.25, 4.0, 1.299038105676658, 3, 5, 3, 3, 6, 3, 5, 4
Organ-DETR: 3D Organ Detection Transfomer with Multiscale Attention and Dense Query Matching,4.666666666666667, 3.0, 2.357022603955158, 8, 5, 3, 5, 3, 5
Neural Sinkhorn Gradient Flow,4.2, 3.0, 1.469693845669907, 3, 4, 3, 4, 6, 4, 3, 4, 6, 3
Fairness-Aware Domain Generalization under Covariate and Dependence Shifts,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 4, 3, 4
SelfDreamer: Dual-Prototypical Regularization for Frame-masked Model-based Reinforcement Learning,4.0, 4.0, 1.0, 3, 5, 5, 4, 3, 4, 5, 5
GInX-Eval: Towards In-Distribution Evaluation of Graph Neural Networks Explanations,5.0, 6.0, 1.4142135623730951, 6, 4, 6, 3, 3, 4
Towards 4D Human Video Stylization,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 2, 5, 4
RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback,5.75, 6.0, 1.7853571071357126, 8, 4, 3, 4, 6, 4, 6, 4
RASP Quadratures: Efficient Numerical Integration for High-Dimensional Mean-Field Variational Inference,5.0, 6.0, 1.4142135623730951, 6, 2, 3, 4, 6, 3
How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models,7.5, 8.0, 0.8660254037844386, 6, 4, 8, 5, 8, 2, 8, 4
Guided Evolution with Binary Discriminators for ML Program Search,5.333333333333333, 5.0, 2.0548046676563256, 8, 4, 3, 4, 5, 4
DeCCaF: Deferral Under Cost and Capacity Constraints Framework,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 3, 3, 4, 5, 4
Reflected Schr\"odinger Bridge for Constrained Generative Modeling,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 3, 5, 4
Zero-Level-Set Encoder for Neural Distance Fields,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 3, 4, 5, 4
ICE: Image-Caption Encoding for Improved Out-Of-Distribution Generalization In Vision-Language Models,4.75, 5.0, 1.0897247358851685, 6, 3, 3, 4, 5, 4, 5, 4
Graph-Based Automatic Feature Selection for Multi-Class Classification via Mean Simplified Silhouette,4.25, 4.0, 1.299038105676658, 3, 4, 3, 5, 6, 3, 5, 5
Efficient-3Dim: Learning a Generalizable Single-image Novel-view Synthesizer in One Day,6.75, 7.0, 1.299038105676658, 8, 4, 8, 4, 6, 5, 5, 4
Robust multimodal models have outlier features and encode more concepts,5.25, 5.0, 1.7853571071357126, 3, 3, 8, 4, 5, 1, 5, 3
Lemur: Harmonizing Natural Language and Code for Language Agents,6.75, 7.0, 1.299038105676658, 8, 4, 6, 3, 5, 4, 8, 3
CODE REPRESENTATION LEARNING AT SCALE,5.5, 5.5, 1.8027756377319946, 6, 5, 3, 3, 5, 4, 8, 4
Trading-off Multiple Properties for Molecular Optimization,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 5, 4, 6, 2
Relaxing the Additivity Constraints in Decentralized No-Regret High-Dimensional Bayesian Optimization,5.25, 5.0, 1.7853571071357126, 5, 4, 8, 3, 3, 4, 5, 3
Compressing LLMs: The Truth is Rarely Pure and Never Simple,6.25, 7.0, 2.0463381929681126, 6, 4, 8, 4, 3, 4, 8, 4
How Hessian structure explains mysteries in sharpness regularization,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 6, 3, 3, 4
Capture Concept through Comparison: Vision-and-Language Representation Learning with Intrinsic Information Mining,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 4, 6, 4, 6, 3
A path-norm toolkit for modern networks: consequences promises and challenges,7.0, 7.0, 1.0, 6, 3, 8, 4
Characterising Partial Identifiability in Inverse Reinforcement Learning For Agents With Non-Exponential Discounting,4.333333333333333, 5.0, 0.9428090415820634, 5, 2, 3, 3, 5, 2
An Investigation of Representation and Allocation Harms in Contrastive Learning,6.5, 6.5, 1.5, 8, 3, 5, 3
SEPT: Towards Efficient Scene Representation Learning for Motion Prediction,6.5, 6.5, 1.5, 5, 5, 8, 5, 5, 4, 8, 4
Efficient and Scalable Graph Generation by Spectrum Preserving Local Expansion,5.75, 5.0, 1.299038105676658, 5, 3, 5, 4, 8, 3, 5, 4
Meta-Learning Universal Priors Using Non-Injective Normalizing Flows,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 5, 3, 3, 3
A Multi-Grained Group Symmetric Framework for Learning Protein-Ligand Binding Dynamics,5.0, 5.5, 1.224744871391589, 3, 4, 5, 3, 6, 3, 6, 5
What is a good question? Task-oriented asking with fact-level masking,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4
Networked Inequality: Preferential Attachment Bias in Graph Neural Network Link Prediction,6.25, 6.0, 1.0897247358851685, 5, 4, 8, 4, 6, 3, 6, 3
Rethinking pseudo-labeling: Data-centric insights improve semi-supervised learning,5.0, 5.5, 1.224744871391589, 6, 3, 5, 4, 6, 4, 3, 4
Discovering modular solutions that generalize compositionally,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 3, 3, 4, 5, 2
Less is More: Selective Layer Finetuning with SubTuning,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 4, 5, 4
Long-range Neural Atom Learning for Molecular Graphs,5.0, 6.0, 1.4142135623730951, 6, 4, 6, 3, 3, 3
AS-LLM: When Algorithm Selection Meets Large Language Model,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 5, 2
FairTune: Optimizing Parameter Efficient Fine Tuning for Fairness in Medical Image Analysis,5.5, 5.5, 0.5, 5, 3, 6, 3, 5, 4, 6, 3
Sample Efficient Reinforcement Learning from Human Feedback via Active Exploration,4.8, 5.0, 0.9797958971132712, 5, 3, 6, 2, 3, 5, 5, 3, 5, 2
Bridging Indexing Structure and Graph Learning: Expressive and Scalable Graph Neural Network via Core-Fringe,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 3, 3, 5, 5
Tree-Planner: Efficient Close-loop Task Planning with Large Language Models,5.25, 5.0, 1.7853571071357126, 5, 5, 8, 3, 5, 3, 3, 4
Explainable medical image clustering,2.5, 3.0, 0.8660254037844386, 1, 4, 3, 5, 3, 5, 3, 3
LARGE LANGUAGE MODELS FOR BIOMEDICAL KNOWLEDGE GRAPH CONSTRUCTION,3.0, 3.0, 1.2649110640673518, 1, 5, 5, 3, 3, 5, 3, 3, 3, 4
It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition,6.4, 6.0, 1.8547236990991407, 10, 4, 5, 5, 6, 3, 6, 4, 5, 3
Achieving Minimax Optimal Sample Complexity of Offline Reinforcement Learning: A DRO-Based Approach,4.0, 4.0, 1.0, 3, 4, 5, 3, 5, 3, 3, 4
Internal-Coordinate Density Modelling of Protein Structure: Covariance Matters,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 6, 3, 5, 3
Learning to focus on target for weakly supervised visual grounding,3.0, 3.0, 0.0, 3, 4, 3, 4
Best Response Shaping,4.5, 5.0, 0.8660254037844386, 3, 5, 5, 3, 5, 4, 5, 4
On the Efficiency of Transformers: The Effect of Attention Rank,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 4
α-Former: Local-Feature-Aware (L-FA) Transformer,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 4
LOQA: Learning with Opponent Q-Learning Awareness,4.0, 3.0, 1.2649110640673518, 3, 4, 6, 3, 3, 4, 5, 3, 3, 3
Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages,5.5, 5.5, 1.8027756377319946, 3, 4, 8, 4, 6, 4, 5, 4
Divide and Conquer: Provably Unveiling the Pareto Front with Multi-Objective Reinforcement Learning,3.75, 3.0, 1.299038105676658, 3, 3, 6, 2, 3, 3, 3, 4
Understanding the Transfer of High-Level Reinforcement Learning Skills Across Diverse Environments,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 4, 3, 5, 3, 5
Measuring Fairness Using Probable Segmentation for Continuous Sensitive Attributes,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 5, 5, 4
Unsupervised Cognition,3.0, 3.0, 1.4142135623730951, 3, 5, 1, 3, 3, 4, 5, 4
RealFM: A Realistic Mechanism to Incentivize Data Contribution and Device Participation,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 3, 4, 6, 3
NExT-GPT: Any-to-Any Multimodal LLM,6.0, 5.5, 1.224744871391589, 8, 4, 5, 4, 5, 5, 6, 4
CLA-RA: COLLABORATIVE ACTIVE LEARNING AMIDST RELABELING AMBIGUITY,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 5, 5, 4, 3, 4
Advancing the Adversarial Robustness of Neural Networks from the Data Perspective,3.5, 3.0, 0.8660254037844386, 3, 3, 5, 3, 3, 3, 3, 3
FacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios,6.0, 6.0, 0.0, 6, 4, 6, 3, 6, 4
Auto-Regressive Next-Token Predictors are Universal Learners,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 3, 5, 4
Unsupervised open-vocabulary action recognition with an autoregressive model,5.25, 5.0, 1.7853571071357126, 8, 4, 5, 3, 5, 3, 3, 5
A 2-Dimensional State Space Layer for Spatial Inductive Bias,5.75, 6.0, 0.4330127018922193, 6, 2, 6, 3, 5, 3, 6, 2
Learning 3D Particle-based Simulators from RGB-D Videos,6.5, 6.0, 0.8660254037844386, 8, 3, 6, 4, 6, 3, 6, 3
SocREval: LLMs with the Socratic Method for Reference-free Reasoning Evaluation,4.0, 4.0, 1.0, 5, 4, 3, 4, 5, 4, 3, 4
From Sparse to Soft Mixtures of Experts,7.5, 8.0, 0.8660254037844386, 8, 3, 8, 4, 8, 4, 6, 3
CAMBranch: Contrastive Learning with Augmented MILPs for Branching,5.0, 5.0, 0.0, 5, 5, 5, 3, 5, 4
StyleAdapter: A Unified Stylized Image Generation Model without Test-Time Fine-Tuning,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 3, 5, 5, 5, 5
CARSO: Blending Adversarial Training and Purification Improves Adversarial Robustness,4.5, 5.0, 0.8660254037844386, 3, 5, 5, 3, 5, 4, 5, 2
Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Metrics,6.5, 6.0, 0.8660254037844386, 6, 3, 6, 3, 8, 4, 6, 4
$\mathrm{BP}(\lambda)$: bias-free online learning via synthetic gradients,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 6, 4, 3, 2
Enriching Time Series Representation: Integrating a Noise-Resilient Sampling Strategy with an Efficient Encoder Architecture,5.0, 6.0, 1.4142135623730951, 6, 4, 6, 4, 3, 4, 3, 3, 6, 3, 6, 4
Towards Certified Probabilistic Robustness with High Accuracy,4.0, 4.0, 1.0, 3, 3, 5, 4, 3, 3, 5, 5
Last One Standing: A Comparative Analysis of Security and Privacy of Soft Prompt Tuning LoRA and In-Context Learning,3.75, 4.0, 1.920286436967152, 3, 3, 6, 4, 1, 4, 5, 3
MetaTST: Essential Transformer Components for Time Series Analysis,2.0, 2.0, 1.0, 1, 5, 3, 4, 1, 5, 3, 3
CustomNet: Zero-shot Object Customization with Variable-Viewpoints in Text-to-Image Diffusion Models,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 3, 5, 4
Ophiuchus: Scalable Modeling of Protein Structures through Hierarchical Coarse-graining SO(3)-Equivariant Autoencoders,3.6666666666666665, 3.0, 0.9428090415820634, 3, 2, 3, 4, 5, 3
ALAM: Averaged Low-Precision Activation for Memory-Efficient Training of Transformer Models,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 5, 6, 2, 6, 2
Causal Fairness under Unobserved Confounding: A Neural Sensitivity Framework,4.5, 4.5, 1.5, 3, 3, 6, 3
Listen to Motion: Robustly Learning Correlated Audio-Visual Representations,3.6666666666666665, 5.0, 1.8856180831641267, 5, 4, 5, 3, 1, 1
FedHC: Proximal Correction with Hessian and Cosine Correlation for Federated Learning,1.6666666666666667, 1.0, 0.9428090415820634, 1, 5, 1, 5, 3, 4
One Forward is Enough for Neural Network Training via Likelihood Ratio Method,6.25, 6.0, 1.0897247358851685, 5, 2, 6, 4, 8, 3, 6, 3
Reconstruction as Sequence for Efficient Unified Unsupervised Anomaly Detection,4.25, 4.0, 1.299038105676658, 3, 5, 6, 4, 5, 4, 3, 4
B$^{3}$CT: Three-branch Coordinated Training for Domain Adaptive Semantic Segmentation,5.0, 5.0, 0.0, 5, 5, 5, 5, 5, 3, 5, 5
Understanding AI Cognition: A Neural Module for Inference Inspired by Human Memory Mechanisms,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 4, 5, 3
LLM Performance Predictors are good initializers for Architecture Search,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 4, 3, 4
Extending Multi-modal Contrastive Representations,5.0, 5.5, 1.224744871391589, 3, 4, 6, 5, 6, 4, 5, 3
Counterfactual Density Estimation using Kernel Stein Discrepancies,5.5, 5.5, 0.5, 5, 2, 6, 4, 5, 3, 6, 4
Vision Transformers Need Registers,8.0, 8.0, 1.4142135623730951, 10, 4, 6, 4, 8, 4, 8, 3
Multilingual Visual Speech Recognition with a Single Model using Visual Speech Unit,6.0, 6.0, 1.0954451150103321, 5, 3, 6, 4, 8, 4, 5, 4, 6, 3
Joint Training Does Not Transfer Information between EEG and Image Classifiers,2.6, 1.0, 1.9595917942265426, 1, 5, 1, 5, 1, 5, 5, 4, 5, 1
Beyond Laplace and Gaussian: Exploring the Generalized Gaussian Mechanism for Private Machine Learning,4.25, 4.0, 2.5860201081971503, 1, 5, 3, 3, 8, 2, 5, 3
Analysis of a class of stochastic component-wise soft-clipping schemes,4.0, 3.0, 1.2649110640673518, 3, 3, 3, 4, 6, 3, 5, 2, 3, 4
Does Writing with Language Models Reduce Content Diversity?,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 4, 5, 3
Fair Feature Importance Scores for Interpreting Tree-Based Methods and Surrogates,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 2, 5, 3, 3, 4
Chat-3D: Data-efficiently Tuning Large Language Model for Universal Dialogue of 3D Scenes,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 5, 5, 5
PatchSynth: a Patch-Text Pre-trained Model,5.0, 3.0, 3.40587727318528, 8, 5, 10, 5, 3, 4, 3, 5, 1, 5
DOS: Dreaming Outlier Semantics for Out-of-distribution Detection,4.5, 4.5, 1.5, 3, 3, 6, 4, 3, 3, 6, 4
Conformal Inductive Graph Neural Networks,5.5, 5.5, 0.5, 5, 3, 6, 4, 6, 2, 5, 3
PB-LLM: Partially Binarized Large Language Models,6.0, 5.5, 1.224744871391589, 6, 4, 5, 3, 5, 5, 8, 5
Beyond Linear Spherical Interpolation: Noise Correction for Image Interpolation with Diffusion Models,6.333333333333333, 6.0, 1.247219128924647, 8, 4, 5, 3, 6, 3
Liteformer: Lightweight Evoformer for Protein Structure Prediction,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 4
DomainFusion: Generalizing To Unseen Domains with Latent Diffusion Models,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 5, 4, 3, 4
Random Sparse Lifts: Construction Analysis and Convergence of finite sparse networks,5.75, 5.0, 1.299038105676658, 5, 3, 5, 2, 5, 2, 8, 3
Efficient Gradient Estimation via Adaptive and Importance Sampling,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 4, 6, 3, 5, 4
Course Correcting Koopman Representations,5.4, 5.0, 1.624807680927192, 3, 3, 8, 4, 5, 3, 5, 2, 6, 4
Out-of-Distribution Detection by Leveraging Between-Layer Transformation Smoothness,5.25, 5.0, 0.4330127018922193, 5, 2, 6, 4, 5, 4, 5, 3
PINF: Continuous Normalizing Flows for Physics-Constrained Deep Learning,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 3, 3, 3, 3, 3
SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis,8.0, 8.0, 0.0, 8, 4, 8, 3, 8, 4, 8, 5
Intelligent Switching for Reset-Free RL,6.25, 6.0, 1.0897247358851685, 6, 3, 8, 4, 5, 3, 6, 3
Adversarial Supervision Makes Layout-to-Image Diffusion Models Thrive,5.25, 6.0, 1.299038105676658, 6, 4, 6, 4, 3, 4, 6, 2
Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning,5.75, 5.0, 1.299038105676658, 5, 4, 5, 5, 8, 4, 5, 4
Less is More: One-shot Subgraph Reasoning on Large-scale Knowledge Graphs,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 3, 3, 4
Fixed-Budget Differentially Private Best Arm Identification,6.75, 7.0, 1.299038105676658, 8, 3, 5, 4, 8, 3, 6, 2
Separate and Diffuse: Using a Pretrained Diffusion Model for Better Source Separation,5.333333333333333, 5.0, 0.4714045207910317, 5, 5, 6, 4, 5, 2
On the Limitations of Temperature Scaling for Distributions with Overlaps,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 6, 3, 8, 2
Beyond Shortest-Paths: A Benchmark for Reinforcement Learning on Traffic Engineering,3.6, 3.0, 1.2000000000000002, 3, 4, 3, 4, 6, 3, 3, 5, 3, 4
HAct: Out-of-Distribution Detection with Neural Net Activation Histograms,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 4, 5, 3
Ctrl-Room: Controllable Text-to-3D Room Meshes Generation with Layout Constraints,5.5, 5.5, 0.5, 6, 4, 5, 4, 6, 5, 5, 5
Simplicity Bias in Overparameterized Machine Learning,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 3, 3, 2
MetaCloak: Preventing Unauthorized Subject-driven Text-to-image Synthesis Via Meta-learning,nan, nan, nan
Characterizing Exceptional Distributions with Neural Rule Extraction,4.4, 5.0, 1.2, 3, 4, 5, 4, 6, 3, 3, 3, 5, 4
Physics-aware Hand Object Interaction Denoising,5.0, 4.5, 2.1213203435596424, 3, 4, 3, 4, 6, 4, 8, 3
SILC: Improving Vision Language Pretraining with Self-Distillation,4.0, 4.0, 1.0, 3, 4, 5, 3, 3, 5, 5, 4
Beyond Dynamics: Learning to Discover Conservation Principles,3.0, 3.0, 1.4142135623730951, 3, 3, 5, 3, 1, 2, 3, 5
On the Matrix Form of the Quaternion Fourier Transform and Quaternion Convolution,3.6666666666666665, 5.0, 1.8856180831641267, 5, 3, 1, 4, 5, 3
Unknown Domain Inconsistency Minimization for Domain Generalization,5.75, 6.0, 0.4330127018922193, 5, 5, 6, 3, 6, 4, 6, 3
Change Point Detection via Variational Time-Varying Hidden Markov Model,4.25, 4.0, 1.299038105676658, 6, 4, 3, 3, 5, 3, 3, 3
Balanced Multimodal Learning: An Integrated Framework for Multi-Task Learning in Audio-Visual Fusion,3.0, 3.0, 1.4142135623730951, 3, 4, 5, 4, 1, 5, 3, 4
Entity-Centric Reinforcement Learning for Object Manipulation from Pixels,6.0, 5.5, 1.224744871391589, 6, 4, 5, 4, 5, 4, 8, 3
Memoization-Aware Bayesian Optimization for AI Pipelines with Unknown Costs,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 6, 4, 5, 3
Promoting Exploration in Memory-Augmented Adam using Critical Momenta,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 4, 6, 1
Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs,6.0, 5.5, 1.224744871391589, 5, 3, 8, 4, 6, 3, 5, 4
A multi-view latent space learning framework via adaptive graph embedding,3.0, 3.0, 1.632993161855452, 5, 4, 1, 5, 3, 4
Extracting Robust On-Manifold Interactions Encoded by Neural Networks,4.0, 3.0, 1.4142135623730951, 6, 2, 3, 3, 3, 2
Enhancing Neural Training via a Correlated Dynamics Model,6.5, 6.5, 2.692582403567252, 10, 4, 5, 2, 3, 4, 8, 3
Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization,4.2, 5.0, 0.9797958971132712, 5, 4, 5, 4, 3, 5, 3, 4, 5, 3
An Effective Universal Polynomial Basis for Spectral Graph Neural Networks,4.5, 4.5, 1.5, 3, 5, 6, 4, 3, 4, 6, 2
Capturing Static Short-Term and Long-Term Dynamics Through Self-Supervised Time Series Learning: CHRONOS,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 5, 4, 3, 3
Automata Learning for Neural Event ODEs: An Interpretable Model of Piecewise Dynamics,4.25, 4.0, 1.299038105676658, 3, 3, 5, 2, 3, 3, 6, 4
LLM Lies: Hallucinations are not Bugs but Features as  Adversarial Examples,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 3, 2, 5, 3
Flat Minima in Linear Estimation and an Extended Gauss Markov Theorem,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 3, 5, 4
ReForm-Eval: Evaluating Large Vision Language Models via Unified Re-Formulation of Task-Oriented Benchmarks,4.75, 5.0, 1.0897247358851685, 5, 5, 6, 4, 5, 4, 3, 5
LangProp: A code optimization framework using Language Models applied to driving,4.5, 4.5, 2.362907813126304, 3, 4, 6, 3, 8, 3, 6, 3, 3, 4, 1, 5
Graph Transformers for Large Graphs,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 3, 5, 4
A Simple and Scalable Representation for Graph Generation,6.0, 5.5, 1.224744871391589, 5, 4, 8, 4, 6, 4, 5, 4
Correlated dense associative memories,4.0, 4.5, 2.1213203435596424, 3, 4, 1, 4, 6, 4, 6, 3
True Knowledge Comes from Practice: Aligning Large Language Models with Embodied Environments via Reinforcement Learning,5.5, 5.5, 0.5, 5, 4, 5, 4, 6, 4, 6, 3
Rethinking the Starting Point: Enhancing Performance and Fairness of Federated Learning via Collaborative Pre-Training,5.0, 5.5, 1.224744871391589, 3, 4, 6, 4, 5, 4, 6, 3
AuG-KD: Anchor-Based Mixup Generation for Out-of-Domain Knowledge Distillation,5.0, 5.5, 1.224744871391589, 6, 3, 6, 4, 3, 3, 5, 4
FedGSE:Gradient-based Sub-model Extraction for Resource-constrained Federated Learning,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 4, 6, 3
The Cost of Scaling Down Large Language Models: Reducing Model Size Affects Memory before In-context Learning,5.25, 6.0, 1.299038105676658, 6, 4, 3, 2, 6, 4, 6, 4
Interpreting Adaptive Gradient Methods by Parameter Scaling for Learning-Rate-Free Optimization,5.25, 5.0, 1.7853571071357126, 5, 2, 8, 4, 3, 2, 5, 3
Learning Time-Varying Convexifications of Multiple Fairness Measures,4.0, 3.0, 1.4142135623730951, 6, 3, 3, 2, 3, 3
Knowledge Graph Reasoning with Reinforcement Learning Agent guided by Multi-relational Graph Neural Networks,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 5, 1, 4, 3, 3
OccuQuest: Mitigating Occupational Bias for Inclusive Large Language Models,4.0, 4.0, 1.0, 5, 4, 3, 3
Generalization for Discriminator-Guided Diffusion Models via Strong Duality,3.75, 4.0, 1.920286436967152, 6, 3, 3, 3, 1, 2, 5, 2
Hierarchical-Latent Generative Models are Robust View Generators for Contrastive Representation Learning,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 6, 2, 3, 3
TeLLMe what you see: Using LLMs to Explain Neurons in Vision Models,5.0, 5.0, 0.0, 5, 5, 5, 3, 5, 4, 5, 3
FedInverse: Evaluating Privacy Leakage in Federated Learning,5.5, 5.5, 1.8027756377319946, 6, 3, 3, 4, 8, 4, 5, 4
Uncertainty for Active Learning on Graphs,4.25, 4.0, 1.299038105676658, 3, 3, 3, 4, 5, 4, 6, 3
Adding 32 Parameters to a LLM can improve fine-tuned classification performance by up to 1.5-6 percentage points,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 5, 3, 3, 3
Equivariant Protein Multi-task Learning,4.0, 4.0, 1.0, 5, 4, 5, 3, 3, 3, 3, 3
NoiseOut: Learning to Gate Improves Robustness in Deep Neural Networks,3.0, 3.0, 0.0, 3, 3, 3, 5, 3, 4, 3, 3
Diving into Class-Incremental Learning from Better Balancing Old and New knowledge,3.75, 3.0, 1.299038105676658, 3, 5, 3, 4, 6, 4, 3, 4
From Sparse to Dense: Learning to Construct 3D Human Meshes from WiFi,4.0, 5.0, 1.7320508075688772, 1, 4, 5, 5, 5, 4, 5, 3
Constrained Bi-Level Optimization: Proximal Lagrangian Value function Approach and Hessian-free Algorithm,6.75, 7.0, 1.299038105676658, 5, 4, 8, 5, 8, 3, 6, 2
DeepHandMesh-lite: Learning personalized hand shape using limited data and weak supervision,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 2
Informed POMDP: Leveraging Additional Information in Model-Based RL,5.75, 6.0, 0.4330127018922193, 5, 3, 6, 4, 6, 3, 6, 3
Deterministic Diffusion for Sequential Tasks,4.0, 4.0, 1.0, 5, 4, 5, 4, 3, 4, 3, 4
Effective Learning by Node Perturbation in Deep Neural Networks,4.0, 4.0, 1.0, 5, 4, 3, 5, 3, 4, 5, 5
Inherently Interpretable Time Series Classification via Multiple Instance Learning,7.5, 8.0, 0.8660254037844386, 6, 4, 8, 4, 8, 4, 8, 3
Uniform as Glass: Gliding over the Pareto Front with Neural Adaptive Preferences,4.0, 4.0, 1.0, 3, 3, 5, 4, 3, 4, 5, 3
TOSS: High-quality Text-guided Novel View Synthesis from a Single Image,6.0, 6.0, 0.0, 6, 4, 6, 2, 6, 4, 6, 5
Biological Sequence Analysis Using B ́ezier Curve,5.5, 5.5, 1.8027756377319946, 6, 3, 3, 3, 8, 3, 5, 2
Leveraging Large Language Models for Optimised Coordination in Textual Multi-Agent Reinforcement Learning,4.25, 4.0, 1.299038105676658, 3, 4, 6, 4, 3, 3, 5, 3
Energy Calibration Head: A Plug-In Neural Network Head with Human-like Uncertainty,4.0, 4.0, 1.0, 3, 3, 5, 2, 3, 4, 5, 3
Cont-GRU: Fully Continuous Gated Recurrent Units for Irregular Time Series,4.0, 4.0, 1.0, 5, 3, 3, 3, 3, 5, 5, 3
LoRA-FA: Memory-efficient Low-rank Adaptation for Large Language Models Fine-tuning,4.666666666666667, 5.0, 1.247219128924647, 6, 5, 5, 4, 3, 3
Benchmarking the Robustness of Cross-view Geo-localization Models,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 5, 3, 5
MotionDirector: Motion Customization of Text-to-Video Diffusion Models,5.5, 5.5, 1.8027756377319946, 6, 4, 3, 4, 8, 2, 5, 5
Uncertainty-Aware Decision Transformer for Stochastic Driving Environments,5.0, 5.5, 1.224744871391589, 3, 4, 5, 3, 6, 3, 6, 2
ARCHITECTURE MATTERS: METAFORMER AND GLOBAL-AWARE CONVOLUTION STREAMING FOR IMAGE RESTORATION,2.5, 3.0, 0.8660254037844386, 3, 5, 1, 5, 3, 5, 3, 5
Structural Adversarial Objectives For Self-Supervised Representation Learning,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 4, 3, 4, 5, 4
A Mutual Information Perspective on Federated Contrastive Learning,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 4, 5, 2
Self-Supervised Deep Visual Stereo Odometry with 3D-Geometric Constraints,2.75, 2.0, 2.0463381929681126, 6, 4, 1, 4, 1, 5, 3, 4
Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation,7.25, 8.0, 1.299038105676658, 8, 2, 8, 3, 8, 3, 5, 4
Improved Operator Learning by Orthogonal Attention,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 2, 6, 3, 6, 3
GENERATIVE TIME SERIES LEARNING WITH TIME-FREQUENCY FUSED ENERGY-BASED MODEL,5.4, 5.0, 0.48989794855663565, 5, 4, 6, 2, 5, 4, 6, 2, 5, 4
Droplets of Good Representations: Grokking as a First Order Phase Transition in Two Layer Networks,4.6, 5.0, 1.3564659966250536, 5, 3, 3, 4, 6, 4, 6, 4, 3, 3
GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction,4.25, 4.0, 1.299038105676658, 3, 5, 3, 3, 6, 2, 5, 4
LOVECon: Text-driven Training-free Long Video Editing with ControlNet,5.0, 5.0, 0.0, 5, 5, 5, 4, 5, 4
BLSP: Bootstrapping Language-Speech Pre-training via Behavior Alignment of Continuation Writing,5.0, 5.5, 2.5495097567963922, 6, 4, 1, 2, 8, 3, 5, 4
V-JEPA: Latent Video Prediction for Visual Representation Learning,4.4, 5.0, 1.2, 3, 5, 5, 5, 5, 4, 6, 3, 3, 4
Edge-Sampler: Efficient Importance Sampling for Neural Implicit Surfaces Reconstruction,3.5, 4.0, 1.6583123951777, 3, 5, 5, 2, 1, 5, 5, 3
Model guidance via explanations turns image classifiers into segmentation models,5.25, 5.0, 1.7853571071357126, 5, 4, 3, 4, 8, 4, 5, 4
Understanding Masked Autoencoders From a Local Contrastive Perspective,4.0, 4.0, 1.0, 5, 4, 5, 4, 3, 5, 3, 4
Enhancing Precision Drug Recommendations via Fine-grained Exploration of Motif Relationships,4.0, 4.0, 1.0, 5, 3, 5, 3, 3, 4, 3, 3
Smooth Min-Max Monotonic Networks,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 3, 3, 2
Elucidating the Exposure Bias in Diffusion Models,6.2, 6.0, 0.9797958971132712, 8, 4, 6, 2, 6, 4, 5, 4, 6, 4
Availability Attacks Need to Create Shortcuts for Contrastive Learning,4.4, 5.0, 1.2, 3, 5, 3, 3, 5, 5, 5, 4, 6, 4
Harnessing Orthogonality to Train Low-Rank Neural Networks,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 3, 4, 6, 1
Accelerated Convergence of Stochastic Heavy Ball Method under Anisotropic Gradient Noise,6.25, 6.0, 1.0897247358851685, 8, 4, 6, 3, 6, 4, 5, 4
Transferable Availability Poisoning Attacks,4.4, 5.0, 1.2, 3, 4, 5, 3, 6, 3, 3, 4, 5, 4
CONFIDE: CONtextual FInite DifferencE modelling of PDEs,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 4, 6, 2
Degradation-aware Unfolding Knowledge-assist Transformer for Spectral Compressive Imaging,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 5, 5, 4, 5, 4
Fast Expressive $\mathrm{SE}(n)$ Equivariant Networks through Weight-Sharing in Position-Orientation Space,6.333333333333333, 6.0, 1.247219128924647, 5, 2, 6, 4, 8, 3
Learning Large DAGs is Harder than you Think: Many Losses are Minimal for the Wrong DAG,5.0, 5.5, 1.224744871391589, 6, 3, 5, 3, 3, 3, 6, 4
Why SAM finetuning can benefit Out-of-Distribution Detection?,4.4, 5.0, 1.2, 5, 4, 5, 3, 6, 4, 3, 5, 3, 3
SemSA: Semantic Sparse Attention is hidden in Large Language Models.,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 3, 5, 3
SASSL: Enhancing Self-Supervised Learning via Neural Style Transfer,5.25, 6.0, 1.299038105676658, 6, 3, 6, 3, 6, 4, 3, 5
An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment,7.333333333333333, 8.0, 0.9428090415820634, 8, 3, 6, 3, 8, 3
JointNet: Extending Text-to-Image Diffusion for Dense Distribution Modeling,5.5, 5.5, 1.8027756377319946, 5, 3, 6, 3, 8, 3, 3, 4
Hybrid Retrieval-Augmented Generation for Real-time Composition Assistance,5.0, 5.5, 1.224744871391589, 5, 3, 3, 4, 6, 4, 6, 3
Curvature MPNNs : Improving Message Passing with Local Structural Properties,3.0, 3.0, 1.4142135623730951, 3, 3, 5, 4, 3, 4, 1, 2
Text-to-3D using Gaussian Splatting,nan, nan, nan
Instant Complexity Reduction in CNNs using Locality-Sensitive Hashing,4.6, 5.0, 1.3564659966250536, 3, 3, 3, 4, 6, 5, 6, 4, 5, 4
MMD Graph Kernel: Effective Metric Learning for Graphs via Maximum Mean Discrepancy,6.25, 7.0, 2.0463381929681126, 8, 4, 6, 4, 3, 3, 8, 4
Strided Transformers for Partially-Parallelized Inference,2.3333333333333335, 3.0, 0.9428090415820634, 3, 4, 3, 4, 1, 5
RNNS with gracefully degrading continuous attractors,4.0, 4.0, 1.0, 3, 2, 5, 3, 5, 4, 3, 4
Successor Heads: Recurring Interpretable Attention Heads In The Wild,6.5, 6.0, 0.8660254037844386, 6, 3, 6, 4, 6, 4, 8, 3
Provably Robust Cost-Sensitive Learning via Randomized Smoothing,3.75, 3.0, 1.299038105676658, 3, 5, 3, 4, 6, 3, 3, 4
ALIN: An Active Learning Framework for Incomplete Networks,nan, nan, nan
Learning Energy Decompositions for Partial Inference of GFlowNets,6.25, 6.0, 1.0897247358851685, 6, 4, 5, 5, 8, 2, 6, 3
RAPPER: Reinforced Rationale-Prompted Paradigm for Natural Language Explanation in Visual Question Answering,5.0, 6.0, 1.4142135623730951, 6, 2, 6, 4, 3, 3
KLIP: Keyword-Guided Language-Image Pretraining for Data-Efficient Domain-Specific Image Captioning,4.6, 5.0, 0.7999999999999999, 5, 4, 5, 3, 5, 4, 3, 4, 5, 5
S\(^{2}\)-DMs: Skip-Step Diffusion Models,5.25, 5.0, 1.7853571071357126, 5, 2, 3, 4, 8, 2, 5, 3
SPI-GAN: Denoising Diffusion GANs with Straight-Path Interpolations,5.75, 5.0, 1.299038105676658, 5, 3, 5, 4, 8, 3, 5, 5
Calibration Bottleneck: What Makes Neural Networks less Calibratable?,4.666666666666667, 3.0, 2.357022603955158, 3, 5, 8, 4, 3, 4
Heterogeneity of Regularization between adjacent periods,2.5, 2.0, 1.6583123951777, 3, 5, 1, 5, 1, 5, 5, 3
ZEST: ZEROSHOT SPARSE FINE-TUNING,5.0, 5.5, 1.224744871391589, 5, 4, 6, 2, 6, 4, 3, 4
Information Bottleneck Analysis of Deep Neural Networks via Lossy Compression,4.75, 5.0, 1.0897247358851685, 6, 1, 5, 3, 3, 4, 5, 3
Why not both? Combining Bellman losses in deep reinforcement learning,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 3, 6, 3, 5, 3
Query Efficient  Black-Box  Adversarial Attack with Automatic Region Selection,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 4, 5, 4, 6, 5
LIFT: Efficient Layer-wise Fine-tuning for Large Model Models,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 6, 3, 5, 3
Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization,8.0, 8.0, 0.0, 8, 3, 8, 4, 8, 3
Just-in-Time Security Patch Detection - LLM At the Rescue for Data Augmentation,6.0, 6.5, 2.1213203435596424, 8, 5, 5, 3, 3, 4, 8, 4
Diversifying Deep Ensembles: A Saliency Map Approach for Enhanced OOD Detection Calibration and Accuracy,3.5, 3.0, 0.8660254037844386, 3, 3, 5, 3, 3, 4, 3, 4
Fair Off-Policy Learning from Observational Data,5.75, 5.0, 1.299038105676658, 5, 4, 5, 3, 8, 3, 5, 4
Privacy-Preserving Data Quality Evaluation in Federated Learning Using Influence Approximation,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 3, 5, 3, 5, 3
Optimization Dynamics of Equivariant and Augmented Neural Networks,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 3
SMAAT: Scalable Manifold-Aware Adversarial Training for Large Language Models,4.8, 5.0, 0.9797958971132712, 5, 5, 6, 3, 3, 4, 5, 4, 5, 3
SPFNO: spectral operator learning for PDEs with Dirichlet and Neumann boundary conditions,3.0, 3.0, 1.632993161855452, 3, 5, 1, 4, 5, 4
DualAug: Exploiting Additional Heavy Augmentation with OOD Data Rejection,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 4
Universal Sleep Decoder: Aligning awake and sleep neural representation across subjects,5.0, 6.0, 1.4142135623730951, 6, 4, 6, 4, 3, 5
Continual Contrastive Spoken Language Understanding,5.5, 5.5, 0.5, 5, 4, 5, 3, 6, 3, 6, 3
Linguistically-Inspired and Explainable Demonstration Retrieval for In-Context Learning,4.8, 5.0, 0.9797958971132712, 5, 3, 3, 4, 5, 4, 6, 4, 5, 3
Knowledge Fusion of Large Language Models,5.5, 5.5, 1.8027756377319946, 6, 3, 5, 4, 8, 3, 3, 4
Double Momentum Method for Lower-Level Constrained Bilevel Optimization,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 3, 5, 3
Long-range Meta-path Search through Progressive Sampling on Large-scale Heterogeneous Information Networks,5.6, 5.0, 1.2, 5, 4, 5, 4, 5, 3, 5, 4, 8, 3
Understanding and addressing spurious correlation via Neural Tangent Kernels: A spectral bias perspective,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 4, 3, 4
SGD Finds then Tunes Features in Two-Layer Neural Networks with near-Optimal Sample Complexity: A Case Study in the XOR problem,7.25, 8.0, 1.299038105676658, 8, 4, 8, 4, 8, 3, 5, 2
ISCUTE: Instance Segmentation of Cables Using Text Embedding,5.0, 6.0, 1.4142135623730951, 3, 5, 6, 3, 6, 4
Semi-Supervised End-To-End Contrastive Learning For Time Series Classification,4.4, 5.0, 1.2, 5, 4, 3, 5, 5, 4, 3, 5, 6, 4
Boosting Meta-Training with Base Class Information for Few-Shot Learning,4.25, 4.0, 1.299038105676658, 3, 4, 6, 3, 5, 4, 3, 4
FedAnchor: Enhancing Federated Semi-Supervised Learning with Label Contrastive Loss,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 5, 3, 3, 4
Breadth First Exploration in Grid-based Reinforcement Learning,3.75, 3.0, 1.299038105676658, 3, 3, 3, 4, 3, 4, 6, 4
Adiabatic replay for continual learning,3.5, 3.0, 0.8660254037844386, 3, 5, 5, 4, 3, 5, 3, 4
FedTrans: Client-Transparent Utility Estimation for Robust Federated Learning,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 5, 3, 6, 3
DyVal: Graph-informed Dynamic Evaluation of Large Language Models,6.0, 6.0, 0.0, 6, 4, 6, 3, 6, 2, 6, 3
Designing Long-term Group Fair Policies in Dynamical Systems,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 2, 3, 4, 3, 3
Long-Tailed Recognition on Binary Networks by Calibrating A Pre-trained Model,4.5, 4.5, 1.5, 6, 3, 6, 4, 3, 4, 3, 3
Optimized Large Language Models Accurately Identify Recurrence of VT After Ablation from Complex Medical Notes: Will Chart Review Become Obsolete?,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 3, 3, 3
From Posterior Sampling to Meaningful Diversity in Image Restoration,7.0, 8.0, 1.4142135623730951, 8, 3, 5, 5, 8, 4
A Neural Framework for Generalized Causal Sensitivity Analysis,6.5, 6.0, 0.8660254037844386, 6, 2, 6, 3, 8, 3, 6, 3
AMPipe: Accelerating MoE Model Training with Intra-Block Pipelining,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 5, 2, 6, 2
Active Automated Machine Learning with Self-Training,3.75, 3.0, 1.299038105676658, 6, 4, 3, 3, 3, 3, 3, 4
Graph Clustering with Masked AutoEncoders,3.8, 3.0, 0.9797958971132712, 5, 2, 5, 3, 3, 4, 3, 4, 3, 5
ADAPTER-RL: Adaptation of Any Agent using Reinforcement Learning,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4
OKR-Agent: An Object and Key Results Driven Agent System with Hierarchical Self-Collaboration and Self-Evaluation,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 4, 5, 3, 5, 3
Skill Machines: Temporal Logic Skill Composition in Reinforcement Learning,5.75, 5.0, 1.299038105676658, 5, 5, 5, 4, 5, 3, 8, 4
Video Deblurring with Adaptive High-frequency Extraction,5.5, 5.5, 2.5, 3, 5, 8, 2, 8, 4, 3, 5
Unveiling and Manipulating Prompt Influence in Large Language Models,6.0, 5.5, 1.224744871391589, 5, 4, 5, 4, 8, 4, 6, 3
Spiking CenterNet: A Distillation-boosted Spiking Neural Network for Object Detection,3.75, 4.0, 1.920286436967152, 6, 4, 5, 4, 3, 4, 1, 5
Learning to solve Class-Constrained Bin Packing Problems via Encoder-Decoder Model,6.0, 6.0, 1.0954451150103321, 5, 4, 6, 4, 8, 5, 5, 4, 6, 4
Gauging Learnability in Supervised Fine-tuning Data,3.25, 3.0, 1.7853571071357126, 6, 2, 1, 4, 3, 4, 3, 3
A Bias-Variance-Covariance Decomposition of Kernel Scores for Generative Models,5.75, 6.0, 0.4330127018922193, 6, 2, 6, 2, 6, 2, 5, 1
HumanNorm: Learning Normal Diffusion Model for High-quality and Realistic 3D Human Generation,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 4, 5, 3, 6, 3
Dual Fusion AutoEncoder for Graph Clustering,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 3, 5, 5, 5
Idempotent Generative Network,5.5, 5.5, 1.8027756377319946, 6, 3, 5, 3, 3, 4, 8, 4
DeepSPF: Spherical SO(3)-Equivariant Patches for Scan-to-CAD Estimation,5.0, 6.0, 1.4142135623730951, 6, 3, 6, 2, 3, 3
GNeRV: A Global Embedding Neural Representation For Videos,4.5, 4.5, 1.5, 6, 4, 6, 4, 3, 3, 3, 3
ENHANCEMENT OF GNN’S EXPRESSIVE POWER VIA RECONSIDERING MODAL LOGIC,2.3333333333333335, 3.0, 0.9428090415820634, 3, 5, 1, 4, 3, 2
Test Time Adaptation with Auxiliary Tasks,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 5, 4, 3, 5
Evaluating Hallucinations in Chinese Large Language Models,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 3, 6, 3
Efficient Human-AI Coordination via Preparatory Language-based Convention,5.5, 5.5, 1.8027756377319946, 5, 4, 6, 3, 8, 4, 3, 3
Suppressing Overestimation in Q-Learning through Adversarial Behaviors,4.25, 4.0, 1.299038105676658, 6, 4, 3, 2, 5, 4, 3, 3
P-MapNet: Far-seeing Map Constructer Enhanced by both SDMap and HDMap Priors,5.0, 5.0, 0.0, 5, 4, 5, 5, 5, 5, 5, 4
Text-To-Energy: Accelerating Quantum Chemistry Calculations through Enhanced Text-to-Vector Encoding and Orbital-Aware Multilayer Perceptron,3.25, 2.0, 2.8613807855648994, 3, 5, 1, 4, 1, 5, 8, 4
SparseDFF: Sparse-View Feature Distillation for One-Shot Dexterous Manipulation,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 4, 6, 3, 5, 4
A Theoretical Approach to Characterize the Accuracy-Fairness Trade-off Pareto Frontier,3.75, 3.0, 1.299038105676658, 3, 3, 3, 4, 6, 4, 3, 4
Intrinsic Mesh CNNs,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4, 3, 2
Improving Natural Language Understanding with Computation-Efficient Retrieval Augmentation,5.75, 6.0, 1.7853571071357126, 8, 3, 6, 3, 3, 4, 6, 4
Improve Temporal Consistency In Diffusion Models through Noise Correlations,5.75, 6.0, 0.4330127018922193, 5, 4, 6, 4, 6, 3, 6, 3
Multimodal Distillation of Protein Sequence Structure and Function,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 5
Combinatorial Optimization via Memory Metropolis: Template Networks for Proposal Distributions in Simulated Annealing applied to Nanophotonic Inverse Design,4.333333333333333, 5.0, 0.9428090415820634, 3, 3, 5, 3, 5, 2
FedCDA: Federated Learning with Cross-rounds Divergence-aware Aggregation,5.5, 5.5, 0.5, 5, 4, 5, 4, 6, 4, 6, 3
Binning as a Pretext Task: Improving Self-Supervised Learning in Tabular Domains,5.5, 5.5, 0.5, 6, 4, 5, 4, 6, 4, 5, 4
Divide-and-Conquer Time Series Forecasting with Auto-Frequency-Correlation via Cross-Channel Attention,5.0, 5.5, 1.224744871391589, 5, 3, 3, 3, 6, 4, 6, 3
A Unified Framework for Reinforcement Learning under Policy and Dynamic Shifts,5.75, 6.0, 1.7853571071357126, 8, 3, 6, 3, 6, 4, 3, 3
Illusory Attacks: Detectability Matters in Adversarial Attacks on Sequential Decision-Makers,6.666666666666667, 6.0, 0.9428090415820634, 8, 2, 6, 4, 6, 3
A Fault Forecasting Approach Using Two-Dimensional Optimization (TDO),4.25, 3.0, 2.165063509461097, 3, 4, 8, 4, 3, 5, 3, 4
Who to imitate: Imitating desired behavior from divserse multi-agent datasets,6.0, 6.0, 1.0954451150103321, 5, 3, 8, 2, 6, 2, 6, 3, 5, 3
Optimization over Sparse Restricted Convex Sets via Two Steps Projection,5.0, 4.5, 2.1213203435596424, 8, 1, 6, 3, 3, 4, 3, 4
PointMLLM: Aligning multi-modality with LLM for point cloud understanding generation and editing,4.0, 3.0, 1.4142135623730951, 6, 5, 3, 3, 3, 4
Stealthy Targeted Backdoor Attack Against Image Captioning,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 5, 5, 3, 4
Why are Modern GANs Poor Density Models?,3.4, 3.0, 0.8, 3, 4, 3, 4, 5, 4, 3, 4, 3, 3
Overcoming Distribution Mismatch in Quantizing Image Super-Resolution Networks,5.0, 6.0, 1.4142135623730951, 6, 4, 3, 5, 6, 4
Respect the model: Fine-grained and Robust Explanation with Sharing Ratio Decomposition,5.75, 6.0, 0.4330127018922193, 6, 2, 6, 3, 6, 3, 5, 2
Exploring Diffusion Time-steps for Unsupervised Representation Learning,6.0, 6.0, 0.0, 6, 4, 6, 3, 6, 5, 6, 3
Entropy Voting Between Capsules,3.0, 3.0, 0.0, 3, 4, 3, 2, 3, 5
SweetDreamer: Aligning Geometric Priors in 2D diffusion for Consistent Text-to-3D,5.75, 5.0, 1.299038105676658, 5, 4, 5, 5, 5, 3, 8, 4
Dyn-Adapter: Towards Disentangled Representation for Efficient Visual Recognition,4.333333333333333, 5.0, 0.9428090415820634, 5, 5, 3, 4, 5, 3
Generation of Geodesics with Actor-Critic Reinforcement Learning to Predict Midpoints,5.0, 5.5, 1.224744871391589, 3, 3, 6, 1, 6, 3, 5, 2
How many samples are needed to train a deep-ReLU neural network?,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 3, 6, 3
Hypergraph Dynamic System,4.25, 4.0, 2.5860201081971503, 3, 3, 5, 3, 8, 5, 1, 4
Augmented Bayesian Policy Search,6.0, 6.0, 1.0954451150103321, 6, 3, 6, 4, 8, 3, 5, 4, 5, 4
Subject-Diffusion: Open Domain Personalized Text-to-Image  Generation without Test-time Fine-tuning,5.0, 5.5, 1.224744871391589, 3, 4, 6, 5, 5, 4, 6, 4
Climate-sensitive Urban Planning through Optimization of Tree Placements,4.25, 4.0, 1.299038105676658, 3, 3, 3, 3, 5, 4, 6, 3
Graph Decoding via Generalized Random Dot Product Graph,2.0, 2.0, 1.0, 3, 3, 3, 4, 1, 4, 1, 5
Emu: Generative Pretraining in Multimodality,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 4, 6, 4
Gazelle: A Multimodal Learning System Robust to Missing Modalities,3.0, 3.0, 1.4142135623730951, 3, 4, 1, 5, 5, 5, 3, 4
Client-centric Federated Learning,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 3
Manifold Inspired Graph Contrastive Learning,4.0, 3.0, 1.2649110640673518, 3, 5, 6, 2, 3, 4, 3, 4, 5, 4
Dirichlet-based Per-Sample Weighting by Transition Matrix for Noisy Label Learning,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 4, 5, 3, 5, 3, 6, 3, 6, 3
MSfusion: Enabling Collaborative Training of Large Models over Resource-Constraint Participants,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 3, 4, 5, 3
HoloNets: Spectral Convolutions do extend to Directed Graphs,6.5, 6.0, 0.8660254037844386, 6, 3, 8, 2, 6, 3, 6, 3
Functional Classification Under Local Differential Privacy with Model Reversal and Model Average,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 3, 6, 2, 5, 3
Improving Learning Conditions for Computer Science Students by Using the Flipped Classroom,1.8, 1.0, 0.9797958971132713, 1, 5, 1, 5, 3, 5, 1, 5, 3, 5
TabGraphs: new benchmark and insights for learning on graphs with tabular features,3.25, 3.0, 1.7853571071357126, 6, 3, 3, 4, 3, 4, 1, 5
Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback,5.666666666666667, 6.0, 0.4714045207910317, 5, 2, 6, 3, 6, 3
CLIP-Guided Reinforcement Learning for Open-Vocabulary Tasks,5.6, 6.0, 1.624807680927192, 6, 4, 5, 4, 8, 4, 3, 4, 6, 3
Time Series Prediction With  Events Disturbance Based Causal Representation Learnin,3.0, 3.0, 0.0, 3, 3, 3, 5, 3, 3, 3, 4
Addressing Signal Delay in Deep Reinforcement Learning,5.75, 6.0, 1.7853571071357126, 3, 4, 6, 5, 6, 3, 8, 3
TransNormerLLM: A Faster and Better Large Language Model with Improved TransNormer,5.75, 5.0, 1.299038105676658, 5, 4, 5, 4, 5, 5, 8, 4
Relay Diffusion: Unifying diffusion process across resolutions for image synthesis,5.5, 5.5, 0.5, 5, 4, 6, 4, 5, 4, 6, 3
D3AD: DYNAMIC DENOISING DIFFUSION PROBABILISTIC MODEL FOR ANOMALY DETECTION,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 5
Multi-Concept T2I-Zero: Tweaking Only The Text Embeddings And Nothing Else,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 5
Multi-Source Diffusion Models for Simultaneous Music Generation and Separation,8.0, 8.0, 0.0, 8, 3, 8, 3, 8, 4
On the Optimality of Activations in Implicit Neural Representations,5.25, 6.0, 1.299038105676658, 6, 3, 6, 4, 3, 4, 6, 4
FedPop: Federated Population-based Hyperparameter Tuning,4.8, 5.0, 1.8330302779823362, 8, 4, 5, 4, 3, 4, 3, 4, 5, 4
Neuroexplicit Diffusion Models for Inpainting of Optical Flow Fields,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 5, 3, 6, 4
Utility-based Adaptive Teaching Strategies using Bayesian Theory of Mind,4.0, 5.0, 1.7888543819998317, 5, 4, 5, 3, 6, 4, 1, 5, 3, 2
CogVLM: Visual Expert for Large Language Models,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 4, 6, 4, 5, 4
Improving the Convergence of Dynamic NeRFs via Optimal Transport,5.5, 5.5, 0.5, 6, 2, 5, 4, 5, 4, 6, 2
HiddenKey: Parameter-Efficient FineTuning Meets Dropout under a Unified Framework,4.0, 4.0, 1.0, 3, 3, 3, 4, 5, 4, 5, 3
Fast Updating of Truncated SVD for Representation Learning in Sparse Matrix,5.0, 5.5, 1.224744871391589, 6, 2, 5, 5, 6, 4, 3, 4
Vision-Language Models are Zero-Shot Reward Models for Reinforcement Learning,5.6, 6.0, 2.244994432064365, 6, 5, 3, 4, 3, 4, 8, 4, 8, 4
TokenFlow: Consistent Diffusion Features for Consistent Video Editing,7.0, 7.0, 1.0, 6, 4, 8, 4, 6, 4, 8, 4
DreamTime: An Improved Optimization Strategy for Diffusion-Guided 3D Generation,5.75, 6.0, 1.7853571071357126, 8, 4, 6, 5, 3, 4, 6, 4
Classifier Guidance Enhances Diffusion-based Adversarial Purification by Preserving Predictive Information,5.0, 5.5, 1.224744871391589, 6, 3, 5, 4, 6, 3, 3, 4
MC-JEPA: A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 6, 3, 5, 4
BWS: Best Window Selection Based on Sample Scores for Data Pruning across Broad Ranges,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 4, 5, 3
Sparse-PGD: An Effective and Efficient Attack for $l_0$ Bounded Adversarial Perturbation,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 3, 5, 5, 4
Towards human-like spoken dialogue generation between AI agents from written dialogue,5.666666666666667, 6.0, 2.0548046676563256, 3, 3, 8, 4, 6, 4
A Unified Framework for Consistency Generative Modeling,5.0, 5.5, 1.224744871391589, 6, 2, 6, 3, 3, 4, 5, 3
TabRepo: A Large Scale Repository of Tabular Model Evaluations and its AutoML Applications,4.25, 4.0, 1.299038105676658, 3, 4, 6, 4, 3, 3, 5, 3
Long-term Time Series Forecasting with Vision Transformer,4.25, 5.0, 1.920286436967152, 1, 4, 5, 4, 5, 4, 6, 3
CARD: Channel Aligned Robust Blend Transformer for Time Series Forecasting,5.25, 6.0, 1.299038105676658, 6, 3, 6, 4, 3, 4, 6, 5
Focus on Primary: Differential Diverse Data Augmentation for Generalization in Visual Reinforcement Learning,4.0, 4.0, 1.0, 3, 4, 5, 3, 5, 3, 3, 5
GNN-based Reinforcement Learning Agent for Session-based Recommendation,2.5, 2.0, 1.6583123951777, 5, 3, 3, 3, 1, 4, 1, 3
LLM2Labels: Zero-shot dataset summarizing and labeling using foundational LLM models,3.0, 3.0, 2.0, 1, 5, 5, 3
Reinforcement Symbolic Regression Machine,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 3, 5, 4, 6, 2
Beyond Language: Empowering Unsupervised Machine Translation with Cross-modal Alignment,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 4, 5, 5, 5, 3
ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models,6.25, 6.0, 1.0897247358851685, 6, 4, 6, 3, 8, 4, 5, 4
Support Vector-based Shapley Value Estimation for Feature Selection and Explanation,5.75, 5.0, 1.299038105676658, 5, 4, 5, 4, 5, 3, 8, 2
ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 6, 3, 5, 3
InstructProtein: Aligning Human and Protein Language via Knowledge Instruction,5.0, 5.5, 1.224744871391589, 6, 3, 5, 4, 3, 4, 6, 4
Addressing Real-Time  Fragmentary Interaction Control Problems via Muti-step Representation Reinforcement Learning,5.25, 5.0, 0.4330127018922193, 5, 2, 5, 4, 6, 3, 5, 3
Language Models Struggle to Explain Themselves,4.333333333333333, 5.0, 0.9428090415820634, 3, 3, 5, 4, 5, 4
Asymmetrically Decentralized Federated Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 5
An Inexact Regularized Adaptive Algorithm with Manifold Identification for Training Structured Neural Networks,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 6, 3, 5, 3
Adaptive-Solver Framework for Dynamic Strategy Selection in Large Language Model Reasoning,4.0, 4.0, 1.0, 3, 3, 3, 4, 5, 4, 5, 4
Tailoring Mixup to Data using Kernel Warping functions,5.25, 5.0, 1.7853571071357126, 5, 4, 5, 3, 8, 3, 3, 5
ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by Learning to Scale,5.25, 5.0, 1.7853571071357126, 5, 4, 3, 4, 5, 3, 8, 4
Towards Faithful XAI Evaluation via Generalization-Limited Backdoor Watermark,5.75, 6.0, 1.7853571071357126, 8, 2, 6, 4, 6, 3, 3, 4
OneSpike: Ultra-low latency spiking neural networks,3.75, 3.0, 1.299038105676658, 3, 5, 3, 5, 3, 3, 6, 3
Space Group Constrained Crystal Generation,7.333333333333333, 8.0, 0.9428090415820634, 6, 3, 8, 3, 8, 2
BEEF: Building a BridgE from Event to Frame,4.8, 5.0, 0.9797958971132712, 6, 5, 5, 3, 5, 5, 3, 4, 5, 3
Distribution Aware Active Learning via Gaussian Mixtures,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 6, 5, 8, 4
TransLLaMa: LLM-based Simultaneous Translation System,5.25, 5.0, 0.4330127018922193, 5, 5, 6, 4, 5, 4, 5, 4
TAFS: Task-aware Activation Function Search for Graph Neural Networks,4.5, 5.0, 0.8660254037844386, 5, 5, 5, 4, 5, 3, 3, 3
NSM4D: Neural Scene Model Based Online 4D Point Cloud Sequence Understanding,4.75, 5.0, 1.0897247358851685, 6, 1, 5, 4, 5, 2, 3, 4
A Spitting Image: Superpixel Transformers,5.25, 5.0, 1.7853571071357126, 5, 4, 8, 4, 5, 4, 3, 5
Learning Multi-Agent Communication from Graph Modeling Perspective,6.75, 7.0, 1.299038105676658, 6, 3, 5, 5, 8, 3, 8, 5
Cleaning label noise with vision-language models,4.5, 5.0, 0.8660254037844386, 5, 5, 5, 4, 3, 3, 5, 4
SITReg: Multi-resolution architecture for symmetric inverse consistent and topology preserving image registration using deformation inversion layers,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 4, 5, 4
GC-Mixer: A Novel Architecture for Time-varying Granger Causality Inference,4.25, 4.0, 1.299038105676658, 5, 4, 6, 2, 3, 4, 3, 4
An Efficient Subgraph GNN with Provable Substructure Counting Power,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 4, 3, 3, 5, 3
DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization,5.5, 5.5, 0.5, 5, 4, 5, 3, 6, 4, 6, 4
Vulnerable Region Discovery through Diverse Adversarial Examples,6.0, 5.0, 1.4142135623730951, 5, 4, 8, 5, 5, 3
Experimental methodology to evaluate the effectiveness of uncertainty disentanglement on regression models,1.6666666666666667, 1.0, 0.9428090415820634, 1, 5, 1, 4, 3, 4
Efficient Multi-agent Reinforcement Learning by Planning,5.5, 5.5, 1.8027756377319946, 3, 5, 5, 4, 6, 3, 8, 3
Communication-efficient Random-Walk Optimizer for Decentralized Learning,4.5, 4.5, 1.5, 6, 3, 3, 5, 6, 3, 3, 4
Feature Normalization Prevents Collapse of Non-contrastive Learning Dynamics,5.5, 5.5, 0.5, 6, 3, 5, 4, 6, 4, 5, 2
Generating Transferable and Stealthy Adversarial Patch via Attention-guided Adversarial Inpainting,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 3, 5, 2
Equivariant Deep Weight Space Alignment,5.5, 5.5, 0.5, 6, 4, 6, 4, 5, 3, 5, 2
EventRPG: Event Data Augmentation with Relevance Propagation Guidance,6.0, 5.0, 1.4142135623730951, 5, 3, 5, 3, 8, 3
Fundamental Limitation of Alignment in Large Language Models,6.0, 5.5, 1.224744871391589, 5, 3, 5, 3, 6, 3, 8, 4
Functional Wasserstein Bridge Inference for Bayesian Deep Learning,5.8, 6.0, 1.6, 3, 4, 6, 3, 6, 4, 6, 3, 8, 3
How Over-Parameterization Slows Down Gradient Descent in Matrix Sensing: The Curses of Symmetry and Initialization,6.75, 7.0, 1.299038105676658, 8, 4, 6, 4, 8, 4, 5, 4
NeRM: Learning Neural Representations for High-Framerate Human Motion Synthesis,6.75, 7.0, 1.299038105676658, 8, 4, 5, 4, 8, 4, 6, 3
Regularization is Enough for Last-Iterate Convergence in Zero-Sum Games,5.6, 5.0, 1.2, 5, 4, 5, 4, 5, 3, 5, 2, 8, 5
Cellular Interplay in COVID-19: Insights from Graph Neural Networks with Multidimensional Edge Features,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 1, 4, 3, 4
Adaptive Visual Scene Understanding: Incremental Scene Graph Generation,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 6, 4, 5, 3
Improving the Reliability of Large Language Models by Leveraging Uncertainty-Aware In-Context Learning,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 3
Sequence-SOD: Sequence-aware Spiking Object Detection for Event Cameras,4.25, 4.0, 1.299038105676658, 3, 3, 5, 5, 6, 5, 3, 4
Meta-Learning with Personalized Learning Rates for Rapid Task Mastery,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 5
Improved Generalization of cGAN using Vicinal Estimation and Early Stopping,4.0, 4.0, 1.0, 3, 2, 3, 4, 5, 4, 5, 2
Visual Evidence Prompting Mitigates Hallucinations in Multimodal Large Language Models,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 3, 5, 4
Learning Equi-angular Representations for Online Continual Learning,4.25, 4.0, 1.299038105676658, 3, 5, 5, 5, 6, 3, 3, 4
Node Classification in the Heterophilic Regime via Diffusion-Jump GNNs,4.0, 3.0, 2.943920288775949, 3, 4, 1, 4, 8, 5
AnyText: Multilingual Visual Text Generation and Editing,5.75, 6.0, 1.7853571071357126, 6, 3, 6, 3, 8, 4, 3, 3
IGTO: Individual Global Transform Optimization for Multi-Agent Reinforcement Learning,6.0, 6.0, 1.0954451150103321, 8, 4, 5, 3, 6, 4, 5, 3, 6, 4
CNNGEN: A GENERATOR AND BENCHMARK FOR SUSTAINABLE CONVOLUTIONAL NEURAL NETWORK SEARCH,3.6666666666666665, 3.0, 0.9428090415820634, 3, 2, 3, 4, 5, 3
Con4m: Unleashing the Power of Consistency and Context in Classification for Blurred-Segmented Time Series,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 3, 6, 3, 5, 3
Prediction Tasks in Graphs: a Framework to Control the Interpretability-Performance Trade-off,4.75, 5.0, 1.0897247358851685, 6, 2, 5, 4, 5, 4, 3, 3
Budgeted Online Continual Learning by Adaptive Layer Freezing and Frequency-based Sampling,4.333333333333333, 5.0, 0.9428090415820634, 5, 2, 5, 2, 3, 4
DIFFender: Diffusion-Based Adversarial Defense against Patch Attacks,4.5, 5.0, 0.8660254037844386, 5, 5, 5, 3, 5, 4, 3, 3
Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization,6.25, 6.0, 1.0897247358851685, 6, 4, 5, 5, 8, 3, 6, 4
A Trust Region Approach for Few-Shot Sim-to-Real Reinforcement Learning,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 3, 5, 3
Efficient Backpropagation with Variance Controlled Adaptive Sampling,5.0, 5.5, 1.224744871391589, 3, 3, 5, 4, 6, 3, 6, 4
Meta-Learning with Task-Environment Interaction,3.75, 3.0, 1.299038105676658, 3, 3, 3, 2, 3, 5, 6, 3
Predicated Diffusion: Predicate Logic-Based Attention Guidance for Text-to-Image Diffusion Models,5.0, 5.5, 1.224744871391589, 5, 4, 6, 3, 3, 3, 6, 4
WinNet:time series forecasting with a window-enhanced period extracting and interacting,4.5, 5.0, 0.8660254037844386, 5, 2, 3, 5, 5, 3, 5, 4
Domain Generalization via Content Factors Isolation: A Two-level Latent Variable Modeling Approach,5.5, 5.5, 0.5, 6, 2, 5, 3, 6, 3, 5, 3
Multi-label Cluster Discrimination for Visual Representation Learning,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 3, 5, 4
On the Robustness of Latent Diffusion Models,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 5, 6, 3
Dynamic Neighborhood Construction for Structured Large Discrete Action Spaces,6.666666666666667, 6.0, 0.9428090415820634, 8, 2, 6, 2, 6, 4
LEGO-Prover: Neural Theorem Proving with Growing Libraries,5.5, 5.5, 1.8027756377319946, 6, 3, 5, 4, 8, 4, 3, 3
Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models,6.75, 7.0, 1.299038105676658, 8, 3, 5, 4, 6, 3, 8, 3
DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 4, 6, 3, 5, 4
Generative Retrieval with Large Language Models,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 5, 4, 6, 4
VoxGenesis: Unsupervised Discovery of Latent Speaker Manifold for Speech Synthesis,3.5, 4.0, 1.6583123951777, 5, 4, 3, 4, 5, 4, 1, 4
Text-to-3D Generation with Bidirectional Diffusion using both 3D and 2D priors,5.0, 5.5, 1.224744871391589, 3, 4, 6, 4, 5, 4, 6, 4
An Information Theoretic Approach to Interaction Grounded Learning,5.0, 5.0, 1.0954451150103321, 6, 3, 3, 5, 5, 4, 5, 2, 6, 2
PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images,5.666666666666667, 6.0, 0.4714045207910317, 5, 5, 6, 4, 6, 4
Are Large Language Models Really Robust to Word-Level Perturbations?,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4, 3, 4
Phi-Former: A Pairwise Hierarchical Approach for Compound-Protein Interaction Prediction,3.0, 3.0, 1.4142135623730951, 1, 4, 3, 4, 5, 5, 3, 4
CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets,6.666666666666667, 6.0, 0.9428090415820634, 8, 3, 6, 3, 6, 3
A Variational Framework for Estimating Continuous Treatment Effects with Measurement Error,5.0, 6.0, 1.4142135623730951, 3, 4, 6, 4, 6, 3
TABLEYE: SEEING SMALL TABLES THROUGH THE LENS OF IMAGES,5.25, 5.0, 1.7853571071357126, 5, 2, 3, 4, 5, 3, 8, 4
InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation,6.0, 5.5, 1.224744871391589, 6, 4, 8, 3, 5, 5, 5, 4
Measuring Value Understanding in Language Models through Discriminator-Critique Gap,4.0, 4.0, 1.0, 5, 3, 3, 4
HallE-Switch: Rethinking and Controlling Object Existence Hallucinations in Large Vision-Language Models for Detailed Caption,5.5, 5.5, 1.8027756377319946, 3, 4, 5, 5, 8, 4, 6, 4
Interpreting the Inner Mechanisms of Large Language Models in Mathematical Addition,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 4, 6, 4, 6, 3
Correlated Attention in Transformers for Multivariate Time Series,4.75, 5.0, 1.0897247358851685, 6, 2, 5, 3, 3, 4, 5, 3
Bridging the Domain Gap by Clustering-based Image-Text Graph Matching,4.333333333333333, 5.0, 0.9428090415820634, 3, 5, 5, 5, 5, 4
Pick-or-Mix: Dynamic Channel Sampling for ConvNets,4.5, 5.0, 0.8660254037844386, 5, 5, 5, 5, 5, 4, 3, 4
Cross-domain Recommendation from Implicit Feedback,3.0, 3.0, 1.4142135623730951, 5, 5, 3, 4, 1, 5, 3, 4
Masked Pretraining for Multi-Agent Decision Making,4.4, 5.0, 1.2, 5, 3, 3, 4, 3, 4, 5, 3, 6, 2
Object-Aware Inversion and Reassembly for Image Editing,6.0, 6.5, 2.1213203435596424, 8, 5, 3, 3, 8, 5, 5, 2
Byzantine-Robust Dynamic Weighted Aggregation Framework for Optimal Attack Mitigation in Federated Learning,3.4, 3.0, 0.8, 3, 4, 3, 4, 3, 4, 3, 4, 5, 4
CONTROL: A Contrastive Learning Framework for Open World Semi-Supervised Learning,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 4, 5, 2
Conformal Normalization in Recurrent Neural Network of Grid Cells,4.0, 4.0, 1.0, 3, 3, 5, 4, 3, 4, 5, 2
Taming Mode Collapse in Score Distillation for Text-to-3D Generation,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 4, 3, 5, 5, 2
Bad Habits: Policy Confounding and Out-of-Trajectory Generalization in Reinforcement Learning,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 3, 3, 6, 4
Adaptive Offline Data Replay in Offline-to-Online Reinforcement Learning,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 4, 5, 3
Graph Neural Networks for Multivariate Time-Series Forecasting via Learning Hierarchical Spatiotemporal Dependencies,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 4, 3, 4, 3, 4
SteinDreamer: Variance Reduction for Text-to-3D Score Distillation via Stein Identity,5.0, 5.5, 1.224744871391589, 6, 4, 6, 4, 5, 3, 3, 5
SAN: Inducing Metrizability of GAN with Discriminative Normalized Linear Layer,5.5, 5.5, 0.5, 5, 4, 6, 4
How Neural Networks With Derivative Labels Work: A Neural Tangent Kernel Perspective,3.0, 3.0, 0.0, 3, 3, 3, 5, 3, 3
Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models,5.5, 5.5, 0.5, 5, 3, 5, 3, 6, 4, 6, 4
Leveraging Word Guessing Games to Assess the Intelligence of Large Language Models,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 3, 5, 5, 4
Overcoming Weak Visual-Textual Alignment for Video Moment Retrieval,nan, nan, nan
Sample-Efficient Multi-Agent RL: An Optimization Perspective,5.8, 6.0, 0.39999999999999997, 6, 2, 6, 3, 5, 4, 6, 4, 6, 3
Tactics of Robust Deep Reinforcement Learning with Randomized Smoothing,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 3, 3, 4, 5, 3
Minimum width for universal approximation using ReLU networks on compact domain,6.333333333333333, 6.0, 1.247219128924647, 6, 5, 8, 5, 5, 4
UNLEARNING THE UNWANTED DATA FROM A PERSONALIZED RECOMMENDATION MODEL,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 5, 2, 3, 3
At Which Training Stage Does Code Data Help LLMs Reasoning?,5.75, 6.0, 1.7853571071357126, 6, 4, 8, 5, 6, 3, 3, 4
Reducing Atomic Clashes in Geometric Diffusion Models for 3D Structure-Based Drug Design,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 5, 4, 3, 3
Coordinate-Aware Modulation for Neural Fields,6.5, 6.0, 0.8660254037844386, 6, 4, 8, 1, 6, 2, 6, 3
Prompt-Tuning Decision Transformer with Preference Ranking,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 3, 5, 5, 3
The Program Testing Ability of Large Language Models for Code,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 6, 5, 3, 5
Adversarial enhanced representation for link prediction in multi-layer networks,2.5, 3.0, 0.8660254037844386, 1, 4, 3, 5, 3, 5, 3, 4
MG-NeRF: Multimodal Representation Learning for Generalizable NeRF,3.0, 3.0, 2.0, 1, 5, 5, 4, 5, 4, 1, 4
Drug Discovery with Dynamic Goal-aware Fragments,6.333333333333333, 6.0, 1.247219128924647, 5, 3, 8, 3, 6, 4
Self-Supervised Dataset Distillation for Transfer Learning,5.6, 6.0, 0.48989794855663565, 6, 3, 6, 3, 5, 3, 5, 4, 6, 4
Diffusion Models as Strong Adversaries,4.0, 4.0, 1.0, 5, 3, 5, 4, 3, 3, 3, 4
Poor Teaching: Explore and Question Knowledge Distillation under Distribution Shift,3.0, 3.0, 1.4142135623730951, 1, 5, 5, 3, 3, 5, 3, 4
DOG: Diffusion-based Outlier Generation for Out-of-Distribution Detection,4.25, 4.0, 1.299038105676658, 3, 4, 3, 4, 6, 4, 5, 4
PanoOcc: Unified Occupancy Representation for Camera-based 3D Panoptic Segmentation,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 5, 3, 4, 5, 3
Rethinking the symmetry-preserving circuits for constrained variational quantum algorithms,5.75, 6.0, 1.7853571071357126, 3, 4, 6, 4, 8, 3, 6, 5
Are We in (A)Sync?: Guidance for Efficient Federated Learning,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 4, 3, 4
Task-Distributionally Robust Data-Free Meta-Learning,4.75, 4.0, 2.0463381929681126, 3, 4, 5, 4, 3, 4, 8, 3
An Attention-based Approach for Bayesian Optimization with Dependencies,3.0, 3.0, 1.632993161855452, 1, 4, 5, 4, 3, 4
Towards Codable Text Watermarking for Large Language Models,5.0, 5.5, 1.224744871391589, 3, 4, 6, 4, 6, 2, 5, 2
Bayesian Offline-to-Online Reinforcement Learning : A Realist Approach,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 3, 6, 4, 5, 3
GNRK: Graph Neural Runge-Kutta method for solving partial differential equations,3.4, 3.0, 0.8, 3, 3, 3, 4, 3, 4, 5, 5, 3, 4
Hypothesis Search: Inductive Reasoning with Language Models,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 3, 4, 5, 3, 5, 5, 3, 4, 6, 2
Embed-Search-Align: DNA Sequence Alignment using Transformer models,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 3
RoleLLM: Benchmarking Eliciting and Enhancing Role-Playing Abilities of Large Language Models,4.75, 5.0, 1.0897247358851685, 5, 3, 6, 4, 3, 4, 5, 4
Language Model Decoding as Direct Metrics Optimization,6.333333333333333, 6.0, 1.247219128924647, 8, 3, 5, 3, 6, 4
Amortising the Gap between Pre-training and Fine-tuning for Video Instance Segmentation,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 5, 3, 5, 3, 5
Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment,5.5, 5.5, 0.5, 5, 4, 6, 3, 6, 1, 5, 5
Factual and Personalized Recommendation Language Modeling with Reinforcement Learning,4.75, 5.0, 1.0897247358851685, 5, 3, 6, 3, 5, 2, 3, 4
Decentralized Decoupled Training for Federated Long-Tailed Learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 4
DataFreeShield: Defending Adversarial Attacks without Training Data,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 4
Evaluating the Instruction-Following Robustness of Large Language Models to Prompt Injection,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 3, 6, 4, 5, 4
On the Theoretical Analysis of Dense Contrastive Learning,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 5, 4, 6, 2
Analyzing Implicit Regularization In Federated Learning,nan, nan, nan
LSP: Low-Power Semi-structured Pruning for Vision Transformers,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 5, 6, 4, 5, 5
Reverse Chain: A Generic Rule for LLMs to Master Multi-API Planning,4.2, 5.0, 0.9797958971132712, 3, 5, 5, 3, 3, 3, 5, 4, 5, 4
Exploiting the Potential of Seq2Seq Models as Robust Few-Shot Learners,5.5, 5.5, 0.5, 6, 3, 6, 3, 5, 3, 5, 5
PDED: Revitalize physics laws submerged in data information for Traffic State Estimation,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 2, 5, 4
GAN-based Vertical Federated Learning for Label Protection,5.0, 5.5, 1.224744871391589, 5, 4, 3, 5, 6, 2, 6, 4
Time-Sensitive Replay for Continual Learning,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 4, 3, 3, 3, 4
Dataset Distillation via Adversarial Prediction Matching,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 4
Pay attention to cycle for spatio-temporal graph neural network,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 4, 5, 4, 5, 3
Rethinking Moreau Envelope for Nonconvex Bi-Level Optimization: A Single-loop and Hessian-free Solution Strategy,6.6, 6.0, 1.2, 6, 3, 5, 4, 8, 5, 6, 2, 8, 2
Brain-inspired $L_p$-Convolution benefits large kernels and aligns better with visual cortex,6.4, 8.0, 2.0591260281974, 5, 4, 8, 3, 8, 3, 8, 3, 3, 3
Test-Time Training for Semantic Segmentation with Output Contrastive Loss,4.25, 4.0, 1.299038105676658, 3, 3, 5, 2, 3, 4, 6, 3
Efficient ConvBN Blocks for Transfer Learning and Beyond,6.5, 6.0, 0.8660254037844386, 6, 4, 6, 4, 8, 4, 6, 3
Prompt Tuning with Diffusion for Few-Shot Pre-trained Policy Generalization,6.0, 5.5, 1.224744871391589, 5, 4, 8, 3, 5, 3, 6, 4
Large Content And Behavior Models To Understand Simulate And Optimize Content And Behavior,7.25, 7.0, 1.920286436967152, 10, 3, 5, 3, 8, 3, 6, 3
Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints,7.25, 8.0, 1.299038105676658, 5, 3, 8, 2, 8, 4, 8, 3
MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 3, 5, 4, 6, 5
In Defence Of Wasserstein,4.25, 3.0, 2.165063509461097, 3, 4, 3, 3, 8, 3, 3, 4
Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification,5.25, 5.0, 1.7853571071357126, 3, 5, 8, 5, 5, 4, 5, 3
The Geometry of Truth: Emergent Linear Structure in Large Language Model Representations of True/False Datasets,5.25, 5.0, 1.7853571071357126, 5, 2, 3, 3, 8, 3, 5, 3
Dual Associated Encoder for Face Restoration,6.5, 6.5, 1.5, 5, 3, 5, 4, 8, 3, 8, 4
Topology-Informed Graph Transformer,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 4
Dual-Balancing for Multi-Task Learning,5.4, 5.0, 1.624807680927192, 8, 4, 6, 5, 3, 4, 5, 4, 5, 4
Zero-Sum Positional Differential Games as a Framework for Robust Reinforcement Learning: Deep Q-Learning Approach,5.25, 5.0, 1.7853571071357126, 5, 3, 3, 5, 8, 3, 5, 3
HiCBridge: Resolution Enhancement of Hi-C Data Using Direct Diffusion Bridge,5.2, 6.0, 1.16619037896906, 6, 4, 5, 3, 6, 4, 6, 3, 3, 4
On the Hidden Waves of Image,5.0, 4.5, 2.1213203435596424, 6, 3, 3, 3, 3, 4, 8, 2
Unsupervised Open-Set Task Adaptation Using a Vision-Language Foundation Model,3.5, 3.0, 0.8660254037844386, 5, 5, 3, 3, 3, 4, 3, 4
MGTST: Multi-scale and Cross-channel Gated Transformer for Multivariate long-term time-series forecasting,4.333333333333333, 5.0, 0.9428090415820634, 3, 3, 5, 3, 5, 3
LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression,5.8, 6.0, 0.39999999999999997, 6, 4, 6, 3, 6, 5, 5, 4, 6, 4
CAT-LLM: Context-Aware Training enhanced Large Language Models for multi-modal contextual image retrieval,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 4
Video-CSR: Complex Video Digest Creation for Visual-Language Models,4.666666666666667, 5.0, 1.247219128924647, 3, 2, 5, 4, 6, 4
Density-Softmax: Efficient Test-time Model for Uncertainty Estimation and Robustness under Distribution Shifts,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 5, 5, 3
Spectral Contrastive Regression,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 4
Tensor methods to learn the Green's function to solve high-dimensional PDE,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 3, 4, 5, 3
A2FC: A FEDERATED ADVANTAGE ACTOR-CRITIC LEARNING APPROACH FOR HETEROGENEOUS ACTION SPACES,3.0, 3.0, 0.0, 3, 3, 3, 4, 3, 3
DiffusionSat: A Generative Foundation Model for Satellite Imagery,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 4, 3, 4, 5, 4
FragSel: Fragmented Selection for Noisy Label Regression,5.5, 5.5, 0.5, 6, 5, 6, 2, 5, 4, 5, 4
Object2Scene: Putting Objects in Context for Open-Vocabulary 3D Detection,5.0, 5.5, 1.224744871391589, 5, 5, 6, 5, 3, 4, 6, 4
DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 3, 6, 5, 6, 4
Look Ma No Training! Observation Space Design for Reinforcement Learning,3.5, 4.0, 1.6583123951777, 5, 4, 1, 4, 5, 5, 3, 4
Is Generalized Dynamic Novel View Synthesis from Monocular Videos Possible Today?,5.25, 5.0, 1.7853571071357126, 5, 5, 8, 4, 3, 5, 5, 4
Mining Shallow Layer Representations in Class-Incremental Learning,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 5, 5, 3, 3, 5
Follow-Up Differential Descriptions: Language Models Resolve Ambiguities for Image Classification,5.5, 5.5, 1.8027756377319946, 6, 3, 8, 4, 5, 4, 3, 4
ColA: Collaborative Adaptation with Gradient Learning,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 5, 2, 6, 4
AFDGCF: Adaptive Feature De-correlation Graph Collaborative Filtering for Recommendations,6.5, 6.5, 1.5, 8, 5, 5, 4, 5, 4, 8, 5
Causal Effect Estimation with Mixed Latent Confounders and Post-treatment Variables,4.0, 4.0, 1.0, 3, 3, 5, 3, 3, 4, 5, 3
ACID: Abstractive Content-Based IDs for Document Retrieval with Language Models,4.5, 5.0, 0.8660254037844386, 3, 5, 5, 4, 5, 2, 5, 3
InfoGround: Ground Manipulation Concepts with Maximal Information Boost,4.75, 5.0, 1.0897247358851685, 6, 5, 5, 4, 5, 4, 3, 4
Interpretable Sparse System Identification: Beyond Recent Deep Learning Techniques on Time-Series Prediction,7.0, 8.0, 1.4142135623730951, 8, 2, 8, 4, 5, 3
FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets,6.666666666666667, 6.0, 0.9428090415820634, 8, 2, 6, 2, 6, 4
MindAgent: Emergent Gaming Interaction,5.0, 3.0, 2.449489742783178, 3, 5, 8, 3, 3, 4, 3, 4, 8, 4
STABLE ESTIMATION OF SURVIVAL CAUSAL EFFECTS,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 4, 3, 3
A computational approach to visual ecology with deep reinforcement learning,4.25, 4.0, 1.299038105676658, 6, 3, 3, 5, 5, 3, 3, 4
Multi-Prompt Denoised Self-Training for Open-Vocabulary Model Adaptation,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 5, 6, 3, 5, 5
Learning to Prompt Segmentation Foundation Models,5.0, 5.5, 1.224744871391589, 3, 5, 6, 4, 5, 4, 6, 4
Mitigating Simplicity Bias in Deep Learning for Improved OOD Generalization and Robustness,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 6, 4, 3, 4
Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data,5.25, 5.0, 1.7853571071357126, 3, 4, 5, 3, 8, 4, 5, 4
SAM-guided Unsupervised Domain Adaptation for 3D Segmentation,5.0, 5.0, 1.0954451150103321, 3, 4, 6, 3, 5, 5, 6, 3, 5, 4
Generative Pre-training for Speech with Flow Matching,5.75, 6.0, 1.7853571071357126, 6, 2, 8, 5, 6, 4, 3, 5
Adapting Large Language Models for Content Moderation: Pitfalls in Data Engineering and Supervised Fine-tuning,4.0, 3.0, 1.4142135623730951, 6, 3, 3, 3, 3, 4
Generative and Explainable Data Augmentation for Single-Domain Generalization,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 3
LOTUS: Evasive and Resilient Backdoor Attacks through Sub-Partitioning,5.0, 6.0, 1.4142135623730951, 3, 4, 6, 3, 6, 3
Successor Features for Efficient Multi-Subject Controlled Text Generation,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 3, 6, 2, 6, 3
Neural Probabilistic Protein-Protein Docking via a Differentiable Energy Model,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 3, 3, 3, 5, 5
CausalTime: Realistically Generated Time-series for Benchmarking of Causal Discovery,5.5, 5.5, 0.5, 5, 3, 6, 4, 6, 4, 5, 4
Graph Generation with Destination-Predicting Diffusion Mixture,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 2, 6, 3
ITPNet: Towards Instantaneous Trajectory Prediction for Autonomous Driving,6.5, 6.5, 1.5, 5, 5, 8, 3
BayOTIDE: Bayesian Online Multivariate Time series Imputation with functional decomposition,4.8, 5.0, 1.8330302779823362, 5, 3, 3, 3, 5, 3, 3, 2, 8, 4
CCD-3DR: Consistent Conditioning in Diffusion for Single-Image 3D Reconstruction,4.25, 4.0, 1.299038105676658, 3, 2, 3, 4, 6, 3, 5, 4
Generative Modeling on Manifolds Through Mixture of Riemannian Diffusion Processes,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 5, 6, 3
Protein-ligand binding representation learning from fine-grained interactions,4.333333333333333, 5.0, 0.9428090415820634, 5, 5, 5, 3, 3, 4
Scaling Properties For Artificial Neural Network Models of the $\textit{C. elegans}$ Nervous System,3.6666666666666665, 3.0, 0.9428090415820634, 5, 2, 3, 5, 3, 4
JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models,3.75, 3.0, 1.299038105676658, 3, 4, 3, 5, 3, 4, 6, 3
Model Based Inference of Synaptic Plasticity Rules,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 3, 3, 3, 5, 4
SLiMe: Segment Like Me,6.75, 7.0, 1.299038105676658, 8, 3, 8, 4, 6, 2, 5, 3
Adversarial Attacks on Fairness of Graph Neural Networks,4.666666666666667, 5.0, 1.247219128924647, 3, 5, 5, 3, 6, 4
Large Language Models can be Guided to Evade AI-generated Text Detection,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 3, 6, 4, 5, 5
Faithful Vision-Language Interpretation via Concept Bottleneck Models,5.5, 5.5, 1.8027756377319946, 5, 4, 6, 3, 3, 4, 8, 4
Efficiently Computing Similarities to Private Datasets,7.0, 7.0, 1.0, 8, 3, 8, 3, 6, 3, 6, 2
The Role of Representation Transfer in Multitask Imitation Learning,5.166666666666667, 5.5, 1.0671873729054748, 6, 3, 6, 3, 6, 4, 3, 4, 5, 3, 5, 3
Sliced Denoising: A Physics-Informed Molecular Pre-Training Method,6.0, 5.5, 1.224744871391589, 6, 5, 5, 4, 5, 2, 8, 3
Video-Teller: Enhancing Cross-Modal Generation with Fusion and Decoupling,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 4, 5, 4
Class-Imbalanced Graph Learning without Class Rebalancing,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 5, 3, 5, 5, 4
Every Mistake Counts: Spatial and Temporal Beliefs for Mistake Detection in Assembly Tasks,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 4, 5, 2, 5, 2
Fine-grained Text-to-Image Synthesis with Semantic Refinement,5.25, 5.0, 1.7853571071357126, 5, 4, 3, 4, 5, 5, 8, 3
Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly Detection,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 4, 6, 4
Improving Generalization for Missing Data Imputation via Dual Corruption Denoising Autoencoders,4.2, 3.0, 1.469693845669907, 3, 3, 3, 4, 3, 5, 6, 4, 6, 3
Transitional Uncertainty with Intermediate Neural Gaussian Processes,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 3
P$^2$OT: Progressive Partial Optimal Transport for Deep Imbalanced Clustering,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 3, 5, 5
Graph-Relational Federated Learning: Enhanced Personalization and Robustness,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 5, 5, 5
Rethinking the Polynomial Filter of GNNs via Graph Information Activation Theory,4.0, 4.0, 1.0, 3, 3, 5, 4, 3, 4, 5, 5
Rethinking Adversarial Robustness in the Context of the Right to be Forgotten,5.25, 5.0, 0.4330127018922193, 5, 3, 6, 3, 5, 3, 5, 4
LoRA ensembles for large language model fine-tuning,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 4
SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores,6.75, 8.0, 2.165063509461097, 8, 4, 8, 3, 3, 4, 8, 3
RealChat-1M: A Large-Scale Real-World LLM Conversation Dataset,7.5, 8.0, 0.8660254037844386, 6, 4, 8, 4, 8, 4, 8, 4
Parameter-Efficient Detoxification with Contrastive Decoding,5.75, 5.0, 1.299038105676658, 5, 4, 5, 4, 8, 4, 5, 4
A Unified and General Framework for Continual Learning,5.0, 5.5, 1.224744871391589, 6, 3, 3, 4, 6, 2, 5, 3
MG-TSD: Multi-Granularity Time Series Diffusion Models with Guided Learning Process,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 4, 5, 4
RLAdapter: Bridging Large Language Models to Reinforcement Learning in Open Worlds,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 4, 3, 2, 3, 4
Heterogeneous Personalized Federated Learning by Local-Global Updates Mixing via Convergence Rate,6.0, 5.0, 1.4142135623730951, 5, 3, 5, 4, 8, 2
Score-based Conditional Generation with Fewer Labeled Data by Self-calibrating Classifier Guidance,5.0, 5.0, 0.0, 5, 5, 5, 3, 5, 3, 5, 4, 5, 3
HyperDisGAN: A Controllable Variety Generative Model Via Hyperplane Distances for Downstream Classifications,3.0, 3.0, 2.0, 5, 3, 1, 5
SetCSE: Set Operations using Contrastive Learning of Sentence Embeddings,5.75, 6.0, 1.7853571071357126, 3, 3, 6, 4, 8, 2, 6, 4
Accelerating Non-IID Federated Learning via Heterogeneity-Guided Client Sampling,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 3, 3, 5, 3
Polynormer: Polynomial-Expressive Graph Transformer in Linear Time,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 3
MagicRemover: Tuning-free Text-guided Image Inpainting with Diffusion Models,5.0, 5.0, 0.0, 5, 4, 5, 5, 5, 3, 5, 4
Temporal Repetition Counting with Dynamic Action Queries,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 5, 5, 4
Where We Have Arrived in Proving the Emergence of Sparse Interaction Primitives in AI Models,5.5, 5.5, 1.8027756377319946, 5, 2, 8, 3, 3, 3, 6, 2
Improving Discriminative Multi-Modal Learning with Large-Scale Pre-Trained Models,4.25, 4.0, 1.299038105676658, 3, 5, 3, 4, 6, 3, 5, 4
Effective Generation of Feasible Solutions for Integer Programming via Guided Diffusion,5.5, 5.5, 1.8027756377319946, 5, 5, 6, 4, 3, 3, 8, 2
Debiased Machine Learning and Network Cohesion for Doubly-Robust Differential Reward Models in Contextual Bandits,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 3, 5, 3, 6, 2
BOT: Bootstrapped Optimal Transport for Multi-label Noise Learning,4.25, 3.0, 2.165063509461097, 3, 3, 3, 3, 3, 3, 8, 4
Understanding Continuous-depth Networks through the Lens of Homogeneous Ricci Flows,2.3333333333333335, 3.0, 0.9428090415820634, 3, 3, 3, 2, 1, 5
When Is Multilinguality a Curse? Language Modeling for 252 High- and Low-Resource Languages,6.0, 5.5, 1.224744871391589, 6, 4, 5, 4, 5, 3, 8, 4
Gaussian Mutual Information Maximization for Graph Self-supervised Learning: Bridging Contrastive-based to Decorrelation-based,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 5, 5, 3
AdaSR: Adaptive Super Resolution for Cross Platform and Dynamic Runtime Environments,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 3, 3, 4, 5, 4
Rational Decision-Making Agent with Internalized Utility Judgment,6.25, 6.0, 1.0897247358851685, 6, 3, 6, 4, 5, 4, 8, 4
Boosting Self-Supervised Graph Representation Learning via Anchor-Neighborhood Alignment and Isotropic Constraints,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 4, 5, 3
Shifting Attention to Relevance: Towards the Uncertainty Estimation of Large Language Models,6.0, 6.0, 0.0, 6, 2, 6, 4, 6, 4
A Region-Shrinking-Based Acceleration for Classification-Based Derivative-Free Optimization,4.0, 4.5, 2.1213203435596424, 6, 2, 3, 4, 1, 3, 6, 3
DV-3DLane: End-to-end Multi-modal 3D Lane Detection with Dual-view Representation,6.0, 5.5, 2.5495097567963922, 10, 5, 3, 5, 6, 5, 5, 5
ASID: Active Exploration for System Identification and Reconstruction in Robotic Manipulation,6.0, 6.5, 2.1213203435596424, 5, 3, 8, 4, 3, 3, 8, 3
Abductive Logical Reasoning on Knowledge Graphs,4.8, 5.0, 0.9797958971132712, 3, 4, 6, 3, 5, 3, 5, 2, 5, 4
Continuous Field Reconstruction from Sparse Observations with Implicit Neural Networks,5.0, 5.5, 1.224744871391589, 6, 4, 3, 3, 6, 5, 5, 3
SODA: Stream Out-of-Distribution Adaptation,3.75, 3.0, 1.299038105676658, 3, 4, 3, 3, 3, 3, 6, 2
UniContact:A Basic Model for Robotic Manipulation of Contact Synthesis on Rigid and Articulated Rigid Bodies with Arbitrary Manipulators,4.0, 4.0, 1.0, 3, 3, 5, 3, 5, 3, 3, 4
Unifying User Preferences and Critic Opinions: A Multi-View Cross-Domain Item-sharing Recommender System,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 3, 5, 3
A Curriculum View of Robust Loss Functions,5.5, 5.5, 0.5, 6, 4, 5, 4, 5, 3, 6, 3
EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models,6.5, 6.0, 0.8660254037844386, 6, 3, 6, 4, 8, 5, 6, 5
DipDNN: Decomposed Invertible Pathway Deep Neural Networks,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 3, 5, 4
Curriculum metric learning for robust image retrieval,4.75, 5.0, 1.0897247358851685, 3, 3, 6, 1, 5, 3, 5, 4
TCD: TEXT IMAGE CHANGE DETECTION FOR MULTILINGUAL DOCUMENT COMPARISON,4.0, 4.0, 1.0, 5, 3, 3, 5, 5, 4, 3, 5
Graph Inference Acceleration by Bridging GNNs and MLPs with Self-Supervised Learning,4.4, 5.0, 1.2, 3, 5, 5, 4, 6, 2, 3, 3, 5, 4
A Theoretical Analysis of In-context Task Retrieval and Learning,5.2, 6.0, 1.16619037896906, 3, 3, 6, 3, 5, 4, 6, 2, 6, 3
Weaker MVI Condition: Extragradient Methods with Multi-Step Exploration,6.0, 5.5, 1.224744871391589, 8, 5, 6, 3, 5, 4, 5, 3
BTR: Binary Token Representations for Efficient Retrieval Augmented Language Models,6.5, 6.0, 0.8660254037844386, 6, 4, 8, 4, 6, 3, 6, 3
Towards Precise Prediction Uncertainty in GNNs: Refining GNNs with Topology-grouping Strategy,4.333333333333333, 5.0, 0.9428090415820634, 3, 5, 5, 3, 5, 2
How Language Models Learn Context-Free Grammars,5.0, 5.5, 1.224744871391589, 6, 5, 6, 3, 5, 3, 3, 5
Demystifying Embedding Spaces using Large Language Models,6.5, 6.5, 1.5, 8, 4, 5, 2, 8, 3, 5, 4
The Expressive Power of Low-Rank Adaptation,5.75, 6.0, 1.7853571071357126, 6, 2, 8, 4, 3, 4, 6, 3
Towards Category Unification of 3D Single Object Tracking on Point Clouds,6.666666666666667, 6.0, 0.9428090415820634, 6, 4, 8, 4, 6, 5
LLM-Rec: Personalized Recommendation via Prompting Large Language Models,3.75, 3.0, 1.299038105676658, 6, 3, 3, 4, 3, 4, 3, 5
FairReweighing: density estimation-based reweighing framework for improving separation in fair regression,3.75, 3.0, 1.299038105676658, 3, 4, 3, 5, 3, 5, 6, 4
You Only Query Once: An Efficient Label-Only Membership Inference Attack,5.666666666666667, 6.0, 0.4714045207910317, 5, 3, 6, 4, 6, 4
Teaching wiser Learning smarter: Multi-stage Decoupled Relational Knowledge Distillation with Adaptive Stage Selection,5.5, 5.5, 0.5, 5, 4, 6, 4, 6, 5, 5, 4
Mask Models are Token Level Contrastive Learners,3.75, 3.0, 1.299038105676658, 6, 4, 3, 3, 3, 3, 3, 2
Reinforcement Learning with Human Feedback: Learning Dynamic Choices via Pessimism,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 3, 3, 5, 3
PRISM: Privacy-Preserving Improved Stochastic Masking For Federated Generative Models,4.2, 5.0, 0.9797958971132712, 3, 3, 5, 4, 5, 3, 3, 5, 5, 3
MILE: Mutual Information LogDet Estimator,3.6, 3.0, 1.2000000000000002, 3, 4, 3, 5, 6, 4, 3, 4, 3, 4
From Language Modeling to Instruction Following: Understanding the Behavior Shift in LLMs after Instruction Tuning,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 3, 3, 4
Partitioned-Learned Count-Min Sketch,5.0, 5.5, 1.224744871391589, 3, 4, 6, 3, 5, 4, 6, 4
Frozen Transformers in Language Models Are Effective Visual Encoder Layers,5.25, 6.0, 1.299038105676658, 6, 4, 3, 4, 6, 4, 6, 4
Differentially Private Vision-Language Foundation Models via Image Captioning,5.0, 5.5, 1.224744871391589, 6, 4, 6, 3, 5, 3, 3, 4
Mathematical Justification of Hard Negative Mining via Isometric Approximation Theorem,5.5, 5.5, 1.8027756377319946, 8, 5, 3, 4, 5, 3, 6, 4
Bridging Neural and Symbolic Representations with Transitional Dictionary Learning,6.5, 6.5, 1.5, 8, 2, 8, 3, 5, 2, 5, 4
AirPhyNet: Harnessing Physics-Guided Neural Networks for Air Quality Prediction,5.5, 5.5, 1.8027756377319946, 6, 4, 8, 5, 5, 3, 3, 3
Scaff-PD: Communication Efficient Fair and Robust Federated Learning,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 4, 5, 4
Theory-of-Mind Enhanced Dialogue Generation in Situated Contexts,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 3, 3, 3
Pretrained deep models outperform GBDTs in Learning-To-Rank under label scarcity,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 5, 3, 3
SocioDojo: Building Lifelong Analytical Agents with Real-world Text and Time Series,6.333333333333333, 8.0, 2.357022603955158, 8, 3, 8, 4, 3, 3
Operator-theoretic Implicit Neural Representation,3.0, 3.0, 1.4142135623730951, 3, 3, 1, 4, 3, 3, 5, 4
ResPrompt: Residual Connection Prompting Advances Multi-Step Reasoning in Large Language Models,5.0, 4.5, 2.1213203435596424, 3, 3, 8, 3, 6, 3, 3, 5
ON LEARNABILITY AND EXPERIENCE REPLAY METHODS FOR GRAPH INCREMENTAL LEARNING ON EVOLVING GRAPHS,4.75, 5.0, 1.0897247358851685, 5, 3, 6, 5, 3, 4, 5, 4
Online Speculative Decoding,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 5, 2, 6, 3
Morphological Maze: Control Reconfigurable Soft Robots with Fine-grained Morphology Change,5.0, 5.5, 1.224744871391589, 3, 2, 6, 4, 5, 4, 6, 2
PRES: Toward Scalable Memory-Based Dynamic Graph Neural Networks,5.5, 5.5, 0.5, 6, 3, 5, 3
ROSA: Random Orthogonal Subspace Adaptation,6.0, 5.0, 1.4142135623730951, 8, 3, 5, 3, 5, 4
TEDDY: Trimming Edges with Degree-based Graph Diffusion Strategy,5.6, 6.0, 1.624807680927192, 5, 5, 8, 2, 6, 3, 6, 3, 3, 4
DAVIS: High-Quality Audio-Visual Separation with Generative Diffusion Models,4.25, 4.0, 1.299038105676658, 3, 5, 6, 4, 3, 4, 5, 3
Improving Private Training via In-distribution Public Data Synthesis and Generalization,4.75, 5.0, 1.0897247358851685, 6, 3, 3, 3, 5, 4, 5, 4
Learning to Jointly Understand Visual and Tactile Signals,5.5, 5.5, 0.5, 5, 3, 6, 3, 5, 2, 6, 3
Learning Communication-Efficient Optimizers,4.0, 4.0, 1.0, 3, 3, 5, 3, 5, 4, 3, 4
NeurRev: Train Better Sparse Neural Network Practically via Neuron Revitalization,6.333333333333333, 6.0, 1.247219128924647, 5, 3, 6, 4, 8, 4
Robustness Over Time: Understanding Adversarial Examples’ Effectiveness on Longitudinal Versions of Large Language Models,6.25, 7.0, 2.0463381929681126, 3, 4, 8, 4, 8, 4, 6, 2
Language Agents for Detecting Implicit Stereotypes in Text-to-image Models at Scale,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 3, 5, 3
SPDER: Semiperiodic Damping-Enabled Object Representation,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 3, 6, 4
A Reinforcement Learning Approach to Effective Forecasting of Pediatric Hypoglycemia in Diabetes I Patients: an extended de Bruijn Graph,3.0, 3.0, 0.0, 3, 5, 3, 3, 3, 4
Non-targeted Adversarial Attacks on Vision-Language Models via Maximizing Information Entropy,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 4, 5, 3, 5, 5
Data Overfitting for On-Device Super-Resolution with Dynamic Algorithm and Compiler Co-Design,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 4, 5, 3
Unsupervised Lifelong Learning with Sustained Representation Fairness,5.0, 5.5, 1.224744871391589, 6, 1, 3, 4, 5, 2, 6, 3
Transformers Learn Higher-Order Optimization Methods for In-Context Learning: A Study with Linear Models,4.0, 3.0, 1.4142135623730951, 3, 3, 3, 2, 6, 3
The Unreasonable Effectiveness of Linear Prediction as a Perceptual Metric,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 5, 3, 6, 3
ADOPT: Modified Adam Can Converge with the Optimal Rate with Any Hyperparameters,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 6, 3, 5, 4
Crystalformer: Infinitely Connected Attention for Periodic Structure Encoding,6.0, 5.5, 1.224744871391589, 5, 4, 6, 4, 5, 3, 8, 4
Fast Ensembling with Diffusion Schr\"odinger Bridge,5.4, 5.0, 1.624807680927192, 5, 5, 6, 3, 5, 3, 8, 4, 3, 4
Understanding Inter-Session Intentions via Complex Logical Reasoning,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 5, 5, 6, 3
Decoupling regularization from the action space,4.5, 4.5, 1.5, 6, 3, 3, 4
3D Morphable Master Face Generation: Towards Controllable Wolf Attacks against 2D and 3D Face Recognition Systems,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 3, 3, 4, 5, 4
Robust Similarity Learning with Difference Alignment Regularization,6.25, 6.0, 1.0897247358851685, 8, 5, 6, 4, 5, 5, 6, 5
Learning Riemannian Metrics for Interpolating Animations,3.75, 4.0, 1.920286436967152, 6, 4, 1, 5, 3, 4, 5, 4
Search and Retrieval in Semantic-Structural Representations of Novel Malware,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 1, 4, 3, 4
Overcoming the Pitfalls of Vision-Language Model Finetuning for OOD Generalization,5.25, 5.0, 0.4330127018922193, 5, 5, 6, 4, 5, 3, 5, 2
Learning Performance-Improving Code Edits,6.75, 8.0, 2.165063509461097, 8, 4, 3, 4, 8, 3, 8, 3
ConR: Contrastive Regularizer for Deep Imbalanced Regression,5.5, 5.5, 0.5, 6, 4, 5, 4, 6, 4, 5, 4
Enhancing Temporal Knowledge Graph Completion with Global Similarity and Weighted Sampling,5.0, 5.5, 1.224744871391589, 6, 3, 3, 5, 5, 3, 6, 4
Measuring Local and Shuffled Privacy of Gradient Randomized Response,4.4, 5.0, 1.2, 3, 3, 6, 4, 5, 3, 3, 2, 5, 3
RegionSpot: Unleashing the Power of Frozen Foundation Models for Open-World Region Understanding,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 6, 4, 5, 3
Neural scaling laws for phenotypic drug discovery,3.0, 3.0, 1.632993161855452, 3, 4, 1, 2, 5, 3
LoFT: Local Proxy Fine-tuning Improves Transferability to Large Language Model Attacks,3.5, 3.0, 0.8660254037844386, 3, 2, 5, 3, 3, 4, 3, 4
The Role of Counterfactual Explanations in Model Extraction Attacks,5.0, 5.5, 1.224744871391589, 5, 4, 6, 4, 3, 4, 6, 3
Quasi-Monte Carlo for 3D Sliced Wasserstein,6.5, 6.0, 0.8660254037844386, 8, 4, 6, 3, 6, 3, 6, 4
A Graph is Worth 1-bit Spikes: When Graph Contrastive Learning Meets Spiking Neural Networks,4.75, 5.0, 1.0897247358851685, 5, 3, 6, 2, 5, 4, 3, 2
A  Multi-resolution Dataset of Self-consistent Cloth Drapes for Physics-based Upsampling,5.25, 5.0, 0.4330127018922193, 5, 5, 6, 4, 5, 4, 5, 3
A Poincaré Inequality and Consistency Results for Signal Sampling on Large Graphs,7.0, 7.0, 1.0, 8, 4, 6, 2, 8, 4, 6, 3
PQ-VAE: Learning Hierarchical Discrete Representations with Progressive Quantization,2.3333333333333335, 3.0, 0.9428090415820634, 1, 4, 3, 4, 3, 4
Adversarial Training Should Be Cast as a Non-Zero-Sum Game,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 5, 4, 6, 3
Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 4, 6, 4
Efficient Redundancy-Free Graph Networks: Higher Expressiveness and Less Over-Squashing,5.0, 4.5, 2.1213203435596424, 3, 3, 8, 3, 3, 4, 6, 3
Motif-aware Attribute Masking for Molecular Graph Pre-training,4.6, 5.0, 1.3564659966250536, 3, 4, 6, 4, 5, 4, 6, 4, 3, 4
A Data-Driven Solution for the Cold Start Problem in Biomedical Image Classification,3.0, 3.0, 1.4142135623730951, 3, 5, 1, 5, 3, 3, 5, 2
Culture in Artificial Intelligence: A Literature Review & Proposal,4.0, 3.0, 2.943920288775949, 1, 4, 3, 3, 8, 5
Scaling up Trustless DNN Inference with Zero-Knowledge Proofs,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 2, 3, 3, 5, 3
Cascading Reinforcement Learning,6.25, 7.0, 2.0463381929681126, 3, 3, 8, 3, 6, 4, 8, 4
Trustless Audits without Revealing Data or Models,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 3, 5, 2
Complex priors and flexible inference in recurrent circuits with dendritic nonlinearities,5.5, 5.5, 0.5, 6, 2, 5, 2, 6, 3, 5, 3
Diffusion-TS: Interpretable Diffusion for General Time Series Generation,5.333333333333333, 5.0, 2.0548046676563256, 5, 3, 3, 4, 8, 4
Understanding the Approximation Gap of Neural Networks,4.25, 4.0, 1.299038105676658, 6, 3, 5, 2, 3, 3, 3, 3
Attribute Recognition with Image-Conditioned Prefix Language Modeling,5.75, 5.0, 1.299038105676658, 5, 4, 5, 4, 8, 3, 5, 4
Federated Learning with a Single Shared Image,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 5, 3, 4, 5, 3
Z-score Normalized SAC Plus Behavioural Cloning for Offline Reinforcement Learning,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 5, 1, 5, 3, 4
Gradient-norm Constrained Algorithm on Offline and Online Learning,3.0, 3.0, 1.632993161855452, 1, 5, 5, 3, 3, 3
ARM: Refining Multivariate Forecasting with Adaptive Temporal-Contextual Learning,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 4, 5, 3
BiDST: Dynamic Sparse Training is a Bi-Level Optimization Problem,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 4, 5, 3
On the hardness of learning under symmetries,8.0, 8.0, 0.0, 8, 3
Distributional off-policy evaluation with Bellman residual minimization,5.75, 6.0, 1.7853571071357126, 8, 2, 3, 3, 6, 4, 6, 3
Combining Axes Preconditioners through Kronecker Approximation for Deep Learning,7.333333333333333, 8.0, 0.9428090415820634, 8, 5, 6, 3, 8, 3
Dropout-Based Rashomon Set Exploration for Efficient Predictive Multiplicity Estimation,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 3, 6, 2, 6, 3
Towards the Characterization of Representations Learned via Capsule-based Network Architectures,5.333333333333333, 5.0, 0.4714045207910317, 6, 2, 5, 3, 5, 3
Improving High-Frequency Details in Cerebellum for Brain MRI Super-Resolution,2.0, 2.0, 1.0, 3, 5, 1, 2, 1, 5, 3, 4
Instance-aware 3D Semantic Segmentation powered by Shape Reconstruction and Classification,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 4
Copula Conformal prediction for multi-step time series prediction,6.0, 5.5, 1.224744871391589, 5, 4, 8, 4, 6, 3, 5, 4
An Image Is Worth 1000 Lies: Transferability of Adversarial Images across Prompts on Vision-Language Models,6.0, 6.0, 1.0954451150103321, 5, 4, 6, 4, 5, 5, 8, 4, 6, 4
Refined Partitioning Boosts MGDA: Introducing RP-MGDA for Multi-Objective Learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 4, 5, 4
One For All: Towards Training One Graph Model For All Classification Tasks,6.5, 5.5, 2.0615528128088303, 10, 5, 5, 4, 6, 4, 5, 3
Branch-GAN: Improving Text Generation with (not so) Large Language Models,6.25, 6.0, 1.0897247358851685, 6, 4, 5, 5, 6, 3, 8, 3
Learned Visual Features to Textual Explanations,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 4, 3, 4, 5, 5
Bag of Tricks to Boost Adversarial Transferability,6.0, 5.5, 1.224744871391589, 5, 4, 5, 4, 8, 3, 6, 4
Effective Structural Encodings via Local Curvature Profiles,5.75, 6.0, 1.7853571071357126, 3, 2, 6, 4, 8, 2, 6, 3
Statistical Inference for Deep Learning via Stochastic Modeling,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 2
Domain Randomization via Entropy Maximization,5.333333333333333, 6.0, 1.7950549357115013, 3, 3, 6, 3, 6, 5, 6, 3, 3, 5, 8, 3
ZeroNVS: Zero-shot 360-degree View Synthesis from a Single Real Image,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 6, 3, 5, 3
TRAM: Benchmarking Temporal Reasoning for Large Language Models,5.6, 6.0, 1.624807680927192, 3, 4, 6, 4, 8, 4, 5, 3, 6, 4
OMNI: Open-endedness via Models of human Notions of Interestingness,5.0, 5.5, 1.224744871391589, 6, 3, 6, 5, 5, 4, 3, 4
Centroid- and Orientation-aware Feature Learning,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4
Machine Unlearning for Image-to-Image Generative Models,5.5, 5.5, 1.8027756377319946, 8, 4, 6, 4, 5, 3, 3, 4
Classification with Conceptual Safeguards,6.25, 7.0, 2.0463381929681126, 6, 4, 8, 3, 8, 3, 3, 3
Linear attention is (maybe) all you need (to understand Transformer optimization),6.5, 6.0, 0.8660254037844386, 6, 4, 8, 3, 6, 3, 6, 3
Domain Generalization for Domain-Linked Classes,4.333333333333333, 5.0, 0.9428090415820634, 5, 5, 5, 4, 3, 4
Probabilistic Sampling-Enhanced Temporal-Spatial GCN: A Scalable Framework for Transaction Anomaly Detection in Ethereum Networks,3.5, 4.0, 1.6583123951777, 3, 3, 5, 4, 5, 4, 1, 5
MVDream: Multi-view Diffusion for 3D Generation,6.5, 6.0, 0.8660254037844386, 8, 4, 6, 4, 6, 3, 6, 5
Multilingual Mathematical Autoformalization,5.5, 5.5, 1.8027756377319946, 3, 4, 8, 4, 6, 3, 5, 4
Less is More: Toward Zero-Shot Local Scene Graph Generation via Foundation Models,4.25, 4.0, 1.299038105676658, 3, 3, 3, 4, 6, 5, 5, 3
Robust Model Based Reinforcement Learning Using $\mathcal{L}_1$ Adaptive Control,5.5, 5.5, 1.8027756377319946, 8, 5, 5, 3, 6, 2, 3, 4
Multitask Image-to-Image Diffusion Models with Fine-Grained Control,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 6, 3, 5, 4
Estimating Fréchet bounds for validating programmatic weak supervision,5.5, 5.5, 0.5, 5, 4, 6, 3, 5, 4, 6, 4
Headless Language Models: Learning without Predicting with Contrastive Weight Tying,6.25, 6.0, 1.0897247358851685, 8, 3, 5, 5, 6, 4, 6, 4
Cross-Task Gradient Harmonization for Meta-Learning,3.3333333333333335, 3.0, 0.7453559924999298, 3, 5, 3, 5, 3, 5, 3, 4, 3, 5, 5, 4
The Implicit Bias of Stochastic AdaGrad-Norm on Separable Data,5.0, 5.5, 2.5495097567963922, 8, 3, 6, 3, 1, 5, 5, 2
Federated Learning with Differential Privacy for End-to-End Speech Recognition,3.0, 3.0, 0.0, 3, 3, 3, 4, 3, 4
$\texttt{NAISR}$: A 3D Neural Additive Model for Interpretable Shape Representation,5.75, 6.0, 0.4330127018922193, 6, 5, 5, 4, 6, 4, 6, 3
Towards a statistical theory of data selection under weak supervision,7.25, 8.0, 1.299038105676658, 8, 4, 5, 2, 8, 2, 8, 3
Learning Multi-Modal Representation Alignments from Noisy Data-Pairs,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 5, 5, 3, 5
EA2N: Evidence-based AMR Attention Network for Fake News Detection,4.25, 4.0, 1.299038105676658, 3, 4, 3, 4, 6, 2, 5, 4
The Emergence of Reproducibility and Consistency in Diffusion Models,5.5, 5.5, 1.8027756377319946, 5, 4, 6, 4, 8, 4, 3, 3
Leveraging Optimization for Adaptive Attacks on Image Watermarks,5.5, 5.5, 0.5, 6, 3, 5, 4, 5, 3, 6, 5
ZeRO++: Extremely Efficient Collective Communication for Large Model Training,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 5, 5, 3, 4
FENNs: A Resource-Efficient Adaptive Privacy-Preserving Decentralized Learning Framework,1.5, 1.0, 0.8660254037844386, 1, 4, 1, 4, 1, 5, 3, 4
Large Language Models Cannot Self-Correct Reasoning Yet,6.0, 6.5, 2.1213203435596424, 8, 4, 8, 4, 3, 4, 5, 3
Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion,6.8, 6.0, 1.6, 6, 4, 6, 4, 6, 4, 10, 4, 6, 3
Towards Controllable Diffusion Models via Training-Phase Guided Exploration,4.5, 5.0, 0.8660254037844386, 5, 2, 5, 4, 3, 5, 5, 4
Behind the Myth of Exploration in Policy Gradients,6.0, 5.0, 1.4142135623730951, 5, 3, 5, 3, 8, 4
MUBen: Benchmarking the Uncertainty of Molecular Representation Models,5.75, 5.0, 1.299038105676658, 8, 4, 5, 3, 5, 5, 5, 3
Universal Backdoor Attacks,5.5, 5.5, 0.5, 6, 4, 5, 3, 5, 3, 6, 4
Codebook Features: Sparse and Discrete Interpretability for Neural Networks,5.5, 5.5, 0.5, 5, 3, 6, 3, 5, 3, 6, 3
Towards Zero Memory Footprint Spiking Neural Network Training,5.75, 5.0, 1.299038105676658, 5, 5, 5, 4, 8, 4, 5, 4
Eliciting Human Preferences with Language Models,5.0, 5.5, 1.224744871391589, 3, 3, 6, 4, 6, 2, 5, 4
Large Language Models as Rational Players in Competitive Economics Games,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 3, 3, 4, 3, 3
The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting - An Analytical Model,5.166666666666667, 5.5, 1.7716909687891083, 3, 4, 8, 5, 6, 3, 6, 3, 3, 4, 5, 4
GenCorres: Consistent Shape Matching via Coupled Implicit-Explicit Shape Generative Models,6.0, 6.5, 2.1213203435596424, 5, 4, 3, 3, 8, 3, 8, 4
STExplainer: Global Explainability of GNNs via Frequent SubTree Mining,5.0, 5.5, 1.224744871391589, 3, 5, 6, 5, 5, 3, 6, 3
Rethinking Teacher-Student Curriculum Learning under the Cooperative Mechanics of Experience,4.4, 5.0, 1.2, 3, 3, 5, 3, 5, 3, 3, 2, 6, 4
Diffusion-based Data Generation for Out-of-Distribution Object Detection,3.6666666666666665, 4.0, 1.49071198499986, 1, 5, 3, 4, 5, 4, 5, 4, 3, 3, 5, 3
MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback,6.25, 6.0, 1.0897247358851685, 5, 5, 6, 3, 8, 5, 6, 4
Masked Audio Generative Modeling,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 8, 5, 5, 4
Feature emergence via margin maximization: case studies in algebraic tasks,7.0, 7.0, 1.0, 6, 3, 8, 3, 8, 2, 6, 3
Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions,5.25, 6.0, 1.299038105676658, 6, 4, 6, 3, 3, 4, 6, 4
Learning to Solve Bilevel Programs with Binary Tender,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 4, 5, 4
Tabular Deep-SMOTE: A supervised autoencoder-based minority-oversampling technique for class-imbalanced tabular classification,3.0, 3.0, 0.0, 3, 3, 3, 5, 3, 2, 3, 3
Generating Molecular Conformer Fields,4.25, 4.0, 1.299038105676658, 5, 4, 6, 3, 3, 4, 3, 4
Manifold Diffusion Fields,6.0, 6.0, 0.0, 6, 4, 6, 3, 6, 4
Subwords as Skills: Tokenization for Sparse-Reward Reinforcement Learning,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 4, 5, 2, 6, 4
Fast Explanation of RBF-Kernel SVM Models Using Activation Patterns,6.0, 5.5, 1.224744871391589, 8, 4, 5, 4, 6, 4, 5, 3
Deepfake Detection with Contrastive Learning in Curved Spaces,4.25, 4.0, 1.299038105676658, 3, 4, 6, 3, 5, 4, 3, 4
Multiple Physics Pretraining for Physical Surrogate Models,5.2, 6.0, 1.16619037896906, 6, 4, 3, 5, 5, 3, 6, 3, 6, 4
Mastering Memory Tasks with World Models,6.333333333333333, 6.0, 1.247219128924647, 5, 5, 6, 4, 8, 4
Neur2RO: Neural Two-Stage Robust Optimization,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 4
Neural Networks Decoded: Targeted and Robust Analysis of Neural Network Decisions via Causal Explanations and Reasoning,3.0, 3.0, 0.0, 3, 5, 3, 3, 3, 4
Hindsight-DICE: Stable Credit Assignment for Deep Reinforcement Learning,4.25, 5.0, 1.920286436967152, 5, 4, 6, 4, 5, 4, 1, 5
A Study of the Effects of Transfer Learning on Adversarial Robustness,3.5, 3.0, 0.8660254037844386, 3, 3, 5, 4, 3, 5, 3, 5
DiffImpute: Tabular Data Imputation With Denoising Diffusion Probabilistic Model,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 5, 3, 2
Efficient local linearity regularization to overcome catastrophic overfitting,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 5
Forget-Me-Not: Learning to Forget in Text-to-Image Diffusion Models,4.0, 5.0, 1.7320508075688772, 1, 2, 5, 4, 5, 5, 5, 3
On the Stability of Iterative Retraining of Generative Models on their own Data,6.25, 6.0, 1.0897247358851685, 6, 3, 5, 3, 8, 4, 6, 3
FENDA-FL: Personalized Federated Learning on Heterogeneous Clinical Datasets,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 5, 5, 3, 3, 4
Compressing Latent Space via Least Volume,5.5, 5.5, 0.5, 5, 3, 6, 4, 6, 4, 5, 4
Cultural and Linguistic Diversity Improves Visual Representations,5.666666666666667, 6.0, 2.0548046676563256, 3, 5, 6, 4, 8, 4
LUMEN-PRO: Automating Multi-Task Learning on Optical Neural Networks with Weight Sharing and Physical Rotation,5.666666666666667, 6.0, 2.0548046676563256, 8, 3, 6, 4, 3, 4
Episodic Memory Theory for the Mechanistic Interpretation of Recurrent Neural Networks,3.75, 4.0, 1.920286436967152, 1, 4, 6, 3, 5, 3, 3, 4
A Differentiable Sequence Model Perspective on Policy Gradients,4.25, 4.0, 1.299038105676658, 3, 4, 6, 3, 3, 4, 5, 3
LOLAMEME: LOGIC LANGUAGE MEMORY MECHANISTIC FRAMEWORK,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 3
Fooling Contrastive Language-Image Pre-Training with CLIPMasterPrints,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 4, 3, 4
Speed Limits for Deep Learning,5.666666666666667, 6.0, 0.4714045207910317, 5, 2, 6, 4, 6, 2
Towards Enhanced Controllability of Diffusion Models,3.75, 3.0, 1.299038105676658, 3, 5, 3, 4, 6, 4, 3, 4
Make Small Data Great Again: Learning from Partially Annotated Data via Policy Gradient for Multi-Label Classification Tasks,4.25, 4.0, 1.299038105676658, 3, 4, 5, 3, 6, 4, 3, 4
Parameter-Efficient Multi-Task Model Fusion with Partial Linearizeation,6.5, 6.5, 1.5, 8, 2, 5, 4, 5, 2, 8, 2
Habitat 3.0: A Co-Habitat for Humans Avatars and Robots,6.666666666666667, 6.0, 0.9428090415820634, 8, 5, 6, 3, 6, 4
OLGA: One-cLass Graph Autoencoder,3.0, 3.0, 1.4142135623730951, 3, 4, 5, 4, 3, 2, 1, 4
Removing Spurious Concepts from Neural Network Representations via Joint Subspace Estimation,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 4, 5, 4
Let's Verify Step by Step,5.5, 5.5, 1.8027756377319946, 8, 3, 3, 3, 5, 4, 6, 3
SEE-OoD: Supervised Exploration for Enhanced Out-of-Distribution Detection,4.75, 4.0, 2.0463381929681126, 8, 4, 3, 4, 5, 3, 3, 5
Do Models Explain Themselves? Counterfactual Simulatability of Natural Language Explanations,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 4, 5, 4
Masked Completion via Structured Diffusion with White-Box Transformers,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 4, 5, 4
LaVie: High-Quality Video Generation with Cascaded Latent Diffusion Models,5.0, 5.5, 1.224744871391589, 3, 4, 5, 5, 6, 5, 6, 4
Neuro-Causal Factor Analysis,4.8, 5.0, 0.9797958971132712, 6, 2, 3, 3, 5, 3, 5, 4, 5, 4
Effectively Leveraging Capacity for Improved Deterministic Robustness Certification,6.333333333333333, 6.0, 1.247219128924647, 8, 3, 6, 2, 5, 3
Open-world Instance Segmentation: Top-down Learning with Bottom-up Supervision,4.75, 5.0, 1.0897247358851685, 5, 5, 6, 4, 5, 5, 3, 4
HawkesVAE: Sequential Patient Event Synthesis for Clinical Trials,4.25, 4.0, 1.299038105676658, 3, 4, 3, 4, 6, 4, 5, 3
Reinforcement Learning with Elastic Time Steps,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 6, 3, 3, 4
Navigating the Impending Arms Race between Attacks and Defenses in LLMs,2.0, 2.0, 1.0, 3, 4, 3, 2, 1, 5, 1, 4
Generalising Multi-Agent Cooperation through Task-Agnostic Communication,4.0, 4.0, 1.0, 5, 4, 3, 3, 5, 4, 3, 4
Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems.,8.5, 9.0, 1.6583123951777, 6, 4, 10, 3, 8, 4, 10, 2
Retrosynthesis Prediction via Search in (Hyper) Graph,5.0, 5.0, 0.0, 5, 5, 5, 4, 5, 4
Comfetch: Federated Learning of Large Networks on Constrained Clients via Sketching,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 6, 4, 3, 3
Self-Alignment with Instruction Backtranslation,8.0, 8.0, 0.0, 8, 4, 8, 4, 8, 5, 8, 4
MEND: Meta Demonstration Distillation for Efficient and Effective In-Context Learning,6.25, 6.0, 1.0897247358851685, 6, 4, 8, 4, 5, 5, 6, 4
Test Error Guarantees for Batch-normalized two-layer ReLU Networks Trained with Gradient Descent,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 2, 5, 4, 3, 5
SelfVC: Voice Conversion With Iterative Refinement using Self Transformations,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 4
The LLM Surgeon,5.0, 5.0, 0.0, 5, 5, 5, 4, 5, 3
Your CLIP Model Might Be Undertrained,4.25, 4.0, 1.299038105676658, 6, 5, 5, 5, 3, 4, 3, 4
Learning to Plan and Generate Text with Citations,5.25, 5.0, 1.7853571071357126, 5, 4, 3, 4, 8, 4, 5, 4
POI-based Traffic Generation via Supervised Contrastive Learning on Reconstructed Graph,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 3, 3, 3, 3, 3
Towards Explaining Deep Neural Network Compression Through a Probabilistic Latent Space,4.25, 4.0, 1.299038105676658, 5, 4, 6, 3, 3, 2, 3, 3
Perceptual Measurements Distances and Metrics,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 5, 2, 3, 3
Rotational Equilibrium: How Weight Decay Balances Learning Across Neural Networks,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 3, 5, 4, 5, 4
Fast Unsupervised Deep Outlier Model Selection with Hypernetworks,4.2, 5.0, 0.9797958971132712, 3, 3, 5, 3, 5, 3, 5, 3, 3, 4
Weak Correlations as the Underlying Principle for Linearization of Gradient-Based Learning Systems,2.3333333333333335, 3.0, 0.9428090415820634, 1, 4, 3, 3, 3, 4
Prompt-tuning Latent Diffusion Models for Inverse Problems,5.25, 6.0, 1.299038105676658, 6, 5, 3, 4, 6, 4, 6, 5
Going beyond familiar features for deep anomaly detection,5.0, 6.0, 1.4142135623730951, 6, 4, 6, 3, 3, 4
Delve into Image Style Diffusion Towards Schrödinger Bridge Problem,3.5, 4.0, 1.6583123951777, 5, 4, 3, 3, 5, 3, 1, 5
Reasoning-Enhanced Object-Centric Learning for Videos,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 5, 5, 3, 4
Language Model Inversion,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 5, 3, 6, 4
Decomposed Diffusion Sampler for Accelerating Large-Scale Inverse Problems,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 2, 6, 3
Democratizing Fine-grained Visual Recognition with Large Language Models,6.0, 5.0, 1.4142135623730951, 5, 5, 5, 4, 8, 4
Intriguing Properties of Generative Classifiers,6.333333333333333, 6.0, 1.247219128924647, 6, 3, 5, 4, 8, 4
Model Selection of Anomaly Detectors in the Absence of Labeled Validation Data,5.333333333333333, 5.0, 0.4714045207910317, 5, 5, 6, 4, 5, 3
Growing Tiny Networks: Spotting Expressivity Bottlenecks and Fixing Them Optimally,4.75, 5.0, 1.0897247358851685, 6, 3, 3, 3, 5, 2, 5, 4
Alpagasus: Training a Better Alpaca Model with Fewer Data,5.333333333333333, 5.0, 0.4714045207910317, 5, 5, 5, 4, 6, 4
Learning then Leveraging Structures Help with Complex Compositional Causal Sequential Tasks in Inverse Reinforcement Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 5, 4, 3, 4
Stylist: Style-Driven Feature Ranking for Robust Novelty Detection,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 3, 3, 4
EntProp: High Entropy Propagation via Auxiliary Batch Normalization Layers,4.0, 4.0, 1.0, 5, 4, 3, 3, 5, 3, 3, 5
Universal Graph Random Features,5.75, 6.0, 1.7853571071357126, 6, 3, 6, 4, 8, 4, 3, 5
Advancing Vision Transformers with Group-Mix Attention,4.25, 4.0, 1.299038105676658, 5, 5, 3, 4, 6, 3, 3, 5
LLM-Codebook for Extreme Compression of Large Language Models,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 3, 4, 5, 5
Soft Convex Quantization: Revisiting Vector Quantization with Convex Optimization,4.5, 4.5, 1.5, 6, 4, 6, 4, 3, 3, 3, 3
Model-Free Regret-Optimal Best Policy Identification in Online CMDPs,5.8, 6.0, 0.39999999999999997, 6, 4, 6, 4, 6, 2, 6, 3, 5, 4
HyperAttention: Long-context Attention in Near-Linear Time,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 3, 6, 3
Memorization Through the Lens of Curvature of Loss Function Around Samples,5.2, 5.0, 0.39999999999999997, 5, 4, 5, 4, 5, 4, 5, 4, 6, 4
Repelling Random Walks,5.0, 5.0, 0.0, 5, 3, 5, 4
Fast Imitation via Behavior Foundation Models,7.333333333333333, 8.0, 0.9428090415820634, 8, 3, 6, 3, 8, 4
Stabilizing Backpropagation Through Time to Learn Complex Physics,5.5, 5.5, 2.5, 3, 3, 3, 4, 8, 2, 8, 3
Towards Understanding Neural Collapse: The Effects of Batch Normalization and Weight Decay,4.0, 4.0, 1.0, 5, 4, 5, 3, 3, 3, 3, 4
RACH-Space: Reconstructing Adaptive Convex Hull Space with applications in weak supervision,3.8, 3.0, 0.9797958971132712, 3, 2, 5, 4, 5, 5, 3, 2, 3, 2
Learning Interactive Real-World Simulators,6.75, 7.0, 1.299038105676658, 8, 3, 8, 4, 5, 4, 6, 4
Active Probabilistic Drug Discovery,2.5, 3.0, 0.8660254037844386, 1, 5, 3, 3, 3, 2, 3, 5
Optimization and Generalizability: Fair Benchmarking for Stochastic Algorithms,4.75, 4.0, 2.0463381929681126, 8, 3, 5, 3, 3, 3, 3, 4
Learning in reverse causal strategic environments with ramifications on two sided markets,5.5, 5.5, 2.5, 3, 3, 8, 4
ViFu: Visible Part Fusion for Multiple Scene Radiance Fields,5.0, 5.0, 1.0954451150103321, 3, 4, 5, 4, 6, 3, 5, 4, 6, 4
Horizon-free Reinforcement Learning in Adversarial Linear Mixture MDPs,6.0, 6.0, 0.0, 6, 4, 6, 3, 6, 3, 6, 4
Chain-of-Verification Reduces Hallucination in Large Language Models,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 3, 3, 4, 5, 4
Backdoor Federated Learning by Poisoning Backdoor-Critical Layers,5.5, 5.5, 0.5, 6, 4, 5, 4, 6, 4, 5, 3
PAPM: A Physics-aware Proxy Model for Process Systems,5.0, 5.5, 1.224744871391589, 3, 4, 6, 2, 5, 3, 6, 2
NeuralQP: A General Hypergraph-based Optimization Framework for Large-scale Quadratically Constrained Quadratic Programs,4.0, 5.0, 1.7320508075688772, 5, 4, 5, 4, 5, 4, 1, 4
Task Adaptation from Skills: Information Geometry Disentanglement and New Objectives for Unsupervised Reinforcement Learning,6.75, 7.0, 1.299038105676658, 8, 5, 5, 3, 6, 3, 8, 4
Active Probabilistic Clustering,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4
RECOMBINER: Robust and Enhanced Compression with Bayesian Implicit Neural Representations,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 4, 5, 4
Inductive Transformers: How Large Language Models Form Concepts And How to Make Them Even Better At It,3.0, 3.0, 1.4142135623730951, 3, 3, 3, 2, 1, 5, 5, 2
Candidate Label Set Pruning: A Data-centric Perspective for Deep Partial-label Learning,7.0, 7.0, 1.0, 8, 4, 6, 4, 8, 4, 6, 4
MIPGen: Learning to Generate Scalable MIP Instances,4.75, 4.0, 2.0463381929681126, 3, 4, 8, 2, 5, 3, 3, 2
Multi-Group Tri-plane Based Local Occupancy Estimation for Object Grasping,5.5, 5.5, 0.5, 5, 4, 6, 3, 5, 3, 6, 4
IMAST: Importance-Aware Statistical Test for Transformer Interpretability Evaluation,4.25, 4.0, 1.299038105676658, 5, 5, 6, 4, 3, 4, 3, 4
TorSeq: Torsion Sequential Modeling for Molecular 3D Conformation Generation,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 4, 3, 4
Visual Prompting Upgrades Neural Network Sparsification: A Data-Model Perspective,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 5, 4, 6, 4
Light-MILPopt: Solving Large-scale Mixed Integer Linear Programs with Small-scale Optimizer and Small Training Dataset,4.5, 4.5, 1.5, 3, 4, 3, 4, 6, 3, 6, 4
Emergent Robust Communication for Multi-Round Interactions in Noisy Environments,4.25, 4.0, 1.299038105676658, 6, 3, 3, 4, 3, 4, 5, 4
STARformer: STructural Attention tRansformer for Long-term Time Series Forecasting,2.75, 2.0, 2.0463381929681126, 1, 4, 6, 3, 1, 4, 3, 3
SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression,6.0, 5.5, 1.224744871391589, 5, 4, 8, 5, 6, 5, 5, 4
Lightweight Pre-trained Transformers for Remote Sensing Timeseries,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 3, 4, 6, 4
Towards Understanding Sycophancy in Language Models,5.5, 5.5, 1.8027756377319946, 6, 4, 3, 4, 8, 3, 5, 4
Constructing Informative Subtask Representations for Multi-Agent Coordination,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 3, 5, 6, 3
RIME: Robust Preference-based Reinforcement Learning with Noisy Human Preferences,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 5, 4, 3, 5
Feature Accentuation: Explaining 'what' features respond to in natural images,4.75, 4.0, 2.0463381929681126, 5, 3, 8, 3, 3, 3, 3, 4
Network Memory Footprint Compression Through Jointly Learnable Codebooks and Mappings,6.0, 5.0, 1.4142135623730951, 5, 2, 8, 2, 5, 4
VTranM: Vision Transformer Explainability with Vector Transformations Measurement,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 5, 5, 3, 3
FastDCFlow: Fast and Diverse Counterfactual Explanations Using Normalizing Flows,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 4
HOSC: Hyperbolic Oscillating Periodic Activations for Sharp Feature Preservation in Implicit Neural Representations,4.666666666666667, 3.0, 2.357022603955158, 3, 3, 8, 4, 3, 4
Towards image compression with perfect realism at ultra-low bitrates,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 4, 6, 4
Scaling Laws of RoPE-based Extrapolation,6.0, 5.0, 2.943920288775949, 5, 5, 3, 4, 10, 4
MAS: Multi-view Ancestral Sampling for 3D motion generation using 2D diffusion,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 4, 5, 3
NuwaDynamics: Discovering and Updating in Causal Spatio-Temporal Modeling,6.5, 6.5, 1.5, 8, 4, 8, 5, 5, 3, 5, 5
Enable Quantum Graph Neural Networks on a Single Qubits,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 2, 5, 4, 3, 5
Rethinking the bert-like pretraining for dna sequences,5.0, 5.5, 1.224744871391589, 5, 3, 6, 3, 3, 3, 6, 4
Enhancing Kernel Flexibility via Learning Asymmetric Locally-Adaptive Kernels,5.333333333333333, 5.0, 2.0548046676563256, 3, 4, 5, 4, 8, 4
Foundation Reinforcement Learning: towards Embodied Generalist Agents with Foundation Prior Assistance,5.25, 5.0, 1.7853571071357126, 8, 4, 5, 3, 5, 4, 3, 4
Learning within Sleeping: A Brain-Inspired Bayesian Continual Learning Framework,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 4, 5, 4, 5, 4
Embracing Diversity: Zero-shot Classification Beyond a Single Vector per Class,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 3, 3, 4
On the Verification Complexity of Deterministic Nonsmooth Nonconvex Optimization,4.4, 5.0, 1.2, 3, 3, 3, 4, 5, 3, 6, 3, 5, 3
V-DETR: DETR with Vertex Relative Position Encoding for 3D Object Detection,6.0, 5.5, 1.224744871391589, 6, 3, 5, 5, 8, 4, 5, 4
Factored-NeuS: Reconstructing Surfaces Illumination and Materials of Possibly Glossy Objects,5.75, 6.0, 1.7853571071357126, 6, 5, 8, 4, 6, 4, 3, 4
TETA: Temporal-Enhanced Text-to-Audio Generation,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 5, 4, 3, 4
A Branching Decoder for Set Generation,6.0, 6.0, 0.0, 6, 4, 6, 3, 6, 4, 6, 4
Concise and Organized Perception Facilitates Large Language Models for Deductive Reasoning,5.25, 5.0, 1.7853571071357126, 3, 4, 8, 3, 5, 2, 5, 3
Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View,5.5, 6.5, 2.8722813232690143, 5, 3, 8, 4, 8, 3, 1, 4
Label Privacy Source Coding in Vertical Federated Learning,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 3, 5, 5, 5, 4
Data Filtering Networks,6.25, 7.0, 2.0463381929681126, 6, 5, 3, 5, 8, 4, 8, 3
Fair Text-to-Image Diffusion via Fair Mapping,5.4, 5.0, 0.48989794855663565, 6, 3, 5, 2, 6, 4, 5, 4, 5, 4
Multi-task Learning with 3D-Aware Regularization,6.0, 6.0, 0.0, 6, 5, 6, 4, 6, 4, 6, 3
Dissecting Causal Biases,3.75, 3.0, 1.299038105676658, 3, 3, 3, 3, 3, 4, 6, 3
Disentangled Acoustic Fields For Multimodal Physical Scene Understanding,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 6, 3, 5, 3
Making Multimodal Generation Easier: When Diffusion Models Meet LLMS,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 5, 5, 4, 3, 4
Efficient Streaming Language Models with Attention Sinks,7.0, 7.0, 1.0, 8, 4, 6, 4, 8, 4, 6, 5
Uncovering hidden geometry in Transformers via disentangling position and context,4.333333333333333, 5.0, 0.9428090415820634, 3, 3, 5, 3, 5, 3
ImAD: An End-to-End Method for Unsupervised Anomaly Detection in the Presence of Missing Values,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 3
GraphText: Graph Learning in Text Space,4.25, 4.0, 1.299038105676658, 5, 5, 6, 4, 3, 4, 3, 4
Predict-then-Optimize  via Learning to Optimize from Features,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 5, 3, 3, 4
OWL: A Large Language Model for IT Operations,5.5, 5.5, 0.5, 5, 3, 5, 3, 6, 3, 6, 3
Teach Large Language Models the Concept of Meta-cognition to Reduce Hallucination Text Generation,3.25, 3.0, 1.7853571071357126, 3, 4, 1, 4, 3, 4, 6, 3
Dual Diffusion Model for One-Shot High-Fidelity Talking Head Generation,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 4, 5, 2, 5, 4
PROTEIN DESIGNER BASED ON SEQUENCE PROFILE USING ULTRAFAST SHAPE RECOGNITION,4.5, 5.0, 0.8660254037844386, 3, 3, 5, 3, 5, 4, 5, 4
Bag of Features: New Baselines for GNNs for Link Prediction,4.25, 4.0, 1.299038105676658, 6, 4, 5, 4, 3, 4, 3, 4
Unsupervised Feature Selection using a Basis of Feature Space and Self-Representation Learning,5.333333333333333, 5.0, 0.4714045207910317, 6, 5, 5, 4, 5, 2
SimSCOOD: Systematic Analysis of Out-of-Distribution Generalization in Fine-tuned Source Code Models,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 4, 5, 3, 5, 3
Formally Specifying the High-Level Behavior of LLM-Based Agents,4.0, 3.0, 1.2649110640673518, 5, 4, 3, 4, 6, 4, 3, 4, 3, 4
Retrieval-Based Video Language Model for Efficient Long Video Question Answering,4.0, 4.0, 1.0, 5, 4, 5, 4, 3, 4, 3, 3
Temporal Spiking Generative Adversarial Networks for Heading Direction Decoding,4.75, 5.0, 2.48746859276655, 5, 4, 8, 4, 1, 4, 5, 4
Towards Control-Centric Representations in Reinforcement Learning from Images,5.0, 4.5, 2.1213203435596424, 3, 3, 6, 4, 8, 4, 3, 5
SNN-LPCG: Spiking Neural Networks with Local Plasticity Context Gating for Lifelong Learning,3.75, 4.0, 1.920286436967152, 5, 3, 6, 5, 3, 2, 1, 4
Rethink Depth Separation with Intra-layer Links,4.6, 5.0, 1.8547236990991407, 1, 5, 6, 2, 5, 2, 5, 3, 6, 4
DMBP: Diffusion model based predictor for robust offline reinforcement learning against state observation perturbations,6.75, 7.0, 1.299038105676658, 8, 3, 5, 4, 6, 4, 8, 3
Generative Sliced MMD Flows with Riesz Kernels,5.5, 5.5, 0.5, 6, 3, 6, 4, 5, 2, 5, 3
Optimal Action Abstraction for Imperfect Information Extensive-Form Games,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 3, 3, 4, 5, 4
Alignment as Reward-Guided Search,5.5, 5.5, 1.8027756377319946, 3, 4, 8, 3, 5, 4, 6, 3
Compositional Preference Models for Aligning LMs,5.75, 6.0, 1.7853571071357126, 6, 4, 6, 4, 3, 3, 8, 4
Label-free Node Classification on Graphs with Large Language Models (LLMs),4.75, 5.0, 1.0897247358851685, 6, 5, 3, 4, 5, 4, 5, 4
AutoM3L: Automated Multimodal Machine Learning with Large Language Model,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 4
Text to Image for Multi-Label Image Recognition with Joint Prompt-Adapter Learning,5.0, 5.5, 1.224744871391589, 5, 3, 6, 2, 6, 4, 3, 4
Pre-Training and Fine-Tuning Generative Flow Networks,6.25, 6.0, 1.0897247358851685, 5, 4, 6, 4, 8, 3, 6, 4
Sliced Wasserstein Estimation with Control Variates,5.75, 6.0, 0.4330127018922193, 5, 4, 6, 4, 6, 3, 6, 3
Neural Rate Control for Learned Video Compression,6.0, 5.5, 1.224744871391589, 8, 5, 6, 4, 5, 4, 5, 5
MultiReAct: Multimodal Tools Augmented Reasoning-Acting Traces for Embodied Agent Planning,4.75, 4.0, 2.0463381929681126, 8, 3, 5, 4, 3, 4, 3, 3
Vision-based Discovery of Nonlinear Dynamics for 3D Moving Target,6.5, 6.5, 1.5, 5, 5, 8, 3
DiffusionShield: A Watermark for Data Copyright Protection against Generative Diffusion Models,5.75, 5.0, 1.299038105676658, 5, 3, 8, 5, 5, 4, 5, 5
Convolutions Through the Lens of Tensor Networks,6.0, 5.5, 1.224744871391589, 5, 3, 8, 5, 5, 2, 6, 4
Multi-Task Reinforcement Learning with Mixture of Orthogonal Experts,5.2, 6.0, 1.16619037896906, 6, 3, 6, 3, 6, 3, 3, 5, 5, 4
Self-Tuning Self-Supervised Anomaly Detection,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 3, 5, 4
Enhanced Label Propagation through Affinity Matrix Fusion for Source-Free Domain Adaptation,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 6, 4, 5, 5
Local Composite Saddle Point Optimization,4.5, 4.5, 1.5, 6, 4, 3, 4
Towards Poisoning Fair Representations,5.6, 6.0, 1.624807680927192, 6, 4, 6, 3, 8, 3, 5, 3, 3, 5
Efficient Distributed Training with Full Communication-Computation Overlap,5.6, 6.0, 1.624807680927192, 8, 2, 3, 4, 6, 4, 5, 4, 6, 3
Multi-Task Reinforcement Learning with Shared-Unique Features and Task-Aware Prioritized Experience Replay,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4
Nonparametric Classification on Low Dimensional Manifolds using Overparameterized Convolutional Residual Networks,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 3, 6, 3, 5, 3
Cross-Modal Contextualized Diffusion Models for Text-Guided Visual Generation and Editing,6.25, 6.0, 1.0897247358851685, 6, 4, 8, 3, 5, 4, 6, 3
Theoretical Analysis of Robust Overfitting for Wide DNNs: An NTK Approach,5.4, 5.0, 0.48989794855663565, 5, 3, 6, 3, 5, 4, 6, 3, 5, 2
What's in a Prior? Learned Proximal Networks for Inverse Problems,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 3, 6, 3, 5, 3
Fantastic Generalization Measures are Nowhere to be Found,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 4, 5, 3, 6, 4
Large Language Models Are Not Strong Abstract Reasoners,5.5, 5.5, 0.5, 5, 4, 6, 3
CADS: Unleashing the Diversity of Diffusion Models through Condition-Annealed Sampling,7.333333333333333, 8.0, 0.9428090415820634, 6, 4, 8, 4, 8, 4
Efficient Precision and Recall Metrics for Assessing Generative Models using Hubness-aware Sampling,5.666666666666667, 6.0, 0.4714045207910317, 6, 2, 6, 4, 5, 4
Slightly Harmonizing Certified Robust Radius and Accuracy,4.75, 4.0, 2.0463381929681126, 3, 2, 8, 3, 3, 4, 5, 3
LL-VQ-VAE: Learnable Lattice Vector-Quantization For Efficient Representations,4.75, 5.0, 1.0897247358851685, 5, 2, 6, 4, 5, 2, 3, 4
Self-distillation for diffusion models,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 4
Robust agents learn causal world models,7.0, 6.0, 1.7320508075688772, 6, 3, 6, 4, 10, 4, 6, 3
XAL: EXplainable Active Learning Makes Classifiers Better Low-resource Learners,4.0, 4.0, 1.0, 3, 4, 5, 4, 5, 4, 3, 5
LLM-Deliberation: Evaluating LLMs with Interactive Multi-Agent Negotiation Game,5.0, 5.5, 1.224744871391589, 3, 4, 6, 3, 5, 3, 6, 5
Towards Enhancing Time Series Contrastive Learning: A Dynamic Bad Pair Mining Approach,6.25, 6.0, 1.0897247358851685, 8, 4, 6, 3, 5, 4, 6, 3
IS SYNTHETIC DATA USEFUL FOR TRANSFER LEARNING? AN INVESTIGATION INTO DATA GENERATION VOLUME AND UTILIZATION,5.5, 5.5, 1.8027756377319946, 3, 4, 6, 4, 8, 5, 5, 4
A Self-Supervised Pre-Training Model for Time Series Classification based on Data Pre-Processing,2.5, 3.0, 0.8660254037844386, 1, 4, 3, 3, 3, 4, 3, 3
Adaptive Hierarchical Certification for Semantic Segmentation using Randomized Smoothing,3.75, 3.0, 1.299038105676658, 3, 4, 3, 3, 6, 1, 3, 3
Subgraph-To-Node Translation for Efficient Representation Learning of Subgraphs,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 3, 3, 6, 4
Interpretable Latent Distributions Using Space-Filling Curves,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 5, 5, 3
POUTA - Produce once utilize twice for anomaly detection,4.333333333333333, 5.0, 0.9428090415820634, 3, 5, 5, 4, 5, 4
A Simple Open-Loop Baseline for Reinforcement Learning Locomotion Tasks,4.25, 4.0, 1.299038105676658, 5, 5, 3, 4, 3, 4, 6, 4
Align after Pre-train: Improving Multilingual Generative Models with Cross-lingual Alignment,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 3, 4, 5, 4
Vicinal Assessment of Model Generalization,4.25, 4.0, 1.299038105676658, 5, 4, 3, 5, 6, 4, 3, 3
CARD: Certifiable Reweighting for Single Domain Generalization Object Detection,4.0, 4.0, 1.0, 5, 5, 3, 5
Align With Purpose: Optimize Desired Properties in CTC Models with a General Plug-and-Play Framework,5.666666666666667, 6.0, 2.0548046676563256, 6, 4, 8, 5, 3, 4
IRGen: Generative Modeling for Image Retrieval,5.0, 5.5, 1.224744871391589, 3, 3, 5, 2, 6, 4, 6, 4
Image Inpainting via Iteratively Decoupled Probabilistic Modeling,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 4, 6, 3, 5, 4
Regularized KL-Divergence for well-defined function space variational inference in BNNs,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 3, 4, 5, 3
Decoding Natural Images from EEG for Object Recognition,5.5, 5.5, 2.5, 3, 4, 3, 5, 8, 4, 8, 3
Image2Sentence based Asymmetrical Zero-shot Composed Image Retrieval,5.25, 6.0, 1.299038105676658, 6, 5, 6, 5, 3, 2, 6, 4
Open-Source Can Be Dangerous: On the Vulnerability of Value Alignment in Open-Source LLMs,5.333333333333333, 5.0, 0.4714045207910317, 5, 5, 6, 3, 5, 4
DISK: Domain Inference for Discovering Spurious Correlation with KL-Divergence,3.25, 3.0, 1.7853571071357126, 1, 4, 6, 4, 3, 4, 3, 3
Individual/Joint Deblurring and Low-Light Image Enhancement in One Go via Unsupervised Deblurring Paradigm,4.0, 4.0, 1.0, 3, 4, 3, 5, 5, 4, 5, 5
Bespoke Solvers for Generative Flow Models,6.8, 8.0, 1.469693845669907, 5, 3, 8, 3, 8, 4, 8, 3, 5, 4
Neural Priority Queues for Graph Neural Networks (GNNs),4.25, 4.0, 1.299038105676658, 3, 4, 3, 3, 5, 3, 6, 3
You Only Look at Screens: Multimodal Chain-of-Action Agents,5.25, 5.0, 0.4330127018922193, 6, 3, 5, 4, 5, 4, 5, 3
Learning to Compute Gröbner Bases,5.0, 6.0, 1.4142135623730951, 6, 3, 6, 2, 3, 3
A New Tensor Network: Tubal Tensor Train Network and its Applications,4.25, 4.0, 1.299038105676658, 3, 5, 3, 3, 5, 5, 6, 3
LCOT: Linear Circular Optimal Transport,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 3
GRAPES: Learning to Sample Graphs for Scalable Graph Neural Networks,4.75, 4.0, 2.0463381929681126, 5, 4, 3, 5, 8, 4, 3, 2
Reinforcement Learning based Image Generation via Visual Consensus Evaluation,2.5, 3.0, 0.8660254037844386, 1, 4, 3, 3, 3, 4, 3, 4
Unveiling the Pitfalls of Knowledge Editing for Large Language Models,6.5, 6.5, 1.5, 5, 3, 5, 3, 8, 4, 8, 3
Catastrophic Negative Transfer: An Overlooked Problem in Continual Reinforcement Learning,4.75, 4.0, 2.0463381929681126, 3, 5, 8, 4, 5, 4, 3, 3
InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 3, 5, 5
Physics-informed neural networks with unknown measurement noise,4.25, 4.0, 1.299038105676658, 6, 3, 3, 3, 5, 4, 3, 3
On Compositional Generalization in Language Models,3.75, 3.0, 1.299038105676658, 3, 4, 3, 3, 6, 4, 3, 4
Recovery of Training Data from Overparameterized Autoencoders: An Inverse Problem Perspective,4.25, 4.0, 1.299038105676658, 6, 3, 3, 3, 5, 2, 3, 4
Decongestion by Representation: Learning to Improve Economic Welfare in Marketplaces,7.0, 7.0, 1.0, 6, 3, 6, 3, 8, 2, 8, 3
DiffEnc: Variational Diffusion with a Learned Encoder,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 4, 5, 1, 5, 2
SignKD: Multi-modal Hierarchical Knowledge Distillation for Continuous Sign Language Recognition,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 5, 3, 5
Leveraging augmented-Lagrangian techniques for differentiating over infeasible quadratic programs in machine learning,7.0, 7.0, 1.0, 6, 4, 8, 3, 8, 3, 6, 4
Boolformer: Symbolic Regression of Logic Functions with Transformers,5.5, 5.5, 1.8027756377319946, 3, 3, 5, 4, 8, 3, 6, 4
No Wrong Turns: The Simple Geometry Of Neural Networks Optimization Paths,5.0, 4.5, 2.1213203435596424, 3, 4, 6, 3, 3, 4, 8, 4
From Images to Connections: Can DQN with GNNs learn the Strategic Game of Hex?,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 3
ODEFormer: Symbolic Regression of Dynamical Systems with Transformers,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 3, 6, 4
Amortized Network Intervention to Steer the Excitatory Point Processes,5.5, 5.5, 0.5, 5, 3, 6, 3, 6, 4, 5, 2
Diffusion World Models,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 5, 5, 4, 3, 3
Fast and unified path gradient estimators for normalizing flows,6.0, 6.5, 2.1213203435596424, 3, 4, 5, 3, 8, 3, 8, 3
Multimodal Variational Disentangled  Knowledge Alignment for Cross-domain Recommendation,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 3, 3, 5
All for One and One for All: A Collaborative FL Framework for Generic Federated Learning with Personalized Plug-ins,4.4, 5.0, 1.2, 5, 4, 3, 4, 6, 4, 3, 4, 5, 5
Differentially Pivate Per-Instance Additive Noise Mechanism: A Game Theoretic Approach,4.5, 4.5, 1.5, 6, 4, 3, 4, 3, 2, 6, 2
On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs,6.666666666666667, 6.0, 0.9428090415820634, 6, 2, 6, 4, 8, 4
Variational Federated Continual Learning,5.25, 6.0, 1.299038105676658, 6, 3, 6, 4, 6, 5, 3, 4
Multi-interest Disentangled Representation Learning for Multimodal Recommendation,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 4
CEIR: Concept-based Explainable Image Representation Learning,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 5, 4, 3, 4
BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation,7.0, 7.0, 1.0, 8, 2, 6, 3, 6, 3, 8, 3
Learning invariant representations of time-homogeneous stochastic dynamical systems,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 4, 5, 3, 6, 2
Forgedit: Text Guided Image Editing via Learning and Forgetting,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 4, 6, 2, 5, 4
Exploration and Anti-Exploration with Distributional Random Network Distillation,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 3, 4, 5, 4
Learning to Intervene on Concept Bottlenecks,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 4, 3, 4
Noises are Transferable - An Empirical Study on Heterogeneous Domain Adaptation,4.25, 4.0, 1.299038105676658, 5, 4, 6, 2, 3, 3, 3, 5
Investigating the Impact of Data Distribution Shifts on Cross-Modal Knowledge Distillation,5.5, 5.5, 0.5, 5, 4, 5, 3, 6, 3, 6, 3
Masked Diffusion Models are Fast Distribution Learners,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 4, 3, 4, 5, 3, 5, 3
PATHS: Parameter-wise Adaptive Two-Stage Training Harnessing Scene Transition Mask Adapters for Video Retrieval,5.25, 5.0, 1.7853571071357126, 8, 3, 3, 4, 5, 4, 5, 3
Fast Inverse Rendering by Unified Voxelization of Scene Representation,5.75, 5.0, 1.299038105676658, 5, 5, 5, 5, 5, 4, 8, 5
REDUCR: Robust Data Downsampling Using Class Priority Reweighting,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 4, 3, 3
Learning Nash equilibria in Rank-1 games: Going beyond the Minty Property,5.75, 5.0, 1.299038105676658, 5, 2, 5, 4, 8, 3, 5, 4
Towards Realistic Unsupervised Fine-tuning with Vision-Language Models,5.25, 5.0, 1.7853571071357126, 5, 4, 3, 4, 8, 3, 5, 4
Class-Incremental Learning with Parameter-Efficient Cross-Task Prompts,4.0, 3.0, 1.4142135623730951, 3, 3, 6, 5, 3, 5
Incorporating Implicit Regularization to Enhance the Transition Matrix Method for Effective Handling of Diverse Label Noise,4.5, 5.0, 0.8660254037844386, 5, 5, 3, 4, 5, 5, 5, 4
Enhancing Airside Monitoring: Multi-view Approach for Accurate Aircraft Distance-To-Touchdown Estimation in Digital Towers,2.3333333333333335, 3.0, 0.9428090415820634, 3, 3, 3, 4, 1, 4
Beyond the Benchmark: Detecting Diverse Anomalies in Videos,4.25, 4.0, 1.299038105676658, 3, 5, 5, 5, 3, 5, 6, 4
Guaranteed Out-Of-Distribution Detection with Diverse Auxiliary Set,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 4, 5, 3
P+: Extended Textual Conditioning in Text-to-Image Generation,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 3, 5, 4, 5, 3
Revisiting Knowledge Tracing: A Simple and Powerful Model,5.5, 5.5, 0.5, 6, 3, 5, 4, 6, 5, 5, 4
SELF-TAILORING PROMPTS FOR PARAMETER EFFICIENT TUNING SPEECH RECOGNITION,4.25, 3.0, 2.165063509461097, 3, 4, 3, 4, 8, 3, 3, 5
Reinforcement Learning with Fine-grained Reward for Controllable Text Generation,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 4, 5, 2
WI3D: Weakly Incremental 3D Detection via Visual Prompts,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 5, 5, 4
Rethinking Multi-domain Generalization with A General Learning Objective,4.8, 5.0, 0.9797958971132712, 6, 3, 3, 3, 5, 3, 5, 3, 5, 2
Adversarial Learning of Decomposed Representations for Treatment Effect Estimation,4.2, 5.0, 0.9797958971132712, 3, 5, 5, 4, 5, 3, 5, 4, 3, 3
Gated Attention Bins for Depth Estimation,2.5, 3.0, 0.8660254037844386, 3, 4, 1, 1, 3, 3, 3, 5
Reinforcement Learning with Extreme Minimum Distribution,2.3333333333333335, 3.0, 0.9428090415820634, 1, 4, 3, 4, 3, 5
Temporally Equivariant Contrastive Learning for Disease Progression,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 5, 3, 3, 4
EControl: Fast Distributed Optimization with Compression and Error Control,7.0, 7.0, 1.0, 8, 3, 6, 3, 6, 3, 8, 3
Convergence of Bayesian Bilevel Optimization,6.5, 6.0, 0.8660254037844386, 8, 2, 6, 1, 6, 3, 6, 5
Pre-Training and Fine-Tuning Image Super-Resolution Models for Efficient Video Super-Resolution,3.75, 4.0, 1.920286436967152, 5, 4, 3, 5, 6, 3, 1, 5
MovingParts: Motion-based 3D Part Discovery in Dynamic Radiance Field,5.5, 5.5, 2.5, 3, 5, 3, 5, 8, 4, 8, 3
A Unified Concept-Based System for Local Global and Misclassification Explanations,4.0, 3.0, 1.2649110640673518, 3, 4, 3, 5, 3, 4, 5, 4, 6, 4
BiTGNN: prediction of drug-target interactions based on bidirectional transformer and graph neural network on heterogeneous graph,2.0, 2.0, 1.0, 1, 5, 1, 4, 3, 4, 3, 5
Learning with Complementary Labels Revisited: A Consistent Approach via Negative-Unlabeled Learning,5.25, 6.0, 1.299038105676658, 6, 4, 3, 3, 6, 3, 6, 4
State Representation Learning Using an Unbalanced Atlas,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 2, 5, 2
Retro-fallback: retrosynthetic planning in an uncertain world,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 3, 5, 4
Branch-level Network Re-parameterization with Neural Substitution,4.0, 3.0, 1.2649110640673518, 3, 3, 6, 3, 5, 3, 3, 2, 3, 5
Efficient Multi-Fidelity NAS with Zero-Cost Proxy-Guided Local Search,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 4
ACRF: Compressing Explicit Neural Radiance Fields via Attribute Compression,6.75, 7.0, 1.299038105676658, 6, 4, 8, 4, 8, 4, 5, 4
LiDAR-PTQ: Post-Training Quantization for Point Cloud 3D Object Detection,5.25, 6.0, 1.299038105676658, 3, 4, 6, 3, 6, 3, 6, 4
Multi-label Learning with Random Circular Vectors,5.75, 5.0, 1.299038105676658, 5, 3, 5, 3, 5, 4, 8, 2
Equivariant Matrix Function Neural Networks,5.333333333333333, 5.0, 2.0548046676563256, 3, 3, 8, 4, 5, 2
Learning Graph Representation for Model Ensemble,1.5, 1.0, 0.8660254037844386, 1, 5, 1, 3, 3, 4, 1, 3
Spatio-temporal Twins with A Cache for Modeling Long-term System Dynamics,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 5, 3, 4
End-to-End Spatio-Temporal Action Localisation with Video Transformers,5.5, 5.5, 0.5, 5, 3, 5, 4, 6, 4, 6, 4
SUBER: An RL Environment with Simulated Human Behavior for Recommender Systems,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 3, 5, 5, 4
Optimal transport based adversarial patch to leverage large scale attack transferability,5.6, 6.0, 1.624807680927192, 8, 4, 3, 4, 6, 4, 6, 4, 5, 4
STUDY: Socially Aware Temporally Causal Decoder Recommender Systems,3.8, 5.0, 1.6, 5, 5, 3, 3, 5, 4, 1, 5, 5, 3
Can Agent Learn Robust Locomotion Skills without Modeling Environmental Observation Noise?,5.666666666666667, 6.0, 2.0548046676563256, 6, 4, 3, 4, 8, 4
NIR-Assisted Image Denoising: A Selective Fusion Approach and A Real-World Benchmark Dataset,5.75, 5.0, 1.299038105676658, 5, 4, 5, 3, 8, 2, 5, 4
Pushing the Limits of Pre-training for Time Series Forecasting in the CloudOps Domain,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 4, 3, 4
Duolando: Follower GPT with Off-Policy Reinforcement Learning for Dance Accompaniment,6.0, 6.5, 2.1213203435596424, 8, 4, 3, 4, 8, 4, 5, 3
Semantic Parsing with Candidate Expressions for Knowledge Base Question Answering,5.0, 5.5, 1.224744871391589, 6, 3, 3, 4, 6, 4, 5, 4
TCL-VS: Temporal Contrastive Learning for Self-Supervised Video Summarization,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 3, 3, 4
Expressive Modeling is Insufficient for Offline RL: A Tractable Inference Perspective,5.75, 5.0, 1.299038105676658, 8, 4, 5, 3, 5, 4, 5, 3
Cross-domain Few-shot Classification via Invariant-content Feature Reconstruction,4.0, 3.0, 1.4142135623730951, 3, 3, 3, 4, 6, 4
STREAM: Spatio-TempoRal Evaluation and  Analysis Metric for Video Generative Models,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 5, 5, 4, 6, 4
Explainable Multi-Objective Model Selection for Time Series Forecasting,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 4, 3, 3
Discovering Environments with XRM,4.333333333333333, 5.0, 0.9428090415820634, 3, 2, 5, 4, 5, 4
Accelerated Sampling with Stacked Restricted Boltzmann Machines,6.0, 6.0, 0.0, 6, 4, 6, 3
DECOUPLE QUANTIZATION STEP AND OUTLIER-MIGRATED RECONSTRUCTION FOR PTQ,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 5, 6, 4
CLIP Facial Expression Recognition: Balancing Precision and Generalization,4.25, 4.0, 1.299038105676658, 6, 5, 3, 5, 3, 5, 5, 5
Completion Consistency for Point Cloud Completion Enhancement,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 5, 3, 5, 3, 5
RTMPose: Real-Time Models for Multi-Person Pose Estimation,5.333333333333333, 5.0, 2.0548046676563256, 8, 4, 5, 4, 3, 5
Image Inpainting via Tractable Steering of Diffusion Models,5.5, 5.5, 0.5, 5, 3, 6, 5, 6, 3, 5, 3
Unified Uncertainty Estimation,6.0, 6.5, 2.1213203435596424, 8, 4, 5, 3, 3, 4, 8, 4
Language Guided Interpretable Image Recognition via Manifold Alignment,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 3, 6, 4
SimPLR: A Simple and Plain Transformer for Object Detection and Segmentation,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 3, 6, 5
QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 8, 4, 5, 4
On the Paradox of Generalizable Logical Reasoning in Large Language Models,4.166666666666667, 4.0, 1.2133516482134197, 3, 2, 5, 3, 6, 3, 5, 4, 3, 4, 3, 3
YOLOV6: A SINGLE-STAGE OBJECT DETECTION FRAMEWORK FOR INDUSTRIAL APPLICATIONS,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 5
How Graph Neural Networks Learn: Lessons from Training Dynamics in Function Space,6.333333333333333, 6.0, 1.247219128924647, 8, 3, 6, 2, 5, 3
R-MAE: Regions Meet Masked Autoencoders,5.333333333333333, 5.0, 0.4714045207910317, 5, 5, 5, 5, 6, 3
Transformer-Modulated Diffusion Models for Probabilistic Multivariate  Time Series Forecasting,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 3, 5, 4
EMU: EFFICIENT NEGATIVE SAMPLE GENERATION METHOD FOR KNOWLEDGE GRAPH LINK PREDICTION,3.75, 4.0, 1.920286436967152, 3, 5, 5, 4, 1, 5, 6, 4
OpenChat: Advancing Open-source Language Models with Mixed-Quality Data,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 3, 6, 3, 6, 4
Free-style and Fast 3D Portrait Synthesis,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 3, 5, 4, 5, 4
Retrieval-augmented Text-to-3D Generation,5.0, 5.0, 0.0, 5, 5, 5, 4, 5, 4
LATEC — A benchmark for large-scale attribution & attention evaluation in computer vision,6.0, 6.0, 1.8973665961010275, 3, 4, 6, 2, 8, 4, 5, 3, 8, 4
Convolution on Your 12× Wide Feature: A ConvNet with Nested Design,4.25, 4.0, 1.299038105676658, 3, 5, 5, 4, 6, 4, 3, 4
In-Context Learning Learns Label Relationships but Is Not Conventional Learning,5.5, 5.5, 1.8027756377319946, 6, 4, 3, 5, 8, 4, 5, 3
Amazing Combinatorial Creation: Acceptable Swap-Sampling for Combinatorial Text-to-Image Generation,5.0, 5.5, 1.224744871391589, 6, 4, 5, 4, 3, 4, 6, 4
Democratized Diffusion Language Model,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 3, 4, 5, 5
EditHOI: A framework for HOI image editing with self-generated skeleton guidance,3.75, 4.0, 1.920286436967152, 1, 5, 6, 3, 5, 3, 3, 3
GETMusic: Generating Music Tracks with a Unified Representation and Diffusion Framework,4.25, 4.0, 1.299038105676658, 3, 5, 5, 3, 3, 4, 6, 3
How Temporal Unrolling Supports Neural Physics Simulators,4.75, 5.0, 1.0897247358851685, 6, 2, 5, 4, 5, 4, 3, 4
TwinS: Revisiting Non-Stationarity in Multivariate Time Series Forecasting,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 4, 5, 4, 5, 3
Bandwidth Selection for Gaussian Kernel Ridge Regression via Jacobian Control,3.8, 3.0, 0.9797958971132712, 5, 3, 3, 3, 3, 4, 3, 4, 5, 4
A Graph-Theoretic Framework for Joint OOD Generalization and Detection,5.0, 6.0, 1.4142135623730951, 6, 4, 3, 3, 6, 4
Human Motion Diffusion as a Generative Prior,6.0, 6.0, 0.0, 6, 4, 6, 5, 6, 3, 6, 4
New Insight of Variance reduce in Zero-Order Hard-Thresholding: Mitigating Gradient Error and Expansivity Contradictions,5.333333333333333, 6.0, 1.1055415967851332, 6, 2, 6, 4, 3, 3, 6, 3, 5, 3, 6, 2
mBLIP: Efficient Bootstrapping of Multilingual Vision-LLMs,5.5, 5.5, 0.5, 6, 4, 5, 4, 6, 3, 5, 4
Knowledge Distillation for Closed-Source Language Models,5.5, 5.5, 0.5, 6, 3, 5, 3, 5, 5, 6, 3
Multi-resolution HuBERT: Multi-resolution Speech Self-Supervised Learning with Masked Unit Prediction,7.0, 7.0, 1.0, 8, 4, 8, 3, 6, 3, 6, 5
SMAFace: Sample Mining Guided Adaptive Loss for Face Recognition,3.0, 3.0, 0.0, 3, 5, 3, 5, 3, 4
Fast Neural Architecture Search with Random Neural Tangent Kernel,5.0, 6.0, 1.4142135623730951, 6, 3, 3, 4, 6, 4
AdaMerging: Adaptive Model Merging for Multi-Task Learning,5.25, 5.0, 1.7853571071357126, 3, 4, 5, 5, 5, 3, 8, 4
Self-Supervised High Dynamic Range Imaging with Multi-Exposure Images in Dynamic Scenes,7.0, 7.0, 1.0, 8, 4, 6, 3, 8, 5, 6, 4
LAVITA: Latent Video Diffusion Models with Spatio-temporal Transformers,4.0, 4.0, 1.0, 5, 4, 5, 4, 3, 3, 3, 5
Beyond Conservatism: Diffusion Policies in Offline Multi-agent Reinforcement Learning,4.0, 4.0, 1.0, 5, 4, 3, 4, 5, 2, 3, 4
CAT-Seg: Cost Aggregation for Open-vocabulary Semantic Segmentation,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 4
MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use,5.5, 5.5, 1.8027756377319946, 3, 4, 6, 4, 8, 4, 5, 4
Diffusion Model for Dense Matching,6.5, 6.0, 0.8660254037844386, 6, 4, 6, 3, 8, 3, 6, 4
Composed Image Retrieval with Text Feedback via Multi-grained Uncertainty Regularization,5.666666666666667, 6.0, 2.0548046676563256, 8, 5, 3, 4, 6, 4
Evaluating graph generative models with graph kernels: what structural characteristics are captured?,4.25, 4.0, 1.299038105676658, 3, 4, 3, 5, 5, 3, 6, 5
Explaining How a Neural Network Play the Go Game and Let People Learn,1.6666666666666667, 1.0, 0.9428090415820634, 1, 4, 1, 3, 3, 3
SHARCS: SHARed Concept Space for\\Explainable Multimodal Learning,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 3, 3, 4
RAVL: Reach-Aware Value Learning for the Edge-of-Reach Problem in Offline Model-Based Reinforcement Learning,5.0, 4.5, 2.1213203435596424, 3, 3, 6, 3, 8, 5, 3, 3
On Function-Coupled Watermarks for Deep Neural Networks,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 5, 4, 3, 4
Mean Field Theory in Deep Metric Learning,5.4, 5.0, 1.624807680927192, 5, 5, 6, 3, 8, 3, 3, 4, 5, 3
Implicit Neural Representation Inference for Low-Dimensional Bayesian Deep Learning,5.75, 5.0, 1.299038105676658, 8, 4, 5, 4, 5, 3, 5, 5
Going Beyond Neural Network Feature Similarity: The Network Feature Complexity and Its Interpretation Using Category Theory,5.0, 4.5, 2.1213203435596424, 8, 4, 3, 4, 3, 4, 6, 4
MST-GNN: Graph Neural Network with Multi-Granularity in Space and Time for Traffic Prediction,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 3, 3, 4
Addressing Covariate Shifts with Influence Aware Energy Regularization,3.0, 3.0, 0.0, 3, 2, 3, 4, 3, 2
Multi-Armed Bandits with Abstention,6.75, 7.0, 1.299038105676658, 8, 3, 5, 4, 8, 4, 6, 3
Cross-domain Few-shot Classification via Maximization Optimized Kernel Dependence,6.25, 6.0, 1.0897247358851685, 8, 4, 6, 3, 6, 4, 5, 4
M3C: A Framework towards Convergent Flexible and Unsupervised Learning of Mixture Graph Matching and Clustering,5.5, 5.5, 1.8027756377319946, 6, 5, 8, 3, 3, 4, 5, 3
MacDC: Masking-augmented Collaborative Domain Congregation for Multi-target Domain Adaptation in Semantic Segmentation,4.666666666666667, 5.0, 1.247219128924647, 3, 5, 6, 4, 5, 4
AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 5, 4, 6, 5
Input-gradient space particle inference for neural network ensembles,6.5, 6.5, 1.5, 5, 4, 8, 4, 5, 3, 8, 3
Lightweight In-Context Tuning for Multimodal Unified Models,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 3, 5, 4, 3, 4
An Intrinsic Dimension Perspective of Transformers for Sequential Modeling,3.0, 3.0, 1.2649110640673518, 5, 4, 3, 5, 3, 4, 3, 4, 1, 4
LLaMA-Adapter: Efficient Fine-tuning of Large Language Models with Zero-initialized Attention,6.333333333333333, 6.0, 1.247219128924647, 5, 3, 8, 4, 6, 5
Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation,5.333333333333333, 5.0, 0.4714045207910317, 6, 5, 5, 5, 5, 4
SparseFormer: Sparse Visual Recognition via Limited Latent Tokens,5.5, 5.5, 1.8027756377319946, 5, 5, 6, 4, 3, 4, 8, 3
Distribution Shift-Aware Prediction Refinement for Test-Time Adaptation,5.666666666666667, 6.0, 0.4714045207910317, 6, 5, 6, 4, 5, 5
Learning variable-length skills through Novelty-based Decision Point Identification,5.333333333333333, 5.0, 2.0548046676563256, 3, 4, 5, 3, 8, 3
Demystifying Local & Global Fairness Trade-offs in Federated Learning Using Partial Information Decomposition,5.666666666666667, 6.0, 2.0548046676563256, 6, 3, 3, 2, 8, 3
Protein-Ligand Interaction Prior for Binding-aware 3D Molecule Diffusion Models,6.0, 5.5, 1.224744871391589, 6, 3, 5, 3, 8, 4, 5, 3
Structural Pruning of Large Language Models via Neural Architecture Search,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 5, 6, 2
UltraFeedback: Boosting Language Models with High-quality Feedback,6.0, 5.5, 1.224744871391589, 8, 3, 5, 5, 6, 3, 5, 4
Efficient Link Prediction via GNN Layers Induced by Negative Sampling,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 4, 5, 3, 5, 2
SoftHash: High-dimensional Hashing with A Soft Winner-Take-All Mechanism,5.25, 5.0, 0.4330127018922193, 5, 5, 5, 4, 5, 3, 6, 3
ReX: A Framework for Incorporating Temporal Information in Model-Agnostic Local Explanation Techniques,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 6, 3, 3, 3
Video2StyleGAN: Disentangling Local and Global Variations in a Video,5.25, 5.0, 1.7853571071357126, 5, 4, 5, 4, 3, 4, 8, 4
BELT-2: Bootstrapping EEG-to-Language representation alignment for multi-task brain decoding,5.0, 5.5, 1.224744871391589, 5, 5, 6, 2, 6, 4, 3, 4
AntifakePrompt: Prompt-Tuned Vision-Language Models are Fake Image Detectors,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 3, 3, 5, 3
Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge Graph,7.333333333333333, 8.0, 0.9428090415820634, 8, 4, 8, 4, 6, 4
3DiffTection: 3D Object Detection with Geometry-Aware Diffusion Features,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 5, 4, 3, 4
One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 4, 5, 3, 5, 5
MultiHot Embedding: A Multiple Activation Embedding Model for Numerical Features in Deep Learning,3.8, 3.0, 0.9797958971132712, 3, 4, 3, 4, 5, 2, 3, 4, 5, 2
Self-supervised Heterogeneous Graph Learning:  a Homogeneity and Heterogeneity Perspective,6.5, 7.0, 1.8027756377319946, 6, 4, 8, 4, 8, 5, 6, 3, 3, 3, 8, 3
CoBIT: A Contrastive Bi-directional Image-Text Generation Model,5.4, 5.0, 0.48989794855663565, 6, 4, 5, 4, 6, 5, 5, 4, 5, 5
CAST: Cluster-Aware Self-Training for Tabular Data,4.4, 5.0, 1.2, 6, 4, 5, 3, 3, 4, 3, 3, 5, 4
Prototypical Information Bottlenecking and Disentangling for Multimodal Cancer Survival Prediction,7.0, 6.5, 2.1213203435596424, 5, 4, 5, 4, 8, 5, 10, 4
Policy Disentangled Variational Autoencoder,3.75, 3.0, 1.299038105676658, 3, 4, 3, 3, 3, 3, 6, 2
Protein Multimer Structure Prediction via PPI-guided Prompt Learning,5.25, 5.0, 1.7853571071357126, 8, 3, 5, 3, 5, 3, 3, 4
Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video,6.4, 6.0, 1.3564659966250536, 5, 5, 8, 4, 8, 4, 5, 4, 6, 4
Domain-Agnostic Molecular Generation with Self-feedback,5.5, 5.5, 1.8027756377319946, 6, 4, 3, 4, 8, 4, 5, 4
MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data,5.666666666666667, 6.0, 2.0548046676563256, 8, 4, 3, 4, 6, 4
DAGCN: Distance-based and Aspect-oriented Graph Convolutional Network for Aspect-based Sentiment Analysis,3.0, 3.0, 1.4142135623730951, 1, 5, 3, 4, 5, 3, 3, 3
LLM-grounded Video Diffusion Models,5.0, 6.0, 1.4142135623730951, 6, 3, 6, 3, 3, 5
Adversarial Data Robustness via Implicit Neural Representation,5.4, 5.0, 2.244994432064365, 8, 3, 8, 4, 3, 4, 3, 4, 5, 4
Discovering Mixtures of Structural Causal Models from Time Series Data,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 4, 3, 4
Periodicity Decoupling Framework for Long-term Series Forecasting,6.75, 8.0, 2.165063509461097, 8, 4, 3, 4, 8, 4, 8, 4
Graph Decision Transformer,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 5, 5, 3, 3
Imitation Learning from Observation with Automatic Discount Scheduling,6.0, 5.5, 1.224744871391589, 6, 4, 5, 4, 8, 3, 5, 2
ROBUST SPARSE AND DENSE MATCHING,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 3, 6, 4
Explore Outworld Knowledge in Large Language Models: A Case Study in Pokemon Game,5.6, 6.0, 0.4898979485566356, 6, 3, 6, 3, 5, 4, 6, 3, 5, 2
FutureDD: Planning in POMDP with Encoded Future Dynamics,4.0, 4.0, 1.0, 3, 2, 3, 5, 5, 4, 5, 4
FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of Autonomous Driving,4.25, 4.0, 1.299038105676658, 5, 5, 3, 5, 6, 4, 3, 4
Reinforcement Learning for Control with Stability Guarantee,2.5, 3.0, 0.8660254037844386, 3, 4, 1, 3, 3, 4, 3, 4
iGraphMix: Input Graph Mixup Method for Node Classification,5.8, 6.0, 1.6, 6, 4, 3, 4, 6, 4, 8, 5, 6, 3
Neural Fine-Tuning Search for Few-Shot Learning,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 8, 3, 6, 4
CutSharp: A Simple Data Augmentation Method for Learned Image Compression,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 5, 3, 4
Noise Map Guidance: Inversion with Spatial Context for Real Image Editing,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 8, 4, 6, 4
Output-Domain Focused Inductive Bias on Latent Feature Clusters in Visual Classification,6.0, 5.0, 1.4142135623730951, 5, 3, 8, 4, 5, 3
Simple Minimax Optimal Byzantine Robust Algorithm for Nonconvex Objectives with Uniform Gradient Heterogeneity,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 6, 3, 3, 2
GLD: Generative Latent Dynamics for Structured Motion Representation and Learning,6.333333333333333, 6.0, 1.247219128924647, 6, 2, 5, 4, 8, 4
Data De-Duplication and Semantic Enhancement for Contrastive Language-Image Pre-training,4.75, 5.0, 1.0897247358851685, 5, 5, 6, 4, 5, 4, 3, 5
SuperSNN: Training Spiking Neural Networks with Knowledge from Artificial Neural Networks,3.4, 3.0, 0.8, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3
TopoMLP: An Simple yet Strong Pipeline for Driving Topology Reasoning,6.5, 6.0, 0.8660254037844386, 8, 4, 6, 5, 6, 4, 6, 3
Towards Reliable and Efficient Backdoor Trigger Inversion via Decoupling Benign Features,5.75, 6.0, 1.7853571071357126, 3, 5, 8, 4, 6, 4, 6, 4
Unmasking Transformers: A Theoretical Approach to Data Recovery via Attention Weights,3.0, 3.0, 1.4142135623730951, 3, 4, 5, 4, 1, 1, 3, 4
Personalize Segment Anything Model with One Shot,6.666666666666667, 6.0, 0.9428090415820634, 8, 5, 6, 5, 6, 4
Integrating Planning and Deep Reinforcement Learning via Automatic Induction of Task Substructures,5.75, 5.0, 1.299038105676658, 5, 3, 5, 4, 8, 4, 5, 4
Sequential Indeterminate Probability Theory for Multivariate Time Series Forecasting,1.5, 1.0, 0.8660254037844386, 1, 4, 1, 4, 1, 3, 3, 2
Deep Reinforcement Learning for Efficient and Fair Allocation of Health Care Resources,6.0, 5.0, 2.943920288775949, 3, 2, 10, 4, 5, 3
Contrastive Graph Autoencoder for Geometric Polygon Retrieval from Building Datasets,5.25, 5.0, 1.7853571071357126, 3, 4, 8, 4, 5, 3, 5, 4
An Empirical Study of Simplicial Representation Learning with Wasserstein Distance,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 3, 3, 3
Data geometry and topology dependent bounds on network widths in deep ReLU networks,5.25, 5.0, 1.7853571071357126, 3, 3, 5, 4, 8, 4, 5, 3
Learning with Counterfactual Explanations for Radiology Report Generation,4.5, 5.0, 0.8660254037844386, 5, 5, 5, 3, 5, 4, 3, 4
Low rank field-weighted factorization machines for low latency item recommendation,nan, nan, nan
PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training,5.75, 6.0, 0.4330127018922193, 5, 3, 6, 4, 6, 4, 6, 5
Necessary and Sufficient Watermark for Large Language Models,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 3, 5, 3, 5, 4
Overcoming bias towards base sessions in few-shot class-incremental learning (FSCIL),4.333333333333333, 5.0, 0.9428090415820634, 3, 5, 5, 2, 5, 3
Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach Without Reanalysis Data,5.5, 5.5, 1.8027756377319946, 8, 4, 5, 4, 6, 3, 3, 4
Hierarchy-aware Biased Bound Loss Function for Hierarchical Text Classification,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 3, 3, 4
LoTa-Bench: Benchmarking Language-oriented Task Planners for Embodied Agents,5.25, 6.0, 1.299038105676658, 6, 4, 6, 4, 6, 4, 3, 3
Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts,5.0, 5.5, 1.224744871391589, 5, 3, 6, 5, 6, 4, 3, 4
On Task Description of In-context Learning: A Study from Information Perspective,4.25, 4.0, 1.299038105676658, 3, 4, 6, 4, 5, 3, 3, 4
Momentum-accelerated Diffusion Process for Faster Training and Sampling,5.5, 5.5, 1.8027756377319946, 3, 4, 8, 3, 5, 4, 6, 3
Urial: Aligning Untuned LLMs with Just the 'Write' Amount of In-Context Learning,4.25, 5.0, 1.920286436967152, 6, 3, 5, 4, 5, 5, 1, 4
Applying language models to algebraic topology: generating simplicial cycles using multi-labeling in Wu's formula,4.666666666666667, 3.0, 2.357022603955158, 3, 3, 3, 4, 8, 3
Rethinking RGB Color Representation for Image Restoration Models,5.5, 5.5, 1.8027756377319946, 5, 4, 3, 5, 8, 5, 6, 4
InstructionGPT-4: A 200-Instruction Paradigm for Fine-Tuning MiniGPT-4,4.75, 4.0, 2.0463381929681126, 5, 3, 3, 4, 8, 4, 3, 5
Masked Dual-Temporal Autoencoders for Semi-Supervised Time-Series Classification,5.25, 6.0, 1.299038105676658, 6, 2, 3, 5, 6, 4, 6, 4
Towards Best Practices of Activation Patching in Language Models: Metrics and Methods,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 3, 6, 2
FusionFormer: A Multi-sensory Fusion in Bird's-Eye-View and Temporal Consistent Transformer for 3D Object Detection,5.0, 5.5, 1.224744871391589, 6, 2, 5, 5, 3, 4, 6, 3
Equivariant Graph Neural Operator for Modeling 3D Dynamics,5.75, 5.0, 1.299038105676658, 5, 3, 5, 3, 5, 4, 8, 3
SemanticBoost: Elevating Motion Generation with Augmented Textual Cues,4.0, 4.0, 1.0, 5, 5, 3, 4, 5, 4, 3, 5
On the Analysis of GAN-based Image-to-Image Translation with Gaussian Noise Injection,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 6, 3, 3, 5
Adaptive Resolution Residual Networks,3.75, 3.0, 1.299038105676658, 3, 4, 3, 5, 3, 4, 6, 2
Swift Sampler: Efficient Learning of  Sampler by 10 parameters,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 2
FedHyper: A Universal and Robust Learning Rate Scheduler for Federated Learning with Hypergradient Descent,6.75, 7.0, 1.299038105676658, 5, 3, 8, 5, 8, 4, 6, 4
Deepfake Caricatures: Amplifying attention to artifacts increases deepfake detection by humans and machines,5.5, 5.5, 0.5, 5, 4, 6, 5, 5, 5, 6, 4
AVOID: Alleviating VAE's Overestimation in Unsupervised OOD Detection,5.0, 5.5, 1.224744871391589, 5, 4, 6, 4, 3, 4, 6, 4
Big Learning,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 5, 4, 6, 4
FreeReg: Image-to-Point Cloud Registration Leveraging Pretrained Diffusion Models and Monocular Depth Estimators,6.333333333333333, 6.0, 1.247219128924647, 5, 3, 8, 2, 6, 4
CITING: Large Language Models Create Curriculum for Instruction Tuning,5.0, 5.5, 1.224744871391589, 5, 4, 6, 3, 3, 5, 6, 4
Big Learning Variational Auto-Encoders,4.2, 5.0, 0.9797958971132712, 3, 4, 5, 2, 5, 3, 5, 3, 3, 5
Improving Diffusion Models for Inverse Problems Using Optimal Posterior Covariance,5.333333333333333, 5.0, 0.4714045207910317, 6, 5, 5, 4, 5, 4
A Fast Framework for Post-training Structured Pruning Without Retraining,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 5, 4, 3, 4
Step-Back Prompting Enables Reasoning Via Abstraction in Large Language Models,6.666666666666667, 6.0, 0.9428090415820634, 6, 4, 6, 3, 8, 3
Pink: Unveiling the Power of Referential Comprehension for Multi-modal LLMs,4.0, 3.0, 1.4142135623730951, 3, 5, 3, 5, 6, 3
How Powerful are Graph Neural Networks with Random Weights?,2.6666666666666665, 1.0, 2.3570226039551585, 1, 5, 6, 3, 1, 4
End-to-End Neural Network Compression via $\frac{\ell_1}{\ell_2}$  Regularized Latency Surrogates,5.333333333333333, 5.0, 0.4714045207910317, 5, 5, 6, 4, 5, 3
ImagenHub: Standardizing the evaluation of conditional image generation models,6.0, 5.5, 1.224744871391589, 5, 3, 6, 3, 8, 3, 5, 3
A Critical Look at Classic Test-Time Adaptation Methods in Semantic Segmentation,3.8, 3.0, 0.9797958971132712, 3, 3, 5, 4, 5, 5, 3, 4, 3, 4
Prompt-Guided Dynamic Network for Image Super Resolution,4.5, 4.5, 1.5, 6, 5, 3, 2, 3, 5, 6, 3
Fine-tune Language Models to Approximate Unbiased In-context Learning,3.0, 3.0, 0.0, 3, 3, 3, 3
Learning the Unlearnable: Adversarial Augmentations Suppress Unlearnable Example Attacks,4.5, 4.5, 1.5, 3, 4, 6, 2, 6, 3, 3, 5
Chat-UniVi: A Unified Vision-Language Model for Image and Video Understanding,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 6, 5, 3, 5
On the Role of Momentum in the Implicit Bias of Gradient Descent for Diagonal Linear Networks,3.75, 4.0, 1.920286436967152, 1, 5, 6, 3, 5, 4, 3, 4
Staleness-based subgraph sampling for large-scale GNNs training,4.0, 4.0, 1.0, 3, 4, 5, 3, 5, 3, 3, 4
DST-Det: Simple Dynamic Self-Training for Open-Vocabulary Object Detection,3.8, 3.0, 0.9797958971132712, 3, 4, 3, 5, 5, 3, 5, 5, 3, 4
KDGCN: A Kernel-based Double-level Graph Convolution Network for Semi-supervised Graph Classification with Scarce Labels,5.25, 5.0, 1.7853571071357126, 3, 5, 8, 4, 5, 3, 5, 4
TOAST: Transfer Learning via Top-Down Attention Steering,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 4
UC-NERF: Neural Radiance Field for under-calibrated multi-view cameras,5.6, 6.0, 0.48989794855663565, 6, 5, 6, 4, 5, 4, 5, 5, 6, 4
Image Compression Is an Effective Objective for Visual Representation Learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 5, 3, 5, 5, 4
Adapting Large Language Models via Reading Comprehension,6.5, 6.0, 0.8660254037844386, 6, 4, 8, 3, 6, 4, 6, 3
Building a Special Representation for the Chinese Ancient Buildings in Diffusion models.,3.0, 3.0, 1.632993161855452, 1, 4, 5, 4, 3, 2
Adversarial Instance Attacks for Interactions between Human and Object,3.0, 3.0, 1.4142135623730951, 3, 4, 1, 2, 3, 4, 5, 3
SERA: Sample Efficient Reward Augmentation in offline-to-online Reinforcement Learning,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 5, 3, 4
DIAGNOSIS: Detecting Unauthorized Data Usages in Text-to-image Diffusion Models,6.25, 6.0, 1.0897247358851685, 8, 4, 5, 4, 6, 2, 6, 4
MVoice: Multilingual Unified Voice Generation With Discrete Representation at Scale,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 5, 5, 4, 3, 4
Discovering Logic-Informed Intrinsic Rewards to Explain Human Policies,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 6, 3, 5, 3
Multi-agent Trajectory Prediction with Scalable Diffusion Transformer,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 3, 5, 5, 4
Hybrid Kernel Stein Variational Gradient Descent,5.0, 5.5, 1.224744871391589, 6, 3, 3, 3, 5, 3, 6, 4
Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 8, 5, 5, 4
LEMON: Lossless model expansion,6.25, 7.0, 2.0463381929681126, 8, 4, 8, 3, 6, 4, 3, 4
Dual Grained Quantization: Efficient Fine-grained Quantization for LLM,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 3, 3, 4, 5, 4
FUND-RELATED GRAPH REPRESENTATION FOR MARGINAL EFFECTIVENESS IN MULTI-FACTORS QUANTITATIVE STRATEGY,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 4, 3, 2
Quantifying Uncertainty in Answers from any Language Model and Enhancing their Trustworthiness,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 4, 3, 4
Look-Ahead Selective Plasticity for Continual Learning of Visual Tasks,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 5, 3, 4
Minimum Edit Distance Training for Conditional Language Generation Models,4.5, 4.5, 1.5, 3, 4, 3, 5, 6, 4, 6, 4
A Consistent Lebesgue Measure for Multi-label Learning,5.0, 5.5, 1.224744871391589, 5, 4, 6, 4, 6, 4, 3, 2
YOLOR-Based Multi-Task Learning,3.5, 4.0, 1.6583123951777, 5, 4, 5, 4, 1, 4, 3, 4
ViP: A Differentially Private Foundation Model for Computer Vision,4.666666666666667, 3.0, 2.357022603955158, 3, 3, 3, 3, 8, 4
NeuralMatrix: Compute the Entire Neural Networks with Linear Matrix Operations for Efficient Inference,4.2, 5.0, 0.9797958971132712, 5, 4, 5, 4, 3, 4, 5, 4, 3, 3
Uncovering Time-Invariant Latent Representation for Brain Disorder Diagnosis via Self-Supervised Learning,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 5, 2, 3, 4
A Hard-to-Beat Baseline for Training-free CLIP-based Adaptation,4.666666666666667, 5.0, 1.247219128924647, 3, 5, 5, 4, 6, 4
MiniLLM: Knowledge Distillation of Large Language Models,6.0, 5.5, 1.224744871391589, 5, 4, 8, 5, 5, 3, 6, 4
HYBRID GRANULARITY DISTRIBUTION ESTIMATION FOR FEW-SHOT LEARNING: STATISTICS TRANSFER FROM CATEGORIES AND INSTANCES,5.333333333333333, 5.0, 0.4714045207910317, 6, 5, 5, 4, 5, 5
Spatio-Temporal Graph Learning with Large Language Model,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 4, 6, 3, 5, 4
FourierAugment: Frequency-Based Image Encoding for Resource-Constrained Vision Tasks,5.25, 5.0, 0.4330127018922193, 6, 3, 5, 3, 5, 3, 5, 4
Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 3, 4, 5, 5
Enabling Model Parallelism for Neural Networks Based on Decoupled Supervised Contrastive Learning,4.0, 4.0, 1.0, 5, 4, 3, 4, 5, 4, 3, 2
The importance of feature preprocessing for differentially private linear optimization,6.25, 6.0, 1.0897247358851685, 6, 3, 5, 3, 8, 2, 6, 3
Maximizing Benefits under Harm Constraints: A Generalized Linear Contextual Bandit Approach,4.25, 4.0, 1.299038105676658, 3, 4, 6, 3, 5, 3, 3, 4
Point Cloud Completion with Landau Distribution: A Probabilistic View,4.25, 4.0, 1.299038105676658, 6, 3, 3, 5, 5, 4, 3, 4
Deep graph kernel point processes,5.75, 5.0, 1.299038105676658, 5, 3, 5, 3, 5, 5, 8, 4
Unified Human-Scene Interaction via Prompted Chain-of-Contacts,7.25, 7.0, 1.920286436967152, 10, 4, 5, 2, 8, 4, 6, 3
PTaRL: Prototype-based Tabular Representation Learning via Space Calibration,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 8, 2, 6, 4
Multi-scale Transformers with Adaptive Pathways for Time Series Forecasting,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 4, 3, 5
CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational Autoencoder,4.0, 4.0, 1.0, 3, 5, 5, 3, 5, 3, 3, 4
Graph-level Representation Learning with Joint-Embedding Predictive Architectures,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 4
Bridging the gap between offline and online continual learning,3.75, 4.0, 1.920286436967152, 6, 5, 5, 4, 1, 4, 3, 5
Jailbreaking Language Models at Scale via Persona Modulation,4.0, 4.0, 1.0, 5, 3, 3, 4, 3, 3, 5, 4
Diffusion Models for Imperceptible and Transferable Adversarial Attack,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 3, 3, 5, 4
Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time,6.75, 7.0, 1.299038105676658, 8, 4, 8, 3, 6, 1, 5, 3
DivKnowQA: Verifying the Reasoning Ability of LLM Through Open-Domain Question Answering Over Knowledge Base and Text,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 4
Tree Cross Attention,6.0, 5.5, 1.224744871391589, 5, 2, 5, 3, 8, 3, 6, 4
Synergistic Classification and Unknown Discrimination for Open Set Recognition,3.5, 3.0, 0.8660254037844386, 5, 5, 3, 3, 3, 5, 3, 4
Overcoming both Domain Shift and Label Shift for Referring Video Segmentation,4.25, 4.0, 1.299038105676658, 3, 4, 6, 3, 5, 3, 3, 4
Invariance as A Necessary Condition for Online Continual Learning,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 4, 5, 4
TENSORIZED ATTENTION MODEL,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 4, 5, 5
FedBug: A Bottom-Up Gradual Unfreezing Framework for Federated Learning With Client Drift,4.25, 4.0, 1.299038105676658, 3, 4, 3, 5, 5, 4, 6, 3
LUT-GEMM: Quantized Matrix Multiplication based on LUTs for Efficient Inference in Large-Scale Generative Language Models,6.25, 6.0, 1.0897247358851685, 6, 5, 5, 4, 6, 4, 8, 4
Dual Prompt Tuning for Domain-Aware Federated Learning,5.0, 5.0, 0.0, 5, 4, 5, 5, 5, 4
D2T2: Decision Transformer with Temporal Difference via Steering Guidance,4.0, 4.0, 1.0, 5, 4, 3, 3
On Provable Benefits of Policy Learning from Human Preferences in Contextual Bandit Problems,4.666666666666667, 3.0, 2.357022603955158, 3, 3, 3, 3, 8, 3
Outliers with Opposing Signals Have an Outsized Effect on Neural Network Optimization,5.5, 5.5, 1.8027756377319946, 8, 4, 5, 2, 3, 2, 6, 3
SimVLG: Simple and Efficient Pretraining of Visual Language Generative Models,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 5, 5, 4, 3, 4
ALP: Action-Aware Embodied Learning for Perception,4.25, 4.0, 1.299038105676658, 3, 4, 5, 3, 6, 3, 3, 4
Stable Anisotropic Regularization,6.333333333333333, 8.0, 2.357022603955158, 3, 4, 8, 3, 8, 2
On the Onset of Robust Overfitting in Adversarial Training,3.2, 3.0, 1.6, 1, 4, 3, 4, 3, 4, 3, 4, 6, 4
Learning Graph Representations in Normed Spaces,4.25, 3.0, 2.165063509461097, 3, 5, 8, 2, 3, 4, 3, 4
Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data,6.0, 6.0, 0.0, 6, 4, 6, 3, 6, 3
Threshold-Consistent Margin Loss for Open-World Deep Metric Learning,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 8, 5, 6, 4
Jointly Training Large Autoregressive Multimodal Models,5.5, 5.5, 0.5, 6, 3, 5, 3, 6, 3, 5, 4
Hexa: Self-Improving for Knowledge Augmented Dialogue System,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 4
Rethinking Adversarial Policies: A Generalized Attack Formulation and Provable Defense in RL,5.5, 5.5, 0.5, 5, 4, 6, 4, 5, 3, 6, 3
On the Over-Memorization During Natural Robust and Catastrophic Overfitting,5.25, 6.0, 1.299038105676658, 3, 4, 6, 4, 6, 4, 6, 4
PagFormer: Polar Accumulator Grid  Integrated into Transformers for Medical Image Segmentation,4.25, 4.0, 1.299038105676658, 6, 3, 3, 4, 3, 3, 5, 3
The Generative AI Paradox: “What It Can Create It May Not Understand”,6.25, 7.0, 2.0463381929681126, 3, 4, 8, 4, 6, 3, 8, 3
Semantic Flow: Learning Semantic Fields of Dynamic Scenes from Monocular Videos,6.0, 5.0, 1.4142135623730951, 5, 4, 8, 3, 5, 4
The Closer The Better: Towards Better Representation Learning for Few-Shot Class-Incremental Learning,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 2, 3, 5
Revisiting Link Prediction: a data perspective,5.0, 5.5, 1.224744871391589, 3, 4, 6, 5, 6, 5, 5, 3
Textbooks Are All You Need,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 6, 3, 6, 4, 5, 4, 6, 5, 5, 3
Deterministic Error Bounds for Euclidean Clustering,3.5, 3.0, 0.8660254037844386, 5, 2, 3, 4, 3, 3, 3, 3
FedLAP-DP: Federated Learning by Sharing Differentially Private Loss Approximations,4.0, 4.0, 1.0, 5, 3, 3, 5, 5, 3, 3, 4
Learning from the Future: Improve Long-term Mesh-based Simulation with Foresight,4.0, 4.5, 2.1213203435596424, 3, 4, 6, 4, 1, 4, 6, 3
Exploring Efficient Foundational Multi-modal Models for Video Summarization,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 3, 3, 4
What does the Knowledge Neuron Thesis Have to do with Knowledge?,7.0, 8.0, 1.4142135623730951, 8, 3, 8, 4, 5, 3
Universal Clustering Bounds,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 3, 3, 4, 3, 4
Nonnegative Matrix Factorization through Canonical Edges,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 3
Out-of-Distribution Detection with Hyperspherical Energy,4.5, 5.0, 0.8660254037844386, 3, 5, 5, 4, 5, 3, 5, 3
Maximum Margin Based Activation Clipping for Post-Training Overfitting Mitigation in DNN Classifiers,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 4, 3, 4, 3, 3
Exploring the Effectiveness of Diffusion Models in One-Shot Federated Learning,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 3, 3, 4, 5, 4
MiniGPT-5: Interleaved Vision-and-Language Generation via Generative Vokens,4.5, 5.0, 0.8660254037844386, 3, 5, 5, 4, 5, 3, 5, 4
FiLM: Fill-in Language Models for Any-Order Generation,4.25, 4.0, 1.299038105676658, 5, 4, 6, 3, 3, 3, 3, 5
Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding,5.0, 5.5, 1.224744871391589, 3, 3, 6, 3, 5, 4, 6, 3
Preventing Reward Hacking with Occupancy Measure Regularization,4.8, 5.0, 0.9797958971132712, 3, 4, 5, 4, 6, 4, 5, 4, 5, 2
Hierarchical GFlownet for Crystal Structure Generation,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 5, 5, 4
TextGenSHAP: Scalable Post-hoc Explanations in Text Generation with Long Documents,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 4, 3, 4, 6, 2
Task-Guided Biased Diffusion Models for Point Localization,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 4, 5, 3
Denoising Diffusion Bridge Models,6.0, 6.5, 2.1213203435596424, 5, 4, 8, 3, 3, 4, 8, 4
Learning Temporal Causal Representation under Non-Invertible Generation Process,4.75, 4.0, 2.0463381929681126, 8, 4, 3, 4, 3, 3, 5, 3
TriSAM: Tri-Plane SAM for zero-shot cortical blood vessel segmentation in VEM images,4.666666666666667, 5.0, 1.247219128924647, 3, 5, 5, 4, 6, 3
Incremental Randomized Smoothing Certification,5.0, 5.5, 1.224744871391589, 3, 5, 5, 3, 6, 3, 6, 3
Sapling: $\underline{S}$uccessive $\underline{A}$daptation and Com$\underline{p}$ression with $\underline{L}$ayer Dropp$\underline{ing}$ for LLMs,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 3, 5, 3, 3, 4
Local Graph Clustering with Noisy Labels,6.666666666666667, 6.0, 0.9428090415820634, 6, 2, 6, 3, 8, 3
Wasserstein Distortion: Unifying fidelity and realism,4.0, 4.0, 1.0, 3, 3, 5, 3, 3, 5, 5, 4
Training Neural Networks from Scratch with Parallel Low-Rank Adapters,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 6, 3, 3, 4
Beyond the training set: an intuitive method for detecting distribution shift in model-based optimization,4.6, 5.0, 1.3564659966250536, 3, 4, 3, 5, 6, 3, 5, 3, 6, 3
Principled Federated Domain Adaptation: Gradient Projection and Auto-Weighting,5.5, 5.5, 0.5, 6, 3, 6, 4, 5, 3, 5, 5
Graphpulse: Topological representations for temporal graph property prediction,5.5, 5.5, 0.5, 6, 3, 6, 5, 5, 5, 5, 2
Where have you been? A Study of Privacy Risk for Point-of-Interest Recommendation,5.5, 5.5, 1.8027756377319946, 5, 4, 8, 4, 3, 4, 6, 2
SEESAW: Do Graph Neural Networks Improve Node Representation Learning for All?,4.0, 4.0, 1.0, 5, 4, 3, 3, 5, 2, 3, 4
Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs,5.5, 5.5, 1.8027756377319946, 3, 3, 5, 4, 8, 4, 6, 4
Efficient Low-Rank Diffusion Model Training for Text-to-Image Generation,2.5, 3.0, 0.8660254037844386, 1, 5, 3, 4, 3, 5, 3, 4
SCOT: Improved Temporal Counterfactual Estimation with Self-Supervised Learning,4.666666666666667, 5.0, 1.247219128924647, 6, 5, 3, 5, 5, 5
Potential Based Diffusion Motion Planning,3.0, 3.0, 2.0, 1, 5, 5, 3, 1, 5, 5, 4
MOTSC: Model-based Offline Traffic Signal Control,4.25, 4.0, 1.299038105676658, 5, 3, 3, 4, 6, 3, 3, 4
Understanding Pathologies of Deep Heteroskedastic Regression,4.25, 4.0, 2.5860201081971503, 5, 4, 8, 3, 3, 4, 1, 4
Musketeer: Joint Training/Inference for Multi-task Vision-Language Model with Task Explanation Prompts,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 8, 4, 6, 4
Guided Decoupled Exploration for Offline Reinforcement Learning Fine-tuning,5.5, 5.5, 1.8027756377319946, 3, 4, 5, 4, 6, 3, 8, 4
Exploiting Open-World Data for Adaptive Continual Learning,4.5, 5.0, 0.8660254037844386, 3, 3, 5, 4, 5, 3, 5, 3
A Collaborative Perspective on Exploration in Reinforcement Learning,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 4, 5, 4, 3, 5
QFT: Quantized Full-parameter Tuning of LLMs with Affordable Resources,4.25, 4.0, 1.299038105676658, 3, 5, 6, 4, 3, 3, 5, 4
vFedSec: Efficient Secure Aggregation for Vertical Federated Learning via Secure Layer,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 3
Point2SSM: Learning Morphological Variations of Anatomies from Point Clouds,6.25, 6.0, 1.0897247358851685, 6, 4, 5, 4, 6, 3, 8, 4
Compressed Online Sinkhorn,5.5, 5.5, 0.5, 5, 3, 6, 3, 6, 3, 5, 2
WL-Tree: a New Tool for Analyzing Graph Neural Networks,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 3
PRIME: Prioritizing Interpretability in Failure Mode Extraction,5.5, 5.5, 1.8027756377319946, 6, 4, 8, 3, 5, 4, 3, 4
On gauge freedom conservativity and intrinsic dimensionality estimation in diffusion models,6.0, 5.5, 1.224744871391589, 5, 3, 5, 4, 8, 5, 6, 4
ReFACT: Updating Text-to-Image Models by Editing the Text Encoder,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 3, 5, 4, 5, 4
Personalization Mitigates the Perils of Local SGD for Heterogeneous Distributed Learning,3.75, 3.0, 2.5860201081971503, 3, 3, 8, 2, 3, 3, 1, 4
Less is More: Fewer Interpretable Region via Submodular Subset Selection,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 2, 6, 5
Cameras as Rays: Sparse-view Pose Estimation via Ray Diffusion,6.0, 5.5, 1.224744871391589, 5, 5, 5, 3, 8, 4, 6, 4
ResTran: A GNN Alternative To Learn Graph With Features,3.5, 3.0, 0.8660254037844386, 3, 5, 5, 2, 3, 4, 3, 4
Byzantine Robustness and Partial Participation Can Be Achieved Simultaneously: Just Clip Gradient Differences,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 4, 6, 3
Domain constraints improve risk prediction when outcome data is missing,6.25, 6.0, 1.0897247358851685, 8, 4, 6, 4, 6, 2, 5, 3
Learning Multi-Agent Communication with Contrastive Learning,5.75, 5.0, 1.299038105676658, 5, 4, 8, 4, 5, 4, 5, 4
Improving Out-of-Domain Generalization with Domain Relations,6.166666666666667, 6.0, 1.6749792701868151, 6, 4, 6, 3, 3, 3, 8, 4, 8, 4, 6, 4
Critique Ability of Large Language Models,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 3, 6, 4
Causal Representation Learning and Inference for Generalizable Cross-Domain Predictions,4.0, 4.0, 1.0, 5, 3, 5, 3, 3, 4, 3, 4
VTruST : Controllable value function based subset selection for Data-Centric Trustworthy AI,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 3
Closing the Gap between TD Learning and Supervised Learning - A Generalisation Point of View.,5.25, 5.0, 0.4330127018922193, 6, 3, 5, 4, 5, 3, 5, 3
Overcoming Generic Knowledge Loss with Selective Parameter Update,4.0, 4.0, 1.0, 5, 5, 3, 3, 3, 3, 5, 4
Sample Relationship from Learning Dynamics Matters for Generalisation,6.0, 6.0, 0.0, 6, 3
Continual Learning on a Diet:  Learning from Sparsely Labeled Streams Under Constrained Computation,5.75, 6.0, 1.7853571071357126, 8, 4, 6, 3, 6, 3, 3, 3
Sporadicity in Decentralized Federated Learning: Theory and Algorithm,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 4
LMDX: Language Model-based Document Information Extraction and Localization,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 4, 3, 3
Compound Returns Reduce Variance in Reinforcement Learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 3, 5, 3
ShiftAddAug: Augment Multiplication-Free Tiny Neural Network with Hybrid Computation,5.0, 4.5, 2.1213203435596424, 8, 3, 3, 4, 3, 5, 6, 4
REX: Rapid Exploration and eXploitation for AI agents,4.0, 4.0, 1.0, 5, 2, 3, 4, 5, 4, 3, 4
Adding 3D Geometry Control to Diffusion Models,6.0, 5.5, 1.224744871391589, 5, 3, 5, 4, 6, 4, 8, 4
Momentum Particle Maximum Likelihood,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 4, 5, 3
Grounding Everything: Emerging Localization Properties in Vision-Language Transformers,4.25, 5.0, 1.920286436967152, 1, 4, 5, 3, 6, 3, 5, 4
Brain encoding models based on binding multiple modalities across audio language and vision,4.0, 3.0, 2.943920288775949, 1, 5, 8, 5, 3, 5
Delving Deep into Sim2Real Transformation: Maximizing Impact of Synthetic Data in Training,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 3, 5, 4, 5, 3
Atoms as Words: A Novel Approach to Deciphering Material Properties using NLP-inspired Machine Learning on Crystallographic Information Files (CIFs),3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 5, 3, 5
LegoNet: Piecing Together and Breaking Apart Sub-Networks for Scalable Multi-task Learning,6.0, 5.0, 1.4142135623730951, 5, 5, 5, 4, 8, 4
Natural Language Embedded Programs for Hybrid Language Symbolic Reasoning,4.75, 4.0, 2.0463381929681126, 3, 3, 5, 3, 3, 3, 8, 4
A Generative Augmentation Framework for Contrastive Learning,3.8, 3.0, 0.9797958971132712, 3, 4, 5, 4, 3, 4, 3, 4, 5, 3
Prompting-based Efficient Temporal Domain Generalization,3.5, 3.0, 0.8660254037844386, 5, 2, 3, 4, 3, 4, 3, 4
FARS: FSM-Augmentation to Make LLMs Hallucinate the Right APIs,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 4
Stochastic Subnetwork Annealing: A Regularization Technique for Fine Tuning Subnetworks,4.6, 5.0, 1.3564659966250536, 6, 3, 5, 5, 3, 4, 6, 3, 3, 3
Video Decomposition Prior: Editing Videos Layer by Layer,4.5, 4.5, 1.5, 3, 5, 6, 4, 6, 4, 3, 4
Neighborhood-Informed Diffusion Model for Source-Free Domain Adaptation: Retrieving Source Ground Truth from Target Query's Neighbors,4.75, 4.0, 2.0463381929681126, 3, 4, 5, 5, 8, 5, 3, 5
On the Convergence of AdaGrad-Norm for Non-Convex Optimization,nan, nan, nan
Anarchic Federated Bilevel Optimization,5.333333333333333, 5.0, 2.0548046676563256, 8, 3, 5, 5, 3, 5
Beyond task performance: evaluating and reducing the flaws of large multimodal models with in-context-learning,5.0, 4.5, 2.1213203435596424, 8, 4, 6, 3, 3, 4, 3, 3
Butterfly Effects of SGD Noise: Error Amplification in Behavior Cloning and Autoregression,5.333333333333333, 5.0, 2.0548046676563256, 3, 2, 5, 3, 8, 3
On Stationary Point Convergence of PPO-Clip,5.0, 6.0, 1.4142135623730951, 3, 4, 6, 2, 6, 4
Make a Donut: Language-Guided Hierarchical EMD-Space Planning for Zero-shot Deformable Object Manipulation,4.75, 5.0, 1.0897247358851685, 3, 5, 6, 3, 5, 4, 5, 3
E-MCTS: Deep Exploration by Planning with Epistemic Uncertainty,4.0, 4.0, 1.0, 3, 3, 5, 4, 3, 3, 5, 3
Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks,6.25, 6.0, 1.0897247358851685, 6, 3, 5, 4, 8, 4, 6, 4
LMRL Gym: Benchmarks for Multi-Turn Reinforcement Learning with Language Models,4.0, 4.0, 1.0, 5, 4, 3, 4, 5, 4, 3, 4
Image Hijacks: Adversarial Images can Control Generative Models at Runtime,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 5, 5, 3
High-dimensional SGD aligns with emerging outlier eigenspaces,7.5, 8.0, 1.6072751268321592, 10, 5, 8, 3, 8, 3, 6, 2, 8, 3, 5, 3
Infinitely Deep Residual Networks: Unveiling Wide Neural ODEs as Gaussian Processes,4.25, 4.0, 1.299038105676658, 6, 3, 3, 3, 5, 3, 3, 3
Hadamard Domain Training with Integers for Class  Incremental Quantized Learning,4.0, 4.0, 1.0, 5, 4, 5, 2, 3, 3, 3, 4
CPLLM: Clinical Prediction with Large Language Models,2.0, 2.0, 1.0, 1, 5, 1, 4, 3, 5, 3, 4
Attention-Only Transformers and Implementing MLPs with Attention Heads,nan, nan, nan
One-Hot Encoding Strikes Back: Fully Orthogonal Coordinate-Aligned Class Representations,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 3, 3, 5, 4
Exploiting River Network Topology for Flood Forecasting with Graph Neural Networks,4.0, 4.0, 1.0, 3, 4, 5, 3
Linear Indexed Minimum Empirical Divergence Algorithms,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 5, 3, 3, 4
FABRIC: Personalizing Diffusion Models with Iterative Feedback,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 8, 4, 5, 3
Everyone Counts: Fair and Accurate Heterogeneous Federated Learning with Resource-Adaptive Model Modulation,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 3
Learnable Counterfactual Attention for Singer Identification,4.25, 4.0, 1.299038105676658, 6, 1, 3, 5, 3, 4, 5, 3
Certainty In Certainty Out: REVQCs for Quantum Machine Learning,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 5
Improved Regret Bounds in Stochastic Contextual Bandits with Graph Feedback,4.333333333333333, 6.0, 2.357022603955158, 1, 4, 6, 4, 6, 3
Training-free Linear Image Inversion via Flows,6.25, 7.0, 2.0463381929681126, 3, 5, 8, 4, 8, 3, 6, 2
$\mathcal{B}$-Coder: On Value-Based Deep Reinforcement Learning for Program Synthesis,6.75, 7.0, 1.299038105676658, 5, 4, 8, 2, 6, 4, 8, 3
On robust overfitting: adversarial training induced distribution matters,4.25, 3.0, 2.165063509461097, 3, 4, 3, 4, 3, 4, 8, 4
Visual Grounding with attention-driven constraint balancing,5.25, 5.0, 0.4330127018922193, 6, 3, 5, 4, 5, 4, 5, 4
Equal Long-term Benefit Rate: Adapting Static Fairness Notions to Sequential Decision Making,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 4, 5, 4
Semantic-Guided Consistency and Discrimination for Siamese Representation Learning,4.0, 3.0, 1.2649110640673518, 3, 5, 6, 4, 3, 5, 5, 4, 3, 4
Automatic Functional Differentiation in JAX,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 2, 6, 4, 5, 4
MaskCLR: Multi-Level Contrastive Learning for Robust Skeletal Action Recognition,4.6, 5.0, 1.3564659966250536, 5, 4, 3, 5, 6, 2, 3, 3, 6, 4
FedCompass: Efficient Cross-Silo Federated Learning on Heterogeneous Client Devices Using a Computing Power-Aware Scheduler,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 3, 5, 4, 3, 4
Consistent123: Improve Consistency for One Image to 3D Object Synthesis,5.5, 5.5, 0.5, 6, 4, 5, 4, 5, 5, 6, 4
Memorization for Good: Encryption with Autoregressive Language Models,3.75, 3.0, 1.299038105676658, 3, 5, 3, 4, 3, 3, 6, 3
BioCLIP: A Vision Foundation Model for the Tree of Life,4.5, 4.5, 1.5, 6, 3, 6, 5, 3, 4, 3, 4
Single-Trajectory Distributionally Robust Reinforcement Learning,4.6, 5.0, 1.3564659966250536, 3, 4, 3, 3, 5, 5, 6, 4, 6, 2
Adaptive Chameleon  or Stubborn Sloth: Revealing the Behavior of Large Language Models in Knowledge Conflicts,7.0, 7.0, 1.0, 8, 4, 6, 3, 6, 4, 8, 5
Robustify the Latent Space: Offline Distributionally Robust Reinforcement Learning with Linear Function Approximation,4.4, 5.0, 1.2, 5, 3, 3, 4, 6, 4, 3, 4, 5, 4
Desigen: A Pipeline for Controllable Design Template Generation,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 3, 5, 3
ADoPD: A Large-Scale Document Page Decomposition Dataset,6.25, 6.0, 1.0897247358851685, 8, 4, 6, 5, 6, 4, 5, 2
Curriculum Reinforcement Learning via Morphology-Environment Co-Evolution,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 3, 5, 4
Maximizing LLMs Potential: Enhancing Mongolian Chinese Machine Translation with RL Agents and Adversarial Multi Knowledge Distillation,3.6666666666666665, 5.0, 1.8856180831641267, 1, 5, 5, 3, 5, 5
Provably Efficient CVaR RL in Low-rank MDPs,5.75, 6.0, 0.4330127018922193, 5, 4, 6, 3, 6, 3, 6, 2
On the Disconnect Between Theory and Practice of Overparametrized Neural Networks,6.0, 5.5, 1.224744871391589, 5, 3, 5, 2, 8, 4, 6, 3
3D Object Representation Learning for Robust Classification and Pose estimation,5.0, 5.5, 1.224744871391589, 3, 3, 5, 4, 6, 4, 6, 3
Flexible Residual Binarization for Image Super-Resolution,6.5, 6.5, 1.5, 5, 4, 8, 5, 8, 4, 5, 4
Understanding and Controlling a Maze-Solving Policy Network,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 3, 3, 4
RayE-Sub: Countering Subgraph Degradation via Perfect Reconstruction,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 3, 3, 4
FedDecay: Adapting to Data Heterogeneity in Federated Learning With Gradient Decay,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 3, 6, 4
COPlanner: Plan to Roll Out Conservatively but to Explore Optimistically for Model-Based RL,5.0, 6.0, 1.4142135623730951, 3, 4, 6, 3, 6, 4
A Hierarchical Bayesian Model for Few-Shot Meta Learning,6.5, 6.0, 1.118033988749895, 6, 4, 5, 4, 8, 4, 6, 2, 6, 3, 8, 3
SubDiff: Subgraph Latent Diffusion Model,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 4, 3, 4
Can Transformers Capture Spatial Relations between Objects?,6.2, 5.0, 1.469693845669907, 8, 4, 5, 4, 5, 4, 8, 4, 5, 4
How Does RLHF Shift Behavior Distributions? Distinguishability and Steerability,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4
Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models,5.5, 5.5, 0.5, 6, 3, 5, 2, 5, 4, 6, 3
CSI: Enhancing the Robustness of 3D Point Cloud Recognition against Corruption,5.0, 5.5, 1.224744871391589, 3, 4, 6, 4, 5, 4, 6, 3
Learning Robust Generalizable Radiance Field with Visibility and Feature Augmented Point Representation,5.75, 6.0, 0.4330127018922193, 5, 4, 6, 3, 6, 4, 6, 4
Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation,6.25, 6.0, 1.0897247358851685, 5, 3, 6, 3, 6, 4, 8, 4
Enhancing Vision-Language Prompt Learning through Image-Text Distribution Alignment,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 5
DiPmark: A Stealthy Efficient and Resilient Watermark for Large Language Models,4.5, 4.5, 1.5, 3, 3, 6, 4, 3, 3, 6, 4
Finite Scalar Quantization: VQ-VAE Made Simple,5.5, 5.5, 0.5, 6, 4, 5, 4, 5, 3, 6, 2
From Language to 3D Worlds: Adapting Language Models for Point Cloud Perception,5.0, 5.0, 0.0, 5, 5, 5, 4, 5, 5
Interpretable Meta-Learning of Physical Systems,5.333333333333333, 5.0, 2.0548046676563256, 3, 4, 5, 3, 8, 3
BurstAttention: An Efficient Distributed Attention Framework for Extremely Long Sequences,5.2, 6.0, 1.16619037896906, 6, 3, 5, 3, 6, 4, 6, 3, 3, 4
Detecting Explaining and Mitigating Memorization in Diffusion Models,7.5, 8.0, 0.8660254037844386, 6, 2, 8, 3, 8, 4, 8, 4
Grokking in Linear Estimators -- A Solvable Model that Groks without Understanding,5.5, 5.5, 1.8027756377319946, 3, 4, 8, 3, 5, 4, 6, 4
Discovering Failure Modes of Text-guided Diffusion Models via Adversarial Search,6.75, 6.0, 1.920286436967152, 5, 4, 10, 5, 6, 3, 6, 4
Information-Ordered Bottlenecks for Adaptive Dimensionality Reduction,4.0, 4.0, 1.0, 5, 3, 3, 3, 3, 3, 5, 5
DiffAR: Denoising Diffusion Autoregressive Model for Raw Speech Waveform Generation,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 4, 5, 3, 5, 4
Enhancing Graph Injection Attacks Through Over-Smoothing Amplification,3.8, 3.0, 0.9797958971132712, 3, 5, 5, 4, 5, 4, 3, 3, 3, 3
RGB-Event MOT: A Cross-Modal Benchmark for Multi-Object Tracking,3.6666666666666665, 3.0, 0.9428090415820634, 5, 5, 3, 5, 3, 5
Rationality of Thought Improves Reasoning in Large Language Models,5.5, 5.5, 0.5, 5, 4, 5, 4, 6, 5, 6, 4
Statistical Rejection Sampling Improves Preference Optimization,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 4, 5, 4
On the generalization capacity of neural networks during generic multimodal reasoning,5.666666666666667, 6.0, 2.0548046676563256, 6, 3, 3, 3, 8, 4
The Devil is in the Object Boundary: Towards Annotation-free Instance Segmentation using Foundation Models,5.4, 5.0, 0.48989794855663565, 5, 4, 6, 4, 5, 4, 6, 4, 5, 4
Sparse Training of Discrete Diffusion Models for Graph Generation,3.5, 3.0, 0.8660254037844386, 3, 3, 5, 4, 3, 4, 3, 4
Towards Understanding Masked Distillation,3.5, 4.0, 1.6583123951777, 5, 4, 5, 4, 1, 3, 3, 5
Human-Producible Adversarial Examples,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 3, 3, 4, 5, 4
Mitigating Backdoor Attacks in Federated Learning through Noise-Guided Aggregation,5.0, 6.0, 1.4142135623730951, 6, 4, 6, 3, 3, 5
Test Relative Fairness in Human Decisions With Machine Learning,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 4
Active Procedure Planning with Uncertainty-awareness in Instructional Videos,5.0, 6.0, 1.4142135623730951, 6, 3, 3, 3, 6, 5
Dissecting Zero-Shot Visual Reasoning Capabilities in Vision and Language Models,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 4, 3, 3, 3, 4
Sequential Flow Straightening for Generative Modeling,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 4, 6, 3
From Indeterminacy to Determinacy: Augmenting Logical Reasoning Capabilities with Large Language Models,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 3, 3, 2
EquiPocket: an E(3)-Equivariant Geometric Graph Neural Network for Ligand Binding Site Prediction,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 4, 5, 3, 5, 4
Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages,4.75, 4.0, 2.0463381929681126, 8, 5, 3, 5, 3, 4, 5, 4
DoraemonGPT: Toward Solving Real-world Tasks with Large Language Models,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 5, 3, 6, 3
Cross-Modality Masked Pre-training for Visible-Infrared Person Re-identification,3.0, 3.0, 1.632993161855452, 1, 4, 5, 5, 3, 5
Alleviating Label Shift Through Self-trained Intermediate Distribution: Theory and Algorithms,4.5, 4.5, 1.5, 6, 3, 6, 4, 3, 4, 3, 4
NeuroSURF: Neural Uncertainty-aware Robust Surface Reconstruction,4.0, 4.0, 1.0, 3, 4, 3, 3, 5, 4, 5, 3
Interpreting Equivariant Representations,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 2, 5, 2
Faithful and Efficient Explanations for Neural Networks via Neural Tangent Kernel Surrogate Models,6.4, 6.0, 1.3564659966250536, 8, 4, 5, 2, 6, 4, 5, 4, 8, 4
Improving Compositional Text-to-image Generation with  Large Vision-Language Models,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 5, 3, 5, 3, 5
A Data-Driven Measure of Relative Uncertainty for Misclassification Detection,5.25, 5.0, 1.7853571071357126, 5, 2, 3, 3, 8, 4, 5, 3
FMM-Head: Enhancing Autoencoder-based ECG anomaly detection with prior knowledge,3.0, 3.0, 1.4142135623730951, 5, 4, 3, 5, 3, 5, 1, 5
Maximally discriminative stimuli for functional cell type identification,4.5, 4.5, 1.5, 3, 3, 6, 4, 3, 2, 6, 2
Biased Temporal Convolution Graph Network for Time Series Forecasting with Missing Values.,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 5, 4, 6, 3
A primal-dual perspective for distributed TD-learning,6.25, 6.0, 1.0897247358851685, 8, 4, 6, 3, 6, 3, 5, 4
RegQ: Convergent Q-Learning with Linear Function Approximation using Regularization,5.75, 5.0, 1.299038105676658, 5, 3, 5, 3, 5, 4, 8, 4
Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting,5.0, 5.0, 0.0, 5, 3, 5, 4
Long BERT for bankruptcy prediction,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 3, 3, 3, 3, 4
Precision and Recall Reject Curves for Classification,1.5, 1.0, 0.8660254037844386, 1, 4, 3, 4, 1, 4, 1, 4
Enhancing Vision-Language Model with Unmasked Token Alignment at Scale,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 6, 3, 3, 4
IMP: Benchmarking Image Polysemy in Vision-Language Models,4.8, 5.0, 1.8330302779823362, 3, 4, 5, 2, 8, 4, 5, 3, 3, 3
Distill Gold from Massive Ores: Efficient Dataset Distillation via Critical Samples Selection,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 3, 6, 4, 5, 4
Upgrading VAE Training With Unlimited Data Plans Provided by Diffusion Models,4.0, 4.0, 1.0, 5, 3, 3, 4, 5, 4, 3, 4
Towards Unified and Effective Domain Generalization,4.666666666666667, 3.0, 2.357022603955158, 3, 5, 8, 3, 3, 4
Attention Prompt Tuning,4.25, 4.0, 1.299038105676658, 6, 4, 3, 5, 5, 4, 3, 4
Adaptive Slot Attention: Object Discovery with Dynamic Slot Number,5.0, 5.0, 0.0, 5, 4, 5, 5, 5, 3, 5, 3
Rethinking Channel Dimensions to Isolate Outliers for Low-bit Weight Quantization of Large Language Models,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 4, 5, 5
Hierarchical Side-Tuning for Vision Transformers,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 4, 5, 4
DecompOpt: Controllable and Decomposed Diffusion Models for Structure-based Molecular Optimization,5.0, 5.0, 1.0954451150103321, 5, 4, 3, 4, 5, 3, 6, 4, 6, 3
Understanding MLP-Mixer as a wide and sparse MLP,5.4, 5.0, 0.48989794855663565, 6, 2, 6, 3, 5, 3, 5, 3, 5, 3
Provably Efficient Exploration in Quantum Reinforcement Learning with Logarithmic Worst-Case Regret,5.666666666666667, 6.0, 0.4714045207910317, 5, 3, 6, 4, 6, 3
Advective Diffusion Transformers for Topological Generalization in Graph Learning,4.25, 3.0, 2.165063509461097, 8, 3, 3, 5, 3, 4, 3, 4
Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals,5.0, 5.5, 1.224744871391589, 6, 3, 5, 4, 3, 5, 6, 4
Separating common from salient patterns with Contrastive Representation Learning,7.0, 8.0, 1.2649110640673518, 8, 3, 5, 2, 6, 4, 8, 3, 8, 3
Self-Supervised Contrastive Forecasting,6.0, 5.5, 1.224744871391589, 5, 4, 5, 5, 6, 4, 8, 4
RLLTE: Long-Term Evolution Project of Reinforcement Learning,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 4, 6, 3
Noise-Aware Algorithm for Heterogeneous Differentially Private Federated Learning,6.0, 5.5, 1.224744871391589, 8, 3, 6, 3, 5, 3, 5, 4
L-Eval: Instituting Standardized Evaluation for Long Context Language Models,6.333333333333333, 6.0, 1.247219128924647, 6, 3, 5, 3, 8, 4
Marrying Pixel and Latent Diffusion Models for Text-to-Video Generation,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 5, 5, 5
Identifiable Representation Learning via Architecture Equivariances,3.5, 4.0, 1.6583123951777, 5, 4, 3, 4, 1, 4, 5, 4
On progressive sharpening flat minima and generalisation,5.0, 4.5, 2.1213203435596424, 8, 2, 6, 2, 3, 4, 3, 4
VIPER: Vibrant Period Representation for Robust and Efficient Time Series Forecasting,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 4
OCAtari: Object-Centric Atari 2600 Reinforcement Learning Environments,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 4, 3, 4
Generative Pretrained Embedding and Hierarchical Representation to Unlock Human Rhythm in Activities of Daily Living,4.75, 5.0, 1.0897247358851685, 3, 5, 6, 4, 5, 3, 5, 3
Forward Explanation : Why Catastrophic Forgetting Occurs,1.5, 1.0, 0.8660254037844386, 1, 5, 1, 4, 3, 5, 1, 5
A Semantic Invariant Robust Watermark for Large Language Models,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 3, 5, 3, 6, 4
NeRT: Implicit Neural Representation for Time Series,4.25, 4.0, 1.299038105676658, 6, 4, 3, 4, 5, 4, 3, 4
Fast Equilibrium of SGD in Generic Situations,6.5, 6.0, 0.8660254037844386, 6, 1, 8, 3, 6, 3, 6, 3
AlignCLIP: Enhancing Stable Representations in Vision-Language Pretraining Models through Attention and Prediction Alignment,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 6, 4, 5, 3
Binary Hyperbolic Embeddings,5.75, 6.0, 0.4330127018922193, 6, 5, 6, 3, 5, 3, 6, 3
Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM,6.75, 7.0, 1.299038105676658, 8, 4, 8, 3, 6, 4, 5, 4
Robust Stereo Matching by Risk Minimization,6.0, 6.0, 0.0, 6, 5, 6, 4, 6, 5, 6, 3
Transport meets Variational Inference: Controlled Monte Carlo Diffusions,5.6, 6.0, 1.624807680927192, 5, 4, 8, 3, 6, 3, 6, 4, 3, 3
PETNet - Coincident Particle Event Detection using Spiking Neural Networks,4.333333333333333, 5.0, 0.9428090415820634, 5, 2, 5, 4, 3, 5
DAFA: Distance-Aware Fair Adversarial Training,5.5, 5.5, 0.5, 6, 4, 6, 4, 5, 4, 5, 3
Non-Parameterized Randomization for Environmental Generalization in Deep Reinforcement Learning,2.3333333333333335, 3.0, 0.9428090415820634, 1, 4, 3, 4, 3, 3
AffineQuant: Affine Transformation Quantization for Large Language Models,4.25, 4.0, 2.5860201081971503, 1, 5, 3, 4, 8, 3, 5, 4
Encoding Unitig-level Assembly Graphs with Heterophilous Constraints for Metagenomic Contigs Binning,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 4, 5, 2
Prototypical Influence Function for Fully Test-time Adaptation,5.0, 5.0, 1.0954451150103321, 6, 4, 5, 3, 3, 4, 6, 3, 5, 3
ProtoNMF: Turning a Black Box into a Prototype Based Interpretable Model via Non-negative Matrix Factorization,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 3, 3, 2
CIM: Constrained Intrinsic Motivation for Reinforcement Learning,5.75, 6.0, 1.7853571071357126, 6, 3, 8, 3, 3, 4, 6, 3
Out-Of-Distribution Detection With Smooth Training,5.0, 5.5, 1.224744871391589, 6, 3, 3, 5, 6, 4, 5, 4
Symmetry-preserving graph attention network to solve routing problems at multiple resolutions,3.5, 3.0, 0.8660254037844386, 3, 5, 5, 4, 3, 4, 3, 3
Bootstrapping Audio-Visual Segmentation by Strengthening Audio Cues,5.25, 6.0, 1.299038105676658, 3, 4, 6, 3, 6, 4, 6, 4
Emergent Mixture-of-Experts: Can Dense Pre-trained Transformers Benefit from Emergent Modular Structures?,4.6, 3.0, 2.0591260281974, 6, 4, 3, 4, 3, 3, 8, 3, 3, 4
Conformal Risk Control,6.333333333333333, 6.0, 1.247219128924647, 8, 4, 6, 3, 6, 3, 8, 4, 5, 4, 5, 3
SF(DA)$^2$: Source-free Domain Adaptation Through the Lens of Data Augmentation,5.0, 5.5, 1.224744871391589, 5, 4, 3, 4, 6, 4, 6, 4
Lookbehind Optimizer: k steps back 1 step forward,4.75, 4.0, 2.0463381929681126, 3, 4, 3, 4, 5, 4, 8, 4
RetroBridge: Modeling Retrosynthesis with Markov Bridges,6.5, 6.5, 1.5, 8, 4, 5, 3, 8, 4, 5, 5
Mitigating the Curse of Dimensionality for Certified Robustness via Dual Randomized Smoothing,6.25, 6.0, 1.0897247358851685, 5, 3, 6, 3, 8, 1, 6, 2
In-context Exploration-Exploitation for Reinforcement Learning,6.0, 5.5, 1.224744871391589, 5, 4, 6, 3, 5, 3, 8, 4
Feature Accompaniment: Is It Feasible to Learn Out-of-Distribution Generalizable Representations with In-Distribution Data?,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 4, 5, 4
Out-of-Distribution Detection with Negative Prompts,6.0, 5.5, 1.224744871391589, 5, 4, 6, 5, 8, 4, 5, 5
$\pi$2vec: Policy Representation with Successor Features,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 4, 5, 3, 5, 3
Towards Seamless Adaptation of Pre-trained Models for Visual Place Recognition,7.25, 8.0, 1.299038105676658, 8, 5, 8, 5, 8, 5, 5, 5
Hierarchical Concept Discovery Models: A Concept Pyramid Scheme,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 3, 6, 4, 5, 4
The Uncertainty-Perception Tradeoff,4.75, 4.0, 2.0463381929681126, 5, 3, 3, 2, 3, 4, 8, 4
Multimodal Meta-learning of Implicit Neural Representations with Iterative Adaptation,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 4
Improving Accelerated Federated Learning with Compression and Importance Sampling,5.5, 5.5, 2.5, 3, 3, 8, 2
Detailed 3D Face Reconstruction in Full Pose Range,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 5, 5, 3, 5
BiLoRA: A Bi-level Optimization Framework for Low-rank Adapters,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 3, 5, 3, 5, 3
Generalizable Deep RL-Based TSP Solver via Approximate Invariance,3.0, 3.0, 1.4142135623730951, 5, 4, 1, 5, 3, 4, 3, 3
Mixture Stochastic Block Model for Multi-Group Community Detection in Multiplex Graphs,3.8, 3.0, 0.9797958971132712, 3, 5, 3, 2, 3, 3, 5, 4, 5, 3
CurrMask: Learning Versatile Skills with Automatic Masking Curricula,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 3, 3, 4
FROSTER: Frozen CLIP is A Strong Teacher for Open-Vocabulary Action Recognition,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 3, 5, 5, 6, 4
Interventional Fairness on Partially Known Causal Graphs: A Constrained Optimization Approach,6.666666666666667, 6.0, 0.9428090415820634, 6, 4, 6, 3, 8, 4
Qwen-VL: A Versatile Vision-Language Model for Understanding Localization Text Reading and Beyond,5.333333333333333, 5.0, 2.0548046676563256, 5, 4, 8, 4, 3, 3
Learning Label Shift Correction for Test-Agnostic Long-Tailed Recognition,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 3, 5, 3
Ratio-Residual Diffusion Model for Image Restoration,5.333333333333333, 5.0, 2.0548046676563256, 3, 4, 5, 2, 8, 4
The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World,5.5, 5.5, 0.5, 5, 4, 6, 3
CIFAR-10-Warehouse: Broad and More Realistic Testbeds in Model Generalization Analysis,6.5, 6.0, 0.8660254037844386, 6, 4, 6, 3, 6, 2, 8, 4
Dissolving Is Amplifying: Towards Fine-Grained Anomaly Detection,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 5, 5, 4, 5, 4
Removing Multiple Shortcuts through the Lens of Multi-task Learning,5.0, 5.0, 1.0954451150103321, 5, 4, 6, 3, 6, 2, 5, 3, 3, 4
Orthogonal Function Representations for Continuous Armed Bandits,5.25, 5.0, 0.4330127018922193, 5, 3, 6, 3, 5, 3, 5, 3
TuneMV3D: Tuning Foundational Image Diffusion Models for Generalizable and Scalable Multiview 3D Generation,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 3, 4, 5, 4
TASK PLANNING FOR VISUAL ROOM REARRANGEMENT UNDER PARTIAL OBSERVABILITY,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 4
Reward-Free Exploration by Conditional Divergence Maximization,4.0, 4.0, 1.0, 5, 4, 3, 4, 5, 3, 3, 4
Rethinking the Temporal Modeling for Time Series Forecasting with Hybrid Modeling,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 4, 5, 5
Exploring View Sampling Strategy in Novel View Synthesis from Causal Perspectives,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 2, 3, 3
On Reconstructability of Graph Neural Networks,4.0, 4.0, 1.0, 3, 4, 3, 3, 5, 3, 5, 3
NewTime: Numerically Multi-Scaled Embedding for Large-Scale Time Series Pretraining,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 4, 5, 4, 3, 4
Parallelizing non-linear sequential models over the sequence length,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 3, 6, 4
Unifying Diverse Decision-Making Scenarios with Learned Discrete Actions,4.75, 5.0, 1.0897247358851685, 5, 3, 6, 2, 3, 5, 5, 4
Long-tailed Diffusion Models with Oriented Calibration,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 5, 4, 6, 4
Efficient Discrete Physics-informed Neural Networks for Solving Evolutionary Partial Differential Equations,4.0, 4.0, 1.0, 3, 5, 5, 5, 5, 3, 3, 5
Compresso: Structured Pruning with Collaborative Prompting Learns Compact Large Language Models,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 5, 3, 3, 5, 4
InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior,6.75, 8.0, 2.165063509461097, 8, 4, 3, 2, 8, 4, 8, 5
A Simple Romance Between Multi-Exit Vision Transformer and Token Reduction,7.0, 7.0, 1.0, 8, 4, 6, 2, 6, 4, 8, 5
Learn from the Past: A Proxy based Adversarial Defense Framework to Boost Robustness,4.5, 4.5, 1.5, 6, 4, 3, 5, 3, 4, 6, 4
INRSTEG: FLEXIBLE CROSS-MODAL LARGE CAPACITY STEGANOGRAPHY VIA IMPLICIT REPRESENTATIONS,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 5, 5, 4, 5, 4
Single Motion Diffusion,6.75, 7.0, 1.299038105676658, 8, 4, 8, 3, 5, 3, 6, 3
Optimal Sample Complexity for Average Reward Markov Decision Processes,6.25, 6.0, 1.0897247358851685, 6, 3, 6, 3, 8, 4, 5, 3
Spatio-Temporal Approximation: A Training-Free SNN Conversion for Transformers,5.75, 6.0, 0.4330127018922193, 6, 5, 6, 4, 5, 4, 6, 4
Skill-Conditioned Policy Optimization with Successor Features Representations,5.75, 5.0, 1.299038105676658, 5, 4, 5, 4, 8, 4, 5, 3
Physics-Regulated Deep Reinforcement Learning: Invariant Embeddings,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 3, 5, 2, 6, 3
Heterogeneous Domain Generalization for Single-Source Cross-Dataset Person ReID: An Adaptive Adversarial Augmentation Approach,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 5, 3, 4, 3, 4
SEMANTIC RHEOLOGY: THE FLOW OF IDEAS IN LANGUAGE MODELS,3.25, 3.0, 1.7853571071357126, 6, 3, 1, 5, 3, 3, 3, 4
UniBoost: Boost Zero-shot Vision-Language Tasks via Multitask Fine-tuning with Unsupervised Unimodal Pre-training,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 3, 3, 4
SimVAE: Narrowing the gap between Discriminative & Generative Self-Supervised Representation Learning,4.25, 4.0, 1.299038105676658, 5, 3, 3, 4, 6, 4, 3, 5
AniHead: Efficient and Animatable 3D Head Avatars Generation,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 4, 6, 3
BatteryML:An Open-source platform for Machine Learning on Battery Degradation,6.5, 6.5, 1.5, 8, 3, 5, 3, 8, 3, 5, 2
Representation Bottleneck of Graph Neural Networks for Scientific Problems,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 4, 6, 3
Deep Regression Representation Learning with Topology,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 5, 3, 5, 3, 3, 3, 3, 4, 3, 4
Split and Merge: Aligning Position Biases in Large Language Model based Evaluators,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 5, 6, 4, 5, 3
Revealing the Illusion of Joint Multimodal Understanding in VideoQA Models,4.75, 5.0, 1.0897247358851685, 6, 2, 5, 4, 3, 3, 5, 5
NfgTransformer: Equivariant Representation Learning for Normal-form Games,4.25, 3.0, 2.165063509461097, 8, 4, 3, 4, 3, 4, 3, 4
UPAR: A Kantian-Inspired Prompting Framework for Enhancing Large Language Model Capabilities,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 5, 3, 6, 2
#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models,6.25, 6.0, 1.0897247358851685, 8, 4, 6, 4, 5, 4, 6, 5
When Do Prompting and Prefix-Tuning Work? A Theory of Capabilities and Limitations,6.25, 6.0, 1.0897247358851685, 8, 2, 5, 3, 6, 3, 6, 3
No learning rates needed: Introducing SaLSa - Stable Armijo Line Search Adaptation,6.0, 5.5, 3.082207001484488, 8, 5, 3, 5, 10, 4, 3, 3
Learning Identifiable Balanced Prognostic Score for Treatment Effect Estimation Under Limited Overlap,5.25, 6.0, 1.299038105676658, 3, 4, 6, 4, 6, 2, 6, 3
Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 4, 6, 2
Exploring the Upper Limits of Text-Based Collaborative Filtering Using Large Language Models: Discoveries and Insights,5.5, 5.5, 1.8027756377319946, 3, 4, 8, 4, 6, 3, 5, 4
Understanding In-Context Learning from Repetitions,4.75, 5.0, 1.0897247358851685, 6, 3, 3, 1, 5, 4, 5, 4
LEA: Learning Latent Embedding Alignment Model for fMRI Decoding and Encoding,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4
Analysis of Learning a Flow-based Generative Model from Limited Sample Complexity,6.333333333333333, 8.0, 2.357022603955158, 8, 4, 8, 4, 3, 4
Efficient Diversified Attack: Multiple Diversification Strategies Lead to the Efficient Adversarial Attacks,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 3, 5, 4
Federated Learning Lessons from Generalization Study: Communicate Less Learn More,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 3
Safurai 001: New Qualitative Approach for Evaluation,nan, nan, nan
Ligand Conformation Generation: from singleton to pairwise,3.0, 3.0, 0.0, 3, 2, 3, 3, 3, 4
Few-shot Hybrid Domain Adaptation of Image Generator,5.666666666666667, 6.0, 0.4714045207910317, 5, 2, 6, 4, 6, 3
Boosting Temporal Graph Learning From Global and Local Perspectives,5.0, 5.5, 1.224744871391589, 5, 4, 6, 3, 6, 3, 3, 4
Rethinking Information-theoretic Generalization: Loss Entropy Induced PAC Bounds,6.0, 5.5, 1.224744871391589, 8, 4, 5, 4, 5, 4, 6, 3
Deep Reinforcement Learning for Dynamic Capacitated Vehicle Routing Problem,2.2, 3.0, 0.9797958971132712, 3, 5, 1, 5, 1, 5, 3, 5, 3, 3
Imagination Mechanism: Mesh Information Propagation for Enhancing Data Efficiency in Reinforcement Learning,3.0, 3.0, 0.0, 3, 3, 3, 4, 3, 4, 3, 4
IMO: Greedy Layer-Wise Sparse Representation Learning for Out-of-Distribution Text Classification with Pre-trained Models,3.0, 3.0, 0.0, 3, 4, 3, 4
Towards Robust and Efficient Cloud-Edge Model Adaptation via Selective Entropy Distillation,6.25, 6.0, 1.0897247358851685, 5, 3, 8, 4, 6, 4, 6, 4
TSGM: Regular and Irregular Time-series Generation using Score-based Generative Models,5.25, 5.0, 1.7853571071357126, 5, 3, 8, 3, 3, 3, 5, 4
Causal Structure Learning Supervised by Large Language Model,2.5, 3.0, 0.8660254037844386, 1, 4, 3, 4, 3, 5, 3, 4
KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval,6.25, 6.0, 1.0897247358851685, 8, 3, 6, 3, 6, 3, 5, 4
Boosting Graph Anomaly Detection with Adaptive Message Passing,5.0, 5.5, 1.224744871391589, 5, 4, 6, 3, 6, 4, 3, 3
Knowledge Accumulating Contrastive Prompt for Continual Learning,4.75, 5.0, 1.0897247358851685, 5, 5, 6, 3, 5, 5, 3, 4
Modeling Complex Mathematical Reasoning via Large Language Model based MathAgent,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 3, 5, 4, 3, 4
NF-ICP: Neural Field ICP for Robust 3D Human Registration,5.0, 5.0, 0.0, 5, 5, 5, 3, 5, 4
Cognitive Modeling for Human-Robot Value Soft Alignment,3.0, 3.0, 1.632993161855452, 1, 4, 3, 5, 5, 4
Unsupervised Learning via Network-Aware Embeddings,3.0, 3.0, 1.2649110640673518, 3, 4, 5, 3, 3, 4, 3, 5, 1, 4
Context-Aware Unsupervised Domain Adaptive Lane Detection,4.0, 4.0, 1.0, 5, 4, 3, 4, 3, 4, 5, 4
MINDE: Mutual Information Neural Diffusion Estimation,5.5, 5.5, 0.5, 6, 3, 5, 2, 6, 2, 5, 3
Fine-grained Separation of Action-Background for Point-Level Temporal Action Localization,4.25, 4.0, 1.299038105676658, 5, 5, 3, 5, 6, 4, 3, 5
Semi-Supervised Semantic Segmentation via Marginal Contextual Information,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 6, 5, 5, 3
CAST: Clustering self-Attention using Surrogate Tokens for efficient transformers,4.0, 4.0, 1.0, 3, 5, 5, 4, 3, 5, 5, 4
A Teacher-Guided Framework for Graph Representation Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 3
Point Neighborhood Embeddings,5.5, 5.5, 1.8027756377319946, 6, 5, 8, 3, 3, 4, 5, 3
Continual Momentum Filtering on Parameter Space for Online Test-time Adaptation,5.75, 6.0, 1.7853571071357126, 6, 3, 6, 4, 3, 4, 8, 4
Autoencoders with Intrinsic Dimension Constraints for Learning Low Dimensional Image Representations,4.4, 5.0, 1.2, 5, 3, 3, 4, 6, 4, 5, 4, 3, 4
Relaxed State-Adversarial Offline Reinforcement Learning: A Leap Towards Robust Model-Free Policies from Historical Data,4.0, 4.0, 1.0, 5, 4, 3, 3, 3, 4, 5, 3
Law of Balance and Stationary Distribution of Stochastic Gradient Descent,5.5, 5.5, 1.8027756377319946, 3, 4, 8, 3, 5, 2, 6, 4
Mixup Your Own Pairs,4.666666666666667, 5.0, 1.247219128924647, 3, 5, 5, 4, 6, 3
Generative Adversarial Policy Network for Modelling Protein Complexes,5.5, 5.5, 0.5, 5, 5, 6, 2, 5, 3, 6, 3
fairret: a Framework for Differentiable Fairness Regularization Terms,4.75, 4.0, 2.0463381929681126, 3, 5, 3, 4, 5, 4, 8, 4
Consistency Regularization for Domain Generalization with Logit Attribution Matching,4.4, 5.0, 1.2, 5, 4, 6, 3, 3, 4, 3, 3, 5, 4
On Convergence Rates of Deep Nonparametric Regression under Covariate Shift,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 6, 3, 3, 3
Overcoming Data Inequality across Domains with Semi-Supervised Domain Generalization,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 3, 5, 3, 6, 3
Multi-Agent Bayesian Optimization with Coupled Black-box and Affine Constraints,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 5, 6, 4
RoBERT: Low-Cost Bi-Directional Sequence Model for Flexible Robot Behavior Control,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4
Detecting Out-of-Distribution Samples via Conditional Distribution Entropy with Optimal Transport,5.333333333333333, 5.0, 2.0548046676563256, 3, 4, 5, 4, 8, 4
Easing Non-IID Pain with Dual Relaxations in Federated Learning: SimFAFL redeems an enhanced efficacy,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 5, 4, 3, 3
LeBD: A Run-time Defense Against Backdoor Attack in YOLO,3.25, 3.0, 1.7853571071357126, 3, 5, 3, 4, 1, 5, 6, 3
Debiasing Algorithm through Model Adaptation,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 6, 3, 8, 3
A Foundation Model for Error Correction Codes,6.25, 7.0, 2.0463381929681126, 8, 4, 3, 4, 6, 3, 8, 5
Differentiable Trajectory Optimization as a Policy Class for Reinforcement and Imitation Learning,7.75, 8.0, 1.7853571071357126, 10, 4, 8, 4, 5, 3, 8, 4
The Snowflake Hypothesis: Training Deep GNN with One Node One Receptive field,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 3, 6, 3, 5, 3
Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How,7.5, 8.0, 0.8660254037844386, 8, 4, 8, 3, 8, 3, 6, 4
Drag View: Generalizable Novel View Synthesis with Unposed Imagery,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 4, 3, 4
Revisiting Long-term Time Series Forecasting: An Investigation on Affine Mapping,5.0, 5.5, 1.224744871391589, 6, 4, 6, 3, 3, 4, 5, 4
Ditto: Quantization-Aware Secure Inference of Transformers upon MPC,5.333333333333333, 5.0, 0.4714045207910317, 5, 2, 6, 4, 5, 4
Meta Domain Reweighting for Partially Known Out-of-Distribution Generalization,4.0, 4.0, 1.0, 5, 3, 5, 3, 3, 4, 3, 4
Time Series Missing Imputation with Multivariate Radial Based Function Neural Network,3.0, 3.0, 1.632993161855452, 1, 4, 3, 3, 5, 4
Seer: Language Instructed Video Prediction with Latent Diffusion Models,6.5, 6.0, 0.8660254037844386, 8, 4, 6, 4, 6, 4, 6, 3
Matrix Manifold Neural Networks++,5.333333333333333, 5.0, 2.0548046676563256, 5, 4, 8, 4, 3, 5
EMO: EARTH MOVER DISTANCE OPTIMIZATION FOR AUTO-REGRESSIVE LANGUAGE MODELING,5.25, 6.0, 2.5860201081971503, 1, 4, 6, 4, 6, 4, 8, 4
GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest,6.0, 6.5, 2.1213203435596424, 8, 3, 8, 4, 3, 3, 5, 4
Enhancing Large Language Models in Coding Through Multi-Perspective Self-Consistency,5.2, 5.0, 0.39999999999999997, 5, 4, 5, 4, 5, 5, 6, 5, 5, 4
Corex: Pushing the Boundaries of Complex Reasoning through Multi-Model Collaboration,5.25, 5.0, 1.7853571071357126, 5, 4, 5, 3, 3, 5, 8, 2
Probability-dependent gradient decay in large margin softmax,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 3, 3, 6, 3
Are Human-generated Demonstrations Necessary for In-context Learning?,4.5, 5.5, 2.0615528128088303, 6, 4, 5, 4, 1, 5, 6, 3
Rethinking Texture Patterns in Transformer Neural NetWork for Medical Image Analysis,2.3333333333333335, 3.0, 0.9428090415820634, 3, 5, 3, 5, 1, 4
Provable Dynamic Regularization Calibration,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 5, 4, 3, 4
FLNERF: 3D FACIAL LANDMARKS ESTIMATION IN NEURAL RADIANCE FIELDS,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 5, 3, 3, 5
Revisiting Class-Incremental Learning with Pre-Trained Models: Generalizability and Adaptivity are All You Need,4.75, 5.0, 1.0897247358851685, 6, 5, 3, 5, 5, 4, 5, 3
ViTKD: Feature-based Knowledge Distillation for Vision Transformers,4.25, 4.0, 1.299038105676658, 3, 5, 5, 4, 3, 4, 6, 4
Improving Code Style for Accurate Code Generation,5.666666666666667, 6.0, 0.4714045207910317, 5, 3, 6, 5, 6, 3
Learning without Forgetting for Vision-Language Models,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 5, 5, 5
HumanTOMATO: Text-aligned Whole-body Motion Generation,6.25, 6.0, 1.0897247358851685, 8, 3, 6, 3, 5, 4, 6, 4
Cognition-Supervised Learning: Contrasting EEG Signals and Visual Stimuli For Saliency Detection,4.0, 4.5, 2.1213203435596424, 3, 3, 6, 5, 6, 4, 1, 5
MoleSG: A Multi-Modality Molecular Pre-training Framework by Joint Non-overlapping Masked Reconstruction of SMILES and Graph,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 4, 5, 4
SaProt: Protein Language Modeling with Structure-aware Vocabulary,6.666666666666667, 6.0, 0.9428090415820634, 8, 5, 6, 5, 6, 3
Detecting Change Points in Time Series via Curvatures of Representation Trajectories,4.25, 4.0, 1.299038105676658, 3, 4, 6, 3, 5, 4, 3, 3
PixArt-$\alpha$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis,6.75, 7.0, 1.299038105676658, 5, 4, 8, 4, 6, 4, 8, 4
Sentence-level Prompts Benefit Composed Image Retrieval,6.0, 5.0, 1.4142135623730951, 5, 4, 8, 5, 5, 4
Provable Out-of-Distribution Generalization in Hypersphere,5.0, 6.0, 1.4142135623730951, 3, 4, 6, 3, 6, 3
Towards Generalizable Multi-Camera 3D Object Detection via Perspective Debiasing,5.6, 6.0, 1.624807680927192, 6, 5, 5, 5, 8, 5, 3, 3, 6, 4
Analyzing and Improving OT-based Adversarial Networks,5.6, 6.0, 0.48989794855663565, 6, 4, 6, 3, 6, 4, 5, 3, 5, 3
Unsupervised combinatorial optimization under complex conditions: Principled objectives and incremental greedy derandomization,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 6, 3, 3, 2
Transplant of Perceptrons,3.0, 3.0, 1.4142135623730951, 3, 4, 3, 3, 1, 5, 5, 3
Learning SO(3)-Invariant Correspondence via Point-wise Local Shape Transform,4.8, 5.0, 0.9797958971132712, 6, 2, 5, 4, 3, 4, 5, 4, 5, 4
Quantum AdaBoost with Supervised Learning Guarantee,4.0, 4.0, 1.0, 3, 5, 5, 3, 5, 3, 3, 3
SEABO: A Simple Search-Based Method for Offline Imitation Learning,6.0, 5.5, 1.224744871391589, 5, 4, 6, 5, 8, 4, 5, 4
Hot PATE: Private Aggregation of Distributions for Diverse Tasks,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 3, 5, 3, 3, 4
From generalization analysis to optimization designs for state space models,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 4, 6, 3
Two Time-Slices Help Topological Ordering for Learning Directed Acyclic Graphs,5.333333333333333, 5.0, 2.0548046676563256, 3, 3, 8, 3, 5, 2
ColCLIP: Enhancing Fine-Grained Image Retrieval with Pre-trained Embeddings,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 5, 5, 4
Dynamic Sparse No Training:  Training-Free Fine-tuning for Sparse LLMs,5.666666666666667, 6.0, 0.4714045207910317, 6, 5, 5, 4, 6, 2
Simplifying Transformer Blocks,7.333333333333333, 8.0, 0.9428090415820634, 8, 5, 8, 4, 6, 3
Enhancing Sample Efficiency in Black-box Combinatorial Optimization via Symmetric Replay Training,5.25, 6.0, 1.299038105676658, 6, 3, 3, 4, 6, 4, 6, 4
DEER: A Delay-Resilient Framework for Reinforcement Learning with Variable Delays,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 5, 5, 4
Connection Strength-Based Optimization for Multi-Task Learning,5.0, 5.5, 1.224744871391589, 3, 4, 6, 3, 5, 4, 6, 4
Compositional Generative Inverse Design,5.75, 6.0, 0.4330127018922193, 5, 2, 6, 3, 6, 3, 6, 3
CompoDiff: Versatile Composed Image Retrieval With Latent Diffusion,5.0, 5.0, 0.0, 5, 5, 5, 4, 5, 3, 5, 2
Visual Grounding Helps Learn Word Meanings in Low-Data Regimes,5.0, 4.5, 2.1213203435596424, 3, 4, 6, 4, 8, 3, 3, 4
APC: Predict Global Representation From Local Observation In Multi-Agent Reinforcement Learning,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 5, 5, 3, 5, 3
What does automatic differentiation compute for neural networks?,6.2, 8.0, 2.7129319932501077, 1, 4, 8, 1, 8, 3, 8, 3, 6, 2
Point-Bind & Point-LLM: Aligning Point Cloud with Multi-modality for 3D Understanding Generation and Instruction Following,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 5, 5, 5
Unifying over-smoothing and over-squashing in graph neural networks: A physics informed approach and beyond,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 3, 3, 6, 3
Free Lunches in Auxiliary Learning: Exploiting Auxiliary Labels with Negligibly Extra Inference Cost,7.2, 8.0, 0.9797958971132712, 8, 4, 8, 4, 6, 3, 8, 4, 6, 3
Entropy-enhanced context-aware event prediction based on ontology and external knowledge,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 5, 5, 4
ETGraph: A Pioneering Dataset Bridging Ethereum and Twitter,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 5, 3, 6, 5
Predicting masked tokens in stochastic locations improves masked image modeling,6.0, 5.0, 1.4142135623730951, 5, 3, 8, 4, 5, 4
Enhancing One-Shot Federated Learning Through Data and Ensemble Co-Boosting,4.75, 5.0, 1.0897247358851685, 5, 3, 5, 4, 6, 4, 3, 4
Symbol as Points: Panoptic Symbol Spotting via Point-based Representation,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 5, 3, 4
Fairly Explaining Monotonic Models: a New Shapley Value,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 4, 3, 4
Continual Learning in Open-vocabulary Classification with Complementary Memory Systems,6.0, 5.0, 1.4142135623730951, 8, 3, 5, 4, 5, 4
HypeBoy: Generative Self-Supervised Representation Learning on Hypergraphs,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 4, 5, 3, 5, 3
Preprocessing Enhanced Image Compression for Machine Vision,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 3, 5, 5, 5
Learning Forward Compatible Representation in Class Incremental Learning by Increasing Effective Rank,4.0, 4.0, 1.0, 3, 5, 5, 4, 3, 4, 5, 4
Improving Robustness and Accuracy with Retrospective Online Adversarial Distillation,4.75, 5.0, 1.0897247358851685, 5, 5, 3, 5, 6, 4, 5, 4
Zero-Shot Robustification of Zero-Shot Models,6.5, 6.0, 0.8660254037844386, 6, 4, 6, 3, 8, 5, 6, 3
pEBR: A Probabilistic Approach to Embedding Based Retrieval,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 2, 5, 3
LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 8, 4, 6, 3
MoLE: Human-centric Text-to-image Diffusion with Mixture of Low-rank Experts,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 6, 3, 3, 5
In-Context Learning in Large Language Models: A Neuroscience-inspired Analysis of Representations,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 3, 3, 4, 3, 4
THOUGHT PROPAGATION: AN ANALOGICAL APPROACH TO COMPLEX REASONING WITH LARGE LANGUAGE MODELS,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 6, 4, 8, 4
FedSecurity: A Benchmark for Attacks and Defenses in Federated Learning and Federated LLMs,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 3, 5, 4, 3, 5
Conditional MAE: An Empirical Study of Multiple Masking in Masked Autoencoder,4.25, 4.0, 1.299038105676658, 3, 5, 3, 5, 5, 4, 6, 4
Residual Denoising Diffusion Models,5.25, 5.0, 0.4330127018922193, 5, 4, 6, 4, 5, 5, 5, 4
FreeDyG: Frequency Enhanced Continuous-Time Dynamic Graph Model for Link Prediction,6.5, 6.5, 1.5, 5, 3, 8, 3, 5, 5, 8, 3
Sobolev acceleration for neural networks,4.5, 4.5, 1.5, 6, 3, 6, 2, 3, 3, 3, 3
DreamSmooth: Improving Model-based Reinforcement Learning via Reward Smoothing,5.0, 5.5, 1.224744871391589, 6, 4, 6, 3, 5, 4, 3, 4
OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models,5.2, 6.0, 1.16619037896906, 5, 5, 6, 5, 3, 4, 6, 5, 6, 4
Parameter-Efficient Fine-Tuning via Partially Decomposable Loss Analysis and Sharing,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 3, 3, 2
VONET: ADVANCING UNSUPERVISED VIDEO OBJECT LEARNING,6.0, 5.5, 1.224744871391589, 5, 4, 8, 3, 6, 2, 5, 4
Sparse Mask Representation for Human-Scene Interaction,5.5, 5.5, 1.8027756377319946, 3, 4, 5, 3, 8, 4, 6, 2
Node Duplication Improves Cold-start Link Prediction,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 5, 3, 5
Unified Static and Dynamic: Temporal Filtering Network for Efficient Video Grounding,6.25, 6.0, 1.0897247358851685, 8, 4, 5, 3, 6, 4, 6, 4
Continuous Indeterminate Probability Neural Network,4.666666666666667, 3.0, 2.357022603955158, 3, 2, 8, 3, 3, 3
Efficient Personalized Text-to-image Generation by Leveraging Textual Subspace,5.0, 5.0, 1.0954451150103321, 6, 5, 5, 2, 5, 4, 3, 4, 6, 4
Directional Distance Field for Modeling the Difference between 3D Point Clouds,6.333333333333333, 6.0, 1.247219128924647, 6, 5, 8, 3, 5, 4
Learning Invariant Graph Representations via Virtual Environment Inference,4.0, 4.0, 1.0, 5, 4, 3, 5, 3, 4, 5, 3
LoRAPrune: Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning,4.8, 5.0, 0.9797958971132712, 6, 2, 5, 5, 3, 4, 5, 4, 5, 4
ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source Reconstruction and Target Simulation,4.75, 5.0, 1.0897247358851685, 6, 4, 3, 4, 5, 4, 5, 3
EventCLIP: Adapting CLIP for Event-based Object Recognition,3.8333333333333335, 3.0, 1.2133516482134197, 6, 4, 3, 4, 5, 2, 3, 4, 3, 5, 3, 3
Octavius: Mitigating Task Interference in MLLMs via MoE,5.8, 5.0, 1.9390719429665315, 5, 5, 5, 5, 3, 4, 8, 3, 8, 4
Sampling is as easy as keeping the consistency: convergence guarantee for Consistency Models,5.75, 6.0, 0.4330127018922193, 6, 2, 6, 4, 5, 4, 6, 3
P2P: Transforming from Point Supervision to Explicit Visual Prompt for Object Detection and Segmentation,5.0, 5.5, 1.224744871391589, 5, 4, 6, 4, 6, 3, 3, 5
Motion Guidance: Diffusion-Based Image Editing with Differentiable Motion Estimators,6.25, 6.0, 1.0897247358851685, 6, 3, 6, 4, 8, 4, 5, 4
Improving Multi-task Learning via Seeking Task-based Flat Regions,4.25, 3.0, 2.165063509461097, 3, 5, 3, 4, 8, 3, 3, 4
Learning to Select Camera Views: Efficient Multiview Understanding at Few Glances,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 3, 5, 5, 3
Cosine Similarity Knowledge Distillation for Individual Class Information Transfer,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 4, 3, 4
Balancing Act: Sparse Models with Constrained Disparate Impact,6.333333333333333, 6.0, 1.247219128924647, 5, 3, 8, 3, 6, 4
Boosting Semi-Supervised Learning via Variational Confidence Calibration and Unlabeled Sample Elimination,5.5, 5.5, 0.5, 5, 5, 6, 4, 6, 3, 5, 4
Distribution Shift Resilient GNN via Mixture of Aligned Experts,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 3, 3, 3, 5, 4
FPTQ: FINE-GRAINED POST-TRAINING QUANTIZATION FOR LARGE LANGUAGE MODELS,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 5, 6, 4
NECO: NEural Collapse Based Out-of-distribution detection,5.5, 5.5, 0.5, 5, 3, 6, 4, 5, 3, 6, 4
LightHGNN: Distilling Hypergraph Neural Networks into MLPs for 100x Faster Inference,5.0, 5.5, 1.224744871391589, 5, 3, 6, 4, 6, 2, 3, 4
Maximum Entropy On-Policy Actor-Critic via Entropy Advantage Estimation,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4, 3, 3
Lewis's Signaling Game as beta-VAE For Natural Word Lengths and Segments,5.25, 5.0, 1.7853571071357126, 5, 3, 5, 3, 8, 3, 3, 5
3D Point Cloud Sequences as 2D Videos,4.75, 5.0, 1.0897247358851685, 5, 5, 6, 4, 5, 2, 3, 4
Partial Optimal Transport for Open-set Semi-supervised Learning,5.0, 5.0, 0.0, 5, 3, 5, 4, 5, 4
Probabilistic Stability of Stochastic Gradient Descent,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 3, 5, 4, 3, 3
Domain-Inspired Sharpness Aware Minimization Under Domain Shifts,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 5, 6, 4, 5, 3
Power Characterization of Noisy Quantum Kernels,4.8, 5.0, 0.9797958971132712, 5, 4, 6, 3, 5, 4, 5, 4, 3, 3
Planting a SEED of Vision in Large Language Model,6.0, 5.0, 1.4142135623730951, 8, 4, 5, 5, 5, 3
Semantic Decoupled Distillation,4.0, 4.0, 1.0, 3, 3, 5, 5, 5, 5, 3, 2
Multi-Vision Multi-Prompt for Few-Shot Learning in Vision-Language Model,2.5, 3.0, 0.8660254037844386, 3, 3, 1, 5, 3, 4, 3, 5
A Cognitive Model for Learning Abstract Relational Structures from Memory-based Decision-Making Tasks,6.75, 7.0, 1.299038105676658, 6, 3, 8, 3, 8, 4, 5, 4
LatticeGen: A Cooperative Framework Which Hides Generated Text in A Lattice For Privacy-Aware Generation on Cloud,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 6, 2, 3, 2
Tuning-Free Accountable Intervention for LLM Deployment - A Metacognitive Approach,6.0, 5.5, 1.224744871391589, 5, 4, 8, 3, 6, 2, 5, 3
DynaVol: Unsupervised Learning for Dynamic Scenes through Object-Centric Voxelization,5.0, 5.5, 1.224744871391589, 3, 3, 6, 3, 5, 2, 6, 4
Task Regularized Hybrid Knowledge Distillation For Incremental Object Detection,3.5, 3.0, 0.8660254037844386, 5, 5, 3, 4, 3, 4, 3, 4
Coloring Deep CNN Layers with Activation Hue Loss,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 5, 3, 6, 3
Adaptive Softmax Trees for many-class classification,5.0, 5.5, 1.224744871391589, 6, 4, 6, 2, 5, 4, 3, 3
TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series,5.75, 5.0, 1.299038105676658, 5, 3, 8, 2, 5, 3, 5, 3
Sin3DM: Learning a Diffusion Model from a Single 3D Textured Shape,5.75, 5.0, 1.299038105676658, 8, 4, 5, 3, 5, 4, 5, 4
Ferret: Refer and Ground Anything Anywhere at Any Granularity,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 5, 4, 8, 4
ASPEST: Bridging the Gap Between Active Learning and Selective Prediction,4.25, 4.0, 1.299038105676658, 3, 4, 3, 3, 6, 4, 5, 4
Search-Adaptor: Text Embedding Customization for Information Retrieval,5.333333333333333, 5.0, 2.0548046676563256, 3, 4, 5, 5, 8, 3
From Scarcity to Efficiency: Improving CLIP Training via Visual-enriched Captions,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 5
Physics-Guided Learning of Meteorological Dynamics for Weather Forecasting and Downscaling,4.25, 4.0, 1.299038105676658, 6, 4, 3, 3, 3, 3, 5, 4
Continuously Volumetric Rendering with Neural Density-Distance Fields,2.3333333333333335, 3.0, 0.9428090415820634, 1, 3, 3, 4, 3, 4
Bi-level Contrastive Learning for Knowledge Enhanced Molecule Representations,5.25, 5.0, 1.7853571071357126, 5, 4, 5, 4, 3, 4, 8, 3
Nearest neighbor-based out-of-distribution detection via label smoothing,5.5, 5.5, 1.8027756377319946, 3, 3, 6, 3, 5, 3, 8, 3
Communication Efficient Federated Representation Learning,3.5, 3.0, 0.8660254037844386, 3, 3, 5, 4, 3, 3, 3, 4
On the Implicit Bias of Adam,5.5, 5.5, 0.5, 6, 3, 5, 3, 5, 3, 6, 3
On Causal Discovery in the Presence of Deterministic Relations,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 3, 6, 4, 5, 4
Equivariant Graph Network Approximations of High-Degree Polynomials for Force Field Prediction,5.75, 6.0, 1.7853571071357126, 6, 3, 8, 4, 6, 4, 3, 3
Pooling Image Datasets with Multiple Covariate Shift and Imbalance,5.5, 5.5, 0.5, 5, 1, 6, 3, 6, 3, 5, 4
CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive Learning,5.0, 4.5, 2.1213203435596424, 8, 4, 3, 4, 3, 4, 6, 3
SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation,7.0, 7.0, 1.0, 6, 2, 6, 4, 8, 2, 8, 3
Generalized Knowledge Distillation for Auto-regressive Language Models,6.0, 6.0, 0.0, 6, 3, 6, 3, 6, 3, 6, 3
Adaptive Regularization of Representation Rank as an Implicit Constraint of Bellman Equation,5.5, 5.5, 0.5, 6, 2, 5, 4, 5, 3, 6, 2
Prior Mismatch and Adaptation in PnP-ADMM with a Nonconvex Convergence Analysis,6.0, 5.5, 1.224744871391589, 8, 4, 5, 4, 5, 2, 6, 2
A Stochastic Centering Framework for Improving Calibration in Graph Neural Networks,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 3, 6, 4
Surface Representation in LiDAR Scenes,5.25, 5.0, 0.4330127018922193, 6, 3, 5, 4, 5, 4, 5, 4
Quantifying Zero-shot Coordination Capability with Behavior Preferring Partners,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 5, 3, 4
ReLU to the Rescue: Improve Your On-Policy Actor-Critic with Positive Advantages,4.75, 5.0, 1.0897247358851685, 3, 3, 6, 3, 5, 3, 5, 3
VideoClusterNet: Self-Supervised and Adaptive Face Clustering for Videos,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 4
MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models,4.75, 4.0, 2.0463381929681126, 8, 4, 3, 4, 5, 4, 3, 4
Towards Understanding the Effect of Pretraining Label Granularity,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 6, 2, 5, 2
Symphony: Symmetry-Equivariant Point-Centered Spherical Harmonics for Molecule Generation,5.5, 5.5, 0.5, 6, 3, 6, 4, 5, 4, 5, 3
Bridging the Gap Between Foundation Models and Heterogeneous Federated Learning,6.0, 5.0, 1.4142135623730951, 5, 3, 5, 4, 8, 4
Overcoming Alignment Constraints: G-Patch for Practical Adversarial Attacks on ViTs,4.0, 4.0, 1.0, 5, 4, 5, 4, 3, 4, 3, 5
When Hard Negative Sampling Meets Supervised Contrastive Learning,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 4, 6, 4
Near-optimal algorithms for private estimation and sequential testing of collision probability,5.5, 5.5, 1.8027756377319946, 3, 4, 6, 4, 5, 3, 8, 3
MatFormer: Nested Transformer for Elastic Inference,6.0, 5.5, 1.224744871391589, 8, 3, 5, 4, 6, 4, 5, 3
Set Learning for Accurate and Calibrated Models,5.0, 5.0, 1.8973665961010275, 3, 4, 8, 4, 5, 3, 3, 5, 6, 3
Interpreting and Controlling Vision Foundation Models via Text Explanations,5.25, 5.0, 1.7853571071357126, 5, 4, 5, 4, 8, 4, 3, 3
Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization,5.0, 6.0, 1.4142135623730951, 6, 3, 6, 4, 3, 4
Trajeglish: Learning the Language of Driving Scenarios,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 6, 4, 5, 4
Network calibration under domain shift based on estimating the  target domain accuracy,3.5, 3.0, 0.8660254037844386, 3, 5, 5, 4, 3, 4, 3, 5
SPLITZ: Certifiable Robustness via Split Lipschitz Randomized Smoothing,5.0, 5.5, 2.5495097567963922, 1, 5, 8, 3, 6, 3, 5, 3
Meaning Representations from Trajectories in Autoregressive Models,6.5, 6.0, 0.8660254037844386, 8, 4, 6, 3, 6, 4, 6, 4
Is margin all you need? An extensive empirical study of deep active learning on tabular data,4.75, 5.0, 1.0897247358851685, 3, 2, 5, 5, 5, 4, 6, 2
Instruction-following Evaluation through Verbalizer Manipulation,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 3, 5, 4
How Does Message Passing Improve Collaborative Filtering?,4.75, 4.0, 2.0463381929681126, 5, 4, 3, 4, 3, 5, 8, 4
Splatting-based Motion Context Encoding for Deep Video Compression,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 5, 3, 4
PriViT: Vision Transformers for Fast Private Inference,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 2, 5, 3
Skills-in-Context Prompting:  Unlocking Compositionality in Large Language Models,5.25, 5.0, 1.7853571071357126, 5, 4, 5, 3, 3, 5, 8, 4
Analysis of Task Transferability in Large Pre-trained Classifiers,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 4, 3, 4, 3, 4
DEEP UNSUPERVISED DOMAIN ADAPTATION FOR TIME SERIES CLASSIFICATION: A BENCHMARK,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 3, 4, 5, 3
Robust Network Pruning With Sparse Entropic Wasserstein Regression,6.0, 6.0, 0.0, 6, 2, 6, 2, 6, 2, 6, 3, 6, 3
Circumventing Concept Erasure Methods For Text-To-Image Generative Models,5.8, 6.0, 1.6, 8, 3, 6, 2, 6, 4, 3, 4, 6, 3
Pose Modulated Avatars from Video,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 5, 6, 4
Graph2Tac: Learning hierarchical representations of math concepts in theorem proving,6.0, 5.5, 1.224744871391589, 5, 2, 6, 3, 5, 5, 8, 5
The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images,5.5, 5.5, 1.8027756377319946, 3, 4, 8, 4, 6, 3, 5, 4
Exploring Modality Collaboration with Modality-Agnostic Transformers in Multi-Modal Federated Learning,6.0, 5.5, 3.082207001484488, 10, 4, 3, 4, 8, 4, 3, 4
PEAR: Primitive enabled Adaptive Relabeling for boosting Hierarchical Reinforcement Learning,4.25, 4.0, 1.299038105676658, 6, 3, 3, 4, 5, 4, 3, 3
Unsupervised Representation Learning to Aid Semi-Supervised Meta Learning,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 1, 4, 3, 4
FlexCap: Generating Rich Localized and  Flexible Captions in Images,5.333333333333333, 5.0, 0.4714045207910317, 6, 5, 5, 3, 5, 4
On the Viability of Monocular Depth Pre-training for Semantic Segmentation,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 3, 6, 2, 5, 2
A Discrete and Variational Approach to Speech Representation Learning,5.4, 5.0, 2.244994432064365, 5, 4, 3, 5, 8, 4, 3, 3, 8, 4
Trust Regions for Explanations via Black-Box Probabilistic Certification,4.6, 5.0, 1.3564659966250536, 5, 4, 3, 4, 6, 4, 3, 2, 6, 4
Bayesian Knowledge Distillation for Online Action Detection,4.0, 4.0, 1.0, 5, 4, 3, 4, 5, 2, 3, 4
Complete and Efficient Graph Transformers for Crystal Material Property Prediction,4.75, 5.0, 1.0897247358851685, 5, 5, 5, 3, 3, 5, 6, 3
OpenIns3D: Snap and Lookup for 3D Open-vocabulary Instance Segmentation,5.25, 6.0, 1.299038105676658, 6, 5, 6, 3, 3, 4, 6, 3
Patched Denoising Diffusion Models For High-Resolution Image Synthesis,5.5, 5.5, 0.5, 5, 4, 6, 2, 5, 4, 6, 4
Chunking: Forgetting Matters in Continual Learning even without Changing Tasks,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 3, 4, 5, 4
What Makes Pre-Trained Visual Representations Successful for Robust Manipulation?,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 3
Towards Causal Foundation Model: on Duality between Causal Inference and Attention,6.0, 5.5, 2.5495097567963922, 5, 5, 6, 2, 10, 3, 3, 4
Projected Off-Policy Q-Learning (POP-QL) for Stabilizing Offline Reinforcement Learning,4.0, 4.0, 1.0, 5, 3, 5, 3, 3, 4, 3, 4
SlowFormer: Universal Adversarial Patch for Attack on Compute and Energy Efficiency of Inference Efficient Vision Transformers,4.5, 5.0, 0.8660254037844386, 5, 5, 3, 4, 5, 4, 5, 4
One-stage Prompt-based Continual Learning,5.5, 5.5, 0.5, 6, 4, 5, 4, 6, 3, 5, 4
AV-CPL: Continuous Pseudo-Labeling for Audio-Visual Speech Recognition,3.8, 3.0, 0.9797958971132712, 3, 3, 5, 4, 5, 4, 3, 4, 3, 3
FedMef: Towards Memory-efficient Federated Dynamic Pruning,3.75, 3.0, 1.299038105676658, 3, 5, 6, 4, 3, 4, 3, 1
Local Superior Soups: A Catalyst for Reducing Communication Rounds in Federated Learning with Pre-trained Model,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 3, 5, 6, 4
NOLA: Networks as Linear Combination of Low Rank Random Basis,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 3, 6, 3, 6, 4
Stabilizing Policy Gradients for Stochastic Differential Equations by enforcing Consistency with Perturbation Process,5.333333333333333, 5.0, 0.4714045207910317, 6, 1, 5, 3, 5, 2
Structured Evaluation of Synthetic Tabular Data,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 4, 3, 4
Unveiling Options with Neural Network Decomposition,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 4, 5, 4
Policy Gradient without Boostrapping via Truncated Value Learning,4.75, 5.0, 1.0897247358851685, 3, 2, 5, 3, 5, 3, 6, 3
HIFA: High-fidelity Text-to-3D Generation with Advanced Diffusion Guidance,6.666666666666667, 6.0, 0.9428090415820634, 6, 4, 8, 3, 6, 4
FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing,5.5, 5.5, 0.5, 6, 5, 5, 2, 5, 4, 6, 4
Generalizable Cross-Modality Distillation with Contrastive Learning,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 5, 3, 6, 3
BECLR: Batch Enhanced Contrastive Unsupervised Few-Shot Learning,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 5, 6, 3
Symbolic equation solving via reinforcement learning,3.6666666666666665, 3.0, 0.9428090415820634, 5, 3, 3, 5, 3, 2
How Does Wild Data Provably Help OOD Detection?,5.25, 6.0, 1.299038105676658, 6, 3, 3, 5, 6, 3, 6, 2
Modeling Annotation Delay In Continual Learning,4.0, 4.0, 1.0, 3, 2, 3, 4, 5, 2, 5, 3
Low-coherence Subspace Projection: Enhance the Learning Capacity of Orthogonal Projection Methods on Long Task Sequences,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 2, 3, 4
Delta-AI: Local objectives for amortized inference in sparse graphical models,6.666666666666667, 6.0, 0.9428090415820634, 8, 2, 6, 2, 6, 3
Online Continual Learning Without the Storage Constraint,4.333333333333333, 5.0, 0.9428090415820634, 5, 5, 5, 4, 3, 4
Meta-Tasks: Improving Robustness in Few-Shot Classification with Unsupervised and Semi-Supervised Learning,2.5, 3.0, 0.8660254037844386, 1, 5, 3, 4, 3, 4, 3, 4
Learning Implicit Representation for Reconstructing Articulated Objects,6.2, 5.0, 1.469693845669907, 5, 3, 5, 5, 8, 4, 5, 4, 8, 4
A path toward primitive machine intelligence: LMM not LLM is what you need.,1.0, 1.0, 0.0, 1, 5, 1, 3, 1, 4
LLM-QAT: Data-Free Quantization Aware Training for Large Language Models,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 4, 5, 4
Improving protein optimization with smoothed fitness landscapes,5.0, 5.5, 1.224744871391589, 5, 4, 6, 3, 6, 3, 3, 3
Rethinking Label Poisoning for GNNs: Pitfalls and Attacks,6.0, 6.5, 2.1213203435596424, 3, 5, 8, 3, 5, 3, 8, 3
generative adversarial network with hierarchical semantic prompt constrainting clip for high-quality text-to-image synthesis,3.0, 3.0, 1.4142135623730951, 1, 4, 3, 4, 5, 3, 3, 5
PromptCCD: Learning Gaussian Mixture Prompt Pool for Continual Category Discovery,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 4, 6, 3, 5, 5
Time-Series AutoAugment: Data Augmentation Policy Search for Long-Term Forecasting,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 4, 3, 5
Uniform Approximation of Equivariant/Invariant Neural Networks,3.0, 3.0, 0.0, 3, 3, 3, 5, 3, 4, 3, 4
Structural Estimation of Partially Observed Linear Non-Gaussian Acyclic Model: A Practical Approach with Identifiability,5.75, 6.0, 0.4330127018922193, 5, 4, 6, 3, 6, 3, 6, 4
How to Capture Higher-order Correlations? Generalizing Matrix Softmax Attention to Kronecker Computation,7.333333333333333, 8.0, 0.9428090415820634, 8, 3, 8, 3, 6, 3
From Fake to Real: Pretraining on Balanced Synthetic Images to Prevent Bias,4.25, 4.0, 1.299038105676658, 3, 4, 3, 5, 5, 4, 6, 3
Visual Prompting Reimagined: The Power of Activation Prompts,5.25, 5.0, 1.7853571071357126, 5, 4, 8, 3, 3, 4, 5, 4
BLG: BALANCED LANGUAGE DISTRIBUTION AS GUIDANCE FOR ROBUST LONG-TAILED VISION CLASSIFICATION,4.333333333333333, 5.0, 0.9428090415820634, 3, 5, 5, 4, 5, 2
DreamLLM: Synergistic Multimodal Comprehension and Creation,6.333333333333333, 6.0, 1.247219128924647, 5, 4, 8, 4, 6, 4
Meta Inverse Constrained Reinforcement Learning: Convergence Guarantee and Generalization Analysis,5.5, 5.5, 0.5, 5, 3, 6, 3, 5, 3, 6, 3
Learning to Act from Actionless Videos through Dense Correspondences,5.75, 6.0, 1.7853571071357126, 6, 4, 8, 4, 6, 3, 3, 4
Cleanba: A Reproducible and Efficient Distributed Reinforcement Learning Platform,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 3, 3, 4, 5, 3
Ensembler: Combating model inversion attacks using model ensemble during collaborative inference,3.5, 3.0, 0.8660254037844386, 5, 2, 3, 4, 3, 4, 3, 2
Amortizing intractable inference in large language models,7.25, 8.0, 2.5860201081971503, 8, 3, 8, 4, 10, 4, 3, 4
Correcting Flaws in Common Disentanglement Metrics,3.4, 3.0, 0.8, 3, 2, 3, 4, 5, 3, 3, 3, 3, 4
Combining Spatial and Temporal Abstraction in Planning for Better Generalization,5.5, 5.5, 0.5, 6, 2, 6, 4, 5, 4, 5, 3
LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models,6.0, 6.0, 2.280350850198276, 10, 4, 3, 4, 6, 4, 5, 4, 6, 3
Bayesian low-rank adaptation for large language models,6.333333333333333, 6.0, 1.247219128924647, 8, 3, 5, 3, 6, 4
xMLP: Revolutionizing Private Inference with Exclusive Square Activation,4.0, 4.0, 1.0, 5, 3, 3, 5, 3, 5, 5, 4
Ricci Curvature Robustness and Causal Inference on Networked Data,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 5, 3, 3
On Penalty Methods for Nonconvex Bilevel Optimization and First-Order Stochastic Approximation,6.2, 6.0, 0.9797958971132712, 6, 3, 6, 3, 6, 3, 5, 3, 8, 4
Function-space Parameterization of Neural Networks for Sequential Learning,5.333333333333333, 5.0, 2.0548046676563256, 5, 3, 3, 3, 8, 2
DENEVIL: TOWARDS DECIPHERING AND NAVIGATING THE ETHICAL VALUES OF LARGE LANGUAGE MODELS VIA INSTRUCTION LEARNING,6.5, 5.5, 2.0615528128088303, 5, 3, 5, 3, 10, 4, 6, 3
The Expressive Power of Transformers with Chain of Thought,7.5, 8.0, 0.8660254037844386, 6, 4, 8, 3, 8, 3, 8, 3
DART: A Principled Approach to Adversarially Robust Unsupervised Domain Adaptation,4.5, 4.5, 1.5, 3, 4, 6, 3, 6, 3, 3, 5
TransFusion: Contrastive Learning with Attention Layers,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 3, 4, 5, 4
StyleCL : Latent Dictionary Learning for StyleGAN Without Forgetting,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 3, 4, 5, 2
Fusion over the Grassmannian for High-Rank Matrix Completion,3.0, 3.0, 0.0, 3, 3, 3, 4, 3, 3, 3, 3
Scaling Laws for Sparsely-Connected Foundation Models,6.5, 6.0, 0.8660254037844386, 6, 3, 6, 4, 6, 2, 8, 3
Diff-Privacy: Diffusion-based Face Privacy Protection,6.5, 6.5, 1.5, 8, 4, 5, 4, 8, 4, 5, 3
Decision Transformer is a Robust Contender for Offline Reinforcement Learning,5.25, 6.0, 1.299038105676658, 6, 4, 6, 4, 3, 4, 6, 2
Retentive Network: A Successor to Transformer for Large Language Models,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 2, 5, 5, 6, 5
ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate,5.2, 6.0, 1.16619037896906, 3, 3, 6, 4, 5, 4, 6, 4, 6, 4
GSVA: Gradient-Based Sparse Voxel Attacks \\ on Point Cloud Object Detection,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 3, 3, 4
Towards Environmental Robustness in Deep Reinforcement Learning,4.25, 4.0, 1.299038105676658, 6, 4, 3, 3, 5, 4, 3, 4
Bridging State and History Representations: Understanding Self-Predictive RL,6.0, 6.5, 2.1213203435596424, 8, 3, 5, 4, 8, 3, 3, 2
Linear Convergence Bounds for Diffusion Models via Stochastic Localization,6.666666666666667, 6.0, 0.9428090415820634, 8, 3, 8, 4, 6, 3, 6, 4, 6, 4, 6, 4
GM-DDPM: Denoising diffusion probabilistic models with Gaussian Mixture Noise,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 5, 2, 3, 4
TapMo: Shape-aware Motion Generation of Skeleton-free Characters,6.5, 6.0, 0.8660254037844386, 8, 4, 6, 4, 6, 4, 6, 4
InstructDET: Diversifying Referring Object Detection with Generalized Instructions,5.5, 5.5, 0.5, 5, 4, 6, 3, 5, 3, 6, 4
Democratizing LLMs for Low-Resource Languages by Leveraging their English Dominant Abilities with Linguistically-Diverse Prompts,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 3, 5, 3
Reuse and Diffuse: Iterative Denoising for Text-to-Video Generation,4.0, 4.0, 1.0, 3, 5, 5, 5, 5, 4, 3, 4
Hybrid Representation Learning Via Epistemic Graph,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 5, 3, 3
DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models,5.4, 5.0, 0.48989794855663565, 5, 4, 5, 4, 5, 4, 6, 4, 6, 5
Efficient Training of Multi-task Combinarotial Neural Solver with Multi-armed Bandits,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 3, 5, 3, 3, 3
Iterated Deep $Q$-Network: Efficient Learning of Bellman Iterations for Deep Reinforcement Learning,5.25, 5.0, 1.7853571071357126, 8, 4, 3, 5, 5, 4, 5, 4
SelfEval: Leveraging the discriminative nature of generative models for evaluation,5.0, 6.0, 1.4142135623730951, 3, 4, 6, 3, 6, 3
Universal Metric Learning with Parameter-Efficient Transfer Learning,4.666666666666667, 5.0, 1.247219128924647, 5, 5, 3, 5, 6, 4
RAIN: Your Language Models Can Align Themselves without Finetuning,5.8, 5.0, 1.16619037896906, 5, 4, 6, 4, 5, 3, 8, 3, 5, 3
PBADet: A One-Stage Anchor-Free Approach for Part-Body Association,5.666666666666667, 6.0, 1.4907119849998596, 3, 4, 6, 5, 5, 4, 6, 4, 8, 3, 6, 4
Prompt-based 3D Molecular Diffusion Models for  Structure-based Drug Design,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 6, 3, 3, 4
Performance Gaps in Multi-view Clustering under the Nested Matrix-Tensor Model,6.0, 6.0, 1.0954451150103321, 6, 1, 5, 2, 6, 2, 8, 5, 5, 4
Adapting Cross-View Localization to New Areas without Ground Truth Positions,4.0, 4.0, 1.0, 5, 4, 3, 4
SD4Match: Learning to Prompt Stable Diffusion Model for Semantic Matching,5.333333333333333, 5.0, 2.0548046676563256, 3, 5, 5, 5, 8, 3
Uni3D: Exploring Unified 3D Representation at Scale,6.0, 6.0, 0.0, 6, 4, 6, 4
EZ-CLIP: EFFICIENT ZERO-SHOT VIDEO ACTION RECOGNITION,5.333333333333333, 5.0, 0.4714045207910317, 5, 5, 6, 5, 5, 5
Hierarchical Long-tailed Classification with Visual Language Models,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 6, 4, 5, 4
Set Features for Anomaly Detection,4.0, 4.0, 1.0, 3, 5, 3, 5, 5, 4, 5, 5
Deep Reinforcement Learning Guided Improvement Heuristic for Job Shop Scheduling,7.5, 8.0, 0.8660254037844386, 8, 3, 8, 3, 8, 4, 6, 3
Training-time Neuron Alignment for Improving Linear Mode Connectivity and Model Fusion,5.0, 5.5, 1.224744871391589, 6, 2, 5, 3, 3, 3, 6, 3
MaskedKD: Efficient Distillation of Vision Transformers with Masked Images,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 5, 5, 6, 4
DiffCPS: Diffusion Model based Constrained Policy Search for Offline Reinforcement Learning,5.333333333333333, 5.0, 2.0548046676563256, 3, 5, 8, 4, 5, 4
Unsupervised Data Generation for Offline Reinforcement Learning: A Perspective from Model,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 4, 3, 3
Communication-Efficient Gradient Descent-Accent Methods for Distributed Variational Inequalities: Unified Analysis and Local Updates,5.5, 5.5, 0.5, 5, 3, 5, 3, 6, 4, 6, 4
AutoNeRF: Training Implicit Scene Representations with Autonomous Agents,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 3, 5, 3, 3, 2
Gradient Constrained Sharpness-aware Prompt Learning for Vision-Language Models,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 4, 5, 5
Batch normalization is sufficient for universal function approximation in CNNs,5.25, 5.0, 1.7853571071357126, 5, 3, 3, 2, 8, 5, 5, 2
On the Positive Definiteness of the Neural Tangent Kernel,4.25, 4.0, 1.299038105676658, 3, 3, 5, 3, 6, 3, 3, 4
Unlock Predictable Scaling from Emergent Abilities,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 3, 5, 5, 5, 3
Information based explanation methods for deep learning agents -- with applications on large open-source chess models,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 3, 2, 5, 4
Understanding Calibration Transfer in Knowledge Distillation,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 6, 4, 3, 4
GRAPH-CONSTRAINED DIFFUSION FOR END-TO-END PATH PLANNING,6.0, 6.0, 0.0, 6, 3, 6, 2, 6, 3, 6, 3, 6, 4
How Out-of-Distribution important is,2.5, 3.0, 0.8660254037844386, 1, 3, 3, 4, 3, 4, 3, 3
Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control,6.666666666666667, 6.0, 0.9428090415820634, 6, 4, 6, 2, 8, 3
Elastic Feature Consolidation For Cold Start Exemplar-Free Incremental Learning,6.25, 6.0, 1.0897247358851685, 5, 5, 6, 4, 8, 5, 6, 5
Hyperbolic Visual-Semantic Alignment for Structural Visual Recognition,5.5, 5.5, 0.5, 6, 3, 5, 4
REVISITING LARS FOR LARGE BATCH TRAINING GENERALIZATION OF NEURAL NETWORKS,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 4, 5, 3
Adversarial Causal Bayesian Optimization,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 4, 5, 4
HyperMask: Adaptive Hypernetwork-based Masks for Continual Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 5
Editing Personality for Large Language Models,5.5, 5.5, 1.8027756377319946, 8, 3, 5, 3, 6, 2, 3, 3
Text-to-3D with Classifier Score Distillation,6.75, 7.0, 1.299038105676658, 5, 4, 6, 5, 8, 4, 8, 4
Partitioning-Guided K-Means: Extreme Empty Cluster Resolution for Extreme Model Compression,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 4, 3, 5
Accurate Forgetting for Heterogeneous Federated Continual Learning,5.4, 5.0, 0.4898979485566356, 5, 4, 5, 4, 6, 3, 5, 2, 6, 4
How Far Have We Gone in Vulnerability Detection Using Large Language Model,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 3, 4, 5, 4
ProFITi: Probabilistic Forecasting of Irregular Time Series via Conditional Flows,5.5, 5.5, 0.5, 6, 4, 5, 3, 5, 4, 6, 3
MindGPT: Interpreting What You See with Non-invasive Brain Recordings,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 5, 3, 6, 3
GNeRP: Gaussian-guided Neural Reconstruction of Reflective Objects with Noisy Polarization Priors,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 4, 5, 4, 6, 4
QuickDrop: Efficient Federated Unlearning by Integrated Dataset Distillation,3.75, 3.0, 1.299038105676658, 6, 4, 3, 4, 3, 3, 3, 3
PORF: POSE RESIDUAL FIELD FOR ACCURATE NEURAL SURFACE RECONSTRUCTION,6.0, 5.5, 1.224744871391589, 6, 5, 5, 4, 8, 4, 5, 4
Modelling complex vector drawings with stroke-clouds,5.666666666666667, 6.0, 0.4714045207910317, 6, 5, 6, 4, 5, 4
Spurious Feature Diversification Improves Out-of-distribution Generalization,7.0, 8.0, 1.4142135623730951, 8, 4, 8, 3, 5, 2
Learning Informative Latent Representation for Quantum State Tomography,4.25, 4.0, 1.299038105676658, 3, 3, 5, 4, 6, 4, 3, 5
Ground-A-Video: Zero-shot Grounded Video Editing using Text-to-image Diffusion Models,6.0, 5.5, 1.224744871391589, 5, 4, 6, 3, 8, 4, 5, 4
Harmonized Learning with Concurrent Arbitration: A Brain-inspired Motion Planning Approach,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 4, 3, 4
NDIM: Neuronal Diversity Inspired Model for Multisensory Emotion Recognition,3.5, 4.0, 1.6583123951777, 3, 4, 1, 4, 5, 3, 5, 3
Collapsing the Learning: Crafting Broadly Transferable Unlearnable Examples,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 2, 6, 4, 5, 3
CivRealm: A Learning and Reasoning Odyssey for Decision-Making Agents,7.0, 8.0, 1.4142135623730951, 5, 4, 8, 4, 8, 3
Scalable Language Model with Generalized Continual Learning,6.5, 6.0, 0.8660254037844386, 6, 2, 6, 4, 8, 4, 6, 3
Efficient Backdoor Attacks for Deep Neural Networks in Real-world Scenarios,5.75, 6.0, 1.7853571071357126, 6, 4, 8, 2, 3, 5, 6, 4
Cross-domain Adaptation for Few-shot 3D Shape Generation,5.0, 5.5, 1.224744871391589, 6, 3, 5, 3, 3, 5, 6, 4
Symmetric Basis Convolutions for Learning Lagrangian Fluid Mechanics,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 5, 5, 4, 6, 3
G$^2$N$^2$ : Weisfeiler and Lehman go grammatical,6.333333333333333, 6.0, 1.247219128924647, 8, 3, 6, 2, 5, 4
InstructEdit: Improving Automatic Masks for Diffusion-based Image Editing With User Instructions,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 3, 4, 6, 4
Lightweight Image Super-Resolution via Flexible Meta Pruning,5.8, 5.0, 1.16619037896906, 5, 3, 5, 5, 8, 4, 5, 4, 6, 3
An Image is Worth Multiple Words: Learning Object Level Concepts using Multi-Concepts Prompts Learning,5.75, 6.0, 1.7853571071357126, 6, 3, 8, 3, 6, 3, 3, 3
VertiBench: Advancing Feature Distribution Diversity in Vertical Federated Learning Benchmarks,5.5, 5.5, 0.5, 6, 2, 6, 4, 5, 2, 5, 3
AvatarStudio: High-fidelity and Animatable 3D Avatar Creation from Text,5.333333333333333, 5.0, 2.0548046676563256, 3, 4, 8, 4, 5, 4
Polyak Parameter Ensemble: Exponential Parameter Growth Leads to Better Generalization,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 3, 3, 4
BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge,6.25, 6.0, 1.0897247358851685, 5, 4, 6, 2, 6, 4, 8, 4
Tracking the Change of Knowledge Through Layers in Neural Networks,3.25, 3.0, 1.7853571071357126, 3, 4, 1, 2, 6, 3, 3, 3
Biased Binary Attribute Classifiers Ignore the Majority Classes,3.0, 3.0, 0.0, 3, 4, 3, 2, 3, 4, 3, 4
Motion PointNet: Solving Dynamic Capture in Point Cloud Video Human Action,5.0, 6.0, 1.4142135623730951, 3, 4, 6, 5, 6, 4
Multimodal Web Navigation with Instruction-Finetuned Foundation Models,6.5, 6.5, 1.5, 5, 3, 8, 4
A Real-World WebAgent with Planning Long Context Understanding and Program Synthesis,6.25, 6.0, 1.0897247358851685, 5, 4, 8, 3, 6, 3, 6, 5
Language Model Agents Suffer from Compositional Decision Making,6.25, 6.0, 1.0897247358851685, 6, 4, 5, 3, 8, 4, 6, 3
The Best Defense is Attack: Repairing Semantics in Textual Adversarial Examples,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 4, 6, 2
R2D2-Net: Shrinking Bayesian Neural Networks via R2D2 Prior,4.0, 3.0, 1.4142135623730951, 3, 3, 3, 3, 6, 3
Real-Fake: Effective Training Data Synthesis Through Distribution Matching,5.5, 5.5, 1.8027756377319946, 3, 4, 5, 4, 6, 3, 8, 3
Learning Conditional Invariances through Non-Commutativity,5.333333333333333, 5.0, 2.0548046676563256, 3, 2, 8, 2, 5, 3
Probabilistic Neural Transfer Function Estimation with Bayesian System Identification,4.666666666666667, 3.0, 2.357022603955158, 3, 4, 8, 2, 3, 4
Mitigating Label Noise on Graphs via Topological Curriculum Learning,4.75, 5.0, 1.0897247358851685, 3, 3, 6, 3, 5, 4, 5, 3
Tailored Visions: Enhancing Text-to-Image Generation with Personalized Prompt Rewriting,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4
P4Q: Learning to Prompt for Quantization in Visual-language Models,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 5, 5, 4
Scaling Relationship on Learning Mathematical Reasoning with Large Language Models,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 3, 5, 3
fMRI-PTE: A Large-scale fMRI Pretrained Transformer Encoder for Multi-Subject Brain Activity Decoding,4.0, 4.0, 1.0, 3, 4, 3, 3, 5, 3, 5, 4
KernelWarehouse: Rethinking the Design of Dynamic Convolution,5.833333333333333, 5.5, 1.0671873729054748, 6, 2, 5, 3, 5, 5, 8, 4, 6, 4, 5, 4
Finite Element Operator Learning for Solving Parametric PDEs without Labeled Data,3.0, 3.0, 0.0, 3, 5, 3, 3, 3, 4, 3, 5
Distribution-Free Fair Federated Learning with Small Samples,5.2, 5.0, 1.6, 5, 3, 8, 3, 5, 2, 5, 2, 3, 4
Learning Multiple Coordinated Agents under Directed Acyclic Graph Constraints,4.5, 4.5, 1.5, 3, 3, 6, 3, 3, 4, 6, 3
LEO: Generative Latent Image Animator for Human Video Synthesis,5.0, 6.0, 1.4142135623730951, 3, 4, 6, 3, 6, 4
Form follows Function: Text-to-Text Conditional Graph Generation based on Functional Requirements,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 3, 4, 5, 4
Open-ended VQA benchmarking of Vision-Language models by exploiting Classification datasets and their semantic hierarchy,7.0, 8.0, 1.4142135623730951, 8, 5, 8, 5, 5, 3
OTMatch: Improving Semi-Supervised Learning with Optimal Transport,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 5, 5, 3, 5
Adapting LLM Agents Through Communication,5.0, 5.5, 1.224744871391589, 6, 3, 3, 4, 6, 4, 5, 4
Block-operations: Creating an Inductive Bias to Route Data and Reuse Subnetworks,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 3, 3, 4, 3, 4
GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher,6.5, 6.5, 1.5, 5, 4, 5, 4, 8, 4, 8, 4
Vibroacoustic Frequency Response Prediction with Query-based Operator Networks,6.2, 6.0, 0.9797958971132712, 6, 1, 6, 1, 8, 5, 5, 2, 6, 3
GSINA: Improving Graph Invariant Learning via Graph Sinkhorn Attention,4.2, 5.0, 0.9797958971132712, 5, 4, 5, 4, 3, 3, 3, 4, 5, 3
SEAL: Simultaneous Label Hierarchy Exploration And Learning,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 2, 6, 3, 5, 3
Learning Coverage Paths in Unknown Environments with Reinforcement Learning,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 3, 5, 6, 5
NL2ProGPT: Taming Large Language Model for Conversational Protein Design,4.5, 5.0, 0.8660254037844386, 3, 5, 5, 3, 5, 3, 5, 2
Towards the Fundamental Limits of Knowledge Transfer over Finite Domains,6.25, 6.0, 1.0897247358851685, 6, 3, 6, 3, 8, 4, 5, 2
Dreamix: Video Diffusion Models are General Video Editors,5.25, 5.0, 1.7853571071357126, 8, 5, 5, 3, 3, 5, 5, 4
Activation Function Matters in Graph Transformers,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 3, 5, 3, 5, 4
A PERSPECTIVE OF IMPROPER DYNAMICS ON OFFLINE MODEL-BASED PLANNING,2.5, 3.0, 0.8660254037844386, 3, 4, 1, 4, 3, 4, 3, 4
What Large Language Models Bring to Text-oriented VQA?,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 5, 4, 3, 5
Self-Supervised Speech Quality Estimation and Enhancement Using Only Clean Speech,5.0, 4.5, 2.1213203435596424, 6, 5, 3, 4, 8, 3, 3, 3
Information Flow in Self-Supervised Learning,5.0, 5.5, 2.5495097567963922, 5, 3, 1, 5, 6, 3, 8, 3
Explanation Shift: How Did the Distribution Shift Impact the Model?,5.25, 5.0, 1.7853571071357126, 8, 3, 3, 4, 5, 4, 5, 4
Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning,6.5, 6.5, 1.5, 8, 2, 5, 4, 5, 3, 8, 3
BOWLL: A DECEPTIVELY SIMPLE OPEN WORLD LIFELONG LEARNER,5.75, 5.0, 1.299038105676658, 5, 4, 5, 4, 5, 3, 8, 4
Manifold Kernel Rank Reduced Regression,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 4, 3, 3
LightSeq: Sequence Level Parallelism for Distributed Training of Long Context Transformers,5.0, 5.5, 1.224744871391589, 6, 5, 3, 4, 6, 3, 5, 3
MARINA Meets Matrix Stepsizes: Variance Reduced Distributed Non-Convex Optimization,nan, nan, nan
Contrastive Learning is Spectral Clustering on Similarity Graph,6.0, 5.5, 2.5495097567963922, 6, 3, 5, 4, 3, 4, 10, 3
On the Generalization and Approximation Capacities of Neural Controlled Differential Equations,6.333333333333333, 6.0, 1.247219128924647, 6, 3, 8, 4, 5, 3
Knowledge Transfer through Value Function for Compositional Tasks,3.4, 3.0, 0.8, 3, 4, 3, 3, 5, 4, 3, 4, 3, 4
Connecting the Patches: Multivariate Long-term Forecasting using Graph and Recurrent Neural Network,4.0, 3.0, 1.4142135623730951, 6, 2, 3, 4, 3, 4
GIM: Learning Generalizable Image Matcher From Internet Videos,8.0, 8.0, 1.4142135623730951, 6, 3, 8, 2, 10, 5, 8, 3
Hybrid Defense Strategy for Face Recognition Model Inversion Attack,3.0, 3.0, 1.632993161855452, 1, 4, 3, 3, 5, 4
Voila-A: Aligning Vision-Language Models with User's Gaze Attention,4.75, 5.0, 1.0897247358851685, 5, 3, 6, 3, 3, 2, 5, 4
Ultra-sparse network advantage in deep learning via Cannistraci-Hebb brain-inspired training with hyperbolic meta-deep community-layered epitopology,6.333333333333333, 6.0, 1.247219128924647, 6, 2, 5, 4, 8, 2
Purify Perturbative Availability Poisons via Rate-Constrained Variational Autoencoders,4.5, 5.0, 0.8660254037844386, 3, 3, 5, 4, 5, 3, 5, 2
Continual Test-Time Adaptation by Leveraging Source Prototypes and Exponential Moving Average Target Prototypes,4.8, 5.0, 0.9797958971132712, 3, 4, 5, 4, 5, 5, 6, 3, 5, 4
A Study of Black-Box Attacks Against Robust Federated Learning,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 3, 3, 4
Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs,5.25, 5.0, 0.4330127018922193, 5, 5, 5, 4, 6, 5, 5, 4
Plug-and-Play: An Efficient Post-training Pruning Method for Large Language Models,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 4, 6, 3
Universal Jailbreak Backdoors from Poisoned Human Feedback,5.25, 5.0, 0.4330127018922193, 5, 5, 5, 3, 5, 2, 6, 4
Neural Field Classifiers via Target Encoding and Classification Loss,5.75, 6.0, 0.4330127018922193, 6, 2, 6, 3, 6, 4, 5, 4
Fusion is Not Enough: Single Modal Attack on Fusion Models for 3D Object Detection,5.5, 5.5, 0.5, 6, 4, 5, 3, 6, 4, 5, 4
LipVoicer: Generating Speech from Silent Videos Guided by Lip Reading,5.5, 5.5, 0.5, 6, 4, 5, 4, 6, 4, 5, 3
Fairness Metric Impossibility: Investigating and Addressing Conflicts,4.5, 5.0, 0.8660254037844386, 5, 5, 5, 4, 3, 4, 5, 3
Generalizing to New Dynamical Systems via Frequency Domain Adaptation,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 5, 5, 6, 4
Vision ELECTRA: Adversarial Masked Image Modeling with Hierarchical Discriminator,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 4, 3, 4
Window Attention is Bugged: How not to Interpolate Position Embeddings,5.5, 5.5, 0.5, 5, 3, 6, 3, 5, 4, 6, 2
Embodied Active Defense: Leveraging Recurrent Feedback to Counter Adversarial Patches,6.25, 7.0, 2.0463381929681126, 8, 3, 6, 2, 3, 3, 8, 3
Be Careful What You Smooth For: Label Smoothing Can Be a Privacy Shield but Also a Catalyst for Model Inversion Attacks,5.2, 6.0, 1.16619037896906, 5, 4, 6, 4, 6, 4, 3, 4, 6, 2
NeRFuser: Diffusion Guided Multi-Task 3D Policy Learning,5.25, 5.0, 1.7853571071357126, 8, 4, 3, 4, 5, 4, 5, 3
Continuous Invariance Learning,6.0, 5.5, 1.224744871391589, 6, 4, 5, 4, 8, 4, 5, 3
Style Over Substance: Evaluation Biases for Large Language Models,4.0, 4.0, 1.0, 3, 4, 5, 4
ZipIt! Merging Models from Different Tasks without Training,5.5, 5.5, 0.5, 6, 4, 5, 3, 5, 4, 6, 3
Hybrid Distillation: Connecting Masked Autoencoders with Contrastive Learners,5.5, 5.5, 1.8027756377319946, 6, 4, 8, 3, 5, 5, 3, 4
AdaProj: Adaptively Scaled Angular Margin Subspace Projections for Anomaly Detection with Auxiliary Classification Tasks,4.25, 4.0, 1.299038105676658, 3, 4, 3, 4, 6, 4, 5, 3
SyncDreamer: Generating Multiview-consistent Images from a Single-view Image,7.6, 8.0, 1.4966629547095764, 8, 1, 10, 4, 8, 5, 6, 4, 6, 5
Associative Transformer is a Sparse Representation Learner,4.0, 3.0, 1.4142135623730951, 6, 3, 3, 3, 3, 3
UMMAN: UNSUPERVISED MULTI-GRAPH MERGE ADVERSARIAL NETWORK FOR DISEASE PREDICTION BASED ON INTESTINAL FLORA,4.0, 4.0, 1.0, 3, 3, 5, 4, 3, 3, 5, 3
Facing the Elephant in the Room: Visual Prompt Tuning or Full finetuning?,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 3, 5, 4, 6, 4
Light-Implicit Uncalibrated Photometric Stereo Network With Fourier Embedding,3.5, 3.0, 0.8660254037844386, 3, 5, 5, 5, 3, 5, 3, 5
A Hierarchical Reinforcement Learning Based Optimization FrameWork for Large Scale Storage Location Assignment Problem,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 5, 4
Finite-State Autoregressive Entropy Coding for Efficient Learned Lossless Compression,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 4, 6, 4
PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations,4.0, 5.0, 2.160246899469287, 5, 4, 6, 4, 1, 2
Grounding Multimodal Large Language Models to the World,6.75, 7.0, 1.299038105676658, 6, 4, 8, 4, 5, 4, 8, 4
Understanding the Initial Condensation of Convolutional Neural Networks,4.0, 3.0, 1.4142135623730951, 3, 2, 3, 3, 6, 3
Learning Pseudo 3D Guidance for View-consistent 3D Texturing with 2D Diffusion,4.0, 4.0, 1.0, 5, 4, 5, 3, 3, 4, 3, 4
VFLAIR: A Research Library and Benchmark for Vertical Federated Learning,5.666666666666667, 6.0, 2.0548046676563256, 8, 4, 3, 4, 6, 4
Grouplane: End-to-End 3D Lane Detection with Channel-Wise Grouping,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 3, 5, 5
IRAD: Implicit Representation-driven Image Resampling against Adversarial Attacks,6.0, 5.5, 1.224744871391589, 5, 4, 6, 3, 5, 4, 8, 4
Stylized Offline Reinforcement Learning: Extracting Diverse High-Quality Behaviors from Heterogeneous Datasets,5.25, 5.0, 1.7853571071357126, 5, 5, 5, 4, 3, 5, 8, 4
BSPA: Exploring Black-box Stealthy Prompt Attacks against Image Generators,5.25, 5.0, 1.7853571071357126, 8, 3, 5, 4, 5, 3, 3, 5
ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs,5.5, 5.5, 1.8027756377319946, 6, 5, 8, 5, 5, 4, 3, 4
Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 3, 5, 3, 6, 4
Pre-training with Synthetic Data Helps Offline Reinforcement Learning,5.333333333333333, 5.0, 0.4714045207910317, 6, 5, 5, 3, 5, 2
Careful at Estimation and Bold at Exploration for Deterministic Policy Gradient Algorithm,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 3, 5, 3
An Embodied Generalist Agent in 3D World,4.75, 4.0, 2.0463381929681126, 5, 3, 3, 4, 8, 4, 3, 4
The Effects of Overparameterization on Sharpness-aware Minimization: An Empirical and Theoretical Analysis,5.5, 5.5, 1.8027756377319946, 3, 4, 5, 3, 6, 3, 8, 3
AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 2, 6, 3, 6, 5
Federated Learning Empowered by Generative Content,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 3, 3, 5
Generalization Bounds for Magnitude-Based Pruning via Sparse Matrix Sketching,4.0, 4.5, 2.1213203435596424, 6, 3, 3, 4, 6, 3, 1, 2
Exponential Quantum Advantage in Communication for Distributed Learning,nan, nan, nan
Solving Robust MDPs through No-Regret Dynamics,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3
Towards Mitigating Architecture Overfitting in Dataset Distillation,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 5, 5, 6, 3
TADA: Timestep-Aware Data Augmentation for Diffusion Models,5.0, 4.5, 2.1213203435596424, 3, 4, 3, 4, 6, 2, 8, 2
Large Language Models can $\textit{Share}$ Images Too!,3.8, 3.0, 0.9797958971132712, 3, 4, 3, 4, 5, 2, 5, 4, 3, 4
Visual Category Discovery via Linguistic Anchoring,5.0, 4.5, 2.1213203435596424, 3, 5, 6, 4, 3, 3, 8, 3
Robust Reinforcement Learning with Structured Adversarial Ensemble,5.0, 6.0, 1.4142135623730951, 6, 4, 3, 5, 6, 4
IceFormer: Accelerated Inference with Long-Sequence Transformers on CPUs,5.0, 5.0, 1.0954451150103321, 6, 3, 5, 5, 3, 3, 5, 4, 6, 3
Semantically Aligned Task Decomposition in Multi-Agent Reinforcement Learning,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 2, 3, 4, 6, 3
Efficient Planning with Latent Diffusion,6.25, 6.0, 1.0897247358851685, 8, 5, 5, 2, 6, 4, 6, 2
Repositioning the Subject within Image,4.5, 5.0, 0.8660254037844386, 3, 5, 5, 4, 5, 4, 5, 4
Advancing Counterfactual Inference through Quantile Regression,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 6, 4, 3, 3
MIND: Masked and Inverse Dynamics Modeling for Data-Efficient Deep Reinforcement Learning,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 4, 6, 4, 5, 4
Beyond One-Preference-for-All: Multi-Objective Direct Preference Optimization,6.5, 5.5, 2.0615528128088303, 5, 3, 6, 3, 10, 4, 5, 3
LISA: Reasoning Segmentation via Large Language Model,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 4, 5, 4, 5, 4
StructChart: Perception Structuring Reasoning for Visual Chart Understanding,5.666666666666667, 6.0, 0.4714045207910317, 6, 5, 6, 4, 5, 3
Enhancing Graph Tasks with a Dual-Block Graph Transformer: A Synergistic Approach to Local and Global Attention,3.8, 3.0, 0.9797958971132712, 5, 4, 5, 4, 3, 5, 3, 5, 3, 4
Conformal Prediction via Regression-as-Classification,6.0, 6.5, 2.1213203435596424, 3, 5, 8, 4, 8, 4, 5, 4
The Logarithm Trick: achieve better long term forecast via Mean Logarithm Square Loss,3.5, 3.0, 0.8660254037844386, 3, 2, 5, 3, 3, 4, 3, 4
Unlocking the Potential of Knowledge Distillation: The Role of Teacher Calibration,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 4, 6, 4
SCREWS: A Modular Framework for Reasoning with Revisions,3.75, 3.0, 1.299038105676658, 3, 4, 6, 3, 3, 5, 3, 4
Convolution Meets LoRA: Parameter Efficient Finetuning for Segment Anything Model,6.0, 6.0, 0.0, 6, 3, 6, 4, 6, 4, 6, 3
Localized Linear Temporal Dynamics for Self-supervised Skeleton Action Recognition,4.0, 4.0, 1.0, 5, 4, 3, 3, 5, 3, 3, 5
Reinforcement Learning for Node Selection in Branch-and-Bound,4.0, 4.0, 1.0, 3, 4, 5, 3, 3, 3, 5, 3
Diving Deep into Regions: Exploiting Regional information Transformer for Single Image Deraining,6.5, 6.5, 1.5, 8, 5, 8, 5, 5, 5, 5, 5
Continual Offline Reinforcement Learning via Diffusion-based Dual Generative Replay,4.75, 5.0, 1.0897247358851685, 3, 5, 5, 3, 5, 4, 6, 2
How do agents invest strategically under persistent improvement?,3.6666666666666665, 5.0, 1.8856180831641267, 1, 3, 5, 5, 5, 2
Mixing Corrupted Preferences for Robust and Feedback-Efficient Preference-Based Reinforcement Learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 4
Tag2Text: Guiding Vision-Language Model via Image Tagging,5.6, 6.0, 1.624807680927192, 8, 5, 6, 4, 3, 5, 6, 5, 5, 3
Enhanced Face Recognition using Intra-class Incoherence Constraint,6.5, 6.5, 1.5, 8, 5, 5, 4, 5, 4, 8, 4
Class Incremental Learning via Likelihood Ratio Based Task Prediction,6.0, 5.5, 1.224744871391589, 5, 4, 8, 3, 5, 4, 6, 4
Re-Reading Improves Reasoning in Language Models,6.0, 5.0, 1.4142135623730951, 8, 5, 5, 3, 5, 3
Rethinking the Number of Shots in Robust Model-Agnostic Meta-Learning,4.0, 4.0, 1.0, 5, 3, 3, 4, 5, 4, 3, 4
Entropy is not Enough for Test-time Adaptation: From the Perspective of Disentangled Factors,6.0, 5.5, 1.224744871391589, 5, 5, 5, 3, 6, 5, 8, 4
Lyra: Orchestrating Dual Correction in Automated Theorem Proving,5.0, 5.5, 1.224744871391589, 6, 5, 3, 3, 6, 4, 5, 5
Decentralized Riemannian Conjugate Gradient Method on the Stiefel Manifold,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 4, 5, 3
Discriminatively Matched Part Tokens for Pointly Supervised Instance Segmentation,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 4, 6, 4, 6, 3
Improved Regret Bounds for Non-Convex Online-Within-Online Meta Learning,5.75, 6.0, 0.4330127018922193, 6, 2, 5, 3, 6, 4, 6, 3
Spade : Training-Free Improvement of Spatial Fidelity in Text-to-Image Generation,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 3, 5, 3
PDC-Net: Probability Density Cloud Representations of Proteins for Mutation Effect Prediction,4.25, 4.0, 1.299038105676658, 5, 2, 3, 3, 3, 3, 6, 4
Momentum Benefits Non-iid Federated Learning Simply and Provably,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 5, 4
Vector-valued Representation is the Key: A Study on Disentanglement and Compositional Generalization,4.25, 4.0, 1.299038105676658, 3, 2, 5, 5, 3, 4, 6, 5
LLM-Oriented Retrieval Tuner,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 6, 3, 3, 3
Detecting Machine-Generated Texts by Multi-Population Aware Optimization for Maximum Mean Discrepancy,6.25, 6.0, 1.0897247358851685, 5, 3, 6, 3, 8, 3, 6, 3
SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution,7.0, 7.0, 1.0, 8, 4, 6, 2, 8, 5, 6, 4
Model-Based Offline Reinforcement Learning with Conservative Bidirectional Rollouts,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 4, 3, 4
Defect Spectrum: A Granular Look of Large-Scale Defect Datasets with Rich Semantics,5.5, 5.5, 1.8027756377319946, 5, 5, 3, 4, 8, 4, 6, 4
Only Pay for What Is Uncertain: Variance-Adaptive Thompson Sampling,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 3, 6, 4, 5, 4
Isometric Representation Learning for Disentangled Latent Space of Diffusion Models,5.5, 5.5, 1.8027756377319946, 6, 4, 3, 4, 8, 3, 5, 3
Dynamic Electroencephalography Representation Learning for Improved Epileptic Seizure Detection,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 4, 6, 4
Dissecting Arbitrary-scale Super-resolution Capability from Pre-trained Diffusion Generative Models,5.5, 5.5, 0.5, 6, 4, 6, 5, 5, 4, 5, 3
CEDNet: A Cascade Encoder-Decoder Network for Dense Prediction,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 5, 3, 5
Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood,5.6, 6.0, 0.4898979485566356, 6, 3, 5, 5, 6, 2, 6, 4, 5, 5
Valley: Video Assistant with Large Language model Enhanced abilitY,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 6, 5, 5, 3
Semantic Memory Guided Diffusion Networks for Image-to-Long Text Generation,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 2, 5, 4
Bi-directional Deformation for Parameterization of Neural Implicit Surfaces,4.0, 4.0, 1.0, 3, 4, 5, 3, 3, 3, 5, 4
Re-imagine the Negative Prompt Algorithm for 2D/3D Diffusion,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 4, 5, 5, 5, 5
Anytime Neural Architecture Search on Tabular Data,5.0, 5.5, 1.224744871391589, 6, 4, 5, 5, 3, 3, 6, 3
Differential Model Scaling using Differential Topk,5.0, 5.0, 1.0954451150103321, 5, 5, 5, 3, 6, 5, 3, 3, 6, 4
Learning Label Refinement and Thresholds for Imbalanced Semi-Supervised Learning,4.0, 4.0, 1.0, 3, 5, 3, 5, 5, 3, 5, 4
Instructed Diffuser with Temporal Condition Guidance for Offline Reinforcement Learning,4.75, 5.0, 1.0897247358851685, 3, 3, 6, 1, 5, 3, 5, 3
Direct Inversion: Boosting Diffusion-based Editing with 3 Lines of Code,5.5, 5.5, 0.5, 6, 4, 5, 2, 6, 4, 5, 4
TaCA: Hot-Plugging Upgrades for Foundation Model with Task-agnostic Compatible Adapter,5.25, 5.0, 0.4330127018922193, 6, 5, 5, 3, 5, 4, 5, 4
Lipschitz Singularities in Diffusion Models,7.5, 8.0, 0.8660254037844386, 6, 4, 8, 4, 8, 3, 8, 3
Local Expert Diffusion Models for Efficient Training in Denoising Diffusion Probabilistic Models,3.75, 3.0, 1.299038105676658, 3, 3, 6, 1, 3, 5, 3, 2
MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning,7.0, 7.0, 1.0, 6, 4, 6, 3, 8, 4, 8, 4
A Benchmark Study on Calibration,5.0, 6.0, 1.4142135623730951, 6, 4, 3, 4, 6, 3
Enhancing Human-AI Collaboration Through Logic-Guided Reasoning,5.75, 6.0, 1.7853571071357126, 8, 2, 3, 4, 6, 3, 6, 2
Learning with Mixture of Prototypes for Out-of-Distribution Detection,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 5, 6, 3, 5, 3
PINNsFormer: A Transformer-Based Framework For Physics-Informed Neural Networks,6.0, 6.5, 2.1213203435596424, 3, 3, 5, 4, 8, 5, 8, 4
Attention-Guided Contrastive Role Representations for Multi-agent Reinforcement Learning,4.25, 4.0, 1.299038105676658, 6, 4, 3, 5, 3, 4, 5, 3
DeeDiff: Dynamic Uncertainty-Aware Early Exiting for Accelerating Diffusion Model Generation,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 4, 5, 4
SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 3, 5, 5, 4
Towards More Accurate Diffusion Model Acceleration with A Timestep Aligner,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 2
Multi-Objective Molecular Design through Learning Latent Pareto Set,4.333333333333333, 5.0, 0.9428090415820634, 5, 5, 3, 3, 5, 4
UniINR: Unifying Spatial-Temporal INR for RS Video Correction Deblur and Interpolation with an Event Camera,5.0, 5.0, 0.0, 5, 4, 5, 1, 5, 5, 5, 4
Advancing Beyond Identification: Multi-bit Watermark for Large Language Models,4.8, 5.0, 0.9797958971132712, 3, 4, 5, 5, 5, 2, 6, 4, 5, 3
CTP: A Causal Interpretable Model for Non-Communicable Disease Progression Prediction,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 3, 3, 5, 5, 3
SAIR: LEARNING SEMANTIC-AWARE IMPLICIT REPRESENTATION,5.5, 5.5, 0.5, 5, 4, 6, 3, 6, 4, 5, 2
Debias the Training of Diffusion Models,4.75, 4.0, 2.0463381929681126, 5, 4, 8, 5, 3, 4, 3, 4
A Statistical Analysis of Wasserstein Autoencoders for Intrinsically Low-dimensional Data,6.0, 6.0, 0.0, 6, 3, 6, 4, 6, 3, 6, 4
Pixel Reweighted Adversarial Training,4.75, 5.0, 1.0897247358851685, 3, 4, 6, 4, 5, 3, 5, 3
Dense Representation Learning for a Joint-Embedding Predictive Architecture,5.5, 5.5, 1.8027756377319946, 6, 5, 8, 4, 3, 4, 5, 5
Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models,6.0, 6.0, 0.0, 6, 4, 6, 3, 6, 4
UniPose: Detecting Any Keypoints,5.0, 5.5, 1.224744871391589, 3, 4, 6, 3, 5, 5, 6, 3
Structuring Representation Geometry with Rotationally Equivariant Contrastive Learning,6.25, 6.0, 1.0897247358851685, 5, 4, 8, 3, 6, 3, 6, 3
STFormer : Spatial Temporal Spiking Transformer,3.0, 3.0, 0.0, 3, 5, 3, 5, 3, 3, 3, 4
Decodable and Sample Invariance Continuous Object Encoder,7.333333333333333, 8.0, 0.9428090415820634, 8, 2, 6, 4, 8, 3
Neural Snowflakes: Universal Latent Graph Inference via Trainable Latent Geometries,6.333333333333333, 6.0, 1.247219128924647, 6, 2, 8, 3, 5, 3
Multi-Task Learning with Hypernetworks and Task Metadata,4.0, 4.0, 1.0, 5, 4, 5, 4, 3, 4, 3, 3
Graph ODE with Factorized Prototypes for Modeling Complicated Interacting Dynamics,4.75, 5.0, 1.0897247358851685, 5, 5, 5, 4, 6, 4, 3, 2
Context is Environment,5.5, 5.5, 1.8027756377319946, 3, 4, 6, 3, 5, 3, 8, 3
FIAT: Fusing learning paradigms with Instruction-Accelerated Tuning,3.75, 4.0, 1.920286436967152, 5, 4, 6, 3, 1, 4, 3, 4
Generalized Neural Sorting Networks with Error-Free Differentiable Swap Functions,5.5, 5.5, 0.5, 5, 3, 6, 3, 6, 3, 5, 1
IMPUS: Image Morphing with Perceptually-Uniform Sampling Using Diffusion Models,5.5, 5.5, 0.5, 5, 3, 6, 4, 6, 4, 5, 4
Bridge-TTS: Text-to-Speech Synthesis with Schrodinger Bridge,4.25, 4.0, 1.299038105676658, 3, 5, 5, 2, 6, 2, 3, 3
Don't Paint Everyone with the Same Brush: Adaptive Prompt Prototype Learning for Vision-Language Models,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 5, 5, 5, 5, 4
Adaptive Instrument Design for Indirect Experiments,5.75, 6.0, 1.7853571071357126, 3, 3, 6, 4, 8, 3, 6, 3
Towards Personalized AI: Early-stopping Low-Rank Adaptation of Foundation Models,4.25, 4.0, 1.299038105676658, 3, 4, 3, 3, 6, 4, 5, 3
Divided Attention: Unsupervised Multiple-object Discovery and Segmentation with Interpretable Contextually Separated Slots,4.75, 5.0, 1.0897247358851685, 5, 3, 6, 2, 5, 4, 3, 5
Sub-token ViT Embedding via Stochastic Resonance Transformers,6.0, 5.0, 1.4142135623730951, 8, 4, 5, 3, 5, 4
Sequence-Level Certainty Reduces Hallucination In Knowledge-Grounded Dialogue Generation,4.0, 4.0, 1.0, 5, 4, 5, 4, 3, 3, 3, 4
Finding Adversarially Robust Graph Lottery Tickets,5.0, 5.5, 1.224744871391589, 3, 5, 5, 3, 6, 1, 6, 4
Silencer: Pruning-aware Backdoor Defense for Decentralized Federated Learning,4.5, 5.0, 0.8660254037844386, 3, 3, 5, 3, 5, 3, 5, 3
Self-Guided Masked Autoencoders for Domain-Agnostic Self-Supervised Learning,5.2, 5.0, 0.39999999999999997, 5, 3, 5, 4, 5, 4, 6, 3, 5, 2
Rethinking Effectiveness of Unsupervised Domain Adaptation Methods,4.25, 4.0, 1.299038105676658, 3, 5, 3, 5, 6, 4, 5, 3
OmniMixup: Generalize Mixup with Mixing-Pair Sampling Distribution,3.4, 3.0, 1.4966629547095767, 3, 5, 3, 3, 5, 3, 1, 4, 5, 4
Zero-shot Visual Recognition via Pairwise Attribute Contrasting,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 3, 4, 5, 3
Expert Proximity as Surrogate Rewards for Single Demonstration Imitation Learning,5.25, 5.0, 0.4330127018922193, 6, 3, 5, 4, 5, 3, 5, 4
Optimal and Generalizable Multimodal Representation Learning Framework through Adaptive Graph Construction,3.0, 3.0, 1.4142135623730951, 5, 4, 1, 4, 3, 5, 3, 4
Accelerating Retrieval-augmented Language Model Serving with Speculation,4.25, 4.0, 1.299038105676658, 6, 3, 5, 4, 3, 3, 3, 3
Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL,5.5, 5.5, 0.5, 5, 4, 6, 4, 5, 3, 6, 3
Time Travel in LLMs: Tracing Data Contamination in Large Language Models,5.75, 6.0, 1.7853571071357126, 6, 3, 8, 3, 6, 2, 3, 4
Compact Text-to-SDF via Latent Modeling,5.75, 6.0, 1.7853571071357126, 6, 4, 8, 3, 3, 4, 6, 4
UniPredict: Large Language Models are Universal Tabular Predictors,4.8, 5.0, 1.8330302779823362, 5, 3, 8, 3, 3, 5, 3, 3, 5, 5
BioBridge: Bridging Biomedical Foundation Models via Knowledge Graph,5.75, 6.0, 0.4330127018922193, 6, 5, 6, 3, 5, 4, 6, 4
MediTab: Scaling Medical Tabular Data Predictors via Data Consolidation Enrichment and Refinement,5.0, 6.0, 1.4142135623730951, 6, 3, 3, 5, 6, 3
WinSyn: A High Resolution Testbed for Synthetic Data,3.5, 3.0, 0.8660254037844386, 3, 3, 5, 4, 3, 3, 3, 4
Traveling Words: A Geometric Interpretation of Transformers,3.5, 3.0, 0.8660254037844386, 5, 2, 3, 4, 3, 2, 3, 4
Knowledge Distillation for Predicting Varying Environment Maps from Single Images,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 6, 3, 3, 3
Hypothesis- and Structure-based prompting for medical and business diagnosis,2.5, 3.0, 0.8660254037844386, 3, 4, 1, 4, 3, 3, 3, 2
Predicate-Argument Relations in the Human Brain,4.25, 3.0, 2.165063509461097, 3, 3, 3, 4, 8, 4, 3, 5
Does Calibration Affect Human Actions?,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 5, 4, 6, 4
Interpreting CLIP's Image Representation via Text-Based Decomposition,7.0, 7.0, 1.0, 8, 4, 6, 4, 6, 2, 8, 4
Does GPT-4 have good intuition about functions?,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 4, 3, 4
Learning from Fragmentary Multivariate Time Series Data with Scalable Numerical Embedding,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 5, 5, 3, 5
ShareFormer: Share Attention for Efficient Image Restoration,5.0, 6.0, 1.4142135623730951, 6, 2, 6, 5, 3, 4
Towards Few-Shot Adaptation of Foundation Models via Multitask Finetuning,6.0, 5.5, 1.224744871391589, 6, 3, 8, 3, 5, 4, 5, 5
When Self-Supervised Learning Meets Unbounded Pseudo-Label Generation,4.333333333333333, 5.0, 0.9428090415820634, 5, 2, 3, 4, 5, 4
ReTaSA: A Nonparametric Functional Estimation Approach for Addressing Continuous Target Shift,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 4, 6, 3, 6, 3
Variational Inference for SDEs Driven by Fractional Noise,6.25, 6.0, 1.0897247358851685, 8, 5, 6, 3, 5, 3, 6, 4
MaXTron: Mask Transformer with Trajectory Attention for Video Panoptic Segmentation,4.5, 4.5, 1.5, 3, 5, 6, 3, 6, 4, 3, 4
Leveraging Task Structures for Improved Identifiability in Neural Network Representations,5.0, 5.0, 0.0, 5, 3, 5, 2, 5, 3
Neural Tangent Kernels for Axis-Aligned Tree Ensembles,5.5, 5.5, 0.5, 6, 3, 5, 4, 6, 2, 5, 3
Integrating View Conditions for Image Synthesis,5.0, 5.0, 0.0, 5, 5, 5, 3, 5, 3, 5, 4
SMOOT: Saliency Guided Mask Optimized Online Training,nan, nan, nan
GPAvatar: Generalizable and Precise Head Avatar from Image(s),6.0, 6.0, 0.0, 6, 5, 6, 4, 6, 4
Efficient Quantization-aware Training with Adaptive Coreset Selection,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 3, 3, 5
Aligning Persistent Homology with Graph Pooling,4.25, 4.0, 1.299038105676658, 6, 3, 3, 4, 5, 4, 3, 4
Implicit regularization of deep residual networks towards neural ODEs,7.0, 7.0, 1.0, 8, 4, 6, 2, 8, 4, 6, 2
NetInfoF Framework: Measuring and Exploiting Network Usable Information,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 8, 3, 6, 4
Self-Evolving Neural Radiance Fields,5.0, 5.5, 1.224744871391589, 6, 3, 3, 3, 5, 4, 6, 5
Latent Space Symmetry Discovery,5.666666666666667, 6.0, 2.0548046676563256, 6, 3, 3, 4, 8, 5
On the Generalization of Temporal Graph Learning with Theoretical Insights,5.25, 5.0, 1.7853571071357126, 8, 4, 3, 4, 5, 3, 5, 2
Can Neural Networks Improve Classical Optimization of Inverse Problems?,3.25, 3.0, 1.7853571071357126, 1, 4, 3, 4, 6, 2, 3, 4
Mind Your Augmentation: The Key to Decoupling Dense Self-Supervised Learning,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 8, 2, 6, 4
Entropy-MCMC: Sampling from Flat Basins with Ease,6.2, 6.0, 0.9797958971132712, 5, 3, 6, 3, 6, 4, 8, 4, 6, 4
General-purpose Pre-trained Model Towards Cross-domain Molecule Learning,5.25, 5.0, 1.7853571071357126, 5, 4, 8, 4, 5, 4, 3, 4
Pruning-as-Reconstruct: Masked Autoencoders are Efficient Importance Indicators,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 3, 5, 5
IPR-NeRF: Ownership Verification Meets Neural Radiance Field,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 2, 5, 2, 6, 4
ConceptHash: Interpretable Fine-Grained Hashing with Concept Discovery,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 6, 3, 5, 3
Xformer: Hybrid X-Shaped Transformer for Image Denoising,6.5, 6.5, 1.5, 8, 5, 5, 2, 8, 4, 5, 4
LatentWarp: Consistent Diffusion Latents for Zero-Shot Video-to-Video Translation,5.25, 5.0, 0.4330127018922193, 5, 5, 6, 4, 5, 5, 5, 4
Asynchronous Graph Generators,3.0, 3.0, 0.0, 3, 4, 3, 3
SemiAugIR: Semi-supervised Infrared Small Target Detection via Thermodynamics-Inspired Data Augmentation,5.333333333333333, 5.0, 2.0548046676563256, 8, 5, 5, 3, 3, 2
Spiking Hybrid Attentive Mechanism with Decoupled Layer Normalization for Joint Sound Localization and Classification,5.0, 5.5, 2.5495097567963922, 5, 4, 1, 3, 8, 2, 6, 3
De novo Drug Design using Reinforcement Learning with Dynamic Vocabulary,3.0, 3.0, 0.0, 3, 4, 3, 3, 3, 3, 3, 4
Learning to Embed Time Series Patches Independently,6.25, 6.0, 1.0897247358851685, 5, 2, 8, 4, 6, 2, 6, 3
SemPLeS: Semantic Prompt Learning for Weakly-Supervised Semantic Segmentation,5.25, 5.0, 1.7853571071357126, 3, 5, 5, 5, 5, 5, 8, 4
TransFace: Unit-Based Audio-Visual Speech Synthesizer for Talking Head Translation,5.25, 6.0, 1.299038105676658, 6, 3, 6, 4, 6, 3, 3, 3
Understanding Convergence and Generalization in Federated Learning through Feature Learning Theory,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 6, 3, 5, 4
BarLeRIa: An Efficient Tuning Framework for Referring Image Segmentation,6.666666666666667, 6.0, 0.9428090415820634, 6, 4, 8, 4, 6, 2
Unleashing the power of Neural Collapse for Transferability Estimation,5.8, 5.0, 1.16619037896906, 5, 4, 5, 4, 6, 3, 5, 5, 8, 2
Local Search GFlowNets,6.333333333333333, 6.0, 1.247219128924647, 8, 2, 5, 4, 6, 3
Awakening Collective Wisdom: Elevating Super-Resolution Network Generalization through Cooperative Game Theory,6.25, 6.0, 1.0897247358851685, 8, 4, 6, 5, 6, 5, 5, 3
Open Sesame! Universal Black Box Jailbreaking of Large Language Models,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 4, 5, 5, 5, 4
Quantifying the Sensitivity of Inverse Reinforcement Learning to Misspecification,6.25, 6.0, 1.0897247358851685, 6, 2, 6, 3, 5, 2, 8, 3
Rethinking CNN’s Generalization to Backdoor Attack from Frequency Domain,5.0, 5.5, 1.224744871391589, 6, 3, 3, 4, 6, 2, 5, 3
Adversarial Robust Representation Learning via Contrast and Alignment,5.25, 5.0, 1.7853571071357126, 5, 4, 8, 5, 5, 4, 3, 4
LLCP: Learning Latent Causal Processes for Reasoning-based Video Question Answer,5.8, 5.0, 1.9390719429665317, 8, 5, 3, 4, 5, 3, 5, 4, 8, 4
CosPGD: an efficient white-box adversarial attack for pixel-wise prediction tasks,4.75, 5.0, 1.0897247358851685, 5, 4, 3, 4, 5, 4, 6, 5
Which pre-trained model is effective for speech separation ?,5.0, 5.0, 0.0, 5, 5, 5, 4, 5, 3, 5, 4
VoiceGen: Describing and Generating Voices with Text Prompt,5.0, 5.5, 1.224744871391589, 5, 4, 6, 5, 6, 3, 3, 3
Speeding Up Speech Synthesis In Diffusion Models By Reducing Data Distribution Recovery Steps Via Content Transfer,nan, nan, nan
Observation-Guided Diffusion Probabilistic Models,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 3, 5, 4
VEGA: Visual Expression Guidance for Referring Expression Segmentation,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 5
Out of Sight: A Framework for Egocentric Active Speaker Detection,4.0, 4.5, 2.1213203435596424, 1, 4, 3, 4, 6, 3, 6, 4
T-Stitch: Accelerating Sampling in Pre-Trained Diffusion Models with Trajectory Stitching,5.5, 5.5, 1.8027756377319946, 3, 4, 5, 4, 8, 4, 6, 3
A Study of Unsupervised Evaluation Metrics for Practical and Automatic Domain Adaptation,5.0, 5.5, 1.224744871391589, 6, 4, 5, 3, 6, 4, 3, 5
Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 6, 3, 8, 3
SEEKER: Semi-Supervised Knowledge Transfer for Query-Efficient Model Extraction,5.333333333333333, 5.0, 0.4714045207910317, 5, 2, 5, 3, 6, 3
Rethinking One-vs-the-Rest Loss for Instance-dependent Complementary Label Learning,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 3, 3, 4
Unified Interpretation of Smoothing Methods for Negative Sampling Loss Functions in Knowledge Graph Embedding,5.0, 5.5, 1.224744871391589, 6, 2, 3, 3, 5, 3, 6, 4
A SYSTEMATIC STUDY ON EARLY STOPPING CRITERIA IN HPO AND THE IMPLICATIONS OF UNCERTAINTY,4.666666666666667, 3.0, 2.357022603955158, 3, 3, 8, 3, 3, 5
Stay on Topic with Classifier-Free Guidance,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 4, 6, 3
VC dimensions for deep neural networks with bounded-rank weight matrices,3.75, 3.0, 1.299038105676658, 6, 3, 3, 2, 3, 3, 3, 4
Multi-conditioned Graph Diffusion for Neural Architecture Search,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 5, 3, 3, 4
RTFS-Net: Recurrent time-frequency modelling for efficient audio-visual speech separation,7.0, 7.0, 1.0, 8, 4, 6, 4, 6, 4, 8, 4
Incorporating Domain Knowledge in VAE Learning via Exponential Dissimilarity-Dispersion Family,4.8, 5.0, 0.9797958971132712, 5, 4, 5, 2, 5, 3, 6, 4, 3, 3
Vision-Language Instruction-enhanced Tuning via Parameter-efficient Learning,4.0, 4.0, 1.0, 5, 4, 3, 5, 3, 4, 5, 3
RRescue: Ranking LLM Responses to Enhance Reasoning Over Context,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 3, 3, 3, 3, 5
Can Pre-trained Networks Detect Familiar Out-of-Distribution Data?,4.0, 4.0, 1.0, 3, 4, 3, 3, 5, 5, 5, 3
OceanGPT:  A Large Language Model for Ocean  Science Tasks,4.333333333333333, 5.0, 0.9428090415820634, 3, 5, 5, 4, 5, 4
Reverse Stable Diffusion: What prompt was used to generate this image?,4.0, 5.0, 2.160246899469287, 6, 3, 1, 4, 5, 4
Structured Pruning Adapters,3.75, 4.0, 1.920286436967152, 1, 4, 3, 5, 5, 4, 6, 4
Prompt Space Optimizing Few-shot Reasoning Success with Large Language Models,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 4, 3, 4, 3, 4
DGTAT: DECOUPLED GRAPH TRIPLE ATTENTION NETWORKS,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 3, 5, 4
RegCLIP: A Label-Efficient Coarse-to-Fine Learner for Ordinal Regression,4.8, 5.0, 1.8330302779823362, 3, 4, 5, 5, 5, 4, 8, 5, 3, 5
Arithmetic with Language Models: from Memorization to Computation,4.25, 4.0, 1.299038105676658, 5, 4, 6, 2, 3, 3, 3, 3
DER-Solomon: A Large Number of CVRPTW Instances Generated Based on the Solomon Benchmark Distribution,3.75, 3.0, 1.299038105676658, 3, 3, 3, 4, 6, 3, 3, 3
Consistent Video-to-Video Transfer Using Synthetic Dataset,6.5, 6.5, 1.5, 5, 4, 8, 4, 5, 4, 8, 3
Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a Bayesian Game,5.0, 6.0, 1.4142135623730951, 6, 4, 3, 3, 6, 4
Causal Unsupervised Semantic Segmentation,5.0, 5.5, 1.224744871391589, 3, 4, 6, 4, 5, 4, 6, 3
Scale-Adaptive Diffusion Model for Complex Sketch Synthesis,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 4, 6, 4, 5, 4
Sparse Labels Node Classification: Unsupervised Learning for Mentoring Supervised Learning in Sparse Label Settings,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 4, 5, 4
Uncertainty-aware Distributional Offline Reinforcement Learning,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 5, 3, 3, 4
Towards Complex-query Referring Image Segmentation: A Novel Benchmark,4.25, 3.0, 2.165063509461097, 8, 5, 3, 5, 3, 5, 3, 2
Query-Efficient Offline Preference-Based Reinforcement Learning via In-Dataset Exploration,4.666666666666667, 5.0, 1.247219128924647, 3, 3, 6, 3, 5, 4
Fast-DetectGPT: Efficient Zero-Shot Detection of Machine-Generated Text via Conditional Probability Curvature,5.8, 6.0, 2.5612496949731396, 8, 4, 6, 4, 8, 4, 6, 3, 1, 5
Defining and extracting generalizable interaction primitives from DNNs,6.0, 5.0, 1.4142135623730951, 8, 4, 5, 2, 5, 4
3D Human Reconstruction in the Wild with Synthetic Data Using Generative Models,3.75, 3.0, 1.299038105676658, 3, 5, 3, 4, 6, 3, 3, 5
Revisiting Deep Audio-Text Retrieval Through the Lens of Transportation,6.666666666666667, 6.0, 0.9428090415820634, 8, 4, 6, 4, 6, 4
Matcher: Segment Anything with One Shot Using All-Purpose Feature Matching,6.0, 5.5, 1.224744871391589, 8, 5, 5, 5, 5, 4, 6, 4
DomainStudio: Fine-Tuning Diffusion Models for Domain-Driven Image Generation using Limited Data,4.5, 4.5, 1.5, 6, 4, 6, 4, 3, 5, 3, 4
Idempotence and Perceptual Image Compression,6.25, 7.0, 2.0463381929681126, 3, 3, 8, 4, 8, 4, 6, 4
Characterizing Robust Overfitting in Adversarial Training via Cross-Class Features,4.0, 4.0, 1.0, 5, 5, 3, 4, 3, 5, 5, 4
Vision-Language Subspace Prompting,4.75, 5.0, 1.0897247358851685, 5, 5, 3, 4, 5, 3, 6, 3
A Logical Framework for Verification of AI Fairness,2.5, 2.0, 1.6583123951777, 5, 4, 3, 2, 1, 4, 1, 2
The Temporal Structure of Language Processing in the Human Brain Corresponds to The Layered Hierarchy of Deep Language Models,6.2, 6.0, 1.8330302779823362, 6, 3, 3, 4, 8, 4, 6, 5, 8, 4
Symmetry Leads to Structured Constraint of Learning,6.0, 5.0, 1.4142135623730951, 5, 3, 8, 2, 5, 3
LayoutNUWA: Revealing the Hidden Layout Expertise of Large Language Models,5.75, 6.0, 0.4330127018922193, 5, 2, 6, 5, 6, 3, 6, 3
Causality-Based Black-Box Backdoor Detection,5.0, 5.5, 1.224744871391589, 6, 3, 6, 4, 5, 3, 3, 4
Analyzing and Mitigating Object Hallucination in Large Vision-Language Models,6.0, 5.5, 1.224744871391589, 5, 3, 8, 3, 6, 4, 5, 4
SEFAR: SparsE-FeAture-based Regularization for Fine-Tuning on Limited Downstream Data,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 3, 3, 4, 3, 4
Hebbian Learning based Orthogonal Projection for Continual Learning of Spiking Neural Networks,5.5, 5.5, 1.8027756377319946, 8, 4, 5, 3, 3, 3, 6, 3
Forward $\chi^2$ Divergence Based Variational Importane Sampling,5.5, 6.5, 2.8722813232690143, 8, 4, 8, 3, 1, 5, 5, 3
SIEVE: Multimodal Dataset Pruning using Image-Captioning Models,4.666666666666667, 3.0, 2.357022603955158, 3, 5, 8, 4, 3, 4
DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models,6.5, 6.5, 1.5, 8, 4, 5, 4, 5, 3, 8, 4
Dataset Distillation in Latent Space,4.25, 4.0, 1.299038105676658, 6, 3, 3, 5, 5, 4, 3, 5
Modeling Knowledge as Functionals for Knowledge Reasoning,5.0, 5.0, 2.280350850198276, 5, 2, 5, 3, 8, 3, 1, 2, 6, 3
PanoDiffusion: 360-degree Panorama Outpainting via Diffusion,6.25, 6.0, 1.0897247358851685, 5, 3, 6, 3, 8, 4, 6, 3
Robust Video Perception by Seeing Motion,4.2, 5.0, 0.9797958971132712, 5, 3, 3, 3, 3, 3, 5, 2, 5, 4
ZeroP: Zero-Shot Quantization via Proxy Data,4.4, 5.0, 1.2, 5, 5, 3, 4, 5, 4, 6, 3, 3, 5
ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation,6.5, 6.0, 0.8660254037844386, 8, 4, 6, 4, 6, 4, 6, 4
IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models,5.6, 6.0, 1.624807680927192, 6, 3, 6, 3, 3, 4, 5, 4, 8, 5
PIE: Simulating Disease Progression via Progressive Image Editing,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 3, 3, 5, 3
Connect Collapse Corrupt: Learning Cross-Modal Tasks with Uni-Modal Data,6.75, 7.0, 1.299038105676658, 5, 4, 8, 4, 8, 3, 6, 3
Keqing: Knowledge-based Question Answering is A Nature Chain-of-Thought mentor of LLMs,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 4, 3, 3, 5, 4
Human Pose Estimation via Parse Graph of Body Structure,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 5, 3, 3, 5
How does representation impact in-context learning: An exploration on a synthetic task,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 3, 5, 2, 5, 3
EFFL: Egalitarian Fairness in Federated Learning for Mitigating Matthew Effect,4.75, 4.0, 2.0463381929681126, 3, 3, 8, 4, 5, 2, 3, 4
Unifying Feature and Cost Aggregation with Transformers for Dense Correspondence,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 6, 3, 5, 4
Dual-level Adaptive Self-Labeling for Novel Class Discovery in Point Cloud Segmentation,5.0, 5.5, 1.224744871391589, 3, 3, 6, 3, 5, 3, 6, 4
Data-independent Module-aware Pruning for Hierarchical Vision Transformers,7.0, 7.0, 1.0, 8, 4, 6, 5
DBRNet: Advancing Individual-Level Continuous Treatment Estimation through Disentangled and Balanced Representation,5.0, 5.0, 1.0954451150103321, 6, 4, 3, 4, 5, 3, 5, 3, 6, 3
LeCO-NeRF: Learning Compact Occupancy for Large-scale Neural Radiance Fields,5.25, 5.0, 1.7853571071357126, 3, 4, 5, 5, 8, 2, 5, 4
Multisize Dataset Condensation,7.5, 8.0, 0.8660254037844386, 8, 5, 8, 4, 8, 4, 6, 3
Implicit Reinforcement Learning Properties in Supervised Transformer-based Object Detection,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 3, 5, 2
A Novel Approach For Adversarial Robustness,2.0, 2.0, 1.0, 3, 4, 1, 4, 3, 4, 1, 5
From Cluster Assumption to Graph Convolution: Graph-based Semi-Supervised Learning Revisited,4.0, 4.0, 1.0, 5, 3, 5, 4, 3, 4, 3, 4
Proactive Learning: Search-augmented learning using Pre-trained Models,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 4, 3, 4
Efficient Offline Preference-Based Reinforcement Learning with Transition-Dependent Discounting,2.5, 3.0, 0.8660254037844386, 1, 4, 3, 4, 3, 4, 3, 4
Backdiff: a diffusion model for generalized transferable protein backmapping,4.5, 4.5, 1.5, 3, 4, 6, 4
DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation,6.5, 6.0, 0.8660254037844386, 8, 4, 6, 3, 6, 5, 6, 4
To Simulate Neural Organoid: A Framework and A Benchmark based on AI,3.0, 3.0, 0.0, 3, 5, 3, 4, 3, 2, 3, 4
Mini-batch Submodular Maximization,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 4, 5, 3
APD: Boosting Adversarial Transferability via Perturbation Dropout,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 4, 5, 3
Why do Features of Multi-Layer Perceptrons Condense in Training?,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 4
Scaling for Training Time and Post-hoc Out-of-distribution Detection Enhancement,6.25, 6.0, 1.0897247358851685, 5, 4, 8, 5, 6, 3, 6, 3
It HAS to be Subjective: Human Annotator Simulation via Zero-shot Density Estimation,5.5, 5.5, 0.5, 5, 2, 6, 1, 6, 4, 5, 4
Benchmarking Large Language Models as AI Research Agents,5.25, 4.0, 2.8613807855648994, 3, 5, 5, 3, 3, 3, 10, 4
Simplifying and Stabilizing Model Selection in Unsupervised Domain Adaptation,4.333333333333333, 5.0, 0.9428090415820634, 3, 4, 5, 4, 5, 4
A Simple and Effective Pruning Approach for Large Language Models,6.25, 6.0, 1.0897247358851685, 6, 4, 6, 4, 5, 4, 8, 4
GeoLLM: Extracting Geospatial Knowledge from Large Language Models,5.4, 5.0, 1.624807680927192, 5, 4, 5, 5, 8, 4, 6, 3, 3, 4
Agent-Centric State Discovery for Finite-Memory POMDPs,3.75, 3.0, 2.947456530637899, 5, 3, 8, 3, 1, 4, 1, 3
Noisy Interpolation Learning with Shallow Univariate ReLU Networks,8.0, 8.0, 0.0, 8, 4, 8, 4, 8, 4
Instant3D: Fast Text-to-3D with Sparse-view Generation and Large Reconstruction Model,7.0, 8.0, 1.4142135623730951, 8, 5, 8, 5, 5, 3
LSPT: Long-term Spatial Prompt Tuning for Visual Representation Learning,4.75, 5.0, 1.0897247358851685, 5, 5, 3, 4, 5, 3, 6, 3
Tree-as-a-Prompt: Boosting Black-Box Large Language Models on Few-Shot Classification of Tabular Data,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 3, 6, 3
Goal2FlowNet: Learning Diverse Policy Covers using GFlowNets for Goal-Conditioned RL,3.0, 3.0, 0.0, 3, 4, 3, 4
Effective and Efficient Federated Tree Learning on Hybrid Data,5.5, 5.5, 1.8027756377319946, 8, 3, 5, 2, 3, 5, 6, 3
Revisiting Few-Shot Object Detection using Vision-Language Models,4.0, 4.0, 1.0, 5, 4, 3, 4, 5, 5, 3, 3
Rethinking Audiovisual Segmentation with Semantic Quantization and Decomposition,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 3
A Coefficient Makes SVRG Effective,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 3, 4, 6, 2
Weight Selection for Model Initialization,5.5, 5.5, 1.8027756377319946, 3, 4, 8, 4, 5, 4, 6, 4
ConvNet vs Transformer Supervised vs CLIP: Beyond ImageNet Accuracy,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 3, 4, 5, 4
Knowledge Distillation Based on Transformed Teacher Matching,5.5, 5.5, 0.5, 6, 5, 5, 4, 5, 3, 6, 2
Image Translation as Diffusion Visual Programmers,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 3, 6, 4, 5, 3
MultiIoT: Towards Large-scale Multisensory Learning for the Internet of Things,3.0, 3.0, 1.632993161855452, 5, 5, 3, 4, 1, 4
Harnessing large-language models to generate private synthetic text,4.75, 5.0, 1.0897247358851685, 3, 5, 6, 4, 5, 3, 5, 4
Reason for Future Act for Now: A Principled Architecture for Autonomous LLM Agents,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 4, 3, 3, 3, 3
Individual Fairness as an Extension of Group Fairness,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4
DMV3D: Denoising Multi-view Diffusion Using 3D Large Reconstruction Model,6.75, 8.0, 2.165063509461097, 8, 5, 8, 4, 3, 4, 8, 5
Active Learning for Image Segmentation with Binary User Feedback,4.75, 5.0, 1.0897247358851685, 5, 3, 6, 4, 5, 5, 3, 3
Influencer Backdoor Attack on Semantic Segmentation,6.0, 5.5, 1.224744871391589, 6, 4, 5, 5, 5, 2, 8, 4
PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction,5.5, 5.5, 1.8027756377319946, 3, 5, 5, 4, 8, 3, 6, 4
LRM: Large Reconstruction Model for Single Image to 3D,7.5, 8.0, 0.8660254037844386, 8, 5, 8, 4, 6, 3, 8, 5
OmniInput: A Model-centric Evaluation Framework through Output Distribution,4.5, 5.0, 0.8660254037844386, 5, 2, 5, 4, 5, 4, 3, 3
Empowering Active Learning for 3D Molecular Graphs with Geometric Graph Isomorphism,5.333333333333333, 5.0, 0.4714045207910317, 5, 2, 6, 4, 5, 4
PAIR Diffusion: A Comprehensive Multimodal Object-Level Image Editor,4.8, 6.0, 1.469693845669907, 6, 3, 6, 4, 6, 4, 3, 5, 3, 5
GPT-FL: Generative Pre-trained Model-Assisted Federated Learning,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 4, 3, 4, 5, 3
NLPBench: Evaluating Large Language Models on Solving NLP Problems,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 3, 6, 4
Synthetic Data as Validation,3.0, 3.0, 1.2649110640673518, 3, 4, 3, 4, 5, 5, 1, 4, 3, 2
How Well Do Supervised Models Transfer to 3D Image Segmentation?,6.2, 6.0, 1.8330302779823362, 6, 3, 8, 3, 3, 5, 6, 4, 8, 3
Completing Visual Objects via Bridging Generation and Segmentation,5.25, 5.0, 0.4330127018922193, 5, 5, 5, 4, 5, 5, 6, 3
Knowledge Storage and Extraction in Language Models (Part A),6.4, 6.0, 1.3564659966250536, 5, 5, 8, 4, 5, 4, 6, 3, 8, 4
ReBotNet: Fast Real-time Video Enhancement,5.0, 5.0, 0.0, 5, 4, 5, 4, 5, 5, 5, 4
Knowledge Manipulation in Language Models (Part B),5.666666666666667, 6.0, 2.0548046676563256, 3, 5, 6, 4, 8, 4
LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models,4.25, 4.0, 1.299038105676658, 3, 5, 3, 5, 6, 4, 5, 4
Procedural Fairness Through Decoupling Objectionable Data Generating Components,4.666666666666667, 5.0, 1.247219128924647, 5, 2, 3, 4, 6, 3
Detecting  Generated Text via Rewriting,6.0, 5.5, 1.224744871391589, 5, 4, 6, 5, 8, 3, 5, 4
LangNav: Language as a Perceptual Representation for Navigation,5.0, 5.0, 1.8973665961010275, 6, 4, 8, 5, 3, 4, 5, 3, 3, 4
Graph as Point Set,5.75, 5.0, 1.299038105676658, 5, 5, 8, 3, 5, 4, 5, 3
FTA: Stealthy and Adaptive Backdoor Attack with Flexible Triggers on Federated Learning,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 5, 4, 6, 3
Proto-CLIP: A Vision-Language Prototype Alignment Approach for Few-Shot Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 5
DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning,5.25, 6.0, 1.299038105676658, 3, 5, 6, 4, 6, 4, 6, 3
Language Models as Black-Box Optimizers for Vision-Language Models,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 4, 3, 5
Revisiting the Role of Language Priors in Vision-Language Models,4.75, 4.0, 2.0463381929681126, 3, 3, 8, 5, 3, 4, 5, 3
Covariance-corrected Whitening Alleviates Network Degeneration on Imbalanced Classification,5.0, 5.5, 1.224744871391589, 5, 4, 6, 4, 6, 4, 3, 4
Lifelong Audio-video Masked Autoencoder with Forget-robust Localized Alignments,4.8, 5.0, 0.9797958971132712, 5, 4, 5, 4, 6, 2, 5, 3, 3, 3
Multi-View Representation is What You Need for Point-Cloud Pre-Training,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 5, 6, 4, 5, 5
Leveraging Temporal Graph Networks Using Module Decoupling,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 5
RefConv: Re-parameterized Refocusing Convolution for Powerful ConvNets,6.0, 5.0, 1.4142135623730951, 8, 4, 5, 5, 5, 5
Key-Graph Transformer for Image Restoration,5.5, 5.5, 0.5, 6, 2, 6, 5, 5, 3, 5, 2
Accelerated Neural Network Training with Rooted Logistic Objectives,3.75, 3.0, 1.299038105676658, 3, 4, 6, 3, 3, 4, 3, 4
SingleInsert: Inserting New Concepts from a Single Image into Text-to-Image Models for Flexible Editing,4.333333333333333, 5.0, 0.9428090415820634, 3, 5, 5, 4, 5, 4
VDT: General-purpose Video Diffusion Transformers via Mask Modeling,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 4
EVEREST: Efficient Masked Video Autoencoder by Removing Redundant Spatiotemporal Tokens,5.333333333333333, 5.0, 2.0548046676563256, 5, 5, 8, 4, 3, 4
RelationVLM: Making Large Vision-Language Models Understand Visual Relations,5.0, 5.0, 1.0, 6, 5, 5, 3, 3, 4, 5, 4, 5, 3, 6, 3
Rare Event Probability Learning by Normalizing Flows,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 3, 4, 5, 3
TransCues: Boundary and Reflection-empowered Pyramid Vision Transformer for Semantic Transparent Object Segmentation,5.333333333333333, 5.0, 0.4714045207910317, 5, 5, 6, 5, 5, 4
Learning Identifiable Causal Structures with Pairwise Representation,4.25, 4.0, 1.299038105676658, 5, 2, 6, 4, 3, 3, 3, 3
Non-negative Probabilistic Factorization,4.75, 4.0, 2.0463381929681126, 3, 4, 8, 4, 3, 4, 5, 3
Diverse Offline Imitation Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 3, 5, 3
Stress Testing Byzantine Robustness in Distributed Learning,4.5, 5.0, 1.118033988749895, 3, 4, 6, 3, 5, 5, 5, 3, 3, 4, 5, 3
Sparsity-Aware Grouped Reinforcement Learning for Designated Driver Dispatch,4.75, 5.0, 1.0897247358851685, 6, 4, 3, 4, 5, 4, 5, 3
Vision-Language Foundation Models as Effective Robot Imitators,6.25, 6.0, 1.0897247358851685, 6, 4, 5, 4, 6, 4, 8, 4
A Generalized Convolutional Neural Network for Small Dataset Classification,3.75, 4.0, 1.920286436967152, 3, 3, 1, 4, 6, 3, 5, 2
InsertNeRF: Instilling Generalizability into NeRF with HyperNet Modules,6.666666666666667, 5.0, 2.357022603955158, 10, 4, 5, 3, 5, 3
Augmenting transformers with recursively composed multi-grained representations,5.5, 5.5, 0.5, 5, 4, 5, 4, 6, 4, 6, 3
MOESR: MULTI-OBJECTIVE EVOLUTIONARY ALGORITHM FOR IMAGE SUPER-RESOLUTION,3.6666666666666665, 5.0, 1.8856180831641267, 5, 5, 1, 4, 5, 3
Evolving Neural Network's Weights at Imagenet Scale,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 5
P2RBOX:A SINGLE POINT IS ALL YOU NEED TRAINING ORIENTED OBJECT DETECTOR,4.666666666666667, 4.0, 1.8856180831641267, 6, 4, 3, 5, 8, 4, 5, 4, 3, 5, 3, 3
P2Seg: Pointly-supervised Segmentation via Mutual Distillation,5.4, 5.0, 1.624807680927192, 3, 4, 5, 4, 6, 3, 8, 5, 5, 4
Bound and Average: Leveraging Weights as Knowledge for Class Incremental Learning,3.5, 3.0, 0.8660254037844386, 3, 5, 5, 5, 3, 5, 3, 3
Knowledge Fusion by Evolving Language Models,4.25, 4.0, 1.299038105676658, 3, 4, 5, 5, 3, 5, 6, 4
Flatness-aware Adversarial Attack,5.333333333333333, 5.0, 2.0548046676563256, 3, 5, 5, 4, 8, 4
Towards Architecture-Insensitive Untrained Network Priors for Accelerated MRI,5.0, 5.5, 1.224744871391589, 6, 5, 3, 4, 6, 4, 5, 3
A Light-robust Reconstruction Method for Spike Camera,6.0, 5.5, 1.224744871391589, 5, 4, 8, 3, 6, 3, 5, 4
TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting,5.333333333333333, 5.0, 2.0548046676563256, 3, 3, 8, 3, 5, 4
Continuous-Multiple Image Outpainting in One-Step via Positional Query and A Diffusion-based Approach,6.333333333333333, 6.0, 1.247219128924647, 5, 5, 6, 4, 8, 4
Decoupled Diffusion Models: Image to Zero and Zero to Noise,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 3, 5, 4, 3, 4
ComSD: Balancing Behavioral Quality and Diversity in Unsupervised Skill Discovery,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 3, 5, 4
Can pre-trained models assist in dataset distillation?,4.75, 5.0, 1.0897247358851685, 5, 2, 5, 5, 3, 4, 6, 4
Better Imitation Learning in Discounted Linear MDP,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 3, 3, 4, 5, 4
Learning Pseudo 3D Representation for Ego-centric 2D Multiple Object Tracking,5.0, 5.5, 2.5495097567963922, 8, 4, 6, 4, 1, 5, 5, 5
Delta-LoRA: Fine-Tuning High-Rank Parameters with the Delta of Low-Rank Matrices,4.5, 4.5, 1.5, 6, 3, 3, 3, 6, 4, 3, 5
Text-Driven Image Editing using Cycle-Consistency-Driven Metric Learning,4.25, 4.0, 1.299038105676658, 5, 4, 6, 5, 3, 4, 3, 4
On the Embedding Collapse When Scaling up Recommendation Models,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 4, 5, 3, 3, 4
Revisiting High-Resolution ODEs for Faster Convergence Rates,3.75, 3.0, 2.5860201081971503, 3, 4, 8, 2, 1, 5, 3, 4
Harnessing Attention Prior for Reference-based Multi-view Image Synthesis,3.75, 3.0, 1.299038105676658, 6, 3, 3, 5, 3, 1, 3, 4
SELF: Language-Driven Self-Evolution for Large Language Model,4.666666666666667, 5.0, 1.247219128924647, 5, 2, 3, 5, 6, 4
When Semantic Segmentation Meets Frequency Aliasing,5.333333333333333, 5.0, 0.4714045207910317, 5, 5, 5, 4, 6, 4
ChatSearch: a Dataset and a Generative Retrieval Model for General Conversational Image Retrieval,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 3, 5, 4, 6, 3
Efficient Sharpness-Aware Minimization for Molecular Graph Transformer Models,6.0, 6.0, 0.0, 6, 4, 6, 5, 6, 3, 6, 4
α-Rank: Unified Item-Fair Ranking from A Cooperative Game Theory View,4.25, 4.0, 1.299038105676658, 3, 4, 6, 3, 3, 4, 5, 2
Language as Kernels,3.5, 4.0, 1.6583123951777, 5, 4, 5, 1, 1, 4, 3, 4
Unleashing the Power of Annotation: Enhancing Semi-Supervised Learning through Unsupervised Sample Selection,4.0, 4.0, 1.0, 3, 3, 3, 5, 5, 3, 5, 4
HUB: Enhancing Learned Optimizers via Hybrid Update-based Strategy,4.333333333333333, 5.0, 0.9428090415820634, 5, 2, 3, 4, 5, 4
Distance Estimation for High-Dimensional Distributions,5.5, 5.5, 1.8027756377319946, 5, 3, 3, 3, 6, 4, 8, 4
MuDreamer: Learning Predictive World Models without Reconstruction,4.333333333333333, 5.0, 0.9428090415820634, 3, 5, 5, 3, 5, 4
Toward Open-ended Embodied Tasks Solving,4.5, 4.5, 1.5, 3, 2, 6, 4, 6, 3, 3, 4
UOEP: User-Oriented Exploration Policy for Enhancing Long-Term User Experiences in Recommender Systems,5.333333333333333, 5.0, 2.0548046676563256, 3, 4, 8, 3, 5, 3
Beyond Demographic Parity: Redefining Equal Treatment,4.75, 4.0, 2.0463381929681126, 3, 3, 8, 3, 5, 3, 3, 4
Towards Bringing Advanced Restoration Networks into Self-Supervised Image Denoising,4.0, 4.0, 1.0, 5, 3, 3, 4, 3, 5, 5, 5
Wide Neural Network Training Dynamics for Reinforcement Learning,2.5, 3.0, 0.8660254037844386, 3, 4, 1, 4, 3, 3, 3, 4
MVSFormer++: Revealing the Devil in the Transformer's Details for Multi-View Stereo,6.0, 6.0, 1.0954451150103321, 6, 5, 5, 3, 5, 2, 8, 3, 6, 4
Subgraph Diffusion for 3D Molecular Representation Learning: Combining Continuous and Discrete,4.5, 4.5, 1.5, 6, 4, 6, 3, 3, 4, 3, 5
OctoPack: Instruction Tuning Code Large Language Models,7.333333333333333, 8.0, 0.9428090415820634, 8, 4, 8, 5, 6, 3
PROSPECT: Learn MLPs Robust against Graph Adversarial Structure Attacks,4.0, 4.0, 1.0, 5, 4, 3, 4, 5, 3, 3, 4
Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision,6.666666666666667, 6.0, 0.9428090415820634, 6, 4, 8, 5, 6, 5
iTransformer: Inverted Transformers Are Effective for Time Series Forecasting,7.0, 7.0, 1.0, 8, 4, 8, 4, 6, 3, 6, 4
A Generative Pre-Training Framework for Spatio-Temporal Graph Transfer Learning,5.75, 6.0, 1.7853571071357126, 8, 4, 3, 4, 6, 5, 6, 5
A Effective Variance Change Detection Method under constantly Changing Mean,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 3
NeuManifold: Neural Watertight Manifold Reconstruction with Efficient and High-Quality Rendering Support,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 4, 3, 4, 5, 4
Rethinking Independent Cross-Entropy Loss For Graph-Structured Data,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 6, 3, 3, 3
De novo Protein Design Using Geometric Vector Field Networks,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 5, 5, 4
Rep-Adapter: Parameter-free Automatic Adaptation of Pre-trained ConvNets via Re-parameterization,5.666666666666667, 6.0, 2.0548046676563256, 3, 5, 8, 5, 6, 4
Molecular Conformation Generation via Shifting Scores,4.0, 4.0, 1.0, 3, 4, 5, 4, 5, 4, 3, 3
HelmSim: Learning Helmholtz Dynamics for Interpretable Fluid Simulation,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 3, 3, 5, 5
Theoretical Understanding of Learning from Adversarial Perturbations,5.5, 5.5, 0.5, 6, 4, 5, 3, 6, 3, 5, 3
Graph Lottery Ticket Automated,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 5, 3, 6, 3
CASR: Refining Action Segmentation via marginalizing frame-level causal relationships,3.25, 3.0, 1.7853571071357126, 3, 3, 6, 3, 3, 3, 1, 3
Prompt Gradient Projection for Continual Learning,5.0, 6.0, 1.4142135623730951, 3, 3, 6, 4, 6, 5
Multimodal Representation Learning by Alternating Unimodal Adaptation,4.6, 5.0, 0.7999999999999999, 5, 4, 5, 4, 5, 3, 5, 4, 3, 4
Harmony World Models: Boosting Sample Efficiency for Model-based Reinforcement Learning,4.75, 5.0, 1.0897247358851685, 5, 4, 6, 4, 3, 3, 5, 3
Elucidating the Solution Space of Extended Reverse-Time SDE for Diffusion Models,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 6, 4, 5, 3
Decoupled Kullback-Leibler Divergence Loss,4.0, 4.0, 1.0, 5, 4, 5, 2, 3, 4, 3, 4
FreeNoise: Tuning-Free Longer Video Diffusion via Noise Rescheduling,5.75, 6.0, 0.4330127018922193, 6, 4, 5, 4, 6, 4, 6, 4
Inner Classifier-Free Guidance and Its Taylor Expansion for Diffusion Models,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 6, 3, 3, 3
Diversity Plausibility and Difficulty: Dynamic Data-Free Quantization,4.0, 4.0, 1.0, 5, 5, 3, 5, 3, 5, 5, 5
Rotative Factorization Machines,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 5, 5, 5, 3, 2
RoDyn-SLAM: Robust Dynamic Dense RGB-D SLAM with Neural Radiance Fields,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 5, 4, 8, 3
Rethinking Adversarial Training with Neural Tangent Kernel,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 3, 3, 3, 3, 3
Towards the Vulnerability of Watermarking Artificial Intelligence Generated Content,4.0, 4.0, 1.0, 3, 4, 3, 4, 5, 3, 5, 4
ADDP: Learning General Representations for Image Recognition and Generation with Alternating Denoising Diffusion Process,5.75, 6.0, 0.4330127018922193, 6, 3, 5, 3, 6, 2, 6, 4
Omnipotent Adversarial Training in the Wild,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 4
Alleviating the Effect of Data Imbalance on Adversarial Training,4.75, 5.0, 1.0897247358851685, 5, 2, 6, 3, 3, 4, 5, 3
CAT: Collaborative Adversarial Training,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 2, 5, 4, 5, 4
SqueezeLLM: Dense and Sparse Quantization,5.75, 5.0, 1.299038105676658, 8, 4, 5, 4, 5, 4, 5, 3
R-EDL: Relaxing Nonessential Settings of Evidential Deep Learning,6.6, 6.0, 1.2, 5, 3, 6, 3, 8, 5, 8, 4, 6, 4
Scaling Sentence Embeddings with Large Language Models,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 5, 3, 6, 5
Graph Learning with Distributional Edge Layouts,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 6, 2, 3, 5
Visualizing the Emergence of Primitive Interactions During the Training of DNNs,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 3, 3, 4
Zero-shot Inversion Process for Image Attribute Editing with Diffusion Models,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 5, 3, 4
Mastering Symbolic Operations: Augmenting Language Models with Compiled Neural Networks,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 5, 3, 6, 4
State-drive Implicit Modeling,4.25, 4.0, 1.299038105676658, 3, 3, 3, 3, 6, 2, 5, 3
Generating Less Certain Adversarial Examples Improves Robust Generalization,4.2, 5.0, 0.9797958971132712, 5, 4, 5, 3, 5, 4, 3, 4, 3, 4
LMUFormer: Low Complexity Yet Powerful Spiking Model With Legendre Memory Units,5.75, 6.0, 1.7853571071357126, 6, 2, 6, 2, 8, 2, 3, 4
Weakly-supervised Camera Localization by Ground-to-satellite Image Registration,5.0, 6.0, 1.4142135623730951, 6, 4, 6, 4, 3, 5
InterpGNN: Understand and Improve Generalization Ability of Transdutive GNNs through the Lens of Interplay between Train and Test Nodes,5.4, 5.0, 0.4898979485566356, 5, 3, 6, 3, 5, 4, 5, 3, 6, 3
UniSeMi: Toward Unified Semi-supervised Medical Image Segmentation,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 5, 5, 4, 5, 4
Unpaired Panoramic Image-to-Image Translation Leveraging Pinhole Images,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 2, 3, 4, 5, 5
STanHop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction,6.0, 5.5, 1.224744871391589, 5, 3, 6, 4, 5, 2, 8, 4
On the Evaluation of Generative Models in Distributed Learning Tasks,4.666666666666667, 5.0, 1.247219128924647, 6, 4, 5, 3, 3, 3
Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization,5.5, 5.5, 1.8027756377319946, 3, 4, 8, 3, 5, 3, 6, 3
Optimal Noise Pursuit for Augmenting Text-to-Video Generation,4.5, 5.0, 0.8660254037844386, 3, 5, 5, 3, 5, 3, 5, 5
SSL Framework for Causal Inconsistency between Structures and Representations,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 5, 4, 3, 3
From CLIP to DINO: Visual Encoders Shout in Multi-modal Large Language Models,3.75, 3.0, 1.299038105676658, 3, 5, 3, 5, 3, 3, 6, 4
ResFields: Residual Neural Fields for Spatiotemporal Signals,6.666666666666667, 6.0, 0.9428090415820634, 6, 4, 8, 4, 6, 4
TRACE: A Comprehensive Benchmark for Continual Learning in Large Language Models,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 3, 3, 5, 5, 4
Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images,6.0, 5.0, 1.4142135623730951, 5, 4, 5, 4, 8, 3
DeNAV: Decentralized Self-Supervised Learning with a Training Navigator,3.0, 3.0, 0.0, 3, 4, 3, 4
AMMD: Attentive Maximum Mean Discrepancy for Few-Shot Image Classification,4.5, 5.0, 0.8660254037844386, 5, 5, 3, 5, 5, 5, 5, 4
Progressive Fourier Neural Representation for Sequential Video Compilation,6.0, 5.5, 1.224744871391589, 5, 3, 6, 4, 5, 4, 8, 4
LAMDA: Unified Language-Driven Multi-Task Domain Adaption,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 3, 5, 3
SegGen: Supercharging Segmentation Models with Text2Mask and Mask2Img Synthesis,6.0, 5.5, 1.224744871391589, 6, 4, 8, 5, 5, 3, 5, 4
Towards the Universal Learning Principle for Graph Neural Networks,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 4
SpikeCLIP: A Contrastive Language-Image Pretrained Spiking Neural Network,4.25, 4.0, 1.299038105676658, 3, 4, 3, 5, 6, 5, 5, 5
TD-MPC2: Scalable Robust World Models for Continuous Control,7.0, 7.0, 1.0, 8, 5, 6, 5, 6, 3, 8, 4
LIRE: Listwise Reward Enhancement for Preference Alignment,5.2, 5.0, 0.39999999999999997, 5, 3, 6, 3, 5, 3, 5, 4, 5, 3
Adaptive deep spiking neural network with global-local learning via balanced excitatory and inhibitory mechanism,5.5, 5.5, 1.8027756377319946, 3, 5, 6, 5, 8, 5, 5, 3
Newton Losses: Using Curvature Information for Learning with Differentiable Algorithms,5.5, 5.5, 0.5, 6, 3, 5, 5, 6, 4, 5, 3
DySTreSS: Dynamically Scaled Temperature in Self-Supervised Contrastive Learning,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 5, 3, 4, 5, 4
Realistic Human Motion Generation with Cross-Diffusion Models,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 6, 3, 5, 5
A unified theory of scene representation learning and object representation learning,3.0, 3.0, 0.0, 3, 3, 3, 3, 3, 5, 3, 4
Simple Yet Effective Spatio-Temporal Prompt Learning,4.5, 5.0, 0.8660254037844386, 3, 5, 5, 5, 5, 2, 5, 2
UniPAD: A Universal Pre-training Paradigm for Autonomous Driving,5.5, 5.5, 0.5, 6, 5, 6, 3, 5, 3, 5, 4
Diffusion Posterior Sampling for Linear Inverse Problem Solving: A Filtering Perspective,6.0, 5.5, 2.5495097567963922, 10, 4, 5, 4, 6, 4, 3, 5
Stochastic Controlled Averaging for Federated Learning with Communication Compression,6.666666666666667, 6.0, 0.9428090415820634, 6, 4, 8, 3, 6, 2
Overcoming Data and Model heterogeneities in Decentralized Federated Learning via Synthetic Anchors,4.8, 6.0, 1.469693845669907, 3, 5, 6, 3, 3, 4, 6, 4, 6, 3
How connectivity structure shapes rich and lazy learning in neural circuits,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 6, 4, 5, 3
Federated Virtual Learning on Heterogeneous Data with Local-global Distillation,5.0, 5.0, 0.0, 5, 2, 5, 4
An LLM can Fool Itself: A Prompt-Based Adversarial Attack,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 6, 5, 5, 3
AutoLoRa: A Parameter-Free Automated Robust Fine-Tuning Framework,5.5, 5.5, 0.5, 5, 4, 6, 4, 6, 4, 5, 3
Collaborative World Models: An Online-Offline Transfer RL Approach,4.2, 5.0, 0.9797958971132712, 5, 4, 3, 2, 3, 2, 5, 4, 5, 2
AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning,7.0, 7.0, 1.0, 6, 3, 8, 5, 8, 4, 6, 4
Denoising Diffusion Step-aware Models,5.5, 5.5, 1.8027756377319946, 8, 4, 3, 5, 5, 4, 6, 3
Learning Rate Re-scheduling for AdaGrad in training Deep Neural Networks,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 3
Code Representation Pre-training  with Complements from Program Executions,4.75, 5.0, 1.0897247358851685, 3, 5, 6, 4, 5, 4, 5, 4
Get more for less: Principled Data Selection for Warming Up Fine-Tuning in LLMs,5.5, 5.5, 1.8027756377319946, 8, 4, 5, 3, 3, 4, 6, 3
Towards efficient deep spiking neural networks construction with spiking activity based pruning,4.0, 4.0, 1.0, 3, 4, 5, 5, 3, 4, 5, 4
Action Shapley: A training data selection metric for high performance and cost efficient reinforcement learning,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 5, 3, 5
Matrix Information Theory for Self-Supervised Learning,5.5, 5.5, 1.8027756377319946, 3, 5, 6, 4, 5, 4, 8, 3
RelationMatch: Matching In-batch Relationships for Semi-supervised Learning,5.25, 5.0, 1.7853571071357126, 8, 3, 3, 5, 5, 4, 5, 3
Taming Encoder for Zero Fine-tuning Image Customization with Text-to-Image Diffusion Models,5.25, 5.0, 0.4330127018922193, 5, 3, 5, 4, 6, 3, 5, 4
On Accelerating Diffusion-based Molecular Conformation Generation in SE(3)-invariant Space,3.6666666666666665, 3.0, 0.9428090415820634, 5, 4, 3, 4, 3, 4
Cumulative Reasoning with Large Language Models,5.5, 5.5, 0.5, 6, 4, 5, 4, 5, 4, 6, 3
Progressive Fusion for Multimodal Integration,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 3, 5, 4, 5, 5
A/B testing under Identity Fragmentation,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 1, 3, 4, 5, 4
Exploring the Impact of Information Entropy Change in Learning Systems,5.333333333333333, 5.0, 2.0548046676563256, 3, 5, 8, 3, 5, 3
Pseudo-Calibration: Improving Predictive Uncertainty Estimation in Domain Adaptation,5.0, 5.5, 1.224744871391589, 5, 4, 3, 3, 6, 4, 6, 4
3D Reconstruction with Generalizable Neural Fields using Scene Priors,5.4, 5.0, 0.4898979485566356, 6, 4, 5, 3, 5, 4, 5, 5, 6, 4
Causal Structure Recovery with Latent Variables under Milder Distributional and Graphical Assumptions,5.5, 5.5, 1.8027756377319946, 3, 3, 6, 2, 8, 3, 5, 3
Contrastive Diffuser: Planning Towards High Return States via Contrastive Learning,5.25, 4.0, 2.8613807855648994, 5, 3, 3, 3, 3, 5, 10, 3
Adv3D: Generating 3D Adversarial Examples for 3D Object Detection in Driving Scenarios with NeRF,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 4, 3, 4, 5, 4
SSIF: Learning Continuous Image Representation for Spatial-Spectral Super-Resolution,4.25, 4.0, 1.299038105676658, 6, 5, 3, 4, 5, 3, 3, 5
AutoVP: An Automated Visual Prompting Framework and Benchmark,4.75, 5.0, 1.0897247358851685, 5, 5, 3, 3, 5, 4, 6, 4
Revisiting the Lottery Ticket Hypothesis for Pre-trained Networks,4.0, 4.0, 1.0, 5, 3, 3, 4, 3, 5, 5, 4
Robustness May be More Brittle than We Think under Different Degrees of Distribution Shifts,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 4, 5, 5, 3, 4
Dolfin: Diffusion Layout Transformers without Autoencoder,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 5, 4, 3, 4
Score Propagation as a Catalyst for Graph Out-of-distribution Detection: A Theoretical and Empirical Study,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 5, 5, 6, 3
MMBench: Is Your Multi-modal Model an All-around Player?,5.0, 5.5, 1.224744871391589, 5, 3, 3, 4, 6, 4, 6, 3
Warped Convolutional Neural Networks For Large Homography Transformation with $\mathfrak{sl}(3)$ Algebra,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 5, 4, 8, 4
Selective Mixup Helps with Distribution Shifts But Not (Only) because of Mixup,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 5, 4, 6, 3
Text-driven Editing of 3D Scenes without Retraining,4.0, 5.0, 1.7320508075688772, 5, 4, 5, 4, 1, 3, 5, 2
SPOT: Scalable 3D Pre-training via Occupancy Prediction for Autonomous Driving,4.0, 3.0, 1.4142135623730951, 6, 5, 3, 4, 3, 4
Structured Video-Language Modeling with Temporal Grouping and Spatial Grounding,6.25, 6.0, 1.0897247358851685, 5, 5, 6, 4, 6, 5, 8, 4
Gate-guided and subgraph-aware Bilateral Fusion for Molecular Property Prediction,3.0, 3.0, 1.4142135623730951, 5, 4, 3, 5, 1, 5, 3, 5
Diffusion Denoising as a Certified Defense Against Clean-Label Poisoning Attacks,3.0, 3.0, 0.0, 3, 4, 3, 5, 3, 4, 3, 3
Composing Recurrent Spiking Neural Networks using Locally-Recurrent Motifs and Risk-Mitigating Architectural Optimization,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 5, 3, 6, 4
Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View,7.333333333333333, 8.0, 0.9428090415820634, 8, 4, 8, 4, 6, 4
WizardCoder: Empowering Code Large Language Models with Evol-Instruct,6.0, 5.5, 1.224744871391589, 8, 4, 5, 4, 5, 5, 6, 4
Generalizing Denoising to Non-Equilibrium Structures Improves Equivariant Force Fields,5.8, 5.0, 1.16619037896906, 8, 2, 6, 3, 5, 4, 5, 4, 5, 4
Guiding Instruction-based Image Editing via Multimodal Large Language Models,7.0, 7.0, 1.0, 8, 4, 8, 4, 6, 3, 6, 3
CryoFormer: Continuous Heterogeneous Cryo-EM Reconstruction using Transformer-based Neural Representations,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 5, 5, 3, 6, 2
Clean-NeRF:  Defogging using Ray Statistics Prior in Natural NeRFs,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4, 3, 4
Deep Neural Room Acoustics Primitive,4.25, 4.0, 1.299038105676658, 5, 3, 3, 5, 3, 3, 6, 5
Deceptive-NeRF: Enhancing NeRF Reconstruction using Pseudo-Observations from Diffusion Models,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 2, 5, 3
Order-Preserving GFlowNets,6.0, 6.0, 1.0954451150103321, 5, 4, 6, 3, 8, 4, 6, 3, 5, 4
Hyperbolic Active Learning for Semantic Segmentation under Domain Shift,5.0, 5.0, 0.0, 5, 4, 5, 3
VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs,5.4, 5.0, 0.48989794855663565, 5, 4, 6, 4, 6, 4, 5, 4, 5, 3
Efficacy of Dual-Encoders for Extreme Multi-label Classification,5.5, 5.5, 0.5, 6, 3, 5, 3, 5, 2, 6, 3
Winograd Structured Pruning,4.5, 4.5, 1.5, 3, 4, 6, 4, 6, 3, 3, 4
Tuning LayerNorm in Attention: Towards Efficient Multi-Modal LLM Finetuning,7.0, 7.0, 1.0, 6, 4, 6, 3, 8, 2, 8, 4
DiffiT: Diffusion Vision Transformers for Image Generation,5.0, 5.0, 0.0, 5, 5, 5, 4, 5, 5, 5, 5
Class-Context-Aware Phantom Uncertainty Modeling,4.0, 4.0, 1.0, 5, 3, 3, 4, 3, 4, 5, 3
Elevating Augmentation: Boosting Performance via Sub-Model Training,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 4, 6, 4
FasterViT: Fast Vision Transformers with Hierarchical Attention,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 4, 5, 5, 6, 4
Video Generation Beyond a Single Clip,4.75, 5.0, 1.0897247358851685, 6, 4, 5, 4, 5, 5, 3, 5
ViR: Vision Retention Networks,3.5, 3.0, 0.8660254037844386, 5, 4, 3, 5, 3, 4, 3, 2
Aligner: One Global Token is Worth Millions of Parameters When Aligning LLMs,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 4, 5, 3
Long-Term Impacts of Model Retraining with Strategic Feedback,4.0, 4.0, 1.0, 5, 3, 3, 4, 5, 4, 3, 4
Deep Metric Tensor Regularized Policy Gradient,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 1, 3, 4
Universal Humanoid Motion Representations for Physics-Based Control,7.333333333333333, 8.0, 0.9428090415820634, 8, 4, 8, 2, 6, 3
AutoCast++: Enhancing World Event Prediction with Zero-shot Ranking-based Context Retrieval,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 3, 5, 4
Emerging Semantic Segmentation from Positive and Negative Coarse Label Learning,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 4, 5, 4, 5, 4
Feature Collapse,5.5, 5.5, 0.5, 5, 3, 6, 3, 6, 3, 5, 2
Interleaving Multi-Task Neural Architecture Search,4.0, 3.0, 1.4142135623730951, 3, 4, 3, 4, 6, 3
Unleashing the Creative Mind: Language Model As Hierarchical Policy For Improved Exploration on Challenging Problem Solving,4.75, 5.0, 1.0897247358851685, 6, 3, 5, 4, 5, 3, 3, 4
Timesteps meet Bits: Low-Latency Accurate & Energy-Efficient Spiking Neural Networks with ANN-to-SNN Conversion,4.25, 4.0, 1.299038105676658, 5, 5, 3, 5, 3, 4, 6, 2
Adaptive Rational Activations to Boost Deep Reinforcement Learning,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 3, 6, 4, 5, 4
MOESART: An Effective Sampling-based Router for Sparse Mixture of Experts,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 3, 5, 4, 6, 2
Learning No-Regret Sparse Generalized Linear Models with Varying Observation(s),6.0, 5.0, 1.4142135623730951, 5, 3, 5, 3, 8, 2
Large-Scale Public Data Improves Differentially Private Image Generation Quality,5.25, 5.0, 0.4330127018922193, 6, 5, 5, 4, 5, 2, 5, 4
Revealing Hidden Causal Variables and Latent Factors from Multiple Distributions,3.5, 3.0, 0.8660254037844386, 3, 3, 5, 4, 3, 3, 3, 2
SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks,3.75, 4.0, 1.920286436967152, 6, 2, 5, 5, 3, 5, 1, 4
LLMs Represent Contextual Tasks as Compact Function Vectors,5.5, 5.5, 0.5, 6, 3, 6, 2, 5, 3, 5, 4
Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 3, 6, 4
Perceptual Group Tokenizer: Building Perception with Iterative Grouping,5.4, 5.0, 1.624807680927192, 5, 5, 6, 4, 3, 4, 5, 3, 8, 4
Vision-Language Dataset Distillation,5.5, 5.5, 0.5, 5, 5, 6, 2, 5, 5, 6, 4
EcoAssistant: Using LLM Assistant More Affordably and Accurately,5.0, 5.0, 0.0, 5, 2, 5, 4
ImageNet-OOD: Deciphering Modern Out-of-Distribution Detection Algorithms,5.5, 5.5, 0.5, 6, 5, 5, 3, 6, 3, 5, 4
Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game,6.333333333333333, 6.0, 1.247219128924647, 8, 2, 5, 3, 6, 3
Self-supervised Representation Learning from Random Data Projectors,5.8, 5.0, 1.16619037896906, 5, 4, 5, 5, 6, 2, 8, 4, 5, 3
Approximately Piecewise E(3) Equivariant Point Networks,6.333333333333333, 6.0, 1.247219128924647, 5, 2, 8, 3, 6, 3
Choosing Public Datasets for Private Machine Learning via Gradient Subspace Distance,4.5, 4.5, 1.5, 3, 3, 6, 3, 6, 3, 3, 4
Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency,6.75, 7.0, 1.299038105676658, 8, 3, 5, 4, 6, 3, 8, 4
Adversarially Robust Deep Learning with Optimal-Transport-Regularized Divergences,5.0, 5.5, 1.224744871391589, 3, 4, 6, 3, 5, 4, 6, 4
CODA: Temporal Domain Generalization via Concept Drift Simulator,5.0, 5.5, 1.224744871391589, 5, 3, 6, 3, 6, 4, 3, 5
A Comprehensive Study of Privacy Risks in Curriculum Learning,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 6, 4, 5, 4
PrACTiS: Perceiver-Attentional Copulas for Time Series,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 2, 3, 4, 5, 2
DAM: A Foundation Model for Forecasting,5.5, 5.5, 0.5, 5, 4, 6, 4, 5, 4, 6, 4
SELECTFORMER: PRIVATE AND PRACTICAL DATA SELECTION FOR TRANSFORMERS,5.4, 5.0, 1.624807680927192, 8, 2, 5, 3, 5, 4, 6, 3, 3, 3
Mode-Aware Continual Learning for Conditional Generative Adversarial Networks,4.0, 4.0, 1.0, 3, 5, 5, 4, 5, 5, 3, 4
Mining Patents with Large Language Models Demonstrates Congruence of Functional Labels and Chemical Structures,5.5, 5.5, 1.8027756377319946, 3, 4, 8, 4, 6, 3, 5, 4
Welfare Diplomacy: Benchmarking Language Model Cooperation,6.333333333333333, 6.0, 1.247219128924647, 6, 3, 5, 4, 8, 4
Impact of Agent Behavior in Distributed SGD and Federated Learning,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 3, 6, 3
DISPEL: Domain Generalization via Domain-Specific Liberating,4.25, 4.0, 1.299038105676658, 3, 5, 5, 3, 3, 4, 6, 4
Weakly-supervised Audio Separation via Bi-modal Semantic Similarity,6.0, 5.0, 1.4142135623730951, 8, 3, 5, 5, 5, 4
Improving Language Models via Plug-and-Play Retrieval Feedback,5.0, 5.5, 1.224744871391589, 5, 5, 3, 4, 6, 4, 6, 5
Expected flow networks in stochastic environments and two-player zero-sum games,5.25, 5.0, 1.7853571071357126, 5, 3, 3, 5, 8, 3, 5, 4
Neural Polynomial Gabor Fields for Macro Motion Analysis,5.5, 5.5, 0.5, 5, 2, 6, 4, 6, 2, 5, 4
Denoising Diffusion via Image-Based Rendering,5.5, 5.5, 0.5, 5, 5, 5, 3, 6, 3, 6, 4
Masked Diffusion as Self-supervised Representation Learner,4.25, 4.0, 1.299038105676658, 6, 4, 5, 3, 3, 3, 3, 4
Statistically Optimal $K$-means Clustering via Nonnegative Low-rank Semidefinite Programming,6.75, 8.0, 2.165063509461097, 8, 2, 3, 4, 8, 4, 8, 3
The Map Equation goes Neural,2.3333333333333335, 3.0, 0.9428090415820634, 3, 5, 1, 4, 3, 4
Generalized Neural Collapse for a Large Number of Classes,6.5, 6.0, 0.8660254037844386, 6, 3, 8, 5, 6, 4, 6, 3
Co-learning synaptic delays weights and adaptation in spiking neural networks,3.5, 3.0, 0.8660254037844386, 5, 5, 3, 4, 3, 5, 3, 4
What Images are More Memorable to Machines?,3.25, 3.0, 1.7853571071357126, 1, 4, 3, 4, 6, 4, 3, 4
Mask and Restore: Blind Backdoor Defense at Test Time with Masked Autoencoder,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 3
LEAP: Liberate Sparse-View 3D Modeling from Camera Poses,6.6, 6.0, 1.7435595774162693, 6, 4, 10, 4, 5, 4, 6, 5, 6, 5
Limits to Reservoir Learning,3.3333333333333335, 3.0, 2.0548046676563256, 3, 2, 6, 3, 1, 4
Learning the greatest common divisor: explaining transformer predictions,5.75, 5.0, 1.299038105676658, 5, 4, 5, 4, 8, 4, 5, 4
Reliable Test-Time Adaptation via Agreement-on-the-Line,5.5, 5.5, 0.5, 5, 4, 6, 4, 5, 4, 6, 3
DynamicBEV: Leveraging Dynamic Queries and Temporal Context for 3D Object Detection,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 3, 5, 4, 5, 4
Q-Tuning: Continual Queue-based Prompt Tuning for Language Models,5.0, 5.0, 0.0, 5, 5, 5, 5, 5, 4, 5, 4
Programmatic Evaluation of Rule-Following Behavior,4.75, 5.0, 1.0897247358851685, 5, 2, 6, 4, 5, 4, 3, 5
Sequential Data Generation with Groupwise Diffusion Process,4.666666666666667, 5.0, 1.247219128924647, 5, 4, 3, 4, 6, 4
SAIF: Sparse Adversarial and Imperceptible Attack Framework,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 3, 5, 5, 4
SPFQ: A Stochastic Algorithm and Its Error Analysis for Neural Network Quantization,4.25, 4.0, 1.299038105676658, 3, 3, 6, 3, 3, 3, 5, 4
CResT: Cross-Query Residual Transformer for Object Goal Navigation,3.0, 3.0, 0.0, 3, 5, 3, 5, 3, 4, 3, 5
Dynamic Adapter Merging for Continual Video Question-Answering Learning,5.25, 5.0, 0.4330127018922193, 5, 5, 6, 4, 5, 4, 5, 3
Learning Embodied Vision-Language Programming From Instruction Exploration and Environmental Feedback,4.0, 4.0, 1.0, 5, 4, 3, 5, 5, 4, 3, 4
Generative Reinforcement Learning with Transformers,4.0, 3.0, 1.2649110640673518, 3, 4, 3, 4, 5, 4, 6, 3, 3, 3
Language Modeling Is Compression,5.75, 6.0, 0.4330127018922193, 6, 4, 6, 3, 6, 3, 5, 3
TiG-BEV: Multi-view BEV 3D Object Detection via Target Inner-Geometry Learning,5.0, 5.0, 1.8973665961010275, 3, 5, 3, 4, 5, 4, 6, 3, 8, 4
Planning with an Ensemble of World Models,4.25, 3.0, 2.165063509461097, 3, 3, 3, 3, 3, 3, 8, 3
OpenNerf: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views,5.75, 5.0, 1.299038105676658, 5, 3, 5, 4, 8, 5, 5, 4
Learning with a Mole: Transferable latent spatial representations for navigation without reconstruction,6.333333333333333, 6.0, 1.247219128924647, 6, 4, 8, 4, 5, 3
3D-GPT: Procedural 3D Modeling with Large Language Models,4.25, 4.0, 1.299038105676658, 3, 4, 3, 4, 6, 3, 5, 4
SCoRe: Submodular Combinatorial Representation Learning for Real-World Class-Imbalanced Settings,5.0, 5.0, 0.0, 5, 3, 5, 3, 5, 4
Reverse Forward Curriculum Learning for Extreme Sample and Demo Efficiency,6.0, 5.0, 1.4142135623730951, 5, 3, 8, 4, 5, 4
BatchPrompt: Accomplish more with less,6.0, 5.5, 1.224744871391589, 6, 4, 8, 3, 5, 4, 5, 4
Large Language Models as Optimizers,5.5, 5.5, 1.8027756377319946, 6, 4, 8, 4, 5, 4, 3, 4
ContextRef: Evaluating Referenceless Metrics for Image Description Generation,6.0, 6.0, 0.0, 6, 3, 6, 3, 6, 1
Tractable Probabilistic Graph Representation Learning with Graph-Induced Sum-Product Networks,5.666666666666667, 6.0, 0.4714045207910317, 6, 2, 6, 3, 5, 3
Domain Bridge: Generative Model-based Domain Forensic for Black-box Models,4.4, 5.0, 1.2, 6, 3, 5, 3, 3, 4, 5, 2, 3, 4
Diffusion Model-Augmented Behavioral Cloning,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 4, 3, 5
HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion,6.75, 6.0, 1.920286436967152, 5, 3, 6, 4, 6, 4, 10, 3
ZeroFlow: Scalable Scene Flow via Distillation,6.0, 5.0, 1.4142135623730951, 5, 2, 5, 4, 8, 4
One-Versus-Others Attention: Scalable Multimodal Integration,4.666666666666667, 5.0, 1.247219128924647, 6, 3, 3, 5, 5, 4
DIVA: A Dirichlet Process Mixtures Based Incremental Deep Clustering Algorithm via Variational Auto-Encoder,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 3, 4, 5, 3
Continual Learners are Viable Long-Tailed Recognizers,4.5, 5.0, 0.8660254037844386, 3, 3, 5, 4, 5, 4, 5, 4
R&B: Region and Boundary Aware Zero-shot Grounded Text-to-image Generation,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 4, 5, 4, 6, 4
Space and time continuous physics simulation from partial observations,7.0, 8.0, 1.2649110640673518, 8, 3, 5, 3, 8, 3, 6, 2, 8, 4
Temporal Causal Mechanism Transfer for Few-shot Action Recognition,5.25, 5.0, 0.4330127018922193, 6, 4, 5, 3, 5, 2, 5, 3
Energy-Based Concept Bottleneck Models,5.0, 5.0, 1.0954451150103321, 6, 4, 3, 4, 6, 5, 5, 4, 5, 4
Amicable Perturbations,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 4, 5, 3, 5, 3
SpeechTokenizer: Unified Speech Tokenizer for Speech Language Models,5.25, 5.0, 1.7853571071357126, 5, 4, 5, 3, 3, 4, 8, 4
Boosting Efficiency in Task-Agnostic Exploration Through Causal Knowledge,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 5, 5, 3, 3, 4
Enhancing High-Resolution 3D Generation through Pixel-wise Gradient Clipping,5.0, 6.0, 1.4142135623730951, 6, 4, 3, 4, 6, 2
GROOT: Learning to Follow Instructions by Watching Gameplay Videos,6.25, 7.0, 2.0463381929681126, 8, 5, 6, 3, 3, 3, 8, 4
Translating Labels to Solve Annotation Mismatches Across Object Detection Datasets,5.0, 6.0, 1.4142135623730951, 3, 3, 6, 4, 6, 4
Variational Learning of  Gaussian Process Latent Variable Models  through  Stochastic Gradient Annealed Importance Sampling,5.75, 5.0, 1.299038105676658, 5, 4, 5, 3, 5, 3, 8, 3
Tailoring Retrieval Representations to Long-term Visual Localization,6.333333333333333, 6.0, 1.247219128924647, 8, 3, 5, 5, 6, 3
DreamClean: Restoring Clean Image Using Deep Diffusion Prior,7.0, 7.0, 1.0, 8, 3, 6, 4, 8, 5, 6, 5
Clearer Frames Anytime: Resolving Velocity Ambiguity in Video Frame Interpolation,5.75, 6.0, 1.7853571071357126, 6, 2, 6, 5, 8, 4, 3, 4
One-shot Federated Learning with Training-Free Client,4.2, 5.0, 0.9797958971132712, 3, 4, 5, 4, 3, 4, 5, 2, 5, 4
CausalLM is not optimal for in-context learning,6.25, 6.0, 1.0897247358851685, 8, 4, 5, 3, 6, 3, 6, 4
End-to-End (Instance)-Image Goal Navigation through Correspondence as an Emergent Phenomenon,7.0, 7.0, 1.0, 8, 5, 6, 4, 6, 5, 8, 4
Strategic Preys Make Acute Predators: Enhancing Camouflaged Object Detectors by Generating Camouflaged Objects,6.5, 6.5, 1.5, 8, 5, 5, 1, 5, 2, 8, 4
Consistency-guided Prompt Learning for Vision-Language Models,5.0, 5.5, 1.224744871391589, 6, 5, 5, 4, 3, 5, 6, 5
FMLock: Preventing Unauthorized Use of Large Foundation Models,4.6, 3.0, 2.0591260281974, 6, 3, 8, 3, 3, 4, 3, 4, 3, 5
From Trojan Horses To Castle Walls: Revealing Bilateral Backdoor Effects In Diffision Models,5.0, 5.5, 1.224744871391589, 3, 4, 6, 3, 5, 4, 6, 4
Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting,6.666666666666667, 6.0, 0.9428090415820634, 6, 3, 6, 4, 8, 5
Language-Informed Visual Concept Learning,5.25, 5.0, 0.4330127018922193, 6, 3, 5, 5, 5, 4, 5, 3
Out-of-Distribution Detection & Applications With Ablated Learned Temperature Energy,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 4, 5, 4, 3, 3
Online Continual Learning for Interactive Instruction Following Agents,5.5, 5.5, 0.5, 5, 2, 5, 4, 6, 4, 6, 3
Cluster-Learngene: Inheriting Adaptive Clusters for Self-Attention,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 3, 3, 5, 2
Can Adversarial Examples Be Parsed to Reveal Victim Model Information?,4.4, 5.0, 1.2, 3, 4, 5, 4, 6, 2, 5, 4, 3, 3
Deep Stochastic Mechanics,6.75, 7.0, 1.299038105676658, 5, 4, 8, 3, 8, 3, 6, 4
Towards Text-guided 3D Scene Composition,5.0, 5.5, 1.224744871391589, 3, 3, 6, 3, 6, 4, 5, 4
Detect Every Thing with Few Examples,5.5, 5.5, 0.5, 5, 5, 6, 4, 5, 4, 6, 4
Addressing Long-Horizon Tasks by Integrating Program Synthesis and State Machines,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 3, 5, 5, 5, 3
Localizing and Editing Knowledge In Text-to-Image Generative Models,6.5, 6.5, 1.5, 8, 3, 5, 3, 8, 4, 5, 4
A Unified View on Neural Message Passing with Opinion Dynamics for Social Networks,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 3, 2, 5, 4
Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization,5.333333333333333, 5.0, 0.4714045207910317, 5, 3, 5, 4, 6, 3
Towards domain-invariant Self-Supervised Learning with Batch Styles Standardization,5.0, 5.0, 1.0954451150103321, 6, 4, 5, 3, 3, 5, 5, 4, 6, 2
CTRL: Graph condensation via crafting rational trajectory matching,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 4, 6, 3, 5, 3
LaneSegNet: Map Learning with Lane Segment Perception for Autonomous Driving,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 5, 3, 6, 3
DRMGuard: Defending Deep Regression Models against Backdoor Attacks,4.666666666666667, 3.0, 2.357022603955158, 3, 4, 3, 5, 8, 4
Spike-driven Transformer V2: Meta Spiking Neural Network Architecture Inspiring the Design of Next-generation Neuromorphic Chips,5.666666666666667, 6.0, 0.4714045207910317, 5, 4, 6, 4, 6, 3
Unseen Image Synthesis with Diffusion Models,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 6, 4, 5, 4
BrainSCUBA: Fine-Grained Natural Language Captions of Visual Cortex Selectivity,6.0, 6.5, 2.1213203435596424, 8, 4, 5, 3, 8, 4, 3, 3
Representing part-whole hierarchy with coordinated synchrony in neural networks,4.25, 4.0, 1.299038105676658, 3, 4, 5, 3, 3, 3, 6, 3
Solving (partial) unbalanced optimal transport via transform coefficients and beyond,2.6, 3.0, 0.8, 3, 4, 3, 4, 1, 4, 3, 4, 3, 4
Hard View Selection for Contrastive Learning,5.25, 5.0, 1.7853571071357126, 8, 3, 5, 4, 3, 4, 5, 5
GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion,6.25, 6.0, 1.0897247358851685, 5, 4, 6, 2, 8, 4, 6, 3
Get What You Want Not What You Don't: Image Content Suppression for Text-to-Image Diffusion Models,5.75, 6.0, 0.4330127018922193, 5, 4, 6, 3, 6, 5, 6, 4
Self-Supervised Detection of Perfect and Partial Input-Dependent Symmetries,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 3, 2, 5, 4
Unprocessing Seven Years of Algorithmic Fairness,6.25, 6.0, 1.0897247358851685, 6, 3, 6, 5, 8, 3, 5, 4
Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge Distillation,6.0, 5.5, 1.224744871391589, 6, 4, 8, 5, 5, 4, 5, 4
Unraveling the Enigma of Double Descent: An In-depth Analysis through the Lens of Learned Feature Space,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 5, 3, 3, 5, 2
Guided Sketch-Based Program Induction by Search Gradients,2.5, 3.0, 0.8660254037844386, 1, 5, 3, 3, 3, 4, 3, 4
Specializing SAM: Online Adaptation of the Segment Anything Model for Interactive Segmentation in Uncommon Situations,2.5, 2.0, 1.6583123951777, 1, 5, 1, 4, 3, 4, 5, 3
Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation,5.4, 5.0, 1.624807680927192, 5, 4, 3, 2, 6, 4, 8, 4, 5, 4
Modeling Time Series as Text Sequence A Frequency-vectorization Transformer for Time Series Forecasting,4.4, 5.0, 1.2, 5, 4, 6, 5, 3, 4, 3, 4, 5, 4
MM-LDM: Multi-Modal Latent Diffusion Model for Sounding Video Generation,5.75, 5.0, 1.299038105676658, 5, 4, 5, 5, 8, 5, 5, 4
StableSSM: Alleviating the Curse of Memory in State-space Models through Stable Reparameterization,4.666666666666667, 5.0, 1.247219128924647, 5, 2, 6, 3, 3, 3
Meta-Evolve: Continuous Robot Evolution for One-to-many Policy Transfer,6.0, 5.5, 1.224744871391589, 5, 4, 6, 4, 8, 3, 5, 5
Think Before You Act: Decision Transformers with Internal Memory,5.0, 5.5, 1.224744871391589, 5, 4, 3, 4, 6, 4, 6, 3
A Wasserstein-2 Distance for Efficient Reconstruction of Stochastic Differential Equations,4.8, 5.0, 0.9797958971132712, 3, 2, 5, 3, 6, 1, 5, 4, 5, 4
Implicit NNs are Almost Equivalent to Not-so-deep Explicit NNs for High-dimensional Gaussian Mixtures,5.0, 4.5, 2.1213203435596424, 8, 2, 3, 2, 3, 3, 6, 3
Towards Robust Training via Gradient-diversified Backpropagation,3.75, 3.0, 1.299038105676658, 3, 4, 3, 4, 6, 2, 3, 4
DFormer: Rethinking RGBD Representation Learning for Semantic Segmentation,4.666666666666667, 5.0, 1.247219128924647, 5, 5, 6, 5, 3, 5
SignAvatars: A Large-scale 3D Sign Language Holistic Motion Dataset and Benchmark,5.75, 6.0, 1.7853571071357126, 8, 4, 3, 5, 6, 2, 6, 5
DeCUR: decoupling common & unique representations for multimodal self-supervision,5.25, 5.0, 1.7853571071357126, 5, 4, 3, 4, 5, 3, 8, 4
Encoding Expert Knowledge into Federated Learning using Weak Supervision,5.333333333333333, 5.0, 0.4714045207910317, 6, 4, 5, 3, 5, 4
ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving,6.75, 7.0, 1.299038105676658, 6, 3, 5, 5, 8, 3, 8, 5
Contrastive losses as generalized models of global epistasis,4.5, 4.5, 1.5, 3, 4, 6, 3, 6, 2, 3, 4
Self-Paced Augmentations (SPAug) for Improving Model Robustness,4.5, 5.0, 0.8660254037844386, 5, 3, 3, 4, 5, 4, 5, 4
Bayesian Bi-clustering of Neural Spiking Activity with Latent Structures,5.666666666666667, 6.0, 0.4714045207910317, 6, 3, 5, 5, 6, 4
GRANDE: Gradient-Based Decision Tree Ensembles,6.25, 6.0, 1.0897247358851685, 5, 5, 8, 4, 6, 4, 6, 3
GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers,6.25, 6.0, 1.0897247358851685, 6, 4, 5, 3, 6, 3, 8, 3
Generalization error bounds for iterative learning algorithms with bounded updates,3.75, 3.0, 1.299038105676658, 3, 4, 6, 4, 3, 3, 3, 5
Independently-prepared Query-efficient Model Selection,4.666666666666667, 3.0, 2.357022603955158, 3, 4, 8, 5, 3, 5
Zero-Shot Video Sampling from Image,4.25, 4.0, 1.299038105676658, 5, 3, 6, 4, 3, 4, 3, 5
Boosting Unsupervised Contrastive Learning Using Diffusion-Based Data Augmentation From Scratch,4.0, 4.0, 1.0, 3, 4, 5, 4, 3, 4, 5, 5
Boosting Backdoor Attack with A Learnable Poisoning Sample Selection Strategy,5.5, 5.5, 0.5, 5, 3, 5, 4, 6, 4, 6, 4
VDC: Versatile Data Cleanser for Detecting Dirty Samples via Visual-Linguistic Inconsistency,5.0, 6.0, 1.4142135623730951, 3, 5, 6, 4, 6, 3
InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning,6.0, 5.5, 1.224744871391589, 6, 4, 5, 4, 5, 4, 8, 4
EC-Conf: An Ultra-fast Diffusion Model for Molecular Conformation Generation with Equivariant Consistency,nan, nan, nan
Implicit Semi-auto-regressive Image-to-Video Diffusion,4.5, 5.0, 0.8660254037844386, 5, 4, 3, 5, 5, 4, 5, 3
Brain2Music: Reconstructing Music from Human Brain Activity,4.666666666666667, 3.0, 2.357022603955158, 3, 5, 3, 4, 8, 3
Towards Lossless Dataset Distillation via Difficulty-Aligned Trajectory Matching,6.5, 6.0, 0.8660254037844386, 8, 4, 6, 3, 6, 4, 6, 3
αMax-B-CUBED: A Supervised Metric for Addressing Completeness and Uncertainty in Cluster Evaluation,4.75, 4.0, 2.0463381929681126, 3, 5, 5, 4, 3, 4, 8, 2
Neural Network Diffusion,4.0, 3.0, 1.4142135623730951, 3, 3, 3, 4, 6, 3
When Why and How Much? Adaptive Learning Rate Scheduling by Refinement,5.8, 5.0, 1.16619037896906, 5, 3, 6, 2, 5, 4, 5, 3, 8, 4
IW-GAE: Importance weighted group accuracy estimation for improved calibration and model selection in unsupervised domain adaptation,4.25, 4.0, 1.299038105676658, 3, 3, 6, 2, 5, 3, 3, 4
SYMBOL: Generating Flexible Black-Box Optimizers through Symbolic Equation Learning,6.5, 6.0, 0.8660254037844386, 8, 2, 6, 3, 6, 1, 6, 3
Provably Efficient Learning in Partially Observable Contextual Bandit,4.25, 4.0, 1.299038105676658, 5, 3, 3, 3, 6, 2, 3, 3
Provable Convergence of Clipped Normalized-gradient Heavy-Ball Momentum for Adversarial Attacks,4.5, 5.0, 0.8660254037844386, 3, 3, 5, 3, 5, 2, 5, 3
Doubly Robust Structure Identification from Temporal Data,4.8, 6.0, 1.469693845669907, 3, 3, 3, 3, 6, 2, 6, 3, 6, 3
SEA: Sparse Linear Attention with Estimated Attention Mask,5.0, 6.0, 1.4142135623730951, 6, 3, 3, 2, 6, 3
On the Importance of Backbone to the Adversarial Robustness of Object Detectors,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 5, 5, 3, 5
ReweightOOD: Loss Reweighting for Distance-based OOD Detection,4.0, 3.0, 1.2649110640673518, 3, 4, 3, 4, 3, 5, 5, 4, 6, 4
Zero-Mean Regularized Spectral Contrastive Learning,6.0, 6.0, 0.0, 6, 3, 6, 3, 6, 5
Contraction and Alienation: Towards Theoretical Understanding of Non-Contrastive Learning with Neighbor-Averaging Dynamics,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 6, 2, 5, 4
Variance-enlarged Poisson Learning for Graph-based Semi-Supervised Learning with Extremely Sparse Labeled Data,5.5, 5.5, 0.5, 5, 4, 5, 4, 6, 3, 6, 3
MoDA: Mixture of Domain Adapters for Parameter-efficient Generalizable Person Re-Identification,3.8, 3.0, 0.9797958971132712, 3, 5, 5, 4, 3, 5, 5, 5, 3, 4
Mask-based modeling for Neural Radiance Fields,6.571428571428571, 6.0, 0.9035079029052513, 8, 4, 6, 4, 6, 4, 8, 4, 6, 4, 6, 4, 6, 4
Neural Manifold Operators for Learning the Evolution of Physical Dynamics,4.2, 3.0, 2.4819347291981715, 8, 2, 3, 3, 6, 3, 3, 3, 1, 5
Angle-optimized Text Embeddings,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 5, 3, 6, 3
Turbulent Flow Simulation using Autoregressive Conditional Diffusion Models,5.0, 5.0, 0.0, 5, 5, 5, 4, 5, 5, 5, 3
Large Language Models Are Not Robust Multiple Choice Selectors,6.75, 7.0, 1.299038105676658, 5, 4, 6, 3, 8, 2, 8, 4
Linear diffusion models meet contextual bandits with large action spaces,4.8, 6.0, 1.9390719429665317, 1, 4, 6, 4, 6, 3, 5, 4, 6, 4
Enhancing Contrastive Learning for Ordinal Regression via  Ordinal Content Preserved Data Augmentation,4.8, 5.0, 0.9797958971132712, 3, 4, 5, 2, 5, 3, 6, 4, 5, 4
Accelerated Policy Gradient: On the Nesterov Momentum for Reinforcement Learning,4.75, 5.0, 1.0897247358851685, 3, 3, 5, 3, 6, 4, 5, 3
Self-Distilled Disentanglement for Counterfactual Prediction,5.0, 4.5, 2.1213203435596424, 6, 3, 8, 5, 3, 3, 3, 2
Beyond Size: How Gradients Shape Pruning Decisions in Large Language Models,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 5, 3, 4, 5, 4
SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning,5.0, 5.5, 1.224744871391589, 6, 4, 3, 4, 6, 4, 5, 4
Robust prediction under missingness shifts,5.0, 5.5, 1.224744871391589, 6, 5, 6, 3, 3, 4, 5, 3
Communication-Efficient Federated Learning via Gradient Distillation,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 5
Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula,6.0, 6.0, 0.0, 6, 4, 6, 4, 6, 4, 6, 3
Dataset Distillation in Large Data Era,5.5, 5.5, 0.5, 6, 4, 5, 5, 5, 2, 6, 5
Continual Learning via Winning Subnetworks That Arise Through Stochastic Local Competition,5.0, 5.5, 1.224744871391589, 6, 3, 6, 3, 5, 4, 3, 3
OmniControl: Control Any Joint at Any Time for Human Motion Generation,5.75, 6.0, 1.7853571071357126, 6, 4, 3, 5, 6, 4, 8, 3
Fine-tuning Multimodal LLMs to Follow Zero-shot Demonstrative Instructions,6.75, 7.0, 1.299038105676658, 5, 4, 6, 5, 8, 4, 8, 4
Med-Tuning: Parameter-Efficient Transfer Learning with Fine-Grained Feature Enhancement for Medical Volumetric Segmentation,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 6, 4, 3, 3
RetinexGAN Enables More Robust Low-Light Image Enhancement Via Retinex Decomposition Based Unsupervised Illumination Brightening,2.5, 3.0, 0.8660254037844386, 3, 4, 3, 5, 1, 5, 3, 5
Learning Epipolar Feature Fields for Multi-Image Super-Resolution,6.5, 6.5, 2.692582403567252, 5, 5, 3, 5, 8, 5, 10, 4
Towards Faster and Stronger Deep Earth Mover's Distance for Few-Shot Learning,5.666666666666667, 6.0, 0.4714045207910317, 6, 4, 5, 4, 6, 4
Guaranteed Approximation Bounds for Mixed-Precision Neural Operators,6.75, 7.0, 1.299038105676658, 6, 3, 8, 3, 5, 4, 8, 4
TreeDQN: Learning to minimize Branch-and-Bound tree,4.25, 4.0, 1.299038105676658, 6, 3, 3, 4, 3, 3, 5, 3
LINK PREDICTION USING NEUMANN EIGENVALUES,4.0, 4.0, 1.0, 5, 3, 5, 3, 3, 4, 3, 5
AbnormalLog: A Deep Anomaly Detection Method for Log Sequence Data,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 4, 5, 4
Geometry-Aware Projective Mapping for Unbounded Neural Radiance Fields,5.0, 5.5, 1.224744871391589, 3, 3, 6, 5, 6, 2, 5, 4
Multi-Instance Learning Based Anomaly Detection Method for Sequence Data with Application to the Credit Card Delinquency Risk Control,4.25, 4.0, 1.299038105676658, 3, 4, 5, 5, 6, 5, 3, 3
REValueD: Regularised Ensemble Value-Decomposition for Factorisable Markov Decision Processes,5.0, 6.0, 1.4142135623730951, 6, 4, 6, 3, 3, 4
Towards Well-distributed Generative Networks Using Adversarial Autoencoders,3.0, 3.0, 0.0, 3, 4, 3, 4, 3, 4, 3, 4
A Conservative Image Boundary Extraction Method with Application to the ILM Tumor Surgery,2.3333333333333335, 3.0, 0.9428090415820634, 3, 4, 1, 4, 3, 4
ChEF: A Comprehensive Evaluation Framework for Standardized Assessment of Multimodal Large Language Models,5.75, 6.0, 1.7853571071357126, 6, 4, 6, 5, 8, 4, 3, 3
LeRaC: Learning Rate Curriculum,4.75, 5.0, 1.0897247358851685, 6, 2, 5, 3, 3, 4, 5, 3
Exploring Unified Perspective For Fast Shapley Value Estimation,5.5, 5.5, 2.5, 3, 4, 8, 4
Path Choice Matters for Clear Attributions in Path Methods,6.666666666666667, 6.0, 0.9428090415820634, 8, 3, 6, 3, 6, 3
Matrix and Tensor Completion with Noise via Low-rank Deconvolution,3.3333333333333335, 3.0, 2.0548046676563256, 1, 4, 6, 3, 3, 3
CLAP: Collaborative Adaptation for Checkerboard Learning,6.75, 7.0, 1.299038105676658, 6, 4, 8, 4, 8, 5, 5, 2
PROSAC: Provably Safe Certification for Machine Learning Models under Adversarial Attacks,3.5, 3.0, 0.8660254037844386, 5, 3, 3, 4, 3, 2, 3, 3
Collaboration! Towards Robust Neural Methods for Vehicle Routing Problems,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 3, 5, 3, 6, 3
Exploring Target Representations for Masked Autoencoders,5.25, 6.0, 1.299038105676658, 6, 5, 6, 3, 6, 4, 3, 4
Koopman-based generalization bound: New aspect for full-rank weights,6.333333333333333, 6.0, 1.247219128924647, 6, 3, 8, 4, 5, 3
The Pitfalls and Promise of Conformal Inference Under Adversarial Attacks,4.0, 3.0, 1.4142135623730951, 6, 3, 3, 4, 3, 3
Towards Energy Efficient Spiking Neural Networks: An Unstructured Pruning Framework,5.5, 5.5, 1.8027756377319946, 6, 5, 3, 3, 8, 5, 5, 4
Masked Autoencoders Are Robust Neural Architecture Search Learners,4.0, 4.0, 1.0, 5, 4, 3, 5, 3, 4, 5, 3
Online Stabilization of Spiking Neural Networks,6.0, 5.5, 1.224744871391589, 5, 5, 6, 5, 8, 4, 5, 4
Parameter-Efficient Long-Tailed Recognition,5.5, 5.5, 0.5, 6, 4, 5, 4, 6, 5, 5, 5
OpenMixup: A Comprehensive Mixup Benchmark for Visual Classification,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 5, 5, 5, 6, 4
Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis,6.0, 5.5, 1.224744871391589, 8, 4, 5, 3, 6, 4, 5, 3
Fast Learning in Balanced Deep Spiking Neural Networks with Strong and Weak Synapses,4.5, 4.5, 2.692582403567252, 1, 5, 3, 4, 6, 4, 8, 4
SITTO: Single-Image Textured Mesh Reconstruction through Test-Time Optimization,2.3333333333333335, 3.0, 0.9428090415820634, 3, 5, 3, 5, 1, 5
MagicDrive: Street View Generation with Diverse 3D Geometry Control,6.0, 5.5, 1.224744871391589, 6, 2, 8, 4, 5, 4, 5, 4
Geom-Erasing: Geometry-Driven Removal of Implicit Concept in Diffusion Models,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 3, 5, 4, 3, 2
MogaNet: Multi-order Gated Aggregation Network,5.5, 5.5, 0.5, 5, 5, 6, 5, 6, 4, 5, 4
Test like you Train in Implicit Deep Learning,4.666666666666667, 5.0, 1.247219128924647, 5, 3, 6, 2, 3, 3
Continuous Multi-step Predictions of Highly Imbalanced Multivariate Time Series via Deep Learning Network,3.25, 3.0, 1.7853571071357126, 3, 4, 1, 4, 6, 4, 3, 3
What Does Stable Diffusion Know about the 3D Scene?,4.5, 5.0, 0.8660254037844386, 5, 4, 5, 3, 3, 4, 5, 3
Boosting Discriminative Visual Representation Learning with Scenario-Agnostic Mixup,4.75, 5.0, 1.0897247358851685, 6, 4, 3, 2, 5, 4, 5, 3
GeoDiffusion: Text-Prompted Geometric Control for Object Detection Data Generation,5.5, 5.5, 0.5, 5, 4, 6, 4, 5, 4, 6, 4
Pure Message Passing Can Estimate Common Neighbor for Link Prediction,5.75, 5.0, 1.299038105676658, 8, 4, 5, 4, 5, 4, 5, 5
Motion Flow Matching for Efficient Human Motion Synthesis and Editing,4.333333333333333, 5.0, 0.9428090415820634, 5, 3, 3, 4, 5, 2
Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal Correlation,6.0, 6.0, 0.0, 6, 3, 6, 3, 6, 3, 6, 3
HarmonyLM: Advancing Unified Large-Scale Language Modeling for Sound and Music Generation,1.6666666666666667, 1.0, 0.9428090415820634, 3, 4, 1, 5, 1, 4
MULTISCALE ATTENTION VIA WAVELET NEURAL OPERATORS FOR VISION TRANSFORMER,4.2, 3.0, 1.469693845669907, 3, 4, 3, 4, 6, 3, 3, 4, 6, 4
Understanding deep neural networks through the lens of their non-linearity,5.0, 5.0, 0.0, 5, 4, 5, 3, 5, 4, 5, 2
Constraint-Free Structure Learning with Smooth Acyclic Orientations,5.0, 5.0, 1.0954451150103321, 5, 3, 3, 5, 6, 4, 6, 3, 5, 3
RepCodec: A Speech Representation Codec for Speech Tokenization,5.0, 5.5, 1.224744871391589, 6, 3, 3, 3, 5, 3, 6, 4
Pareto Deep Long-Tailed Recognition: A Conflict-Averse Solution,5.333333333333333, 5.0, 0.4714045207910317, 5, 4, 6, 4, 5, 5
KITS: Inductive Spatio-Temporal Kriging with Increment Training Strategy,5.5, 5.5, 0.5, 5, 4, 6, 3
SheAttack: A Silhouette Score Motivated Restricted Black-Box Attack on Graphs,4.75, 5.0, 1.0897247358851685, 3, 4, 5, 5, 6, 4, 5, 3
Multiple Positive Views in Self-Supervised Learning,5.333333333333333, 5.0, 0.4714045207910317, 6, 3, 5, 4, 5, 3
BRIDGING THE GAP BETWEEN HUMAN MOTION AND ACTION SEMANTICS VIA KINEMATIC PHRASES,4.75, 5.0, 1.0897247358851685, 6, 4, 3, 3, 5, 4, 5, 2
MixSup: Mixed-grained Supervision for Label-efficient LiDAR-based 3D Object Detection,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 6, 4, 5, 4
GUC: UNSUPERVISED NON-PARAMETRIC GLOBAL CLUSTERING AND ANOMALY DETECTION,2.3333333333333335, 3.0, 0.9428090415820634, 3, 5, 3, 4, 1, 5
Enhancing Image Restoration Transformer with Adaptive Token Dictionary,4.5, 5.0, 0.8660254037844386, 3, 5, 5, 4, 5, 2, 5, 4
Accelerated Inference and Reduced Forgetting: The Dual Benefits of Early-Exit Networks in Continual Learning,4.0, 3.0, 1.4142135623730951, 6, 4, 3, 4, 3, 4
Knowledge Distillation via Flow Matching,5.333333333333333, 5.0, 0.4714045207910317, 6, 5, 5, 4, 5, 4
PPTSER: A Plug-and-Play Tag-guided Method for Few-shot Semantic Entity Recognition on Visually-rich Documents,5.666666666666667, 6.0, 2.0548046676563256, 3, 4, 8, 4, 6, 3
Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation,3.75, 3.0, 1.299038105676658, 6, 3, 3, 4, 3, 3, 3, 3
Perceptual Metrics for Video Game Playstyle Similarity and Diversity,4.25, 4.0, 1.299038105676658, 5, 4, 3, 4, 6, 2, 3, 3
Boosting Vanilla Lightweight Vision Transformers via Re-parameterization,6.2, 6.0, 1.8330302779823362, 6, 5, 8, 4, 8, 4, 6, 3, 3, 4
Learning Deep Improvement Representation to Accelerate Evolutionary Optimization,3.6666666666666665, 3.0, 0.9428090415820634, 3, 4, 3, 5, 5, 4
Robust Angular Synchronization via Directed Graph Neural Networks,6.0, 5.5, 1.224744871391589, 8, 2, 6, 2, 5, 3, 5, 2
Clover: Closed-Loop Verifiable Code Generation,4.75, 5.0, 1.0897247358851685, 5, 5, 5, 4, 6, 4, 3, 4
Feature selection with neural estimation of mutual information,2.3333333333333335, 3.0, 0.9428090415820634, 1, 5, 3, 4, 3, 4
Unitention: Attend a sample to the dataset,5.25, 5.0, 0.4330127018922193, 5, 5, 6, 5, 5, 3, 5, 4
Efficient Fully Single-Loop Variance Reduced Methods for Stochastic Bilevel Optimization,5.5, 5.5, 0.5, 6, 4, 5, 4, 6, 4, 5, 4
On the Role of Riemannian Metric in Isometric Representation Learning,3.5, 3.0, 0.8660254037844386, 3, 5, 3, 3, 3, 5, 5, 4
GenN2N: Generative NeRF2NeRF Translation,4.4, 5.0, 1.2, 3, 4, 5, 4, 3, 4, 5, 5, 6, 4
Explicit Personalization and Local Training: Double Communication Acceleration in Federated Learning,4.0, 3.0, 1.4142135623730951, 3, 4, 6, 3, 3, 3
Multi-Scale Representations by Varing Window Attention for Semantic Segmentation,5.25, 5.0, 0.4330127018922193, 5, 5, 5, 3, 6, 4, 5, 3
Bounded Loss Robustness: Enhancing the MAE Loss for Large-Scale Noisy Data Learning,5.25, 5.0, 1.7853571071357126, 5, 3, 3, 4, 5, 4, 8, 3
FedP3: Federated Personalized and Privacy-friendly Network Pruning under Model Heterogeneity,5.5, 5.5, 1.8027756377319946, 8, 4, 3, 4, 6, 5, 5, 3
ReBaR: Reference-Based Reasoning for Robust Human Pose and Shape Estimation from Monocular Images,5.4, 5.0, 0.48989794855663565, 6, 5, 5, 5, 6, 4, 5, 5, 5, 5
LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition,4.666666666666667, 5.0, 1.247219128924647, 5, 5, 6, 3, 3, 4
Improving Knowledge Distillation via Regularizing Feature Direction and Norm,5.0, 5.5, 1.224744871391589, 3, 5, 6, 5, 6, 4, 5, 4
How many views does your deep neural network use for prediction?,4.5, 5.0, 0.8660254037844386, 5, 5, 3, 4, 5, 3, 5, 4
AutoAgents: A Framework for Automatic Agent Generation,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 3, 6, 3, 5, 4
Roadside Monocular 3D Detection via 2D-Detection Prompting,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 5, 3, 5, 6, 4
The Power of Linear Combinations: Learning with Random Convolutions,4.5, 4.5, 1.5, 3, 4, 6, 4, 3, 4, 6, 3
Weight-Entanglement Meets Gradient-Based Neural Architecture Search,3.75, 3.0, 1.299038105676658, 3, 5, 3, 2, 6, 5, 3, 4
Long-Tailed 3D Detection via 2D Late Fusion,4.333333333333333, 5.0, 0.9428090415820634, 3, 5, 5, 4, 5, 5
Compressed Context Memory for Online Language Model Interaction,5.25, 6.0, 1.299038105676658, 6, 4, 3, 4, 6, 4, 6, 4
Offline Robustness of Distributional Actor-Critic Ensemble Reinforcement Learning,3.5, 3.0, 0.8660254037844386, 3, 3, 3, 4, 3, 3, 5, 3
TUVF: Learning Generalizable Texture UV Radiance Fields,5.5, 5.5, 0.5, 6, 3, 5, 4, 5, 5, 6, 4
Model Pruning with Model Transfer,4.5, 5.0, 0.8660254037844386, 5, 3, 5, 4, 5, 5, 3, 4
Detection-Oriented Image-Text Pretraining for Open-Vocabulary Detection,4.75, 5.0, 1.0897247358851685, 5, 3, 3, 5, 6, 4, 5, 4
Decoupled Prioritized Resampling: Advancing Offline RL with Improved Behavior Policy,3.5, 4.0, 1.6583123951777, 3, 4, 5, 4, 5, 4, 1, 3
PPT: Token Pruning and Pooling for Efficient Vision Transformers,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 3, 5, 6, 4
Tackling Underestimation Bias in Successor Features by Distributional Reinforcement Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 3, 3, 2, 5, 3
CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping,7.25, 7.0, 1.920286436967152, 6, 5, 5, 5, 8, 4, 10, 4
Neural Processing of Tri-Plane Hybrid Neural Fields,5.5, 5.5, 1.8027756377319946, 3, 5, 8, 4, 6, 4, 5, 4
PICL: Incorporating Coarse-Grained Data and Physics Information for Superior Physical Systems Modeling,3.5, 3.0, 0.8660254037844386, 3, 4, 5, 2, 3, 5, 3, 3
A Simple Unified Uncertainty-Guided Framework for Offline-to-Online Reinforcement Learning,4.0, 4.0, 1.0, 3, 5, 3, 4, 5, 4, 5, 4
Large-Vocabulary 3D Diffusion Model with Transformer,6.0, 6.0, 0.0, 6, 3, 6, 4, 6, 4
SAS: Structured Activation Sparsification,5.333333333333333, 5.0, 0.4714045207910317, 5, 5, 5, 4, 6, 3
Sample-aware RandAugment,4.333333333333333, 5.0, 0.9428090415820634, 5, 4, 5, 4, 3, 3
PROTO: Iterative Policy Regularizied Offline-to-Online Reinforcement Learning,5.75, 6.0, 1.7853571071357126, 8, 4, 3, 4, 6, 4, 6, 2
A Progressive Training Framework for Spiking Neural Networks with Learnable Multi-hierarchical Model,5.75, 5.0, 1.299038105676658, 8, 5, 5, 3, 5, 3, 5, 3
Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis,6.0, 5.5, 1.224744871391589, 5, 5, 6, 4, 5, 3, 8, 3
REVO-LION: Evaluating and Refining Vision-Language Instruction Tuning Datasets,3.5, 3.0, 0.8660254037844386, 3, 3, 5, 4, 3, 5, 3, 3
Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis,6.25, 6.0, 1.0897247358851685, 6, 4, 8, 4, 5, 3, 6, 5
A Symmetry-Aware Exploration of Bayesian Neural Network Posteriors,4.8, 5.0, 1.8330302779823362, 5, 4, 3, 4, 5, 4, 3, 3, 8, 3
AdaRec: Adaptive Sequential Recommendation for Reinforcing Long-term User Engagement,4.666666666666667, 5.0, 1.247219128924647, 3, 4, 5, 3, 6, 3
Modelling brain connectomes networks: Solv is a worthy competitor to hyperbolic geometry!,4.5, 4.5, 1.5, 6, 2, 3, 3, 3, 4, 6, 3
Threaten Spiking Neural Networks through Combining Rate and Temporal Information,6.5, 6.0, 0.8660254037844386, 6, 4, 6, 5, 6, 4, 8, 4
Through the Dual-Prism: A Spectral Perspective on Graph Data Augmentation for Graph Classification,5.5, 5.5, 1.8027756377319946, 3, 4, 5, 3, 6, 4, 8, 4
QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 5, 4, 6, 5
3D-Aware Hypothesis & Verification for Generalizable Relative Object Pose Estimation,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 3, 6, 4, 5, 4
Language Model Self-improvement by Reinforcement Learning Contemplation,5.4, 5.0, 1.624807680927192, 5, 4, 6, 4, 3, 3, 8, 3, 5, 4
GeONet: a neural operator for learning the Wasserstein geodesic,5.0, 5.5, 1.224744871391589, 6, 5, 6, 4, 3, 4, 5, 3
Bridging ML and algorithms: comparison of hyperbolic embeddings,4.25, 4.0, 1.299038105676658, 3, 3, 5, 3, 3, 2, 6, 3
Divide and not forget: Ensemble of  selectively trained experts  in Continual Learning,6.0, 6.5, 2.1213203435596424, 3, 4, 5, 3, 8, 4, 8, 3
Unsupervised Discovery of Object-Centric Neural Fields,6.0, 5.5, 1.224744871391589, 8, 4, 5, 4, 6, 4, 5, 5
Robust Classification via a Single Diffusion Model,6.666666666666667, 6.0, 0.9428090415820634, 8, 3, 6, 4, 6, 4
Based on What We Can Control Artificial Neural Networks,1.6666666666666667, 1.0, 0.9428090415820634, 3, 3, 1, 4, 1, 2
Towards Offline Opponent Modeling with In-context Learning,4.25, 4.0, 1.299038105676658, 3, 3, 5, 4, 6, 4, 3, 3
Multi-granularity Correspondence Learning from Noisy Instructional Videos,7.5, 8.0, 0.8660254037844386, 8, 5, 8, 5, 8, 4, 6, 3
Benchmarking Few-shot Transferability of Pre-trained Models with Improved Evaluation Protocols,4.0, 5.0, 1.7320508075688772, 5, 4, 5, 5, 1, 4, 5, 4
Mastering Pixel-Based Reinforcement Learning via Positive Unlabeled Policy-Guided Contrast,4.0, 5.0, 1.7320508075688772, 1, 4, 5, 4, 5, 2, 5, 3
Lightweight Image Classification Network Based on Feature Extraction Network SimpleResUNet and Attention,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 3, 5, 5, 5
Less is More: On the Feature Redundancy of Pretrained Models When Transferring to Few-shot Tasks,4.25, 4.0, 1.299038105676658, 5, 5, 6, 4, 3, 4, 3, 4
Human-in-the-Loop Test-Time Domain Adaptation for Object Detection,4.0, 4.0, 1.0, 3, 3, 3, 4, 5, 5, 5, 5
Discovering the question-critical moments: Towards building event-aware multi-modal large language models for complex video question answering,4.5, 5.0, 0.8660254037844386, 3, 4, 5, 5, 5, 4, 5, 5
Early Stopping Against Label Noise Without Validation Data,4.75, 5.0, 1.0897247358851685, 5, 4, 5, 4, 3, 4, 6, 4
Recursive Generalization Transformer for Image Super-Resolution,7.5, 8.0, 0.8660254037844386, 8, 4, 8, 5, 6, 5, 8, 5
Rethinking Model Ensemble in Transfer-based Adversarial Attacks,7.0, 7.0, 1.0, 6, 4, 8, 3, 6, 3, 8, 2
Going Further: Flatness at the Rescue of Early Stopping for Adversarial Example Transferability,4.25, 4.0, 1.299038105676658, 3, 4, 6, 4, 3, 5, 5, 4
Challenging the Foundations: Mining Hard Test Samples through Diffusion Generation,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 6, 3, 3, 3
Training Adversarially Robust SNNs with Gradient Sparsity Regularization,5.0, 5.5, 2.5495097567963922, 5, 4, 1, 5, 6, 4, 8, 2
Revisiting Supervision for Continual Representation Learning,3.6666666666666665, 3.0, 0.9428090415820634, 3, 5, 3, 3, 5, 2
RDBench: ML Benchmark for Relational Databases,nan, nan, nan
Langevin Monte Carlo for strongly log-concave distributions: Randomized midpoint revisited,6.5, 6.0, 0.8660254037844386, 6, 2, 6, 4, 8, 3, 6, 3
MuSc : Zero-Shot Anomaly Classification and Segmentation by Mutual Scoring of the Unlabeled Images,5.2, 6.0, 1.16619037896906, 6, 5, 5, 4, 6, 3, 3, 3, 6, 5
Realistic Evaluation of Test-Time Adaptation: Surrogate-Based Model Selection Strategies,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 4, 3, 4, 5, 4
Unveiling Temporal Telltales: Are Unconditional Video Generation Models Implicitly Encoding Temporal Information?,4.4, 5.0, 1.2, 5, 4, 3, 4, 5, 5, 3, 2, 6, 3
A Large-Scale 3D Face Mesh Video Dataset via Neural Re-parameterized Optimization,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 6, 4, 5, 5
To the Cutoff... and Beyond? A Longitudinal Perspective on LLM Data Contamination,5.75, 6.0, 0.4330127018922193, 6, 3, 6, 4, 6, 2, 5, 2
I-PHYRE: Interactive Physical Reasoning,6.25, 6.0, 1.0897247358851685, 5, 4, 6, 3, 8, 4, 6, 4
EXPOSING TEXT-IMAGE INCONSISTENCY USING DIFFUSION MODELS,6.0, 5.5, 1.224744871391589, 6, 3, 5, 4, 5, 3, 8, 3
Video Super-Resolution Transformer with Masked Inter&Intra-Frame Attention,4.25, 4.0, 1.299038105676658, 3, 4, 5, 4, 3, 5, 6, 4
Contrastive Predict-and-Search for Mixed Integer Linear Programs,3.5, 3.0, 0.8660254037844386, 3, 4, 3, 3, 5, 4, 3, 4
Federated Generative Learning with Foundation Models,5.25, 5.0, 0.4330127018922193, 5, 4, 5, 4, 5, 4, 6, 3
